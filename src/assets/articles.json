[
  {
    "cover_image": null,
    "date": "2018-10-28T23:33:50.875Z",
    "description": "A deep dive through a simple Haskell program",
    "tags": "haskell, beginners, programming, tutorial",
    "markdown": "# Some Haskell, English'd\r\n\r\nA TicTacTour Without Honor or Humanity\r\n\r\n## The Intro\r\n\r\nHaskell is just not that bad.  What can be scary is how different it can be to work with than what you're used to so you hit a lot more walls at the very beginning.  This post is a deep dive into a program that would be trivial to write in something imperative with the aim of demystifying how you'd go about framing the problem in an unfamiliar paradigm.\r\n\r\nAs opposed to a traditional tutorial where we build the program step by step this is a top-down, let's see what's here sort of deal. I’m going to start with `main`, the first thing run when you execute the program, and will step through every line of code as it's called and explain what's going on.  Thus, this is more an exercise in reading Haskell than writing it but the two skills are not unrelated and hopefully this can help demystify how to do some simple tasks of your own as well as feel more equipped to approach larger Haskell examples.\r\n\r\n### You\r\n\r\nHaskell-curious.  This is written with a baseline understanding of programming in an imperative language assumed, but zero Haskell or functional programming knowledge.  If you think you could implement this program in your language of choice, you're good to go.  I'm going to cover why things are the way they are as thoroughly as I can.  If you're brand new to programming and the below program *doesn't* look like something you know how to make, you still should be able to follow me through this, albeit with more effort!  There might be a little extra research on your part required here and there.   If you're not new to functional programming but are to Haskell, there may be a few headers you can just skip.\r\n\r\nIn case it wasn't already clear, this is pretty introductory stuff, Haskell-wise.  If you're already well-versed in the basics it might be fun to read just to see what you'd do differently, but this implementation is probably not gonna blow your mind or anything - in fact, I want to see yours!\r\n\r\n### Me\r\n\r\nNot a Haskell programmer.  I partially wrote this to psyche myself up about it again and this particular program was the biggest thing I made in my little bit of time I spent learning it a year and a half ago... you know, in the interest of full disclosure.  I'm no expert in general - reading this old code again and fully explaining it was an educational exercise.  Both writing it the first time and writing this post now taught me a lot about Haskell, so hopefully it can teach some other beginners some stuff about Haskell too!  I think Haskell is really cool and I want more beginners to play with it no matter what other language you're focusing on for the bulk of your work.  This is a non-stuffy but (overly?) thorough way to look at a small program you've probably written before in something more familiar.\r\n\r\nWhile I don't believe I'm off the mark with any of the content here, if any Haskell (or otherwise) programmers notice something egregious please let me know at ben@deciduously.com.\r\n\r\nIf I've totally turned you off from reading on with *that* impressive bio, it's been a pleasure.  Enjoy your day!\r\n\r\nAs for the intrepid remainder, I think this is gonna be a good time.  You're gonna learn at least a thing, maybe two things.  You know, good clean fun.  ¡Vámonos!\r\n\r\n### The Program\r\n\r\nThis is a dirt simple Tic Tac Toe game played on the command line against a computer opponent that just plays randomly. Fun, right? Hours if not days of entertainment await the lucky user. A project like this is usually my go-to \"hello world\" in a new language because at the end it demonstrates you can leverage the language's various facilities at least a little, like control flow and IO. For Haskell it was more a \"TTFN, world\", but the point stands. \r\n\r\nThe full source can be found [here](https://github.com/deciduously/tictactoe-hs/blob/master/src/Main.hs), the entirety of which will appear in snippet-form below.\r\n\r\nIf you'd like to build the code locally you'll need to have `stack` installed.  See the [stack docs](https://docs.haskellstack.org/en/stable/README/) for installation instructions - if you're planning to keep exploring Haskell you'll want this tool.  It will automatically manage your GHC installations and package dependencies.\r\n\r\nOnce you've got that good to go you can open a terminal in the project directory (clone [this repo](https://github.com/deciduously/tictactoe-hs)) and run `stack setup` to install the compiler and dependencies followed by `stack exec ttt` to compile and run the executable or `stack ghci` to open a REPL from which you can interact directly with the functions defined (including `main`).  I recommend the REPL because that way you can also try each individual function on whatever inputs you'd like.  If you tweak `src/Main.hs` you can type `:r` at the prompt to recompile and load the new version (or get yelled at a little, depending how you did).  Use `:q` to quit.\r\n\r\nHere's a sample game, as executed from the REPL:\r\n\r\n```\r\n*Main> main\r\n 1  2  3\r\n 4  5  6\r\n 7  8  9\r\n\r\nYour move: 2\r\nComputer plays 9\r\n 1  X  3\r\n 4  5  6\r\n 7  8  O\r\n\r\nYour move: 1\r\nComputer plays 8\r\n X  X  3\r\n 4  5  6\r\n 7  O  O\r\n\r\nYour move: 6\r\nComputer plays 3\r\n X  X  O\r\n 4  5  X\r\n 7  O  O\r\n\r\nYour move: 37\r\nOnly one digit allowed!\r\n X  X  O\r\n 4  5  X\r\n 7  O  O\r\n\r\nYour move: 4\r\nComputer plays 5\r\n X  X  O\r\n X  O  X\r\n 7  O  O\r\n\r\nYour move: 7\r\n X  X  O\r\n X  O  X\r\n X  O  O\r\n\r\nHuman won!\r\n*** Exception: ExitSuccess\r\n*Main>\r\n```\r\n\r\nSuck it, random number generator.\r\n\r\n## The Good Stuff\r\n\r\n### First steps\r\n\r\nHaskell programs are organized into modules.  If you’re coming from an object-oriented world, it’s not quite analogous to a class - it’s more just a way of describing a namespace. In this way you do encapsulate functionality, but not quite as rigidly as a class does as a “blueprint” for an object.  Each module consists of “entities” like functions and types, which can be imported into other modules for use.\r\n\r\nOpening up Main.hs we see the following declarations:\r\n\r\n```haskell\r\nmodule Main where\r\n\r\nimport           Control.Monad (forever, when)\r\nimport           Data.Bool     (bool)\r\nimport           Data.Char     (digitToInt)\r\nimport           Data.List     (isSubsequenceOf)\r\nimport           Data.Maybe    (isJust, isNothing)\r\nimport           System.Exit   (exitSuccess)\r\nimport           System.IO     (hFlush, stdout)\r\nimport           System.Random (randomRIO)\r\n```\r\n\r\nThe module is the first term followed by the functions we're importing. This program only has the one module, but if there were more Main would be a sensible place to start looking for our program entry.  All other modules listed here are available in Haskell's standard library and I'll discuss each in turn as we use it during the walkthrough.  The module name is the first part with the specific imports from that module we use listed individually in the parens.\r\n\r\nI see some type declarations right under the import statements but I don't really understand what needs modelling yet, so instead I'm going to skim down and see which actual function is called first when you execute this (I did promise in the intro I’d do that).  In an imperative language the task is to write a subroutine telling the computer step by step how to execute a game of Tic Tac Toe.  In Haskell everything is a pure mathematical transformation.  Our task is to define a value so that evaluating it plays a game of Tic Tac Toe with you as it resolves.  Instead of how to get to the end result step by step, we're just defining what the end result is which involves a bit of a mental twist if functional programming is new to you - especially because a turn-based, IO-oriented program inherently has some imperative parts!  In `Main.hs` this value is also called `main` and lives at the bottom of the file.\r\n\r\nBefore we can dive into the code, though, the line `main :: IO ()` itself has some unpacking to do.\r\n\r\nIn Haskell every value has a type. Functions count because they evaluate to values.   The compiler doesn’t need to worry about unexpected mutation and side effects so every function can simply be viewed as equivalent its return value much more than in an imperative language.  Haskell also goes hard on the types in a way that you've likely never come across if languages like Java, C#, or C++ are as heavy a type system as you've ever worked with. The compiler is actually magic (no, really, *magic*) and does not require annotations - it's considered good style for top-level functions in a module but they can be omitted for internal values. However, they are a huge help if you start getting bogged down in compiler errors! A type annotation has the value's name first, followed by the double colon `::`, followed by the type, and you'll see them all over Haskell code.\r\n\r\nOur main value has the type `IO ()`. Right off the bat we get a taste of some of funky fresh Haskell weirdness.  We have our regular looking types available like `Int`, but this `IO ()` is our first hint the types are set to \"Maximum Cool\".  Before we can talk about the logic inside this `IO ()` *thing*, we've got to get to the bottom of what exactly it even is.\r\n\r\n#### Setting the scene: `IO ()`\r\n\r\nI'm going to preface this by saying I am not making this a blog post about Monads if you've heard the good advice about generally running away from those. I do need to talk about them at least a little (we can keep it to 30,000 feet but there's a `(>>=)` or two just sitting there), and they're really not a scary thing at all. This is the super simple shakedown, and it's only a shakedown because I thought it sounded good after \"super simple\".\r\n\r\nIO is a monad. In Haskell, Monad is a design pattern that allows us to imbue simpler types with some higher-order functionality that strictly adheres to a set of laws in order to compose them with more flexibility than a pure functional model would afford.  I'll unpack this below.  This pattern is not specific to Haskell, but the Haskell compiler is able to verify these \"monad laws\" for us at compile time due to its powerful typeclass system and comes with a number of built-in instances for various useful types - though you could absolutely approximate the pattern in any language with facilities for generic programming.  I'll talk more about what typeclasses and instances are later - for know, know that Haskell has a concept of \"categories of types\" which it can enforce and one such category is \"Monad\".  Our whole program here is type `IO ()`, which is a monad.\r\n\r\nAs we’ve stated, Haskell is a functional programming language which is really a rather broad category of languages that emphasize a style of programming in which the function is the basic unit of computation. In Haskell this is further constrained by demanding that every function be a pure function. If you're not familiar with the terminology \"pure\" means that the function does not rely upon or act on values outside of its own body. Put another way, the function will always return the same output for a given input because there is nothing else the output depends on and you're guaranteed that nothing outside of itself will change in the course of running it. The entire result of the computation is 100% determined by the arguments themselves.\r\n\r\nHere's a small example in JavaScript:\r\n\r\n```javascript\r\nvar impureIncrementAll = function(nums) {\r\n  const len = nums.length\r\n  for (var i = 0; i < len; i++) {\r\n    nums[i] += 1;\r\n  }\r\n  return nums\r\n}\r\n\r\nvar pureIncrementAll = function(nums) {\r\n  const len = nums.length\r\n  var ret = []\r\n  for (var i = 0; i < len; i++) {\r\n    ret[i] = nums[i] + 1\r\n  }\r\n  return ret\r\n}\r\n\r\nvar a = [1, 2, 3]\r\n\r\nimpureIncrementAll(a)\r\n\r\nconsole.log(a) /* [2, 3, 4] */\r\n\r\na = [1, 2, 3]\r\n\r\nvar b = pureIncrementAll(a)\r\n\r\nconsole.log(a) /* [1, 2, 3] */\r\nconsole.log(b) /* [2, 3, 4] */\r\n```\r\n\r\nIf you were to just call `pureIncrement(a)` without introducing the `b` value to capture the result, nothing would happen - the function would still execute, it's not a no-op, but the result will just be discarded and `a` will remain the same.\r\n\r\nHaskell doesn't have anything like `impureIncrementAll`.  You cannot do that.  This definition of \"function\" maps a lot more closely to the *mathematical* concept.  In most imperative languages what we call a \"function\" is more accurately a \"subroutine\", which may or may not be effectful.  Haskell doesn't have those.  The savvy among you might already be asking \"but wait! There are all kinds of things a function might want to do outside of itself. How about printing a letter to the screen or responding to any external input?\" To which Haskell says \"Oh, shoot. We hadn't thought of that. Pack it up!\" Good post everyone.\r\n\r\n...Hah! Got you, didn't I. Monads conveniently allow Haskell to get around this little technicality of actually having to be useful by wrapping up the ugly-but-necessary effects like using `stdout` and compartmentalizing them in a purely functional way.  I read this particular type as \"IO Unit\". The first part means it's of type IO, so it does something with IO (Input/Output). But we need to know what type this monad returns so that we can use it within our typed functional program (spoiler alert: specifically within other monads.)  An IO monad like main will do something with IO in its body but also evaluates to (`return`s) something in the context of your purely functional program. The Monad is a way of encapsulating that idea - whatever IO it does will happen inside of it and then you get this second type back, still wrapped up as an `IO something`. A monad can be thought of as an \"action\" or \"computation.\" It isn't the action itself, it's just the concept of carrying out that action. It's a noun through and through, just a \"thing\" we can pass around in our program (NOT a function, though functions can return Monads), but it's definitely a little weird at first. Monads turn out to be a great way to compose functionality without sacrificing that sweet, saucy purity.  All of our `console.log()`-equivalent code will be neatly inside a type marked so and use that to contain it's effectfullness and not get all over everything, which would break the really nice guarantee that innocent values like `a` will never be mutated willy-nilly by rogue calls to `impureIncrementAll` when you least expect it.\r\n\r\nThat probably doesn’t sit well with you.  One possible reason is that it’s a bald-faced lie or at least a gross over-simplification.  You can't just hand-wave away the fact that somehow being in an IO monad lets us write seemingly impure code, I can hear you saying.  Hold your rotten tomatoes, please.  The Monad structure is allowing us to contextualize the world outside the program in a really handy way and pass it around.  Building up how that’s working out in Haskell is both a cool exercise to step through yourself and completely outside the scope of this tutorial.  It's best left to somebody who knows a lot more about what they’re talking about, and not at all on a need-to-know basis to utilize monadic IO.  Here, we’re using it to tag every single part of our program that does any IO - it helps me to think of that `IO` part as a sort of phantom argument to your function you can’t use that’s representing the entire world outside our Haskell program.  The world outside is getting passed in to your function so you can act upon it safely, and then getting neatly passed out in its new form when you're done for the next step of the pipeline.  It’s not precisely what’s going on but its not completely unlike it either!  This pattern allows us to keep our “100% of the result of this function is determined by the arguments themselves” constraint and still interact with a user while still writing clean, easy-to-follow code.\r\n\r\nMonads have use far beyond just containing IO effects, but for our use in this program the IO Monad is the (slightly confusing) type of \"doing input and/or output\" and it will yield a thing when it’s done. The type it yields is the second term. For main, we don't have anything, so we return something of type `()`, the empty tuple (there is only one possible value of type `()`, which is `()` - the empty tuple itself). Putting them together, we have our type `IO ()`. This is akin to `void` in C/C++, or, well, `unit` or `()` in a bunch of different languages. Zilch.\r\n\r\nAs a side note, an `IO ()` on its own doesn’t do anything unless it’s been executed inside `main`!  That’s the only way to get it to do something.\r\n\r\nFor a superior but still blitz pace Monad (etc.) usage run-through with pictures [this blogpost](http://adit.io/posts/2013-04-17-functors,_applicatives,_and_monads_in_pictures.html) will get you up to speed surprisingly quickly from the author of [\"Grokking algorithms\"](http://a.co/ba5icnv).  The Haskell wiki also has a number of excellent articles digging deeper into IO specifically and more general Haskell type theory goodness.\r\n\r\nIt's completely normal for this to make little sense - it doesn't need to yet.  Monads are truly not complicated at all and show up all over the place in all sorts of languages, but the way to learn how to program with them is to sit down and write some code with monads - no amount of reading is going to give you the instinctual understanding you need.  They're notoriously hard to describe, and I promise you you're not just one more analogy away from understanding it.  Write some code!  With that in mind, let's get back to the grizz.\r\n\r\n### Back to the Grizz\r\n\r\nThat wasn't too terrible, right? Or maybe it was, I don't have a response mechanism from any sort of audience as I'm writing this. Let me know. I regret saying \"Grizz\" already, no need to mention that. It's not a real word and I've really leaned into it, I know.  I'm sorry.\r\n\r\nAnyway, let's look back up at `main :: IO ()`:\r\n\r\n```haskell\r\n-- line 93\r\nmain :: IO ()\r\nmain = do\r\n  let board = freshBoard\r\n  runGame board\r\n```\r\n\r\nFrom the type we know it will perform IO and give us NOTHING back. Friggin' main, pull a little weight once in a while, huh?\r\n\r\nThe definition of `main` is directly below the type declaration.  Just to drive the point home once more - I’m not calling it a function.  It isn’t one, like it would be in, say, C:\r\n\r\n```C\r\nint main() { return 0; }\r\n```\r\n\r\nThat C snippet defines a function that returns an int.  In our Haskell program, there’s no function call - It's just an `IO ()` - an IO action. A noun, not a verb - a thing that performs some IO to resolve to its final value.  Similar to how if you define a binding `let a = 2`, typing `a` at a REPL will just give you back the value 2, typing `main` will just give you back the value \"the action of playing a tic tac toe game\", which involves user interaction to resolve.  It's a weird but important distinction.\r\n\r\nWe can tell it's a simple value because the type doesn't have an arrow `->` in it. All functions are mappings from a type to another type (or more), like `Int -> Int` for something like `int double(int x) { return x * x; }` or `Int -> ()`, like the direct translation of the C would yield - `()` is a lot like `void`. Main just does our IO and has () to show for it.\r\n\r\nAt this point I’ll note that Haskell is like Python in that its scopes are delimited by semantic whitespace.  I’m not touching the pros and cons of this choice, it is what it is.  Anything indented is inside the parent scope. Our main is going to `do` a few things.\r\n\r\n#### Gettin Your Sequence On With `do`\r\n\r\n`do` is actually syntactic sugar for some more monadic jazz, so as with my first digression this is not a full explanation but rather a taste - just enough to keep moving. We can use this structure inside any monad and it lets us \"fake\" an imperative style of programming. You may have noticed main doesn't look like what you'd think a functional program should, doing things and then other things all imperatively and stuff. We’re supposed to be operating in this super pure mathematical world of function evaluation and nothing else! That's not how a functional program works, it's supposed to just compose the results of other functions.\r\n\r\nIn fact, we still are.  `do` is syntactic sugar which lets you chain monads together with the `(>>)`/'then' operator, which is specific to Monads (as in, it's defined in the `Monad` typeclass, so all monads are guaranteed to work with it). Pure and strongly typed, like GHC (our magical compiler) demands. The do notation just helps it look cleaner and easier to follow while we pass around our “phantom outside world” parameter in the course of the computation through several successive IO operations.\r\n\r\nThe takeaway is that if you're in a monad like `main :: IO ()`, you can generally use `do` to do some monadic things (like IO) sequentially and that's a-okay with Haskell. This is what allows monads to, for instance, respond to input based on the contents. Inside the do block both things I call out to are also IO monads. The total value of main, i.e. the result of running the executable, relies on some external input to compute and it's going to need to respond based on whatever input it receives.\r\n\r\nWhew. Another token, another couple paragraphs of exposition. So, what is it we're `do`ing? The first statement is something I finally don't have a whole paragraph about. With the line `let board = freshBoard` we're creating a binding of the name board and assigning it the value `freshBoard`. What's `freshBoard`, you ask? Why, lines 27 and 28 of Main.hs of course!\r\n\r\n### Leaving `main`\r\n\r\n```haskell\r\n-- line 27\r\nfreshBoard :: Board\r\nfreshBoard = Board $ replicate 9 Nothing\r\n```\r\n\r\nAlright, `freshBoard` has type `Board`.  I don't even want to know what a fresh one of these bad boys is without know what a `Board` looks like in general, so now lets go back up to the top and see what types I've defined.\r\n\r\n```haskell\r\n-- line 12\r\nnewtype Board = Board [Maybe Player]\r\ndata Player = Human | Computer deriving (Eq, Show)\r\n```\r\n\r\nAnd there you have it.  A `Board` is a container for a `[Maybe Player]`.  The brackets around `Maybe Player` mean that it's a list of `Maybe Player.`.  Obvious, right?  I'm joking, I'll talk about it.\r\n\r\nIt makes sense to get familiar with `Player` first, since we're using it inside the definition of `Board`.  This is a union type, like an enum.  If you've never worked with those it's just a bit of data that can either be a `Human` or a `Computer` and nothing else.  We've auto-derived the *typeclasses* `Eq` and `Show` for it that let us compare `Players` for equality, i.e. tell if `Human == Human`, and to display them to the console as is.  I'll come back to typeclasses a little later, they're quite neat.  So we know that anywhere that expects a value of *type* `Player`, that *value* is either `Human` or `Computer` - there's nothing else it can possibly be.\r\n\r\nA `Maybe` is a useful type (spoiler alert, another monad!) allowing you to encode the concept of nullablillity into the type system, instead of as a `null` value that can get thrown around.  Similar concepts appear in other languages like Rust and Swift (and OCaml and Scala and F# and SML and Elm and etc, etc - it's not a new or Haskell-specific concept is the point here), and if your language of choice doesn't come with it, you can probably handroll one yourself, albeit maybe without some of the compile-time property checking we're getting here.  A `Maybe` can either be a value of `Nothing` or a `Just <something>`, in our case a `Player` from the type.  `Maybe Player` is actually also a type - `Maybe` is a *higher-kinded type* meaning it must parameterized with a type before it can be used in the context of your program.  Putting it all together, a list of these `Maybe Player`s might look something like the following:\r\n\r\n```haskell\r\n[Nothing, Just Human, Nothing, Just Computer, Nothing, Just Human, ...]\r\n```\r\n\r\nEven though there are three different possible values for each cell, the type `Maybe Player` concisely expresses those three values and only those three values.  This constraint is now checked at compile time for you with no boilerplate needed.\r\n\r\nThe word `kind` in higher-kinded type refers to *how many layers* of parameterization this type requires.  Without a type parameter, `Maybe` is not a complete, usable type at all - every `Maybe` will carry a specific type.  `Maybe` has *kind* `* -> *`, meaning a mapping from something to something.  When `Player` is that something it becomes the fully resolved type `Maybe Player` with *kind* `*` that can be fully evaluated in other functions.\r\n\r\nRemember earlier when I called the compiler magic?  It goes further... `Either`, which is *kind* `* -> * -> *`takes two type-level arguments, creates curried (partially applied) types by only supplying one parameter!  For example `Either Player` is a partially resolved type that still has kind `* -> *`, and only by specifying the other type, e.g. `Either Player Int` do you have a fully resolved `Either`, which similar to how a Maybe means you've either got a `Nothing` or a `Just <sometype>`, you will either have a value of `Left Player` or`Right Int`.  This `Either` type is a neat way to manage error-handling encoded into your types.\r\n\r\nWhat's super interesting is that these higher-kinded types work like *type-level functions*.  Try that in Java.  What else have we used that has a type that looks like this?  Why, our new best friend the IO monad of course!  It can be an `IO ()` or an `IO Int` or anything you like, but it's still an IO monad, with kind `* -> *` until it's specified further.  It turns out `Maybe` is *also* a monad, but instead of contextualizing the scary mutable outside world, we're just contextualizing nullability.  The monad-ness is going to allow us to operate on the contained type while still ensuring we're keeping it inside a `Maybe` no matter what.  There are, though, higher-kinded types which aren't monads as well.  It's cool stuff, but not at all important for this program.\r\n\r\nAlright, armed with at least some of that knowledge we can take a look at `Board $ replicate 9 nothing`.  This is nice and neat in that even though it looks a little incantation-y, it's got a nice simple ring to it - it almost reads like English.  It's almost like reading a sentence, or at least pseudocode.  Before going forward you'll want to know about `$` - this is just function application with different precedence/associativity rules.  Its `Board(replicate 9 nothing)`.  It seems redundant at first but the low precedence and right-associativity let you omit parens: `f $ g $ h x  =  f (g (h x))`.  It looks funky but if I recall it felt natural pretty quickly.  Buckle up because there's a little more token soup below.  Haskell is not shy about esoteric operators.\r\n\r\n`replicate 9 nothing` isn't too hard to tease apart.  Function application is just via spaces in Haskell (it's a function-oriented language after all), so we're calling `replicate` with the arguments `9` and `Nothing` instead of `replicate(9, Nothing)`.  And `Board` wanted a list of `Maybe Player`s.  `replicate` makes uses the first argument to decide how many \"replicas\" of the 2nd to make, and returns them as a list.  Which is what we said a `Board` held. Okay, cool, so a `freshBoard` is a `Board` has nine cells that *can* hold a `Player` but don't currently:\r\n\r\n```haskell\r\nfreshBoard = [Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing]\r\n```\r\n\r\nWe could have simply written the above, but we get there with much fewer keystrokes using `replicate`.  And that's the whole data structure for the app.\r\n\r\nGreat!  So to recap, we've now stored a `Board` of 9 cells that might contain a `Human` or a `Computer` but are currently empty.  What say you we move on to the *third* line of `main`?\r\n\r\n### The Third Line of `main`\r\n\r\nNow we're cooking with gas!  Our `freshBoard` is ready for some killer moves.  The next line is a simple function call reads `runGame board` - easy enough.  We're going to pass our new board into the `runGame` function.  What does that look like?\r\n\r\n```haskell\r\n-- line 75\r\nrunGame :: Board -> IO ()\r\nrunGame board = forever $ do\r\n  gameOver board\r\n  print board\r\n  putStr \"Your move: \"\r\n  hFlush stdout\r\n  n <- getLine\r\n  case n of\r\n    [c] ->\r\n      if [c] `elem` map show [(1::Integer)..9]\r\n      then do\r\n          let n' = digitToInt c\r\n          if openCell board n'\r\n          then handleInput board n' >>= compTurn >>= runGame\r\n          else putStrLn \"That's taken!\"\r\n      else putStrLn \"1-9 only please\"\r\n    _   -> putStrLn \"Only one digit allowed!\"\r\n```\r\n\r\nThat's a bulky one.  Let's take it one step at a time.  For starters, the type itself should look familiar enough by now.  `runGame` is a `Board -> IO ()` which is to say a function that takes a `Board` and returns an IO monad carrying Unit, or nothing at all, just like `main`. We know it's a function this time because of the `->` - it's a mapping from one thing to another.\r\n\r\nDiving into the definition we see we're going to define another `do` block, but it's going to get wrapped inside a `forever`.  We already know the `$` operator is just regular old function application, so everything after it in our definition is inside the `forever`.  Back at the top of the file you can see we brought it in from the `Control.Monad` module, so, you guessed it, it's a monad thing.  Luckily this one is simple - it just means we want to execute this monad forever.  I bet you already got that.\r\n\r\nWhat's inside this function, then?  The next line immediately calls out to another function called `gameOver` and passes it the board, which right now is fresh.  Let's look at `gameOver`:\r\n\r\n```haskell\r\n-- line 68\r\ngameOver :: Board -> IO ()\r\ngameOver board@(Board b) =\r\n  when ( all isJust b) $ do\r\n    print board\r\n    putStrLn \"Draw!\"\r\n    exitSuccess\r\n```\r\n\r\nWell, that type signature should be getting repetitive.  This is another one that takes a `Board`, does some sort of IO, and doesn't pass anything back to the caller.  The token soup in the second line is just destructuring syntax.  Our `Board` is the only argument, and all `board@(Board b)` does is allow us to refer to both the whole structure as `board` (with type `Board`) as well as specifically the inside list of cells as `b` (with type `[Maybe Player]`).\r\n\r\nThe body of this function is straightforward to read.  `when ( all isJust b)` we're going to `do` something.  `when` is another thing we imported from `Control.Monad`, but it's also not scary and does what you'd expect - checks the predicate and enters the block if true.  Remember that each one of the nine cells is a type of `Maybe Player`, and a `Maybe a` can be either `Just a` or `Nothing`, using `a` as a stand-in for any type.  `isJust` is a helper predicate from `Data.Maybe` (imported, like a fine wine) that returns true if what was passed in is the `Just` variety of `Maybe`.  We passed it along with our list of cells `b` into `all`, which is like a big ol' `AND`/`&&` - it returns the false the first time it hits a false, or the whole expression is true.\r\n\r\nTo summarize, when every cell has a player in it `gameOver` will notice that it's time to pack it up and end the game.  Specifically, it will show you the board with `print` (details below) and tell you the game was a draw with `putStrLn`.  These only work in an IO Monad, both being type `String -> IO ()` and finally now I can justify all that hullaballoo about monads before we even started looking at code!  That's some good old fashioned output.  Remembering that `do` is secretly chaining together its children with a `then/(>>)`, this ends up looking a lot like your garden variety imperative, impure stuff, but never breaks any Haskell rules to do so.  It's all one big IO monad built from the inner results of calling each of these functions, which themselves return IO monads making it all work.  That's why `main` has to be an IO monad as well even though it doesn't perform any IO explicitly - it's built from functions that call functions (that call functions) that do.  When the printing is over we just `exitSuccess`, terminating the program with status code 0.\r\n\r\n`gameOver` makes sure there's still a game to play on the board before diving in and trying to run a turn.  If we're done, the whole process ends, and if not this function doesn't do or return anything at all so `runGame` can progress.  We've just begun our journey, so when we passed in the `Board`, `all` of it was definitely not `isJust`.  In fact, this predicate kicked back a `false` when we got to the very first cell.  Moving on, what does a run of the game loop look like?\r\n\r\nFirst, it looks like we `print` it out.  Groovy.  But wait!  Slow down.  How does the compiler know what a `Board` should look like?  We made that type up ourself (here's your previously promised details!)  In Haskell \"printablility\" is expressed as a *typeclass* called `Show`.  We've been using typeclasses this whole time - they're (to me) the whole point of learning Haskell in the first place.\r\n\r\n#### A digression - Typeclasses: types, with class\r\n\r\nI know I said I wouldn't go too much into it but this is fun and quick.  We already know `Maybe` is a higher-kinded type, specifically of *kind* `* -> *`, which means it's one of those fancy type-level functions - those asterisks stand in for any type.  This syntax is used to describe the *kind*s of types.  What we didn't talk about with `Maybe` is that it's a member of several useful typeclasses like `Eq` and`Show` and `Monad`.  These apply to specific types like `Int` or `Maybe` and define what happens to them in certain situations, and as we saw above when we defined our `Player` type can be derived automatically in some cases.  You can think of them as not unlike interfaces in an object-oriented setting, but they're really so much more than just interfaces.  The compiler comes with a lot of these already implemented for built-in types and knows how to derive simple ones for us for simple types.  For instance, when you want to print a `7` to the screen you pretty much always want to simply write that numeral to stdout.  If you wanted it to instead print the word `seven`, you could implement a custom version of `Show` with that logic.  If you ask if that `7` is `==` another `7` it's reasonable to assume the compiler can tell you it, in fact, is.  Thus, the type `Int` comes ready to go with an `Eq`.  At the REPL you can use the built-in `ghci` command `:info <type>` to get a list of all the typeclasses that type implements, as well as where it's defined:\r\n\r\n```\r\nPrelude> :info Int\r\ndata Int = GHC.Types.I# GHC.Prim.Int#   -- Defined in GHC.Types\r\ninstance Bounded Int -- Defined in GHC.Enum\r\ninstance Enum Int -- Defined in GHC.Enum\r\ninstance Eq Int -- Defined in GHC.Base\r\ninstance Integral Int -- Defined in GHC.Real\r\ninstance Num Int -- Defined in GHC.N…\r\n```\r\n\r\nAs expected, the fourth line of output above tells us we've indeed got an `Eq` instance on the `Int` type to work with.\r\n\r\n### `Show` Me The Money\r\n\r\nFor union types like `Player`, we can tell the compiler to assume we just want to print out the name of the variant like `Human` or `Computer`.  But if we wanted to do something crazy we could easily just define our own instance of `Show` that has code to manipulate it.  With a more complicated type, like `Board`, we want to have that control.  Here's our definition of `Show` for `Board`, which `print :: IO ()` is currently asking for in order to evaluate.  It's defined up with our other definitions:\r\n\r\n```haskell\r\n-- line 15\r\ninstance Show Board where\r\n  show (Board cs) = foldr spaceEachThird [].withIndicesFrom 1.fmap showCell $ withIndicesFrom 1 cs\r\n    where spaceEachThird a = (++) (bool (snd a) (snd a ++ \"\\n\") (fst a `rem` 3 == 0))\r\n```\r\n\r\nOh no.  This should be good.  Or perhaps terrible.  Lets tease this apart.  That first list just says we're defining what `Show` should do for `Board`.  So every time a caller needs to `Show` a board (with `show` the function, for example, or indirectly via a call to `putStr`), it will come here and evaluate what's inside.\r\n\r\nTo define a typeclass instance you need to define the functions the typeclass requires.  `Show` is an easy one to define - there's just the one, `show a`, where in this case `a` will be `Board`.  And as you'd expect, we can see the left half of the definition agrees: this function will `show (Board cs)`, so if we pass in our `Board` newtype `cs` will refer to the list of cells inside.\r\n\r\nLuckily, Past Ben seems to have golfed this one, the bastard, which means taking some nicely formatted, readable code and yanking the readability out to save on characters.  No comments or anything here.  To be fair, I don't think Past Ben expected Present Ben (Future Ben?) to write this post, and Haskell is a lot of fun to golf.  No matter.  That first function, `foldr`, gives me an idea what I'm getting at already.  Let's talk about folding.\r\n\r\nI've been talking about how Haskell is *functional* and not *imperative* - the unit of computation is the function and you construct computations by composing functions.  However, I immediately threw that `do` thing at you which does kinda-sorta let you code imperatively, but that's still just a special syntax for describing a purely functional set of computations.  We're going to run in to a problem if we want to perform the same action on a list of things.  Which is exactly what needs to happen and monads won't help us now.\r\n\r\nIn a C-style language to solve this problem of printing each cell to the screen you'd iterate over the cells with something like a `for` loop.  In Haskell there's no such thing.  A loop isn't a function or a value and those comprise our whole toolbox.  But we still have to solve this problem.  Luckily Haskell provides a rich set of tools for approaching this type of problem functionally using *recursion* and the `fold` operation is a building block that makes this easier than writing it out by hand.\r\n\r\nBy the way this whole bit is not at all Haskell specific.  Recursion and folds will show up in all sorts of places, Haskell just happens to be an excellent evironment for getting familiar with how to build them.\r\n\r\n#### A Digression on `foldr`\r\n\r\nFolds are not an uncommon concept in mainstream languages - if you're already good and comfy with them, feel free to skip this whole bit.  If not, though, it will help to know how they work.\r\n\r\nThe way we take a collection values and make sure we do something with every member of the collection is to consume the collection recursively.  That is, we're going to pass our whole collection into some sort of function which is going to do some sort of processing.  At the end of the function it's going to call itself again with a smaller part of the list as the argument - the part we haven't processed through the function yet.  It will do this again and again, calling itself with smaller and smaller parts of the collection until the whole thing is processed.  Easy peasy.  A `fold` is a specific type of recursive function that takes in a data structure, a collection of some type, and a function to use for each member - specifically the first element of the collection on each iteration.  It eventually yields just one single value, after the list has been fully drained.  The `reduce` operation is a special case of a `fold`, if you've come across that in JavaScript or Python or what have you.\r\n\r\nTypes are one thing that I find easier to talk about in Haskell than English.  Here's the type signature for `foldr`:\r\n\r\n```haskell\r\nfoldr :: (a -> r -> r) -> r -> [a] -> r\r\n```\r\n\r\nIt's fine if you stared blankly at this, that's usually step one of unraveling a type signature.  They all work the same way though, so we can walk our way through.  We know this is a function that takes three arguments because everything evaluates to one value in the end - so the compiler will expect three bits of information while processing this to get to that final `r`.  Parentheses in type signatures work as you'd expect - that first part is grouped, signifying it's a single argument with the type `a -> r -> r` instead of three separate arguments.  The second unknown type is conventionally shown with a `b` - I'm using `r` to indicate it's our return type.  If you went to look this up online, you'll probably see a `b` instead.  It doesn't matter what type, it could be anything.  This second type placeholder could even be another `a` and often is, but it doesn't *have* to be for the function to be correct so we use a different letter.\r\n\r\nThe first thing is our processing function.  This itself is a function which takes two arguments.  It takes in a single element of our `[a]`, or a list of `a` types, and some value of the type that we're returning and returns a new value with our expected return type.  When you pass in one cell of our `Board` (with type `Maybe Player`) this function will give back the next accumulated result.  The next argument is a single instance of that return type - the \"destination\" so to speak.  We know we're going to be getting a single value from this fold, and we have a function that takes a cell and our current running result and gives us back the new result, so we can drop that cell from the next run through the recursion.  On the first run through, though, we need somewhere to deposit the result of the computation, so `foldr` asks for a container as the second argument of type `r` to apply the result to.  This initial value we pass in is going to be transformed every run through the function and is eventually what gets returned.\r\n\r\nIf this all was too abstract, here's a simple example that might look more familiar - let's fold some basic addition into a collection:\r\n\r\n```haskell\r\nnums :: [Int]\r\nnums = [1, 2, 3, 4, 5]\r\n\r\naddEmUp ns :: [a] -> r\r\naddEmUp ns = foldr (+) 0 ns\r\n```\r\n\r\nThat's a lot less noisy.  In this example calling `addEmUp nums` will yield `15 :: Int`.  First, I defined a `[Int]` - a list of `Int`s - called `nums`.  Then I created a function `addEmUp` which is really an alias for a specific `fold` - notice how it doesn't do anything other than specify which arguments to use with the fold.  That's why the type signature for `addEmUp` is a lot simpler - it only takes the `[a]` collection, in this case `nums`.  So our `a` is `Int`.  The first argument, the processor, is `(+)` - the addition operator.  Operators are functions and this one takes in two values and produces a third.  Let's compare to our expected type: `a -> r -> r`.  In this case `a` is `Int` and we want an `Int` at the end, so we can substitute that type in for `r` too.  If you add an `Int` to an `Int`, lo and behold, an `Int` will pop out.  So our processor, addition, has type `Int -> Int -> Int`, which fits!  It's totally fine if `a` and `r` or any two unspecified types are the same, we just note that they don't *have* to be.\r\n\r\nOur second argument was just a `0` - an `Int`.  We've just decided that's a perfectly fine `r` type so the second argument makes sense as an initializer for our return type.  That just leaves us with `[a]`.  Thankfully we've left that part of the type intact and are passing it in as the argument to `addEmUp`!  For this simple example, the fully qualified type of this `foldr` reads: `(Int -> Int -> Int) -> Int -> [Int] -> Int`.  Just a bunch of `Int`s.\r\n\r\nWhen Haskell goes to evaluate this it will start with the full collection.  When we get to the first run through the processor will grab the first cell and then look for our accumulated result.  We haven't done anything yet so it's just `0` - we told it that in the second argument.  The first value is `1`.  Our accumulator added to our base value is `1`.  Then, we recur!  Only this time we've already processed the one, so we're calling this same function again but only on the rest of the collection, and using our newly minted `1` as the accumulator instead of the base value `0`:\r\n\r\n```haskell\r\nfoldr (+) 0 [1, 2, 3, 4, 5]\r\nfoldr (+) 1 [2, 3, 4, 5]\r\n```\r\n\r\nSee what happened there?  We processed the one and dropped it so our collection got shorter and we have a running total.  Expanding:\r\n\r\n```haskell\r\n  foldr (+) 3 [3, 4, 5]\r\n= foldr (+) 6 [4, 5]\r\n= foldr (+) 10 [5]\r\n= foldr (+) 15 []\r\n= 15\r\n```\r\n\r\nWhen a recursive function tries to recur on an empty list it knows it's done and returns the final value - in this case `15`.  We've managed to iterate without looping!  Instead we folded an operation in: `[1 + 2 + 3 + 4 + 5]`.  It's almost like we replaced the commas with our operator a step at a time from right to left.  In that way, we were able to reuse the same exact function over and over again while only changing what we pass in based on the output of the previous run.  Recursion, yo.\r\n\r\nIf this sounds outrageously inefficient, calling loads and loads of functions all the time with very similar values, well, it is.  To mitigate that overhead, Haskell performs something called \"[tail-call](https://en.wikipedia.org/wiki/Tail_call) optimization\" which I won't detail here but essentially means that instead of allocating a new stack frame for each successive call it's able to reuse the same stack frame and substitute the new vals and then just jump execution back up, `GOTO`-style, provided the function recurs in \"tail position\", which means it's the last part of the function to execute.  If you're not familiar with stack frames we're getting way beyond the scope of this post - it's not required knowledge here but interesting in general and important to understand if you'd like to use a functional language in anger.  In toy programs, the elegant functional solutions are generally fine, but as your apps scale it can start to cause problems, and languages which allow a more hybrid style generally recommend you fall back to more imperative patterns at that point.  A good old `for` loop will as a rule of thumb perform better on large amounts of data than a one-liner using a `forEach` or something similar - sometimes by orders of magnitude.  In Haskell, dealing with these performance problems involves other sorts of patterns as well, as there's no `for` loop to speak of.  I recommend you do some poking around!\r\n\r\nAs an aside this example could have been rewritten: `addEmUp = foldr (+) 0` - if the argument is the final term in the definition and the argument list it can be dropped.  This process is known as an [eta-reduction](https://en.wikipedia.org/wiki/Lambda_calculus#%CE%B7-conversion) in the lambda calculus lingo.  The compiler instead sees this definition as a curried function expecting one more value.  If it gets called with that value it will fully evaluate the expression.\r\n\r\n### The `Show` Must Go On\r\n\r\nThat digression got a little nuts but now we're armed to dive in to this bigger, messier fold.  We know its going to do the same basic type of thing as `addEmUp`.  The first thing to look for is those three elements we know we'll need: the processing function, the starting value to use as an accumulator, and the collection to process.  \r\n\r\nThe final part - the collection - is easy.  Remembering that `$` is function application we know we're going to apply this fold to `withIndicesFrom 1 cs`.   We know `cs` from the argument list is our list of cells: `Board cs`.  Then we just call a helper function:\r\n\r\n```haskell\r\n-- line 19\r\nwithIndicesFrom :: Int -> [a] -> [(Int, a)]\r\nwithIndicesFrom n = zip [n..]\r\n```\r\n\r\nThis is just an alias to attach a more domain-specific semantic name to the general function `zip`.  Given two collections, `[a]` and `[b]`, `zip` gives you back a single collection `[(a, b)]`:\r\n\r\n```haskell\r\nlet listA = [1, 2, 3]\r\nlet listB = [\"a\", \"b\", \"c\"]\r\nzip listA listB == [(1, \"a\"), (2, \"b\"), (3, \"c\")]\r\n-- True\r\n```\r\n\r\nThis alias just defines the first term to pass to `zip`.  You might notice the argument list doesn't match up with our type declaration - we're expecting two arguments, an `Int` and some list, but only have one below.  This is an example of the \"eta-reduction\" I mentioned earlier - the second argument, namely the list to zip with, appears last in the argument list and the function body so we drop it from both.  The fully specified version would read:\r\n\r\n```haskell\r\nwithIndicesFrom :: Int -> [a] -> [(Int, a)]\r\nwithIndicesFrom n cs = zip [n..] cs\r\n```\r\n\r\nThe type isn't any different so always look for the types if you get confused.  They'll tell you what's up.\r\n\r\nWe're using the argument to define the beginning of a range `[n..]`, that is, `[n, n + 1, n + 2, n + 3, ...]`.  to zip with, which will have the effect of attaching an index to each element in the list.  That's all.\r\n\r\n#### A Brief Digression on Laziness\r\n\r\nThis function brushed up on another super-cool property of Haskell that I haven't made much use of in this program but is too neat to just blow by.\r\n\r\nYou may notice that the seemingly-innocuous expression `[n..]` doesn't specify a top value.  What we've done, then, is defined an *infinite list* starting at `n` and just going and going.\r\n\r\nIn most programming languages this is quite obviously not okay.  The process would drop everything else and build this infinite list until it blows the stack and crashes resulting in a pretty shit game.  Well, more shit at least.  Haskell, on the other hand, employs *lazy* evaluation semantics.  When the compiler passes through it's perfectly content to leave that `[n..]` alone (technically it will pre-process everything to [weak head normal form](https://wiki.haskell.org/Weak_head_normal_form)) until it needs to begin the expansion - and even then it only expands *as-needed*.  In the case of `withIndicesFrom` the argument we pass it will be finite which, if you need a refresher, is smaller than infinite.  When we hit the last value of that collection to pass into `zip` we're good to go - no need to keep drilling our way through `[n..]` for indices we won't use.  Haskell just leaves it unevaluated wherever we are and moves on.\r\n\r\nThis is a pretty incredible property that allows for all kinds of patterns not possible in strict-evaluation languages but does have the side effect of making some performance characteristics difficult to reason about, as with recursion.  It's a good thing to keep in mind when writing Haskell.\r\n\r\n#### Back to work\r\n\r\nMoving back to the code!  As a reminder here's the first line of our `show` definition:\r\n\r\n```haskell\r\n-- line 16\r\nshow (Board cs) = foldr spaceEachThird [].withIndicesFrom 1.fmap showCell $ withIndicesFrom 1 cs\r\n```\r\n\r\nWe do have a fold, but it's the *final* part of a larger *composed* function.  The composition operator in Haskell is `.`.  This particular specimen is composed of three different parts.  Writing `a.b.c x` is like writing `a(b(c(x)))`.  It's much less noisy.\r\n\r\nOur first part, `fmap showCell`, is going to call `showCell` on each cell in our indexed list of cells `[(0, Nothing), (1, Just Human), (2, Nothing)...]` and return the result.  Lets look at `showCell`:\r\n\r\n```haskell\r\n-- line 22\r\nshowCell :: (Int, Maybe Player) -> String\r\nshowCell (n, Nothing)         = \" \" ++ show n ++ \" \"\r\nshowCell (_, (Just Human))    = \" X \"\r\nshowCell (_, (Just Computer)) = \" O \"\r\n```\r\n\r\nThis function has been written to take one of our conveniently pre-indexed cells and just boil it down to a string.  We actually define the function three times - the first definition with an argument pattern that matches how it's called will be executed.  Again, cool stuff!  A few other programming languages I've tried can do this sort of syntax too and it's easy to get spoiled.  In this case there are just three possible values for any given cell, having been defined as a `Maybe Player`.  We have a separate choice for each - if nobody's played yet we `show` the index and if it's got a player we return the proper character.\r\n\r\nThis is only part of the battle though!  This gives something like `[\" 1 \", \" X \", \" 3 \", \" O \", ...]`.  The second part of our composed function calls our new friend `withIndicesFrom` again to retain our indices so we're back up at `[(1, \" 1 \"), (2, \" X \"), (3, \" 3 \"), (4, \" O \"), ...]`.\r\n\r\nFinally, we get to the last outer function: `foldr spaceEachThird []`.  This whole part is the final outer function.  In a C-like language, we might have written this:\r\n\r\n```c\r\nfoldr(spaceEachThird, [], withIndicesFrom(1, showCell(withIndicesFrom(1, cs))))\r\n```\r\n\r\nThat means that now we have our collection to fold over - it's the result of everything up to here.   Our base accumulator is just `[]` - the empty list.  The missing piece is our function to fold in:\r\n\r\n```haskell\r\n-- line 17\r\nwhere spaceEachThird a = (++) (bool (snd a) (snd a ++ \"\\n\") (fst a `rem` 3 == 0))\r\n```\r\n\r\nThe `where` just means we're defining `spaceEachThird` locally for this function only - it isn't needed outside of this exact context.  We could have defined it inline using Haskell's anonymous function syntax (`\\x -> x + 1`) but even I must have decided that was too hard to read and split it out.\r\n\r\n`spaceEachThird` has been defined as taking a single argument `a`.  In this case `a` is going to be our current cell - conveniently it matches what we've been using as a stand-in type.  We know the processor acts on two input values because it has type `(a -> r -> r)`, and the other one is our accumulator, so in our definition it's going to look like we're missing an argument.  That \"missing\" argument is the accumulator, which is just `[]` at the beginning.\r\n\r\nThe first part of the definition is `(++)`, or concatenation.  There's a clue to where our other type goes - we're going to have whatever we're doing with `a`, the active cell, on one side, and it's going to get concatenated to the accumulator.  That makes sense - it's kind of like adding an `Int` to the accumulator.  The accumulator will now hold information from both operands.  What on earth are we adding, though?\r\n\r\nI've grabbed the `bool` function from `Data.Bool` and it's really just some control flow.  From [Hoogle](https://hackage.haskell.org/package/base-4.11.1.0/docs/Data-Bool.html): `bool :: a -> a -> Bool -> a`.  This is just a concise way to express an `if` statement with two branches, not unlike the ternary `?` in some other languages with the arguments reversed.  You give it the two potential outcomes first, the first argument being the `False` case and the second being if its `True`, followed by the predicate.  So `spaceEachThird` is just testing the final argument and using `(++)` to concatenate the middle one to the accumulator if it checks out and otherwise the first one.  Put in pseudo-something-JS-like, `(is the index evenly divisible by 3?) ? \"shove a newline on me\\n\" : \"just keep me as is\"`.  The two arguments are straightforward enough - the `True` case simply inserts a newline character `\\n` to the cell's string which is the second/`snd` value in the list item.  The predicate isn't to hard to understand either - the backticks make the `rem` remainder function into an infix function and we're using `fst` to get just the index of the cell - every third cell this will be true, so we'll start a new line.  Now we get our flat 1-D list of nine cells nicely squared away (nyuk) and printed as 3 rows of 3.\r\n\r\n### Gathering Input\r\n\r\nWhew!  That `print board` line turned out to be a little intense.  Luckily, the beauty of programming is that we've only gotta tell it how once, right?  The next order of business is going to be asking the player where they'd like to play.  The next two lines are familiar enough:\r\n\r\n```haskell\r\n-- line 79\r\nputStr \"Your move: \"\r\nhFlush stdout\r\n```\r\n\r\n`putStr` is going to simply send its input to stdout and `hFlush` flushes the stdout buffer (ensuring the full string is printed out) before advancing to the next instruction.\r\n\r\nImmediately following, we've got `n <- getLine`.  `getLine` waits for stdin and returns the contents when we get a `\\n`, which we store to a local binding `n`.  We can do this inside of our `do` block so that the value passed in is available to the rest of the function.  As soon as the user enters a line of text and hits enter, we'll move on.\r\n\r\nNow we get to the big `case` statement of `runGame`.  This is where we appropriately choose an action based on what the user entered.  This control flow construct is not at all dissimilar to a `switch` in other languages - more similar to a `match`, actually, in terms of expressive power.  We're going to match the value we just received from the user against a few patterns to see how to handle it.\r\n\r\nWe'll start with the outer layer:\r\n\r\n```haskell\r\n-- line 82\r\ncase n of\r\n    [c] ->\r\n      -- do some really awesome stuff with our single char\r\n      -- ...\r\n    _   -> putStrLn \"Only one digit allowed!\"\r\n```\r\n\r\nThis syntax just checks if our input `n` consists of a single character.  If it does, we'll keep it and do stuff, and if not we'll lightly admonish the idiot at the keyboard with a `putStrLn` call - this is a `putStr` that includes a trailing newline.  \r\n\r\nThat pattern matching works because of how Haskell thinks about lists.  Instead of being an array, they're represented as a series of elements attached to each other (if you've LISP'd, it's a cons cell), with an empty list at the end of the chain - something attached to a list of somethings:\r\n\r\n```haskell\r\n[1, 2, 3, 4, 5] == 1 : 2 : 3 : 4 : 5 : []\r\n```\r\n\r\nThis is why recursive functions work so well - it's easy to pull apart lists and detect the base case because they're already sort of pulled apart like that under the hood.  In pattern destructuring syntax you can get at the \"head\" (first element) and \"tail\" (everything else) with syntax like `(x:xs)`.  Here `x` is your head (`1`) and `xs` is everything else (`[2, 3, 4, 5]`).  You can get the first two with something like `x:y:xs`, match a two-element list with `x:y:[]` etc.  All lists in Haskell work like this.\r\n\r\nIn this example, we're using `[c]` - there's no `:cs` matching the tail.  This means this pattern will only match on a single-element list.\r\n\r\nThis is the last line of our function - but it's all wrapped up in a `forever`, so if we do get garbage and yell at the user we'll just take it again from the top of `runGame` until the user gives us something we can work with.\r\n\r\nIf the user complied and only passed in a single character we still have a little work to do:\r\n\r\n```haskell\r\n-- line 84\r\nif [c] `elem` map show [(1::Integer)..9]\r\nthen do\r\n  -- We've got us a digit!  Do some awesome stuff with it\r\n  -- ...\r\nelse putStrLn \"1-9 only please\"\r\n```\r\n\r\n`if` in Haskell works more or less how you might expect with the caveat that it's an *expression* as opposed to a *statement* - that is, the entire `if` block must reduce to a value. Remember, a value with type `IO ()` counts - it's just a value of type \"doing some IO\" with nothing being passed back into the function.  Once consequence of the expression-like nature of the construct is that you cannot have an `if` without an `else` to execute of the predicate doesn't pass.  Aside from that, though, it's as expected - you pass in a predicate and if it evaluates to `true`, we'll execute the `then` block and if not, we'll use `else`.  If you have more than two cases I recommend `case` over `if`.\r\n\r\nThe first thing to check is whether or not the single character we now know we have is a valid play or not.  It must be a digit from 1 to 9 and not a letter or a bit of punctuation or anything else.  The first line defines this predicate using the `elem` function which checks if the first operand is an element of the second.  Most functions in Haskell are *prefix* in that the function names come first followed by the arguments.  To use a function of two arguments more like an *infix* operator between two operands, you can wrap it in backticks as in the snippet.\r\n\r\nThis predicate is asking if our char input is a digit from 1 to 9 and employs a handy little trick to do so.  We can't simply ask if `\"1\" == 1` because one is a `String` and the other is an `Int`.  First we need to get a list of valid chars (`[\"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\"]`) to compare against.  A quick way to build this array is our good friend `show`.  We saw this one in action up in our typeclass hullaballoo.  This is how we convert a type into something we can print out on the screen.  In the case of an Integer this means turning it into a string representation first to send to stdout.  We can `map` the `show` function over a list `[1..9]` and it will perform that conversion for us for every element.\r\n\r\n### Functor?  I hardly know her!\r\n\r\nI haven't used `map` yet.  You may see `fmap` or `<$>` in other Haskell code and they all mean the same thing - return the result of calling the passed-in function on each element of a collection - actually, anything that has an instance of the typeclass `Functor` - familiar if you read that \"Monads with Pictures\" link!  Functors are things that keep their structure when applying functions to their contents - there's a set of \"functor laws\" like the \"monad laws\" with a different set of guarantees about what kinds of functions we can call on these types and how they'll behave.  It's a related concept to \"monad\" and you can tell this is just the tip of the category-theory iceberg here.\r\n\r\nLists are functors like the one we're `map`ping over here, and our buddy `Maybe` is a functor too.  It might be a little weird to think about mapping a function over a `Maybe`, but you can write:\r\n\r\n```haskell\r\ncouldBeAnInt1 :: Maybe Int\r\ncouldBeAnInt = Just 7\r\n\r\ncouldBeAnInt2 :: Maybe Int\r\ncouldBeAnInt = Nothing\r\n\r\ncouldBeALargerInt = fmap (+1) couldBeALargerInt1\r\n-- Just 8\r\n\r\ncouldBeALargerInt = fmap (+1) couldBeALargerInt2\r\n-- Nothing\r\n```\r\n\r\nBecause `Maybe` is a `Functor`, it knows how to handle having a function called on it no matter what the contents are and it will retain its structure on the other side having applied the function to any elements it can.  It's not unlike doing it to a list, really - it just will only have 0 or 1 things to apply the function to.\r\n\r\nLearning about how these categories of types work and relate to each other is worth the effort - it's an entirely new level of abstraction to leverage.  If you're already familiar with the concept of generic programming you can probably see how it's an extension over that, providing a higher level of organiziation and classification for it.  Haskell is an excellent environment for exploring the theory and how it relates to more robust real-world application code, and there's nothing stopping you from carrying the concept over to your day job - try writing the Maybe<T> functor as a class and using it instead of `null`.  The difference will be that ensuring your class adheres to the functor laws is up to you whereas Haskell can do that for you out of the box.\r\n\r\nAnyway, unlike folding where we're using our function to generate a new value from a collection this one keeps the shape of the old collection intact in our new return value.  This is also a common functional tool in many languages.\r\n\r\nWe're using the range operator `..` to construct our list, and by tagging the first element with a concrete type `1::Integer` we ensure each element we're mapping `show` over is an integer to begin with.\r\n\r\nWith the predicate out of the way we've now determined whether or not the input stored in `n` is a single digit.  Our else statement looks like the previous - print out a quick error telling the user how exactly they were dumb and that's it - head back on up to the top of `runGame` and hope this chucklehead learned their lesson.  If it was a digit, however, we can move on to one final nested `if`:\r\n\r\n```haskell\r\n-- line 85\r\n then do\r\n          let n' = digitToInt c\r\n          if openCell board n'\r\n          then handleInput board n' >>= compTurn >>= runGame\r\n          else putStrLn \"That's taken!\"\r\n```\r\n\r\nI included the top `then` line to show that we open a new `do` block - `then do` isn't a special syntax, it's just a `do` inside a `then`.\r\n\r\nFirst we save the integer version of our input `c` as a new local binding called `n'`.  Then we have one final predicate - before we can go thrusting the play's move onto the board, the Laws of Tic Tac Toe state that you can only make a move on a square if it's empty.  No playing on top of each other!  We verify this with `openCell`:\r\n\r\n```haskell\r\n-- line 30\r\nopenCell :: Board -> Int -> Bool\r\nopenCell (Board b) n = isNothing $ b !! (n - 1)\r\n```\r\n\r\nThis is a function that takes two arguments, a `Board` and an integer, and returns a boolean like a predicate should.  We're going to pass in the full board and a specific square and `openCell` will tell us if the space is already occupied.\r\n\r\nThanks to Haskell's operator love affair this looks a little more complicated than it is at first glance.  We've seen `$` before - it's function application.  The other funky operator is `!!` - this is just a list subscript.  In a more C-like language, we might have written this exact logic something like `isNothing(b[n - 1])`.  That is, we're asking for the `n - 1`th element of our inner board list `b` (named so via destructuring in the definition: `(Board b)`), and passing it to `isNothing`.  `isNothing` we brought in at the top from `Data.Maybe` and itself is just a predicate which is true if the `Maybe a` passed in is a `Nothing` as opposed to a `Just a`.\r\n\r\nWe initialized our board to a list of `Nothing`s.  The first time through this loop any digit we pass in is going to come up clear.  If there had been a `Just Human` or `Just Computer`, we'd hit the `else` block, yell at the user a little (I mean honestly, we JUST printed out the board, get with the program), and take it from the top.\r\n\r\nHOWEVER!  If `openCell` comes back `true`, we've finally done it - we've ensured the value passed to `n` from stdin is a value we can meaningfully use as the player's next move - it's not only a valid input, but it's a valid play.  Hot diggity dog!\r\n\r\nThe full `then` block reads:\r\n\r\n```haskell\r\nhandleInput board n' >>= compTurn >>= runGame\r\n```\r\n\r\nThis is three separate function calls wrapped up together with `>>=`, which is read `bind`.  This is one of the functions that's required to define as part of the `Monad` typeclass instance along with `return`, so all monads have this behavior.  We'll talk about `bind` first and come back to `return` below - but they're really two parts of the same idea.  `>>=` is going to allow us to pass the result of a monad as the input to a subsequent monad in the chain while still keeping it wrapped up in the proper context, in this case `IO a` or specifically `IO Board`.  We want to do stuff to that `Board` without losing the `IO` wrapping.  I think this is clearest through example, and luckily we're working through an example right now!  The first function call is `handleInput board n'` so let's unpack that first.\r\n\r\n### Making a Play\r\n\r\nI bet we can work out the type of `handleInput` from the call.  `board` is easy - it's a `Board` - and `n'` is our newly converted integer from stdin.  So we know this will be a `Board -> Int -> something`.  What, though?\r\n\r\nWell, we know we're inside an `IO` monad, and in a series of calls chained together with the monadic `>>=`.  So it's a safe bet this will be another `IO a`, that is, an `IO` monad with some type as a result.  And if we look down the chained call, we end things up with a call to `runGame`.  We've already looked at `runGame` (we're inside of it RIGHT NOW), so we know it's a `Board -> IO ()`.  We're calling it here with no argument, but from the type know it will need a `Board`, and we're passing a monadic result through a chain of functions - so it would follow that the type of each step *must* be `IO Board`.  Lo and behold:\r\n\r\n```haskell\r\n-- line 46\r\nhandleInput :: Board -> Int -> IO Board\r\nhandleInput board n = do\r\n  let b = playCell board n Human\r\n  checkWin b Human\r\n  gameOver b\r\n  return b\r\n```\r\n\r\nJust as expected!  In the body of the function we're opening another `do` block and as our first step creating a new binding `b`.  Time to finally examine `playCell` and get this game off the ground:\r\n\r\n```haskell\r\n-- line 33\r\nplayCell :: Board -> Int -> Player -> Board\r\nplayCell (Board b) n m = Board $ take (n - 1) b ++ [Just m] ++ drop n b\r\n```\r\n\r\nFrom the function call we expected a type like that - 3 arguments.  We also now see it will give us back a `Board` to store in `b`. The only type we haven't seen used much yet is `Player` - but we know all about that already from discussing `Board`!  The value can be a `Human` or a `Computer` and nothing else, and in this case we're processing the human's input - so we just pass in `Human`.\r\n\r\nIn the argument list, we've destructured the `Board` again to access the list of cells inside and assigned letters to the other two.\r\n\r\nNow, in a C-style language, you'd probably at first approach this task of adding a play to the board by indexing into the list and changing the value inside.  In Haskell, that's a big nope.  Remember when we discussed purity?  That would involve *changing the state of the world outside of the function* - namely the `Board`.  If we did it this way, this function of have wildly different and unpredicable results based entirely on the state of the `Board` when it was called, which is terrifying.  We cannot definitely look at that function and tell you what *exactly* it will do.  But, of course, this would be a dumb(er) game if nothing was ever allowed to change.\r\n\r\nThe way we get around this restriction in the functional paradigm is to not attempt to change anything at all.  Instead, we're just going to construct a *brand new* `Board` based on the previous one - like what the Javascript snippet did in `pureIncrementAll` up in the beginning.  Haskell is garbage-collected so the old iteration will be automatically dropped by the runtime with no need to call any sort of destructor or free the memory yourself.  That way the game as a whole can continue in a new state and we haven't broken our purity restriction.\r\n\r\nI do this using the super handy `take` and `drop` functions which return new sublists leaving the input list untouched.  `take` returns the specified number of elements from the front, and `drop` returns the end of a list beginning at the index specified.  So in `playCell` I just `take` the cells up to but not including the cell specified, and at the end we'll attach the rest by `drop`ping the beginning.  That only leaves the single cell in question.  Because the `Board` requires each cell to be a `Maybe Player`, we can wrap our `Human :: Player` value inside a `Just`.  We then put it in brackets to make a single element list which we can concatenate (`++`) to our bookend sublists, and wrap the new list up in a new `Board`.  The end result is a `Board` value shaped just like the last except the cell we passed in as an argument has a `Just Human` now instead of a `Nothing`.  Everything else is a direct copy.\r\n\r\nThis way for the same inputs we can always guarantee the same outputs.  The current state of the `Board` is passed directly into the function which allows us to generate the next state appropriately, and we know exactly what it will look like given all the inputs we've got locally available.  This makes reasoning about the flow of logic in Haskell code almost trivially easy in cases that become very convoluted otherwise with shared mutable state.\r\n\r\n### Winners Only, Please\r\n\r\nNow that we've stored our shiny new Board with one cell updated we've got to see how well we did.  The next line of `handleInput` calls `checkWin`:\r\n\r\n```haskell\r\n-- line 57\r\ncheckWin :: Board -> Player -> IO ()\r\ncheckWin board@(Board b) m =\r\n  let\r\n    bi = withIndicesFrom 0 b\r\n    plays = map fst.filter ((Just m==) . snd) $ bi\r\n  in\r\n   when (foldr ((||) . flip isSubsequenceOf plays) False winStates) $ do\r\n     -- End the game!\r\n```\r\n\r\nOkay, this is a little bigger.  It's a function of two arguments returning an IO monad which (I really hope) makes sense by now.  This monad isn't returning anything (note that we havent stored a result to a binding with `<-`, we just called it inside our `do` block - which is to say our `then`/`>>` chain of monads), so `IO ()` is appropriate.  This will just do some IO and will be responsible for terminating the process if we find a win.\r\n\r\nThe `let...in` syntax is a way of creating function-local bindings not unlike `where`.  In fact, they can often be used interchangeably and the difference is subtle: `let...in` is an expression, which can be used anywhere at all that expects an expression (kinda like `if...then...else`), whereas `where` is a syntactic construct that only come after a function body.  I'm not going to get into the subtlies here, see the [Haskell Wiki](https://wiki.haskell.org/Let_vs._Where) for a more thorough discussion.\r\n\r\nAnyway, before diving into the endgame checking we're going to set up some computed local bindings to make our life a little easier:\r\n\r\n```haskell\r\n-- line 59\r\n let\r\n    bi = withIndicesFrom 0 b\r\n    plays = map fst.filter ((Just m==) . snd) $ bi\r\n  in\r\n  -- uber cool codez\r\n```\r\n\r\nWe've saved as `bi` a version of the `Board` we're working with zipped up with indices using our old friend `withIndicesFrom` - instead of, e.g., `[Nothing, Just Human, Nothing...]` we have `[(0, Nothing), (1, Just Human), (2, Nothing)...]`.  We're going to use this in our next `let` binding, `plays`.  This line is a little token-soupy, but we're intrepid as heck.  It's a call to `map`, and the collection (functor) we're mapping over is the newly defined `bi`, so all that junk in the middle must be our mapping function.  Let's see if we can untangle it.\r\n\r\nThis function has opted for concision via the `.` composition operator we saw up in our `Show Board` instance, at the cost of readability.  This one actually has a composed function inside a larger composed function for extra goodness.  These are easiest to read inside-out (Lisp-ers know what's up).\r\n\r\nThe first action that happens to `bi`, our indexed `Board`, is `filter ((Just m==) . snd)`.  The filter function first calls `snd` on each element returning just the second element of the tuple:\r\n\r\n```haskell\r\nsnd (1, Just Human) == Just Human\r\n```\r\n\r\nThen, `(Just m==)` compares it to the value passed in as `m` - remember when we called the function, it looked like `checkWin b Human`.  We're specifically checking if the Human player won the game with their latest play.  This is why we derived the `Eq` typeclass up in the `Player` declaration - this check wouldn't compile otherwise.  So `((Just m==) . snd)` will return true on a `(Int, Maybe Player)` if the second value is `Just Human`, and false otherwise.\r\n\r\nNow that we've pared down `bi` to only the cells that have been played we pass that whole result into `fst` - that is, grab the first value of each tuple.  These are our indices.\r\n\r\nThe end result that's stored in `plays` is a list of the indices from 0 of all of the places the Human has played.  For example, running it on cell list `[(0, Nothing), (1, Just Human), (2, Just Computer), (3, Nothing), (4, Just Human)]` will come back with `[1, 4]`.  Lovely.\r\n\r\nNow that we've got our packed-up Human plays we can check to see if that constitutes a win.  The main body of the function, following the `in`, is another `when ... do` shindig like we saw back in `gameOver`.  This monad will execute its body under this condition, and otherwise its a no-op.\r\n\r\nHow about that condition, then?  Let's see:\r\n\r\n```haskell\r\n`foldr ((||) . flip isSubsequenceOf plays) False winStates\r\n```\r\n\r\nAha, it's our good old friend `foldr`.  I unabashedly love folding.  True to form, we've got three arguments: a transforming function, an initializer, and a collection.  We've looked at two folds before - the trivial example used an `Int` as an initializer that we added numbers to, and the the code from the game used a collection (that we pre-built).  This time around it's simple a `Bool` - `False`.  That's is a-ok too as long as your transforming function returns a `Bool`!  It can be any type at all.  That means this whole fold will return a `Bool` - by definition, the fold always returns the same type as the initializer: `(a -> r -> r) -> r -> [a] -> r`.  And that's what we want because `when` expects a predicate.\r\n\r\nBefore picking apart the transformer let's look at `winStates` - the collection we're folding over.\r\n\r\n```haskell\r\n-- line 53\r\nwinStates :: [[Int]]\r\nwinStates = [[0, 1, 2], [3, 4, 5], [6, 7, 8], [0, 3, 6], [1, 4, 7], [2, 5, 8], [0, 4, 8], [2, 4, 6]]\r\n```\r\n\r\nThis is pretty simple - it's just a list of lists.  This is admittedly not an elegant way to handle this problem, but TicTacToe is simple enough that it's feasible to simply hardcode all the possible winning configurations.  This is a list of lists of `Int`s (`[[Int]]`) just containing all the indexes that are in a row.\r\n\r\nFinally, the transformer: `(||) . flip isSubsequenceOf plays`.  We know this whole bit of code is a function of type `(a -> r -> r)` - filling in the concrete types this becomes `([Int] -> Bool -> Bool)` - out initial collection is a `[[Int]]`, a list of lists of `Int`s, so each time through we're checking just one of these sublists and returning true or false.\r\n\r\nThe workhorse function I chose is the aptly-named `isSubsequenceOf`, imported (with love) from `Data.List`.  It returns true if the elements of the first list appear in order (but not necessarily consecutively) in the second list.  The docs helpfully note that this function is equivalent to calling `elem x (subsequences y)` - the standard library is building useful abstractions by composing smaller abstractions!  I actually came across this library function in the course of researching a problem I came up against trying to implement it myself.  I don't remember the specific nature of the problem I had because all it took to solve was a look at the standard library.  Don't forget to look through it for functionality you need before falling down the wrong rabbit hole.\r\n\r\n#### Typclass constraints - a digression\r\n\r\nAccording to [Hackage](https://hackage.haskell.org/package/base-4.11.1.0/docs/Data-List.html#v:isSubsequenceOf), this function has type `Eq a => [a] -> [a] -> Bool`.  This signture has one syntactic element I haven't touched upon yet - that first part, `Eq a =>`, is a *typeclass constraint* on `a`.  I've been using `a` as a stand-in for \"any type\" over the course of this article.  This syntax lets you more precisely define what sorts of types are ok - unlike a fold, `isSubSequenceOf` only makes sense to call on lists with elements that can be compared to each other.  This stands to reason - it's going to have to check each element in one list against the other.  This is Haskells system for *ad-hoc polymorphism*.  If the types involved do not have instances of the typeclasses specified, either derived or hand-implemented, this won't compile.\r\n\r\n### `flip`ing out\r\n\r\nThe last unfamiliar part of this function composition is the word \"flip\".  This is a simple but useful function that just switches the order in which the arguments are expected.  The way we're calling it in our transformer function, `isSubsequenceOf` receives our `plays` list first and then the element of `winStates` the fold is currently processing.  However, we want it the other way around.  To tell if we've won we want to check if the winState is a subsequence of all the plays this player has made.  You can win with other non-lined-up plays on the board, they're just irrelevant.  `flip` just swaps the positions of the arguments so we get the logic we want!\r\n\r\nFinally, we compose (`.`) that result with the simple operator `(||)`.  This is usually used infix, e.g. `true || false`, but we can use it as a normal prefix function as well by wrapping it in parens.  One value it receives will be the result of our `flip isSubsequenceOf` call, and the other?  Why, that's our initialized `Bool`!  By chaining together all these calls with a big 'ol `OR`/`||`, this transformer will return `True` for the whole collection if any one of these iterations comes back `True` (meaning `plays` contains one of our `winStates`) or remain `False` as we initialized it.\r\n\r\nIf it was `False`, we didn't win and `checkWin` has nothing else to do.  The code inside the block doesn't execute, we have `()` to return, and control passes back to the caller.  If we *did* win:\r\n\r\n```haskell\r\n-- line 63\r\nprint board\r\nputStrLn $ show m ++ \" won!\"\r\nexitSuccess\r\n```\r\n\r\nNow we can finall hop back in and finish up `handleInput`:\r\n\r\n```haskell\r\ngameOver b\r\nreturn b\r\n```\r\n\r\nIf we've gotten here, it means `checkWin` didn't find a winning board configuration, so before we move on we call `gameOver` again to see if this play resulted in a draw, and if not, we `return b`.  `return` is a little different than you're used to - it specifically means to re-wrap our `Board` type in our `IO` context.  This is the other part of `>>=` - it's how we're passing this result around with the gamestate through successively chained IO actions.  This is how we pass the result back to the main `runGame` loop having determined that this play didn't end the game in either a win or a draw.\r\n\r\n### RNG Rover\r\n\r\nWe're nearing the end of the road - if you're still with me, I'm seriously impressed!  We've just got one last part to pull this together.  After all, what's a game of TicTacToe without a steely-eyed, calculating oponent ready to squelch your every plan?\r\n\r\nWell, we're not going to find out here because my computer player is real dumb and plays by dice roll.  It could be fun to try to make a smarter one - I'm leaving that as an exercise to the reader (read: too lazy to do it myself).\r\n\r\nRewinding a little, we entered `handleInput` inside this larger clause:\r\n\r\n```haskell\r\n-- line 87\r\nhandleInput board n' >>= compTurn >>= runGame\r\n```\r\n\r\nSo far, we've updated the world state according to human input, made sure there's still a game going on, and received the new `Board` to work with.  Now we're going to pass that brand new world state into `compTurn` via `>>=` which as we discussed will allow the `Board` to be passed without losing the `IO a` context it started with.  This means we should expect `compTurn` to take a `Board` as input and, because we're in the middle of a `>>=`/`bind` chain, return an `IO Board`:\r\n\r\n```haskell\r\n-- line 36\r\ncompTurn :: Board -> IO Board\r\ncompTurn board@(Board b) = do\r\n  let options = filter (isNothing.snd).withIndicesFrom 1 $ b\r\n  r <- randomRIO (0, length options - 1)\r\n  let play = (fst $ options !! r)\r\n  let b2 = playCell board play Computer\r\n  putStrLn $ \"Computer plays \" ++ show play\r\n  checkWin b2 Computer\r\n  return b2\r\n```\r\n\r\nGreat.  This function is mostly familiar by now.  We see our `IO Board` return type, we're destructuring the argument to get at the list of cells as `b`, we've got our old friend the `do` block - nothing too surprising.\r\n\r\nThe first line creates local binding `options`, which is going to be the result of `filter`ing our list of cells.  Filter will return a collection containing only those elements of the input collection for which the predicate is true.  Again, aptly named.  Let's take a look at the predicate:\r\n\r\n```haskell\r\n(isNothing.snd).withIndicesFrom 1\r\n```\r\n\r\nThis function is composed from parts we've seen before.  First we're going to zip up our cells with indices starting from 1 (spoiler alert, because that's what `playCell` wants as input).  Then we're going to pass that to the composition `.` of `snd` and `isNothing`.  Hopefully this starts to feel a little more readable by now - in English, this `filter` will have the effect of storing to `options` a list of 1-indexed cells that contain a `Nothing` - anything that's a `Just Human` or `Just Computer` will be omitted.  These comprise the possible cells the computer can choose for its next play.\r\n\r\nIn the next line we introduce the randomness.  This ends up looking similar to how you'd do this in the language of your choice.  `randomRIO` from `System.Random` takes a range and will give you a pseudo-random number in that range.  We're using the length of our `options` list, and storing the result to `r`.\r\n\r\nNow we've got to actually make the change.  This is done with `playCell` again - the differences being that instead of user input, we're using `!!` to index into `options` with the random number we just grabbed and we're passing in `Computer` instead of `Human`.  Now `b2` holds our new `Board` with the random play applied.  Afterwards we can just inform the user where the computer went. With all that taken care of, we can see if the computer managed to win the thing with `checkWin`.  If it did `checkWin` will handle ending the game for us and if not, we `return` the new gamestate again.  No need to call `gameOver` again here because `runGame` does so first - and our pipeline `handleInput >>= compTurn >>= runGame` is sending us right back up there to start the next turn.\r\n\r\n### The Thrilling Conclusion\r\n\r\nWe did it!  I'm all out of code to unpack.  `runGame` has everything it needs to alternate human turns and computer turns until somebody wins or we run out of spaces.  Haskell ain't no thang :)",
    "title": "Some Haskell, English'd"
  },
  {
    "cover_image": null,
    "date": "2018-10-29T17:52:35.129Z",
    "description": "Showing DEV my attendance-taker",
    "tags": "react, rust, reason, beginners",
    "markdown": "# Baby's First Full-Stack App\r\n\r\nI've done it - I've made a Thing.  I identified a problem I was having, designed a solution, and wrote a bunch of code that does the thing I wanted well enough for other people to use it.  I've got, like, *six* whole users now.\r\n\r\nI know that's pretty much the name of the game with this craft and all y'all do that on the daily but it's a bit of a big deal for me.  The chasm between being able to complete exercises, tutorials, and little toy terminal apps and a full-fledged application like this is a large one even if the final product is very simple in scope.\r\n\r\nGenerally, the advice from the wise especially when learning is to gravitate towards tools which are battle-tested and widely used.\r\n\r\nI'd like to make a counter-argument for trying the weird stuff anyway - I believe choosing Rust for my backend and ReasonML for the frontend allowed me to spend more time on the problem than the tooling, gently guided me towards better practices, and increased my understanding of the some of the concepts at play all while setting me up well to transition to more mainstream tools without much lead time.\r\n\r\nI'm not going to get into too much detail but just want to mention some parts of this project that I believe were easier because of these choices.\r\n\r\nThe project is hosted on GitHub - it's called [mifkad](https://github.com/deciduously/mifkad).  It's designed to replace a handwritten process for tracking the attendance of a small school and generating rosters for the \"extra hours\" portion of the day based on that attendance.\r\n\r\n## The Backend\r\n\r\nI could not be happier with [actix-web](https://actix.rs).  I had already been playing around with Rust for a bit when I stumbled upon it, and had a few endpoints working as expected within minutes from just reading the website.  Easy to configure, flexible as heck, runs blazingly fast, and because it's Rust I get a small portable binary with no runtime dependencies - I'm sold.  However, while Rust and actix are great, what really struck me about building this backend was how the *rust compiler* taught me how to write asynchronous code.\r\n\r\nThe trickiest part of building this was ensuring it would work between sessions - there would need to be multiple users throughout the day, from different workstations.  I decided to just persist the whole state to a shared network storage on each click, but needed to ensure writes don't conflict.\r\n\r\nNot long ago that sort of problem would have flown way over my head.  Thread-safe code is for smart, experienced people who know what they're doing!\r\n\r\nTurns out, the Rust compiler can basically do it for you.  I'd used Reference Counting types so I vaguely knew something called an [`Arc`](https://doc.rust-lang.org/std/sync/struct.Arc.html) existed.  I knew I'd need some sort of mutex, so I cracked open the standard library docs and found [`RwLock`](https://doc.rust-lang.org/std/sync/struct.RwLock.html), which sounded about right.\r\n\r\nI then...guessed:\r\n\r\n```rust\r\npub struct AppState {\r\n    pub school: Arc<RwLock<School>>,\r\n}\r\n```\r\n\r\nI replaced my regular old School type with the above, just to see if I was on the right track.\r\n\r\nNot only was I on the right track - that was pretty much *it*.  I rewrote my handlers to grab the right locks before reading and writing to and from the app state, and followed the actix docs to switch all my handlers to return Futures (which is a built-in feature of the framework - this took about ten minutes), and then fixed all the `rustc` errors.\r\n\r\nIt just friggin' *worked*.  That's *nuts*.  And now I'm no longer scared of using concurrency primitives in my Rust code.\r\n\r\n## The Frontend\r\n\r\nReact.js in 2018 is a beast.  I mean that lovingly - the ecosystem is huge and powerful and has something for every need that you can pick and choose from.\r\n\r\nStarting a brand new React project, though, having never tried any of it before?  Daunting, to say the least.  No matter what choices you make there's a nagging feeling there's something better on the next search, even though in most cases whatever you're using is just fine.  There's something about an overwhelming amount of choice available that can cause you to just freeze, or build the same beginning of a project over and over again with slightly different libraries and never finish.\r\n\r\nChoosing ReasonML allowed me to completely skip that entire process without forgoing control.  While I know and appreciate tools like `create-react-app`, trying it myself left me with a bad taste in my mouth.  It's very magical, hiding most of what it's doing to provide so much power from the user until you run `eject`.  After ejecting, though, you're left with a *lot* to sift through - too much to learn right off the bat.  I prefer to build up this sort of thing myself, ensuring I actually understand each component, so that tool didn't work for me.\r\n\r\nThe basic app you get via `bsb -init` was very no-frills.  I fully understood everything I looked at in my brand new folder and was able to start iterating immediately.  Not knowing Reason or OCaml that well didn't end up being an issue - ReasonReact maps pretty closely to regular old React!  After perhaps a day of slow progress I wasn't running into syntax errors anymore and knew where every new line of code should fit.\r\n\r\nNot to mention the fact that I didn't need to attach a state management library - it comes with `reducerComponent` built-in so you can have a Redux-ish action dispatcher instead of setState but don't have the boilerplate associated with an app-wide Redux store.  You just set up a sum type for your actions and then use them from a `reducer` method available on your `reducerComponent` like any other React lifecycle method and it's just all so easy to use.\r\n\r\nThe biggest benefit, though, was the compiler.  It's *fast* - you'll never beat it.  TypeScript and Flow aren't even close.  It's built around an industry giant of type inference so you get amazingly helpful error messages pointing you towards exactly what you're doing wrong.  What a phenomenal way to learn a new tool, with training wheels attached - almost everything I learned while building this I'll be able to carry over to a \"real\" React app, but it's like having a dedicated mentor over your shoulder calmly pointing out every stupid thing you do as you do it.  Eventually, you stop doing those things!\r\n\r\nI truly felt like ReasonReact got out of my way and let me just write the application.  It made sense to me to set up types to mirror those used on the backend.  It was trivial to deserialize the json responses into ReasonML data structures.  I loved how all of my props were fully typed by default.  The generated output is just plain old JavaScript that appears alongside your code, so it's not complicated to figure out how to bundle your final app.  There was just no friction anywhere, and at no point did I run into a question that wasn't answered clearly on the Reason or ReasonReact websites.\r\n\r\n## Your turn!\r\n\r\nGranted, I wasn't trying to do anything fancy here - but I did brush up on the interop story and even that was easy.  At no point during this project did I feel I was fighting my tools - it was always the opposite.  I do not have that experience using the mainstream tools I \"should\" be using, by a long shot.  I think I got this done faster and better than I would have with plain JS throughout, and learned more to boot.\r\n\r\nDoes anyone else have an experience like that with a tool they've used?  Any recommendations for some neat things off the beaten path that improved your quality of life?  I'd love to hear about it!",
    "title": "Rust + ReasonML - a beginner's love story"
  },
  {
    "cover_image": null,
    "date": "2018-10-29T14:57:35.513Z",
    "description": "A quick tutorial ",
    "tags": "beginners, tutorial, clojure, webdev",
    "markdown": "# Quickly set up a Clojure webserver with Boot\r\n\r\n## Boot up\r\n\r\nI have done my best to make this easy to follow even if you've never seen a line of Clojure in your life, but of course I can't talk about every facet.  Before diving in, you may want to spend some time with Chapter 3 of Clojure for the Brave and True: [Do Things](https://www.braveclojure.com/do-things/).  It's a good crash course in the syntax - there really isn't much syntax to learn, and you really don't need a ton to understand this post or start building endpoints.\r\n\r\nThe book (rightly) suggests you follow along in a [REPL](https://en.wikipedia.org/wiki/Read-eval-print_loop).  My favorite quick REPL is [planck](http://planck-repl.org), but you can do it using the tools in this project by grabbing the [Makefile](https://github.com/deciduously/example-com/blob/post1/Makefile) I discuss below, running `make deps`, and running `bin/boot repl`.  This will take a little while, especially the first time.\r\n\r\nPlease tell me at ben@deciduously.com if something needs work!\r\n\r\nThis post will be concerned with setting up a blank project.  I *highly* recommend typing everything yourself if you'd like to follow along, but there is an example [repo](https://github.com/deciduously/example-com) you can clone instead.\r\n\r\n### Dependencies\r\n\r\nIf you have a JDK, `bash`, GNU `make`, and `curl` installed, you're good to go.  If you don't, your OS/package manger will be able to help you out.  That's really it - I use `tar` and `xz` to compress releases, you can use anything you like.\r\n\r\nSetting up a `build.boot` file is very similar to setting a up `project.clj` if you've used Leiningen before.  If not, don't sweat it.  It's easy to tweak and test.\r\n\r\n### build.boot\r\n\r\nIf you've only used `lein`, initial setup is slightly but not very different.  First, set up your folder:\r\n\r\n```shell\r\nmkdir -p example-com/ && cd example-com/ && git init\r\necho \"target/\\n\" > .gitignore\r\necho \"v0.0.1\" > version.properties\r\n```\r\n\r\nI also add `.#\\n.nrepl-` to filter out emacs/cider things, you should tailor to fit.\r\n\r\nYou're welcome to procure `boot` any way you like, and may want to install it globally eventually, but you can use the following Makefile to provide a `make deps` command to install boot to the project location.  The shim is very small and just loads version you specify, latest by default, for you, and reads the users maven repository.  You can download the Makefile [here](https://github.com/deciduously/example-com/blob/post1/Makefile) or copy it below:\r\n\r\n```makefile\r\n# Makefile\r\n.PHONY: help deps\r\n\r\nSHELL       := /bin/bash\r\nexport PATH := bin:$(PATH)\r\n\r\nhelp:\r\n\t@echo \"Usage: make {deps|help}\" 1>&2 && false\r\n    \r\nbin/boot:\r\n\t(mkdir -p bin/                                                                              && \\\r\n\tcurl -fsSLo bin/boot https://github.com/boot-clj/boot-bin/releases/download/latest/boot.sh  && \\\r\n\tchmod 755 bin/boot)\r\n\r\ndeps: bin/boot\r\n```\r\n\r\nAfter installing boot, run `boot -u > boot.properties`.  Use this file to specify versions for the shim to load.\r\n\r\nIssue `touch build.boot` in the root dir of the project and open it with your favorite [editor](http://spacemacs.org).  Start with `set-env!`:\r\n\r\n```clojure\r\n;; build.boot\r\n(set-env!\r\n :source-paths #{\"src/\"}\r\n :dependencies '[[org.clojure/clojure \"1.9.0\"]\r\n                 [hiccup \"1.0.5\" :scope \"test\"]\r\n                 [pandeiro/boot-http \"0.8.3\" :scope \"test\"]])\r\n```\r\n\r\nNotably the `:dependencies` vector is quoted to pass to `set-env`, unlike for `defproject`, and you use a set for :source-paths.  I'll go over library each as we use them.\r\n\r\nSpecifying `:scope \"test\"` ensures those deps stay [out of the jar](https://www.zazzle.com/rlv/stay_out_hands_candy_cookie_jar_candy_jars-r7ec7cc8b404143a3be44e853c1d7e4ef_2ih7l_8byvr_512.jpg), which will only need to serve pre-compiled html, css, and javascript!\r\n\r\nThe license/description information is specified with the `pom` options in `task-options`:\r\n```clojure\r\n(task-options!\r\n  pom {:project 'example-com\r\n       :description \"Static website generator and server\"\r\n       :url \"http://www.example.com\"\r\n       :license {\"MIT\" \"https://mit-license.org\"}\r\n       :developers {\"you\" \"dev@example.com\"}})\r\n  \r\n(require '[pandeiro.boot-http :refer [serve]])\r\n```\r\nSet whatever `pom` options you'd like. The only necessary ones are `:project` and `:version`, which you can get from `version.properties` by adding `(second (str/split (slurp \"version.properties\") #\"=\"))` after the `(require)` form. `#\"\"` is a reader macro that compiles to a [`java.util.regex.Pattern`](https://docs.oracle.com/javase/9/docs/api/java/util/regex/Pattern.html), and `slurp` opens a reader on the file specified, returning a string with the contents.\r\n\r\nWe also pull in the `web` namespace we're going to write and the `serve` task from [`boot-http`](https://github.com/pandeiro/boot-http).\r\n\r\nNow you can add a development task:\r\n\r\n```clojure\r\n(deftask dev\r\n  \"Run live development server\"\r\n  []\r\n  (comp\r\n    (serve :handler 'example-com.web/dev-handler :reload true :port 3000)\r\n    (wait)))\r\n```\r\n\r\nAnd that's that!  Four forms.  Configuring `boot` starts off quite simple.  You compose your own build pipelines with `comp` - these are very readable and act as you expect.  This one only has the `serve` task included for now but it's easy to just add another line.\r\n\r\nNow, finally, let's make a Clojure file.  Execute `mkdir -p src/example_com/ && touch src/example_com/web.clj`, noting the underscore in the directory in place of the dash in the project name.  Then declare the namespace:\r\n\r\n```clojure\r\n;; web.clj\r\n(ns example-com.web\r\n  (:require [hiccup.core :refer [html]]))\r\n```\r\n\r\nWe just pull in the `html` function to compile Clojure vectors to html strings from [`hiccup`](https://github.com/weavejester/hiccup).\r\n\r\nThen add a very basic [Ring handler](https://github.com/ring-clojure/ring/wiki/Concepts):\r\n\r\n```clojure\r\n(defn dev-handler [req]\r\n  {:status 200\r\n   :headers {\"Content-Type\" \"text/html\"}\r\n   :body (html [:h1 \"Hello, world!\"])})\r\n```\r\n\r\nI'm deliberately reserving `core` for the `server.jar` main function - you can name the namespace whatever you like.\r\n\r\nHere's the expected output of `tree`:\r\n\r\n```shell\r\n.\r\n├── bin\r\n│   └── boot\r\n├── boot.properties\r\n├── build.boot\r\n├── Makefile\r\n├── src\r\n│   └── example_com\r\n│       └── web.clj\r\n└── version.properties\r\n\r\n3 directories, 7 files\r\n```\r\n\r\nThat's it!  Run `boot dev -h` to make sure you aren't getting any errors, and then `boot dev` will run a server on `localhost:3000`.  Be patient on first run as it gathers dependencies to your local maven repo.\r\n\r\nOnce it finishes, it will output `Started Jetty on http://localhost:3000`.  Point your browser to there and you should see:\r\n# Hello, world!\r\nIf not, double check all your syntax - you can compare against this [tagged commit](https://github.com/deciduously/example-com/releases/tag/post1).  The easiest mistake to make is switching that dash for an underscore in the project source folder.\r\n\r\nCongratulations!  You built a webserver.  Make an edit to the Clojure file and reload your browser, and verify that the changes are recompiled and served on the fly.  Use `C-c` to stop the server and go make a cup of tea -  you deserve it.  This is a great time to commit your work: `git commit -m \"Initial commit\"`.",
    "title": "Up and Running with Clojure for the Web"
  },
  {
    "cover_image": null,
    "date": "2018-10-31T11:57:03.533Z",
    "description": "a run-through of some useful Rust crates",
    "tags": "discuss, rust",
    "markdown": "# Crates I Have Known And Loved\r\n\r\nThere are many reasons I enjoy writing Rust but close to the top is how well-designed the tooling is.  As far as I'm concerned `cargo` is everything I wanted out of a package manager and then some, and you can create your own subcommands if you need.\r\n\r\n[The Book](https://doc.rust-lang.org/stable/book/2018-edition/index.html) does a fantastic job of getting you up and running, but it doesn't touch the crate ecosystem.  Now that I'm several projects deep into my Rust journey I've settled on a few \"must-haves\" that my blank projects almost always end up with.  I wish I'd had this list from the get-go - some of this functionality I had been hand-implementing for far too long before I found the solution.  If you've got some more, let me know!\r\n\r\n## `error-chain`\r\n\r\n[docs.rs](https://docs.rs/error-chain/0.12.0/error_chain/)\r\n\r\nThis is pretty much always my first addition to any project.\r\n\r\nOne of my favorite features of Rust is the `?` operator.  If an operation returns a `Result<T, E>` you can just tack a question mark on it and get the logic you usually want - a success will continue execution and a failure will early-return an `Err`.\r\n\r\nHowever, this only works if the function you're in returns the same exact type.  This often isn't the case - you may have an app-specific error type for the containing function but inside call something from `std::io` - in this case it won't work unless you're implementing error-type conversions all over the place yourself.  The `error-chain` crate lets you, well, chain errors:\r\n\r\n```rust\r\nfn get_dir_listing(dir_str: &str) -> errors::Result<Vec<PathBuf>> {\r\n    let dir_listing: Vec<PathBuf> = read_dir(dir_str)\r\n                                    .chain_err(|| \"could not read dir!\")?\r\n    //etc...\r\n}\r\n```\r\n\r\nNow my error is just a simple string, and I'll see it in the stacktrace connected to the underlying `IO::Error` that was generated!  It also provides a custom `Result<T>` type that automatically uses your error chain.  Which is nice.\r\n\r\nIn application code using strings like that generally gets the job done but for a library you'll want a more robust custom error type - this crate also provides an opinionated structure for defining one should you so choose.  I've so far been content to leave the setup completely empty - all you need is the below in your main.rs and you're good to go:\r\n\r\n```rust\r\nextern crate error_chain;\r\n\r\nmod errors {\r\n    error_chain!{}\r\n}\r\n```\r\n\r\nThen you change `main()` - this is straight from the docs:\r\n\r\n```rust\r\nfn main() {\r\n    if let Err(ref e) = run() {\r\n        error!(\"error: {}\", e);\r\n\r\n        for e in e.iter().skip(1) {\r\n            debug!(\"caused by: {}\", e);\r\n        }\r\n\r\n        if let Some(backtrace) = e.backtrace() {\r\n            trace!(\"backtrace: {:?}\", backtrace);\r\n        }\r\n\r\n        ::std::process::exit(1);\r\n    }\r\n}\r\n```\r\n\r\nIn the above snippet, `run()` is really our main function but it's properly error-chained (returns an `errors::Result`)- your whole app is covered this way.  The `if let` syntax expresses exactly the behavior we want in a concise, clear manner.\r\n\r\nJust add `use errors::*` anywhere you need.\r\n\r\n## `structopt`\r\n\r\n[docs.rs](https://docs.rs/structopt/0.2.12/structopt/)\r\n\r\nStructopt feels like cheating.  The gold standard for scaffolding command-line apps is [clap](https://clap.rs/). Structopt makes it *even easier* than `clap` already does.  It lets you write the following (from the doc link):\r\n\r\n```rust\r\n#[derive(Debug, StructOpt)]\r\n#[structopt(name = \"example\", about = \"An example of StructOpt usage.\")]\r\nstruct Opt {\r\n    /// Activate debug mode\r\n    #[structopt(short = \"d\", long = \"debug\")]\r\n    debug: bool,\r\n    /// Set speed\r\n    #[structopt(short = \"s\", long = \"speed\", default_value = \"42\")]\r\n    speed: f64,\r\n    /// Input file\r\n    #[structopt(parse(from_os_str))]\r\n    input: PathBuf,\r\n    /// Output file, stdout if not present\r\n    #[structopt(parse(from_os_str))]\r\n    output: Option<PathBuf>,\r\n}\r\n```\r\n\r\nIt will automatically generate a `clap::App` for you! The triple-slashed docstrings in the snippet will become the help line for each argument.  To compare, the below is the \"usual\" method from a project I built before I was Enlightened:\r\n\r\n```rust\r\nlet matches = App::new(\"ar-bot\")\r\n        .version(VERSION)\r\n        .author(\"deciduously <ben@deciduously.com>\")\r\n        .about(\"Batching of auto email alerts\")\r\n        .arg(\r\n            Arg::with_name(\"config\")\r\n                .short(\"c\")\r\n                .long(\"config\")\r\n                .value_name(\"CONFIG_FILE\")\r\n                .takes_value(true)\r\n                .help(\"Specify an alternate toml config file\"),\r\n        )\r\n        .arg(\r\n            Arg::with_name(\"digest\")\r\n                .short(\"d\")\r\n                .long(\"digest\")\r\n                .takes_value(false)\r\n                .help(\"Finalizes a digest with the emails in the brain. Make sure to preview first!\")\r\n        )\r\n        .arg(\r\n            Arg::with_name(\"email\")\r\n                .short(\"e\")\r\n                .long(\"email\")\r\n                .takes_value(false)\r\n                .help(\"Placeholder command for developing email functionality\"),\r\n        )\r\n        .arg(\r\n            Arg::with_name(\"preview\")\r\n                .short(\"p\")\r\n                .long(\"preview\")\r\n                .takes_value(false)\r\n                .help(\"Displays the current contents of the batch\"),\r\n        )\r\n        .arg(\r\n            Arg::with_name(\"report\")\r\n                .short(\"r\")\r\n                .long(\"report\")\r\n                .takes_value(false)\r\n                .help(\"Daily report comparing inputs to outputs for the day\"),\r\n        )\r\n        .arg(\r\n            Arg::with_name(\"verbose\")\r\n                .short(\"v\")\r\n                .multiple(true)\r\n                .help(\"Set RUST_LOG verbosity.  There are three levels: info, debug, and trace.  Repeat the flag to set level: -v, -vv, -vvv.\")\r\n        )\r\n        .get_matches();\r\n```\r\n\r\nIt's a lot more typing for the same endgame, and at the end everything is already handily stored in your `Opt` struct.  Struct-opt :)\r\n\r\n\r\n## `envy`\r\n\r\n[github](https://github.com/softprops/envy)\r\n\r\nThis crate is similar to `structopt` but for environment variables.  You define a struct and it can auto-fill it with any environment variables present:\r\n\r\n```rust\r\n#[macro_use]\r\nextern crate serde_derive;\r\nextern crate envy;\r\n\r\n#[derive(Deserialize, Debug)]\r\nstruct Config {\r\n  foo: u16,\r\n  bar: bool,\r\n  baz: String,\r\n  boom: Option<u64>\r\n}\r\n\r\nfn main() {\r\n    match envy::from_env::<Config>() {\r\n       Ok(config) => println!(\"{:#?}\", config),\r\n       Err(error) => panic!(\"{:#?}\", error)\r\n    }\r\n}\r\n```\r\n\r\nNow it will automatically read the FOO, BAR, BAZ, and BOOM env vars at runtime.\r\n\r\nIt's another task that's not necessarily difficult to do by hand but it's tedious and you're likely doing it a lot, over and over again.\r\n\r\n## `serde`\r\n\r\n\r\n[serde.rs](https://serde.rs)\r\n\r\nSerde at least to me feels so intertwined with Rust I'm sure this isn't a surprise to anyone, but it's a seriously solid solution.  Super sound, stupendously speedy.  Say that five times fast.\r\n\r\nMouthful aside, serde is a no-brainer when you need to do any serializing or deserializing, which is...usually.  I'm not even including a snippet because in most cases it can derive all the functionality you need with a single annotation, and it's not hard to hand-implement the traits yourself if you need.  It's fast and simple!\r\n\r\n## `cargo-watch`\r\n\r\n[github](https://github.com/passcod/cargo-watch)\r\n\r\nWatch your files for changes and re-run the `cargo` subcommands of your choosing with, for example, `cargo watch -x test -x run`.  I don't have anything more to say, that pretty much speaks for itself.  This is a must-have for me.\r\n\r\n## `pretty_env_logger`\r\n\r\n[github](https://github.com/seanmonstar/pretty-env-logger)\r\n\r\nThis is kind of a twofer - it's a colorful wrapper around [`env-logger`](https://docs.rs/env_logger/0.5.13/env_logger/).  I didn't start using the latter until I found this crate, though, and the colors are nice.\r\n\r\n`env-logger` allows you to set the logging output level via an environment variable.  Then you use the macros from the [`log`](https://docs.rs/log/0.4.6/log/) crate: `info!`, `warn!`, `debug!`, `trace!`.  When you run your code, only those in the level specified will display.  This is a serious step up over println debugging - you can leave your debug printouts in and then just set a \"verbose\" flag to suppress them in normal usage.\r\n\r\nI'm sure there's a better way to do this, but I've been dropping the below function into each project that uses the logging tools and it's working well enough for me:\r\n\r\n```rust\r\nfn init_logging(level: u64) -> Result<()> {\r\n    let verbosity = match level {\r\n        0 => \"warn\",\r\n        1 => \"info\",\r\n        2 => \"debug\",\r\n        3 | _ => \"trace\",\r\n    };\r\n    if verbosity == \"trace\" {\r\n        set_var(\"RUST_BACKTRACE\", \"1\");\r\n    };\r\n    set_var(\"RUST_LOG\", verbosity);\r\n    info!(\r\n        \"Attempting to set logger to {}\",\r\n        var(\"RUST_LOG\").chain_err(|| \"Failed to set verbosity level\")?\r\n    );\r\n    pretty_env_logger::init();\r\n    info!(\r\n        \"Set verbosity to {}\",\r\n        var(\"RUST_LOG\").chain_err(|| \"Failed to set verbosity level\")?\r\n    );\r\n    Ok(())\r\n}\r\n```\r\n\r\nIt simplifies the levels a little to make it easier to use with a verbosity flag that takes 0, 1, 2, or 3 levels (`-v`, `-vv`, `-vvv`), and makes sure if you've set `RUST_BACKTRACE` that you're getting the `trace` level no matter what, and will set `RUST_BACKTRACE` for you if you pass it `-vvv`.\r\n\r\n## `pretty_assertions`\r\n\r\n[github](https://github.com/colin-kiegel/rust-pretty-assertions)\r\n\r\nThis is in a similar vein as `pretty_env_logger`.  It's a drop-in replacement for `assert_eq!` with colored output.  You just add the crate, no code changes required at all.  Of course, you're a responsible developer and are using `assert_eq!` all over the place - this just makes the output a bit easier to read.\r\n\r\n## `indicatif`\r\n\r\n[link](https://github.com/mitsuhiko/indicatif)\r\n\r\nThis crate provides multiple progress bars and spinners to use in your command-line apps.  See the github README for some animated examples.\r\n\r\n## `r2d2`\r\n\r\n[docs.rs](https://docs.rs/r2d2/0.8.2/r2d2/)\r\n\r\nThis crate if likely familiar if you've done any database work, but I'll throw it in anyway because it's nice.  It's a connection pool for your database.  From the readme:\r\n\r\n> Opening a new database connection every time one is needed is both inefficient and can lead to resource exhaustion under high traffic conditions. A connection pool maintains a set of open connections to a database, handing them out for repeated use.\r\n\r\nIt's backend-agnostic and easy to drop in to your app.  An adapter exists to use it easily with the [`diesel`](https://diesel.rs) ORM.  Now instead of connecting directly to your DB when you need it, you ask for a connection from the Pool instead and it all works as expected.  I love minimal-effort drop-in performance gains, don't you?\r\n\r\n## `pest`\r\n\r\n[pest.rs](https://pest.rs)\r\n\r\nThis won't be useful in all projects, but it's my current go-to for parsing needs.  It's much easier to use than a do-it-yourself parser-combinator library like `nom`.  You define your whole grammar in a separate file.  Then in your Rust code:\r\n\r\n```rust\r\n#[derive(Parser)]\r\n#[grammar = \"grammar.pest\"]\r\nstruct GrammarParser;\r\n```\r\n\r\nAs an example, here's a small (in progress) prefix calculator's grammar:\r\n\r\n```\r\nCOMMENT = _{ \"/*\" ~ (!\"*/\" ~ ANY)* ~ \"*/\" }\r\nWHITESPACE = _{ \" \" }\r\n\r\nnum = @{ int ~ (\".\" ~ digit*)? }\r\n    int = { (\"+\" | \"-\")? ~ digit+ }\r\n    digit = { '0'..'9' }\r\n\r\nsymbol = @{ \"+\" | \"-\" | \"*\" | \"/\" | \"%\" | \"^\" | \"add\" | \"sub\" | \"mul\" | \"div\" | \"rem\" | \"pow\" | \"max\" | \"min\" | \"list\" | \"eval\" }\r\n\r\nsexpr = { \"(\" ~ expr* ~ \")\" }\r\n\r\nqexpr = { \"{\" ~ expr* ~ \"}\" }\r\n\r\nexpr = { num | symbol | sexpr | qexpr }\r\n\r\nblispr = { SOI ~ expr* ~ EOI }\r\n```\r\n\r\nAnd the corresponding code to read the parsed input:\r\n\r\n```rust\r\nfn lval_read(parsed: Pair<Rule>) -> Box<Lval> {\r\n    match parsed.as_rule() {\r\n        Rule::blispr | Rule::sexpr => {\r\n            let mut ret = lval_sexpr();\r\n            for child in parsed.into_inner() {\r\n                // here is where you skip stuff\r\n                if is_bracket_or_eoi(&child) {\r\n                    continue;\r\n                }\r\n                ret = lval_add(&ret, lval_read(child));\r\n            }\r\n            ret\r\n        }\r\n        Rule::expr => lval_read(parsed.into_inner().next().unwrap()),\r\n        Rule::qexpr => {\r\n            let mut ret = lval_qexpr();\r\n            for child in parsed.into_inner() {\r\n                if is_bracket_or_eoi(&child) {\r\n                    continue;\r\n                }\r\n                ret = lval_add(&ret, lval_read(child));\r\n            }\r\n            ret\r\n        }\r\n        Rule::num => lval_num(parsed.as_str().parse::<i64>().unwrap()),\r\n        Rule::symbol => lval_sym(parsed.as_str()),\r\n        _ => unreachable!(),\r\n}\r\n```\r\n\r\nThis library is incredibly easy to use.  I love how it maintains your grammar completely separate from your code, and the PEG format is easy to follow.  Give it a whirl!\r\n\r\n## `actix_web`\r\n\r\n[actix.rs](https://actix.rs)\r\n\r\nThis isn't so much for use in the general case, but if I'm writing a webserver this is what I reach for, without hesitation.  A lot of choice between webservers in the Rust ecosystem does boil down to personal taste, but I like how fast this one is and that it's been running on the stable branch since it launched.\r\n\r\nI haven't had the opportunity to use the actor model without the webserver, but it looks great too!\r\n\r\n## `ggez`\r\n\r\n[ggez.rs](http://ggez.rs/)\r\n\r\nThis is a game framework inspired by [LÖVE](https://love2d.org/), with a Rustier API.  It's quite easy to get up and running with - perfect for prototyping.\r\n\r\nFor a larger game I'd recommend looking at [Amethyst](https://www.amethyst.rs/).  It seems to be the most promising engine at the moment and wraps [`specs`](https://github.com/slide-rs/specs), an Entity-Component System.  `specs` is the *only* ECS I've ever personally used so I can't really compare it to anything else..but that said, I think it's nice?\r\n\r\n## svgbob\r\n\r\nThis one gets honorable mention because its just cool, not because its a library.  [Go check it out](https://ivanceras.github.io/svgbob-editor/) - it converts ASCII diagrams into SVG.\r\n\r\nIf I missed your favorite crate, holla at me below!",
    "title": "Crates I Have Known And Loved"
  },
  {
    "cover_image": null,
    "date": "2018-10-31T22:12:00.999Z",
    "description": "Asking the community their opinion on learning TypeScript first",
    "tags": "discuss, typescript, javascript, beginners",
    "markdown": "## Shiny objects\r\n\r\nAm I shooting myself in the foot by learning TypeScript without properly learning JavaScript first?\r\n\r\nWhen I started taking programming seriously I thought I wasn't interested in web development so I focused on getting productive with C and Rust and dabbling in Haskell - but rather quickly discovered that things are different now then they were in 2004 when I first tackled a website.  The web is a whole new platform and it's ridiculous to avoid it outright.  You cannot beat the portability it offers.\r\n\r\nThis kicked off a largely fruitless chain of hipster tech.  I built little prototypes in ClojureScript's Reagent, Re-Frame, and Om. I built a few Elm toys.  I tried PureScript's Halogen and Pux.  I tried `bucklescript-tea` and ReasonReact.  I built [an app](https://github.com/deciduously/impact) in [`yew`](https://github.com/DenisKolodin/yew), an experimental framework for Rust targeting WebAssembly, which, while cool tech, was definitely a weird use of time figuring out how to hook everything up for someone who'd never done it in JavaScript before - learning `yew` taught me about React before I'd ever looked at any React code.  I even spent a *ridiculous* about of time messing around with GHCJS to write my frontend code in Haskell - my poor old 2011 ThinkPad deserves a medal for that week.\r\n\r\nThe writing was on the wall, though.  If I'm going to take this industry seriously and eventually switch careers, I cannot avoid learning JavaScript.  Being able to read snippets is all well and good but I've gotta learn how it really works, and I'm not even honestly sure why I've been avoiding it in the first place.\r\n\r\nHowever, I'm still having trouble giving up my types.  My favorite of the above menagerie was Re-Frame *except for the lack of types*.  Clojure is a joy to write but a pain to debug - I still spent the *vast* majority of my development time tracking down stupid errors at runtime that I'm used to having caught for me, or sifting through opaque Java stacktraces with very little relevant info.  Part of me thinks this is a lack of experience with dynamic languages - almost everything I've used has been typed and compiled, with the sole exception of Clojure.  Which suggests I *should* invest more time in learning how not to do that.\r\n\r\nEnter TypeScript - at face value it's everything I want.  It uses ES6 constructs, so I can learn about those, and has a pretty advanced type system to boot.  It's object-oriented in a way that's more similar to the big industry-standard OOP systems - something I don't have a lot of exposure to or practice with.  All of the JavaScript bundlers and testing libraries and what have you still apply.  The way I see it, learning TypeScript well is kinda like learning both for the price of one.  All I'd need to do to adapt to a JS codebase is rip my types out.\r\n\r\nIs this disingenuous?  I'd love to hear what people who already know and use these technologies think.  Comfort-zone-wise I'm completely content to continue using TypeScript on my personal projects, and it seems more and more that it's being adopted by larger companies and frameworks.  If that's holding me back, though, I should start learning JS proper now!",
    "title": "TypeScript before JavaScript?"
  },
  {
    "cover_image": null,
    "date": "2018-11-01T16:09:50.511Z",
    "description": "My template for completing small code exercises in Clojure",
    "tags": "beginners, clojure, tutorial",
    "markdown": "Clojure is a fantastic language.  It's quite minimal - there's very little syntax to learn, and it supports absolutely any paradigm of your choosing while still offering seamless (really, seamless) interop with both the massive Java and JavaScript ecosystems.\r\n\r\nUnfortunately, though, getting going with it can be tricky and a little on the heavy side for quick experimentation.  You don't want to spin up a JVM and bootstrap the language just to run a quick function.\r\n\r\nClojureScript has a name that makes it sound like a whole separate thing but it's mostly the same exact language.  It's just hosted by JavaScript instead of Java.  One consequence of this is it becomes feasible for scripting.  You *can* do it with JVM Clojure but there's still more spin-up time than there should be.  My favorite option is called [planck](http://planck-repl.org/).\r\n\r\nIt starts almost instantly.  I've taken advantage of this to use it for language-agnostic code exercises - Advent of Code is just around the corner!  The [planck guide](http://planck-repl.org/guide-all.html) should help answer any questions, and also lists a number of very useful builtins for interacting with the shell and making network requests - you could use this instead of Python or Ruby for scripting tasks.\r\n\r\nHere's my blank template:\r\n\r\n```clojure\r\n(ns exercise.core\r\n  (:require [cljs.test :refer-macros [deftest is run-tests]]\r\n            ;[clojure.string :refer [split]] ; you can import clojure fns!\r\n            [planck.core :refer [slurp]]))\r\n\r\n;; IMPLEMENTATION\r\n\r\n(defn part1\r\n  \"Write your first function here!\"\r\n  [word]\r\n  (str \"Hello \" word)\r\n\r\n;; TESTS\r\n\r\n(deftest test-part1\r\n  (is (= (part1 \"CLJS\") \"Hello, World\")))\r\n\r\n;; RUN\r\n(defn -main []\r\n  (let [puzzle (slurp \"realinput.txt\")]\r\n    (run-tests)\r\n    (println (str \"Part 1 output: \" (part1 puzzle)))\r\n\r\n(set! *main-cli-fn* -main)\r\n\r\n```\r\n\r\nThis setup will run your tests, and then use the builtin `slurp` to read the contents of the file you give it into a string.\r\n\r\nThen you just run it!  Run `planck exercise.cljs` and watch your tests fail :)\r\n\r\nHere's an example completed exercise:\r\n\r\n```clojure\r\n(ns d4.core\r\n  (:require [cljs.test :refer-macros [deftest is run-tests]]\r\n            [clojure.string :refer [split]]\r\n            [planck.core :refer [slurp]]))\r\n\r\n;; IMPLEMENTATION\r\n\r\n(defn part1\r\n  \"Get how many times w occurs in ws\"\r\n  [w ws]\r\n  (->> ws (filter #{w}) count))\r\n\r\n(defn part2\r\n  \"Get how many anagrams of w occur in ws\"\r\n  [w ws]\r\n  (->> ws (filter #(= (sort w) (sort %))) count))\r\n\r\n(defn valid?\r\n  \"Check s for validity according to f\"\r\n  [f s]\r\n  (let [words (split s \" \")]\r\n    (->> (map #(f % words) words)\r\n         (filter #(> % 1))\r\n         (empty?))))\r\n\r\n(defn count-valid\r\n  \"Given string, returns how many lines are valid\"\r\n  [f s]\r\n  (->> (split s \"\\n\")\r\n       (filter #(valid? f %))\r\n       (count)))\r\n\r\n;; TESTS\r\n\r\n(deftest sample1\r\n  (is (valid? part1 \"aa bb cc dd ee\"))\r\n  (is (not (valid? part1 \"aa bb cc dd aa\")))\r\n  (is (valid? part1 \"aa bb cc dd aaa\")))\r\n\r\n(deftest sample2\r\n  (is (valid? part2 \"abcde fghij\"))\r\n  (is (not (valid? part2 \"abcde xyz ecdab\")))\r\n  (is (valid? part2 \"a ab abc abd abf abj\"))\r\n  (is (valid? part2 \"iiii oiii ooii oooi oooo\"))\r\n  (is (not (valid? part2 \"oiii ioii iioi iiio\"))))\r\n\r\n;; RUN\r\n\r\n(defn -main []\r\n  (let [puzzle (slurp \"d4.txt\")]\r\n    (run-tests)\r\n    (println (str \"Part 1 output: \" (count-valid part1 puzzle)))\r\n    (println (str \"Part 2 output: \" (count-valid part2 puzzle)))))\r\n\r\n(set! *main-cli-fn* -main)\r\n```\r\n\r\nHappy coding!",
    "title": "A ClojureScript exercise template"
  },
  {
    "cover_image": null,
    "date": "2018-11-02T13:47:28.021Z",
    "description": "Asking the community for opinions about gRPC",
    "tags": "explainlikeimfive, webdev, beginners",
    "markdown": "I have an app-in-progress which will use multiple frontends - a web console built with TypeScript/React, a native Android app (Java or maybe Kotlin if I feel adventurous), and a CLI (Rust) all talking to a server (Rust for now, but I'm considering a jump to Spring), with some IoT devices reporting in.  I've got bits and pieces of each of these individual components working but this is still very much in the planning stage (and ambitious - this is a long-term idea).\r\n\r\nI'd like to use the opportunity to learn how gRPC works and began looking in to [capnproto](https://capnproto.org/).  It seems like a great idea and designed to tackle this exact scenario, but starting to actually implement this is giving me pause.\r\n\r\nI feel like I am adding a *lot* of technical debt for a situation that could likely be handled just fine by a good old RESTful API.  Are the benefits going to outweigh the code weight, or do I not understand this tool well enough?  Is it worth it to build a REST version first, even though if I do decide to change down the road the switch would require significant rewrites?\r\n\r\nI can't tell if I'm running toward something because it's actually a good idea or because it looks cool and I haven't tried it yet.  I'd love to hear your thoughts!  How are you using gRPC?",
    "title": "At what point should you consider gRPC?"
  },
  {
    "cover_image": null,
    "date": "2018-11-03T18:01:01.605Z",
    "description": "A few examples of higher-order functions in Rust",
    "tags": "rust, beginners, tutorial",
    "markdown": "Rust is an imperative language but it provides many tools in the standard library which adhere to a more functional style, like the [`Iterator`](https://doc.rust-lang.org/std/iter/trait.Iterator.html) trait and its methods like `map`, `for_each`, and `filter`.  This is a quick run-down of how to define your own higher-order functions in Rust which can both take closures as parameters and return closures in such a way that you can use the two together.\r\n\r\n*edit* @theodesp rightly pointed out that these examples do not follow a purely functional style - I'm mutating the input in place.  I wrote it this way because the pure solutions are well covered in the standard library and this use case is less clear, but I've updated the [Rust Playground](https://play.integer32.com/?version=stable&mode=debug&edition=2015&gist=8639706958a3b51389474b328331d9d8) with some hand-rolled pure implementations as well for comparison.\r\n\r\nTo demonstrate these we're going to work with a 2D grid of numbers:\r\n\r\n```rust\r\ntype Grid = Vec<Vec<i32>>;\r\n\r\nfn prepare_grid(rows: i32, columns: i32) -> Grid {\r\n    let mut ret = Vec::new();\r\n    for _ in 0..rows {\r\n        let mut row = Vec::new();\r\n        for _ in 0..columns {\r\n            row.push(0i32)\r\n        }\r\n        ret.push(row);\r\n    }\r\n    ret\r\n}\r\n```\r\n\r\nThis function will initialize the grid to all `0`s:\r\n\r\n```rust\r\nfn main() {\r\n    let mut grid = prepare_grid(5, 5);\r\n    println!(\"{:?}\", grid);\r\n}\r\n// [[0, 0, 0, 0, 0], [0, 0, 0, 0, 0], [0, 0, 0, 0, 0], [0, 0, 0, 0, 0], [0, 0, 0, 0, 0]]\r\n```\r\n\r\nFor whatever nefarious (?) purposes we might have in mind for our number grid it may be useful to act on a row at a time.  We can accept a closure as a parameter using a generic data type implementing the [`Fn`](https://doc.rust-lang.org/std/ops/trait.Fn.html) trait:\r\n\r\n```rust\r\nfn map_rows<F>(grid: &mut Grid, func: F)\r\nwhere\r\n    F: Fn(&mut Vec<i32>)\r\n{\r\n    for row in grid {\r\n        func(row)\r\n    }\r\n}\r\n```\r\n\r\nNow we can, for example, increment the first element of each row:\r\n\r\n```rust\r\nmap_rows(&mut grid, |row: &mut Vec<i32>| row[0] += 1);\r\n    \r\nprintln!(\"{:?}\", grid);\r\n// [[1, 0, 0, 0, 0], [1, 0, 0, 0, 0], [1, 0, 0, 0, 0], [1, 0, 0, 0, 0], [1, 0, 0, 0, 0]]\r\n```\r\n\r\nReturning a function is a tad trickier because of how Rust manages lifetimes.  What say you wanted to decide how much to increment that first value by.  You need to return a `Fn(&mut Vec<i32>)`.  Thing is, Rust needs to calculate the lifetime of that return function at compile time.  We have to explicitly tell the compiler that this function will live as long as the input parameter lives by using a reference and assigning it the lifetime `'a`:\r\n\r\n```rust\r\nfn make_incrementer<'a>(amount:&'a i32) -> Box<Fn(&mut Vec<i32>) + 'a> {\r\n    Box::new(move |row: &mut Vec<i32>| row[0] += amount)\r\n}\r\n```\r\n\r\nWe're using the [`Box`](https://doc.rust-lang.org/std/boxed/index.html) pointer type so that `make_incrementer`'s return type's size is known at compile time, and using a `move` closure to ensure a new stack frame is allocated for the closure and we copy `amount` into it - thus escaping `make_incrementer`'s stack frame.\r\n\r\nUsing it with `map_rows` requires some changes:\r\n\r\n```rust\r\nfn map_rows2<F>(grid: &mut Grid, func: Box<F>)\r\nwhere\r\n    F: for<'a> Fn(&'a mut Vec<i32>) + ?Sized\r\n{\r\n    for row in grid {\r\n        (*func)(row)\r\n    }\r\n}\r\n``` \r\nWe now have an explicit lifetime to deal with but generally it would need to be at least as long as the whole function.  In this case the compiler will complain because it only comes into scope when the closure is called inside the function, way down in our `for` loop - clearly shorter than the whole function.  The `for<...>` syntax is a feature called a Higher-Ranked Trait Bound, which tells the compiler to explicitly calculate the *minimum* lifetime to invoke our closure instead of defining it for the whole function with `map_rows2<'a, F>(...)`, circumventing this problem.\r\n\r\nWe also need to pass the whole `Box` in as our argument because all local variables *must* be `Sized` (though apparently unsized locals are in the works).  You don't need to take ownership - `&Box<F>` is fine.  This, though, will cause Rust to freak out because now we *don't* have a `Sized` value for `F` like before.  We needed to create one in order to get `make_incrementer` to compile but we've gone and undone it all by unwrapping it.  Luckily there's an escape hatch - by adding `?Sized` we can relax that requirement.  The only other change is getting at the actual closure with `(*func)` inside our for loop.\r\n\r\nNow we can go *wild*:\r\n\r\n```rust\r\nmap_rows2(&mut grid, make_incrementer(&2));\r\n    \r\nprintln!(\"{:?}\", grid);\r\n// [[3, 0, 0, 0, 0], [3, 0, 0, 0, 0], [3, 0, 0, 0, 0], [3, 0, 0, 0, 0], [3, 0, 0, 0, 0]]\r\n// we already added 1!\r\n```\r\n\r\nNote: This example would work fine without the reference/lifetimes because our `amount` has type `i32`, which implements `Copy` - the move closure will just copy it for you.  This means you can omit them in the `map_rows2` too.  The reference is only strictly necessary if your parameter to your factory function is not `Copy` - say, a `String`.\r\n\r\n\r\nAll in all higher-order functions are definitely more cumbersome to use in Rust than in a garbage-collected functional language, but absolutely not impossible.  You just need to massage the borrow checker a little and make sure you know what exactly you're asking for!\r\n\r\nHere's the full sample on the [Rust Playground](https://play.integer32.com/?version=stable&mode=debug&edition=2015&gist=8639706958a3b51389474b328331d9d8) to tinker with.",
    "title": "Higher-Order Functions in Rust"
  },
  {
    "cover_image": null,
    "date": "2018-11-06T13:26:24.078Z",
    "description": "A call ",
    "tags": "discuss, books",
    "markdown": "There is an absolute wealth of technical knowledge found in books out there, but nobody has time to read them all.  What's on the top of your \"must-read\" list, either in your specific technology or in general?\r\n\r\nI've got three.\r\n\r\nFirst, [The Little Schemer](https://mitpress.mit.edu/books/little-schemer-fourth-edition) taught me how to think recursively more effectively than any other material I've read.  You don't come out understanding recursive solutions to a set of problems, you come out equipped to tackle any problem at all recursively.  It was a powerful experience, and a fun reading style.\r\n\r\nSecond, [Programming in Scala, 3rd edition](https://www.artima.com/shop/programming_in_scala_3ed).  This is a book about Scala but I learned a lot about programming in general from it and the author cleared up some misconceptions I'd held especially around closures.  I didn't end up going on to use Scala much but this book made me a stronger programmer.\r\n\r\nFinally, I've only just begun [Mazes for Programmers](http://www.mazesforprogrammers.com/) but it's already a blast.  It's both a nice reintroduction to Ruby and a super fun way to explore a bunch of algorithms.  The subject matter is light and not academically presented but does not mean this book isn't absolutely packed with algorithmic goodness.\r\n\r\nWhat else ya got?",
    "title": "What are your favorite books?"
  },
  {
    "cover_image": null,
    "date": "2018-11-08T18:09:09.065Z",
    "description": "How to use FormData from TypeScript",
    "tags": "explainlikeimfive, beginners, typescript, webdev",
    "markdown": "I'm trying to get in the habit of writing a post about anything that takes me more than, say, 15 minutes of trial and error and Google to get right.  Chances are I'm not the first nor the last to hit any particular roadblock.\r\n\r\nThis is both a tutorial and a request for help!\r\n\r\n*edit*: @foresthoffman provided the help I needed!  I've updated the post to include the fix.\r\n\r\nI'm working on a small toy app that needs a few controls to specify how to draw something to the canvas.  A `<form>` seems like the natural choice for this, but using the data from TypeScript proved a little bit tricky.\r\n\r\nThe MDN page on [`FormData`](https://developer.mozilla.org/en-US/docs/Web/API/FormData) suggests using syntax like the following:\r\n\r\n```javascript\r\nconst form = document.querySelector('form')\r\nconst data = new FormData(form);\r\n\r\nfor (const pair of data) {\r\n    // cool stuff\r\n}\r\n// OR\r\nfor (const pair of data.entries()) {\r\n    // cool stuff\r\n}\r\n```\r\n\r\nI had no luck with these.  Using `for..of` causes TypeScript to complain that `data` is not an iterator (I think [it is](https://developer.mozilla.org/en-US/docs/Web/API/FormData/entries), or at least in JS it can be used like one with `for...of`), or that `data` has no such property `entries`.  This makes a little more sense - it doesn't yet in all environments.  I tried tweaking my `tsconfig.json` to target `esnext` but that didn't do it, and I'd rather keep that set to `es5` anyway.  Switching to use `for..in` on `data` does what you'd expect, really - it enumerates all of the methods available on `data`:\r\n\r\n```javascript\r\nconst data = new FormData(form);\r\nfor (const entry in data) {\r\n  console.log(entry);\r\n}\r\n/*\r\nget\r\ngetAll\r\nhas\r\nset\r\nentries\r\nkeys \r\nvalues\r\nforEach\r\n*/\r\n```\r\n\r\nNeat, I guess, but not what I'm looking for!  Frustratingly, `entries` appears.  Why can I not use it?\r\n\r\nIt turns out the fix for this is subtle - you need to specifically tell TypeScript you're going to be using this method by adding `dom.iterable` to your `tsconfig.json` - it's not automatically brought in with \"dom\":\r\n\r\n```json\r\n\"lib\": [\r\n  \"dom\",\r\n  \"dom.iterable\",\r\n  \"esnext\"\r\n],\r\n```\r\n\r\nNow you can `for (let entry of data.entries())` to your heart's content!  That's still not as concise as it could be, though - in JavaScript you can just write `(let entry of data)`.  We can allow this pattern in TypeScript by adding one more line to `tsconfig.json`:\r\n\r\n```json\r\n\"downlevelIteration\": true,    \r\n```\r\n\r\nThis compiler option \"provide[s] full support for iterables in 'for-of', spread, and destructuring when targeting 'ES5' or 'ES3'.\"  Now our code can match the JS exactly!\r\n\r\nI'm leaving my workaround for posterity, because in some simple cases I'd prefer to skip the iterator and do it this way anyway.  It simply doesn't iterate at all, it looks for what it needs.  As an example, here's part of the form in question:\r\n\r\n```html\r\n<form>\r\n        <fieldset>\r\n            <legend>Choices</legend>\r\n\r\n            <input type=\"radio\" name=\"choice\" id=\"choice1\" value=\"choice1\" checked>\r\n            <label for=\"choice1\">Choice 1</label>\r\n\r\n            <input type=\"radio\" name=\"choice\" id=\"choice2\" value=\"choice2\">\r\n            <label for=\"choice2\">Choice 2</label>\r\n        </fieldset>\r\n        <button type=\"submit\">Do The Thing!</button>\r\n</form>\r\n```\r\n\r\nTo get at the user's choice, I'm using code like this:\r\n\r\n```typescript\r\nconst form = document.querySelector('form')!;\r\n\r\nform.onsubmit = (_) => {\r\n  const data = new FormData(form);\r\n  const choice = data.get('choice') as string;\r\n  doCoolThing(choice);\r\n  return false; // prevent reload\r\n};\r\n```\r\n\r\nA few TypeScript-y things to note - I'm using the `!` operator at the end of the `querySelector` call.  This is the non-null assertion operator - `querySelector` returns a value of type `Element | null`.  I prefer to keep `strictNullChecks` on, so TS doesn't enjoy me trying to operate on `form` as if it were an element - this operator tells the compiler that *I* promise there will be a form to select and it won't return null.\r\n\r\nAlso, `FormData.get()` returns a value of type `string | File | null`.  This is another case where I've quite literally just written the form myself - I *know* it's gonna be a string.  I'm using `as` to cast to the proper type.\r\n\r\nFinally, I return false to prevent the page from actually reloading - the re-draw to the canvas happens inside `doCoolThing`, and if the page reloads it'll disappear along with the form data!  I'm not sending anything to a server, just using the user input locally on the page.\r\n\r\nThis does do the trick - I can just grab the the form data I want one at a time without using the iterator to configure the output.",
    "title": "FormData in TypeScript"
  },
  {
    "cover_image": null,
    "date": "2018-11-11T12:37:40.414Z",
    "description": "What makes this place unique",
    "tags": "discuss, meta",
    "markdown": "I am consistently impressed by the respect on display here.\r\n\r\nWhat's the secret sauce?  I've never come across another online community, technical or otherwise, that can maintain this atmosphere especially as it grows.  Inflated egos mixed with the detachment of keyboards and screens between you and everyone else tend towards toxic situations despite best intentions.\r\n\r\nI've seen none of that here yet, but I have seen healthy, spirited debate with intelligent points and discussion on multiple sides.  We don't go all ad hominem, the discussion is always relevant and well-articulated, and everyone seems willing to listen as well as speak.\r\n\r\nWhat voodoo is this?  I know the Dev.to team is pleasant as all heck, and that attitude definitely trickles downward, but that can't be the whole story.  Is there a massive moderation machine at work?  Have the content contributers here simply self-selected for being nice?\r\n\r\nHow can we capture and encourage this positivity to infect other useful, technical communities that are less welcoming?\r\n\r\n",
    "title": "On The Kindness of Strangers"
  },
  {
    "cover_image": "https://thepracticaldev.s3.amazonaws.com/i/llmqtt9mhcl8ikgslbxc.jpg",
    "date": "2018-11-12T18:00:34.910Z",
    "description": "How to add a reactive canvas element to a Vue class-based component",
    "tags": "beginners, typescript, vue, webdev",
    "markdown": "# Or How I Learned to Stop Worrying and Love Custom Directives\n\nAnother in my \"stuff I got stuck on\" series!  The solution to this particular problem ended up being rather straightforward, perhaps to the point of obvious, but arriving at it was a roundabout process for me so here's hoping this is useful for someone anyway.\n\n[Vue](https://vuejs.org/) provides [directives](https://vuejs.org/v2/api/#Directives) to hook your templates to your scripts.  For most cases these are sufficient, but controlling a `canvas` element requires lower-level DOM access.  `<canvas>` does not support `v-model`, so we need some other way to pass data into the element for rendering in such a way that it can keep itself in sync with our ViewModel.\n\nAs luck would have it, they'd *thought of that*.  With [custom directives](https://vuejs.org/v2/guide/custom-directive.html) we can make our own `v-something` for our template for which we can define our own behavior.\n\nThis code is written to fit in a project created by the Vue CLI 3.0 with the \"TypeScript\" option selected and class-style component syntax.  It should be simple to use with other configurations - the meat here is the directive itself.  See the doc links for the full syntax.\n\nWe'll work with a bare minimum Single-File Class-Based Component:\n\n```vue\n<template>\n  <div class=\"rxcanvas\">\n    <span>{{ size }}</span>\n    <input type=\"range\" min=\"1\" max=\"100\" step=\"5\" id=\"size\" v-model=\"size\">\n    <label for=\"size\">- Size</label>\n    <p><canvas></canvas></p>\n  </div>\n</template>\n\n<script lang=\"ts\">\nimport { Component, Vue } from \"vue-property-decorator\";\nimport Dot from \"@/dot\"; // defined below\n\n@Component\nexport default class RxCanvas extends Vue {\n  private data() {\n    return {\n      size: 10\n    };\n  }\n\n  // computed property\n  get dot(): Dot {\n    return new Dot(this.$data.size);\n  }\n}\n</script>\n\n<style scoped>\n</style>\n\n```\n\nOur Dot class just knows to draw itself given a Canvas element for a target:\n\n```typescript\n// dot.ts\nexport default class Dot {\n    private readonly color: string = \"#000\";\n    constructor(private radius: number) { }\n    public draw(canvas: HTMLCanvasElement): void {\n        // resize canvas to dot size\n        const canvasDim = this.radius * 2;\n        canvas.width = canvasDim;\n        canvas.height = canvasDim;\n\n        // get context for drawing\n        const ctx = canvas.getContext('2d')!;\n\n        // start with a blank slate\n        ctx.clearRect(0, 0, canvas.width, canvas.height);\n\n        // find the centerpoint\n        const centerX = canvas.width / 2;\n        const centerY = canvas.height / 2;\n\n        // create the shape\n        ctx.beginPath();\n        ctx.arc(centerX, centerY, this.radius, 0, 2 * Math.PI, false);\n        ctx.fillStyle = this.color;\n        ctx.fill();\n        ctx.stroke();\n    }\n}\n```\n\nTo get the behavior we want, i.e. a properly sized and drawn-to canvas in sync with our slider input, there's a little more logic that we want to fire on each change than simply bumping a number.  We've hidden all that logic inside our `Dot` class - `Dot.draw(el)` knows how to do everything it needs.  We just need this method to automatically fire whenever there's a change.\n\nFor starters, we can throw the directive right on to the canvas element in our template - we already know what data it's concerned with:\n\n```html\n<canvas v-draw=\"dot\"></canvas>\n```\n\nIn this example, our custom directive is called `draw`.  You could name it anything you like.  All directives are prefixed `v-`.  We're passing in `\"dot\"`, which is the computed property defined on our `RxCanvas` class.  This way whenever `size` changes, this computed property will create a new Dot with the correct size.\n\nCustom directives are defined on the Vue component.  When using `vue-property-decorator`, you can place it in the decorator options:\n\n```typescript\n@Component({\n  directives: {\n    \"draw\": function(canvasElement, binding) {\n    // casting because custom directives accept an `Element` as the first parameter\n      binding.value.draw(canvasElement as HTMLCanvasElement);\n    }\n  }\n})\nexport default class RxCanvas extends Vue {\n    // data(), dot(), etc\n}\n```\n\n...and that's it!  `binding.value` contains the actual `Dot` we get from our computed property.  This syntax takes advantage of a shorthand available for directives allowing us to condense the definition and not spell out each hook we use.  Acknowledging that in most cases users of this feature will want the same logic to happen on `bind` and `update`, we just define a function with our logic for the directive instead of an object containing hook functions and it gets that behavior by default.  Without using the shorthand, you'd define this logic as following:\n\n```typescript\ndirectives: {\n    draw: {\n      bind: function(canvasElement: Element, binding: VNodeDirective) {\n        binding.value.draw(canvasElement as HTMLCanvasElement);\n      },\n      update: function(canvasElement, binding) {\n        binding.value.draw(canvasElement as HTMLCanvasElement);\n      }\n    }\n}\n```\n\nThe `bind` rule is fired exactly once on component creation, and the `update` rule will happen any time there is a change to the `VNode` instance created from the `RxCanvas` class - which includes changes to its `data`.  Spelling it out like this is verbose and repetitive - prefer the shorthand where possible.\n\nThis custom directive will only be available on your `RxCanvas` component.  If you'd like to use it on multiple components, define it globally:\n\n```typescript\n// index.ts\nVue.directive('draw': function(canvasElement, binding) {\n      binding.value.draw(canvasElement as HTMLCanvasElement);\n});\n```\n\nHuzzah!",
    "title": "Reactive Canvas with TypeScript and Vue"
  },
  {
    "cover_image": "https://thepracticaldev.s3.amazonaws.com/i/gmxpjdhz2cgv8irnpcjc.jpg",
    "date": "2018-11-14T13:32:40.699Z",
    "description": "An overview of a webapp using Rust and ClojureScript",
    "tags": "rust, clojure, beginners, webdev",
    "markdown": "# Rollin' on 20s\r\n\r\n## Why\r\n\r\nI don't see a ton of material about either of these amazing tools, especially at the beginner level, and this is a solid way to get an overview of all the important bits.\r\n\r\n## The Thing\r\n\r\nIt's a toy dice roller, hosted in this [github repo](https://github.com/deciduously/roll).  The user can submit either regular old dice rolls: `1d6, 2d10`, or define their awn aliases.  For example, you could save `3d8` to `goblin` and then just type `goblin`.  It also accepts a multiplier to repeat the roll: `2 2d6` or `27 goblin`.  Multiple commands are run in sequence: `2d9 goblin` is fine as a single command and will run both.\r\n\r\n## The Tools\r\n\r\nThe backend uses [actix_web](https://actix.rs) to connect to a [SQLite](https://sqlite.org/index.html) database for storing the aforementioned aliases.  The frontend is implemented with the [Re-Frame](https://github.com/Day8/re-frame) framework which is built on top of [Reagent](https://reagent-project.github.io/), a method of defining React components in ClojureScript.  Re-Frame provides a functional state management solution - you're on your own for that with plain Reagent (not unlike React.js).\r\n\r\n## The Journey\r\n\r\nI'm going to examine just one pathway end to end - the click to submit a roll command.  We'll assume we've got the above example alias already defined: `goblin: 3d8`.  I'm not gonna throw 27 goblins at you on your first go, though, I'm not *Satan*...let's try the command `3 goblin` and see how we fare.\r\n\r\nI'm zeroing in on Re-Frame and actix_web stuff, so some function bodies will be omitted in the interest of time.  This post managed to get pretty long anyway without digging into every line!  I'll throw in links to relevant files throughout for the full context.\r\n\r\n### Gather the input\r\n\r\nRe-Frame provides a rigid structure for defining different parts of your application.  We'll jump through a few of them, but our click's journey starts (as many do) with a textbox and a button.  All UI code is located in [views.cljs](https://github.com/deciduously/roll/blob/master/src/cljs/roll/views.cljs).\r\n\r\nReagent, if you're unfamiliar, is *awesome*.  Seriously, I'm even giving you [the link again](https://reagent-project.github.io/).  It takes a lot of ceremony out of React and distills components to their core.  Each component is a function, and it emulates [hiccup](https://github.com/weavejester/hiccup)'s syntax to allow you to define your HTML in the form of succinct Clojure vectors.\r\n\r\nYou use keywords like `:div` - a `[:div]` vector will expand to `<div></div>`.  Everything else is a child of that element.  Each vector optionally takes an options map as above, or an even quicker shorthand: `[:span#firstName.name.focus \"SPAN!\"]` expands to `<span id=\\\"firstName\\\" class=\\\"name focus\\\">SPAN!</span>`.  Lisps with all their tree-ness right out in the open like that are natural choices for representing and manipulating tree structures like the DOM.  Perfect for prototyping React apps!\r\n\r\nHere's the specific component:\r\n\r\n```clojure\r\n(defn command-input\r\n  \"Command input\"\r\n  []\r\n  [:div\r\n   \"Command: \"\r\n   [:input {:type \"text\"\r\n            :id \"field\"\r\n            :name \"cmd\"}]\r\n   [:input {:type \"button\"\r\n            :value \"Submit\"\r\n            :on-click #(re-frame/dispatch\r\n                        [::events/submit-command (-> (.getElementById js/document \"field\") .-value)])}]])\r\n```\r\n\r\nPotentially unfamiliar Clojure-ness aside, this is pretty easy to read.  When called in a Reagent tree, this funciton is a Reagent component that defines an input textboxes and a button, similar to code you'd write using any frontend tool.\r\n\r\nOur trip starts (as so many do) when the user has entered some stuff and clicks the button.  The behavior is in the click handler:\r\n\r\n```clojure\r\n#(re-frame/dispatch [::events/submit-command (-> (.getElementById js/document \"field\") .-value)])`\r\n```\r\n\r\n`#()` defines an anonymous function in Clojure.  In JavaScript this looks like `() => {/* stuff */}`.  Any arguments are `%, %2, %3` etc if used: `#(%)` => `(fn [arg1] (arg1))`.  This one doesn't have any.\r\n\r\nJS interop is dirt simple in ClojureScript.  We're calling `document.getElementById('field')`, rearranged so that Clojure-style the function is in the first position of the s-expression.  Subsequent arugments would follow `\"field\"`.  It's really that easy.  To access the value property of that element, you use the `.-value` syntax - otherwise CLJS will think you're trying to call a method `value()`.\r\n\r\nThis snippet uses the thread macro `->`, which works like a pipe.  It lets you write chained operations without nesting parens too deeply, which Lisps are notorious for.  Perhaps unnecessary with just two operations, but I find this more readable and consistency is always nice.\r\n\r\n### Enter Re-Frame\r\n\r\nThis `submit-command` event is defined along with all the other events this application deals with, in [events.cljs](https://github.com/deciduously/roll/blob/master/src/cljs/roll/events.cljs).  Nice and neat.  This is what I love so much about working with Re-Frame.  Once you get your head around the model which is not as complicated as it sounds at first it's always unambiguous where any new code should go.  It's also got one of the best READMEs on GitHub, but that's just, like, my opinion, man.\r\n\r\nNotice how we're not actually calling a function here to handle the event - we're passing a data structure containing the name of our event to `re-frame/dispatch` which is going to handle that for us in FIFO order.  Lets look at this event specifically:\r\n\r\n```clojure\r\n(re-frame/reg-event-fx\r\n ::submit-command\r\n (fn-traced [_ [_ cmd]]\r\n   {:http-xhrio {:method :get\r\n                 :uri (str \"http://localhost:8080/roll/\" (clojure.string/replace cmd #\" \" \"/\"))\r\n                 :timeout 8000\r\n                 :response-format (ajax/json-response-format {:keywords? true})\r\n                 :on-success [::save-roll]\r\n                 :on-failure [::bad-http-result]}}))\r\n```\r\n\r\nYou create an event by registering its *effects* for the dispatcher with the aptly named `reg-event-fx` function.  Notice how we just give it the name and then immediately open a `fn` - not unlike the `defn` macro.  `fn-traced` just allows this event to plug in to the excellent [re-frame-10x](https://github.com/Day8/re-frame-10x) devtools - it's just a lambda otherwise.\r\n\r\nThe arguments to the `fn` are `[cofx event]`.  We're not using any co-effects yet. We will, don't fret, but for this event I'm ignoring them with `_`.  The `event` argument is then destructured.  Remember the `event` vector?  We made it ourselves a moment ago: `[::events/submit-command (-> (.getElementById js/document \"field\") .-value)]`.  That first part is just the name of the event, which we don't need - there's another `_` - and we're storing whatever the user entered as `cmd`.\r\n\r\nThis event leverages the officially supported [http-fx](https://github.com/Day8/re-frame-http-fx) library for performing AJAX requests.  This library provides the `:http-xhrio` effect handler.  This is also very straightforward to use - you pass it an options map with the request you're making.  It's got all the parts you'd expect to need to define.\r\n\r\nOur specific `cmd` of `3 goblin` shows up in the URI, no surprises there.  We replace the space with a `/`: `http://localhost:8080/roll/3/goblins`.\r\n\r\nThis library has you specify the formats you're using - we're going JSON all the way.\r\n\r\nAlso of note is that we define both what happens on success (`200`) or on failure (anything else).  Both of these are simply other events defined in the same source file.  The Re-Frame dispatcher will call the proper follow-up once the response comes back.\r\n\r\nHowever, before we can take a look at that, we've gotta actually generate the response!  Let's head on over to the backend and take a look at that `GET /roll` handler.\r\n\r\n### Back of the House\r\n\r\nThe whole outline of our server is defined in [`main.rs`](https://github.com/deciduously/roll/blob/master/src/main.rs), beginning on line 78.\r\n\r\nActix comes with built-in support for CORS - any resource registered in this initial setup will gain the correct behavior automatically.  As with many Rust APIS, we're using a builder pattern to define the configuration of the app.  Once all the configuration is done, we finish it off with `register()`.  The resource in question is on [line 89](https://github.com/deciduously/roll/blob/dd747bb59b7d25ebe8a047d2f2d37f42e3f71bae/src/main.rs#L89):\r\n\r\n```rust\r\n.resource(\"/roll/{tail:.*}\", |r| {r.method(http::Method::GET).with(roll)})\r\n```\r\n\r\nThis defines the endpoint, specifies the method, and calls the specific handler `roll`.  `{tail:.*}` means that anything in the URL after `roll/` will be passed to the handler in the request as `tail`.  When a request hits the server, it tries each resource defined in succession.  If it matches this endpoint and method, this handler will be called from [`handlers.rs`](https://github.com/deciduously/roll/blob/master/src/handlers.rs):\r\n\r\n```rust\r\n// GET /roll/{cmd}\r\npub fn roll(req: HttpRequest) -> impl Responder {\r\n    let cmd = &req.match_info()[\"tail\"];\r\n    let cmds = ((&cmd)\r\n        .split('/')\r\n        .collect::<Vec<&str>>()\r\n        .iter()\r\n        .map(|s| s.to_string()))\r\n        .collect::<Vec<String>>();\r\n    roll_strs(&cmds)\r\n}\r\n```\r\n\r\nI find actix_web extraordinarily ergonomic.  For one, it was an early embracer of the fancy-pants `impl Trait` syntax there in the return type.  In order to work as a handler, your function just needs to return any type that implements the `Responder` trait, and `actix_web` provides many out of the box, like for `String` and even `Json` (it's got [`serde`](https://serde.rs/) baked in).  Alternatively you can implement it yourself like we're about to do.\r\n\r\nAfter getting `3/goblin` with `&req.match_info(\"tail\")`, we just turn it into `vec![\"3\", \"goblin\"]` and pass it to `roll_strs()`.  This is our return value for `roll()`, so we know whatever this function returns will implement `Responder`.\r\n\r\n### The Meat 'n' Potatoes\r\n\r\nAs promised `roll_strs()` returns a custom type, `Outcomes`, for which it's necessary to manually implement `Responder`:\r\n\r\n```rust\r\n#[derive(Serialize)]\r\npub struct Outcomes {\r\n    pub outcomes: Vec<Outcome>,\r\n}\r\n\r\npub fn roll_strs(s: &[String]) -> Outcomes {\r\n    validate_input(s).unwrap().run()\r\n}\r\n```\r\n\r\nThe custom type is just a wrapper for a `Vec<Outcome>`.  This is an Outcome:\r\n\r\n```rust\r\n#[derive(Clone, Debug, Serialize)]\r\npub struct Outcome {\r\n    roll: String,\r\n    rolls: Vec<u32>,\r\n}\r\n```\r\n\r\nThese structs define the shape of our JSON response.  The response for `3 goblin` will be shaped like this:\r\n\r\n```json\r\n{\"outcomes\":\r\n    [\r\n        {\"roll\":\"3d8\",\"rolls\":[6,1,3]},\r\n        {\"roll\":\"3d8\",\"rolls\":[7,1,8]},\r\n        {\"roll\":\"3d8\",\"rolls\":[8,1,5]}\r\n    ]\r\n}\r\n```\r\n\r\n`Responder` is not a difficult trait to implement.  It's only got one function, `respond_to`:\r\n\r\n```rust\r\nimpl Responder for Outcomes {\r\n    type Item = HttpResponse;\r\n    type Error = Error;\r\n\r\n    fn respond_to<S>(self, _req: &HttpRequest<S>) -> Result<HttpResponse, Error> {\r\n        let body = serde_json::to_string(&self)?;\r\n\r\n        Ok(HttpResponse::Ok()\r\n            .content_type(\"application/json\")\r\n            .body(body))\r\n    }\r\n}\r\n```\r\n\r\nWe can easily create `Json` from our custom types because of the `Serialize` trait we auto-derived - all it takes is `serde_json::to_string(&Outcomes)?`.  Then we build a successful `HttpResponse`, give it the expected `Content-Type`, and include our JSON string as the response body.  If we had been unable to build the json for whatever reason, the `?` at the end of `serde_json::to_string()` would have returned an `actix_web::Error` - this will also result in an `HttpResponse` going back to the user, but with an unsucessful code.\r\n\r\nFor brevity's sake I'll skip the machinery - there's nothing revolutionary about getting an `Outcome` from an input like `3d8` in Rust.  It's all housed in [`roll.rs`](https://github.com/deciduously/roll/blob/master/src/roll.rs) for the curious.\r\n\r\nFirst, though, we've gotta grab `3d8` from `goblin`, and know to roll it three times.  The body of `roll_strs` calls runs us through the goodies in [`command.rs`](https://github.com/deciduously/roll/blob/master/src/command.rs) first.  Let's take a look.\r\n\r\n### Command Parsing\r\n\r\nFirst, we `validate_input(s)`.  Here's the signature - nothing fancy in the body:\r\n\r\n```rust\r\npub fn validate_input(s: &[String]) -> io::Result<Command> {\r\n   // parsing with regular expressions\r\n}\r\n```\r\n\r\nIn short, we look at the series of strings passed in and try to return a `Command`:\r\n\r\n```rust\r\n#[derive(Debug, PartialEq)]\r\npub enum Command {\r\n    Roll(Vec<Roll>),              // One or more XdX args\r\n    Multiplier(u32, Vec<String>), // an integer repeater, and then either rolls or lookups\r\n    Lookup(Vec<String>),          // we get the roll from the db, there shouldn't be anything else\r\n}\r\n```\r\n\r\nOur `3 goblin` example got parsed  by `validate_input()` to `Command::Multiplier(3, vec![\"goblin\"])`, which will in turn run a `Lookup(\"goblin\")` three times.  Back up in `roll_strs()` we end things off by calling `run()` on the returned command.  This method returns our `Outcomes`:\r\n\r\n```rust\r\nimpl Command {\r\n    pub fn run(&self) -> Outcomes {\r\n        match self {\r\n            // a branch for each Command variant\r\n        }\r\n    }\r\n}\r\n```\r\n\r\n`Multiplier` isn't terribly interesting - it'll run the `Lookup` command here three times, and the returned `Outcomes` will contain all three results.  Let's instead jump right to (the important parts of) `Lookup`:\r\n\r\n```rust\r\nCommand::Lookup(ids) => {\r\n                let conn = DB_POOL\r\n                    .get()\r\n                    .expect(\"Could not get db conn from thread pool\");\r\n                let items = get_items(&conn);\r\n                let mut ret = Vec::new();\r\n                for id in ids {\r\n                    // look for each passed in item in the returned db items\r\n                    // if found, get an Outcome from the associated roll and push it to ret\r\n                    // log output\r\n                }\r\n                Outcomes { outcomes: ret } // return an Outcomes struct\r\n```\r\n\r\n### Goblin Hunting\r\n\r\nBefore we can interact with the database, we need to get a connection.  I'm using the [`r2d2`](https://github.com/sfackler/r2d2) crate to maintain a pool of open database connections instead of creating a new one for each request.  Here's the relevant code from [`db.rs`](https://github.com/deciduously/roll/blob/master/src/db.rs):\r\n\r\n```rust\r\nlazy_static! {\r\n    pub static ref DB_POOL: Pool = init_pool();\r\n}\r\n\r\npub type Pool = r2d2::Pool<ConnectionManager<SqliteConnection>>;\r\n\r\npub const DATABASE_URL: &str = dotenv!(\"DATABASE_URL\");\r\n\r\npub fn init_pool() -> Pool {\r\n    let manager = ConnectionManager::<SqliteConnection>::new(DATABASE_URL);\r\n    r2d2::Pool::new(manager).expect(\"failed to create pool\")\r\n}\r\n```\r\n\r\nThis is standard r2d2 boilerplate that sets up a static `DB_POOL` using the database location defined in a `.env` file in the project folder.  To grab a connection, we use `let conn = DB_POOL.get()`.  One nice thing is that when `conn` goes out of scope at the end of this block the connection will be automatically returned to the pool for us.  We don't have to do anything about it ourselves.\r\n\r\nNow we can call `get_items(&conn)` using this db connection.  I'm using the [`diesel`](https://http://diesel.rs) ORM:\r\n\r\n```rust\r\npub fn get_items(conn: &SqliteConnection) -> Items {\r\n    use schema::items::dsl::*;\r\n    let results = items\r\n        .limit(5)\r\n        .load::<Item>(conn)\r\n        .expect(\"Error loading items\");\r\n\r\n    let mut ret = Vec::new();\r\n    for item in results {\r\n        ret.push(item);\r\n    }\r\n    Items { items: ret }\r\n}\r\n```\r\n\r\nThe `Items` return type is a wrapper struct for a `Vec<Item>`.  The `Item` looks like this:\r\n\r\n```rust\r\n#[derive(Debug, Queryable, Serialize)]\r\npub struct Item {\r\n    pub id: i32,\r\n    pub title: String,\r\n    pub damage: String,\r\n}\r\n```\r\n\r\nThis exactly matches our database schema.  Diesel provides the `Queryable` trait, meaning it can marshall entries in our SQLite database to this Rust type for us automatically.  The `items` table was created with the following SQL:\r\n\r\n```sql\r\nCREATE TABLE items (\r\n       id INTEGER NOT NULL PRIMARY KEY,\r\n       title VARCHAR NOT NULL,\r\n       damage TEXT NOT NULL\r\n)\r\n```\r\n\r\nDiesel creates a DSL for us to compose queries using a Rustic API.  It's quite easy to use.\r\n\r\nThis particular example is grabbing *all* the items from the database, because the `Lookup` command may have multiple strings to look for.  This is pretty bad design (*cough* *Ben* *cough*).  I could optimize it to use syntax like this if there's only one:\r\n\r\n```rust\r\nlet results = items\r\n        .filter(title.eq(lookup_title))\r\n        .load::<Item>(conn)\r\n        .expect(\"Error loading items\");\r\n```\r\n\r\nThis would run a `SELECT * FROM items WHERE title = lookup_title`.\r\n\r\nBringing it all together, our `Lookup` for `goblin` returns something like:\r\n\r\n```rust\r\nItem {\r\n    id: 1,\r\n    title: \"goblin\",\r\n    damage: \"3d8\",\r\n}\r\n```\r\n\r\nThe rest of the `Lookup` block in `Command::run()` just grabs that damage field and executes the roll, saving the result for the response.  Here's the example output again:\r\n\r\n```json\r\n{\"outcomes\":\r\n    [\r\n        {\"roll\":\"3d8\",\"rolls\":[6,1,3]},\r\n        {\"roll\":\"3d8\",\"rolls\":[7,1,8]},\r\n        {\"roll\":\"3d8\",\"rolls\":[8,1,5]}\r\n    ]\r\n}\r\n```\r\n\r\n### Back Up Front\r\n\r\nWhew!  Rust's bit is done - having found our database entry and used our custom `Responder` implementation to send back a JSON response, we've got to display it back the the user.\r\n\r\nRecall that back in our Re-Frame event we defined both an effect for `:on-success` and `:on-failure`.  This roll was a *booming* success, so when this response comes back the Re-Frame dispatcher will trigger the `::save-roll` event back in `events.cljs`:\r\n\r\n```clojure\r\n(re-frame/reg-event-fx\r\n ::save-roll\r\n [(re-frame/inject-cofx :now) (re-frame/inject-cofx :temp-id)]\r\n (fn-traced [{:keys [db temp-id now]} [_ result]]\r\n            {:db (update db :roll-hx conj {:id temp-id :time now :result result})}))\r\n```\r\n\r\nIt's our good old friend `reg-event-fx` again, but this time there's a little bit more going on.  Remember when I mentioned and then completely dropped the concept of *co-effects*?  Before we open the lambda, we use `re-frame/inject-cofx` to add a little more data to the context `reg-event-fx` has available to work with than just the application db.  In Clojure, *eveything* is just data.  Kind of like before when the `event` passed in was just the vector we created, which could be destructured, `cofx` is just a Clojure map.  By default it contains our app's `db`, but we have the opportunity to put anything we want on it.  It's a *much* fancier name than concept, but I have to concede its a pretty accurate name.  Let's look at `:now`, the first co-effect we're injecting:\r\n\r\n```clojure\r\n(re-frame/reg-cofx\r\n :now\r\n (fn-traced [cofx _data]\r\n            (assoc cofx :now (js/Date.))))\r\n```\r\n\r\nIt looks not altogether unike `reg-event-fx`.  Essentially all it does is add a key to our `cofx` map with the key `:now`, and giving it the current date for a value.\r\n\r\nNow, instead of blowing past it with an underscore, we destructure the `cofx` as well as the `event`:\r\n\r\n```clojure\r\n[{:keys [db temp-id now]} [_ result]]\r\n```\r\n\r\nThe second part, `[_ result]`, is exactly what we did earlier with `cmd` - the first element of the vector is the name of the event (`::save-roll`), which we don't need, and `result` will hold the JSON we just generated in the backend.  The first part is our newly augmented `cofx` map.  We're specifically grabbing the values of the keys specified.  `db` is there already for us to use and represents the app state, and `now` is what we just injected - it's the current date.  `temp-id` is the other co-effect I registered - feel free to check it out in `events.cljs`.  It just allows us to assign session-local unique incrementing IDs to each incoming result by bumping an `atom` each time it's injected.\r\n\r\nThe body of this event just attaches a map containing this result along with the date and tempID our co-effects generated to the `:roll-hx` key in our app db using `conj`: `{:id temp-id :time now :result result}`.\r\n\r\n### Bringing it on home\r\n\r\nThe rest happens automagically.  That's the end of our call chain - I don't have more code to follow. We did, though, change the database.  Re-Frame's got it from here - it will handle to page re-render picking up our newly augmented `:roll-hx` because we have a component *subscribed* to it.\r\n\r\nHere's our main panel:\r\n\r\n```clojure\r\n(defn main-panel []\r\n(let [result (re-frame/subscribe [::subs/results])\r\n      error (re-frame/subscribe [::subs/error])\r\n      items (re-frame/subscribe [::subs/items])]\r\n  [:div\r\n   [:h1 \"ROLL\"]\r\n   [usage]\r\n   \"Roll history:  \" [roll-hx @result] [:br]\r\n   [command-input] [:br]\r\n   \"Items: \" [all-items @items] [:br]\r\n   [add-item] [:br]\r\n   [view-error @error] [:hr]\r\n   [footer]]))\r\n```\r\n\r\nThe component in question is `[roll-hx @result]`.  This `result` is created up in the `let` binding using `re-frame/subscribe`.  All of our subscriptions live in [`subs.cljs`](https://github.com/deciduously/roll/blob/master/src/cljs/roll/subs.cljs).  Here's `::subs/results`:\r\n\r\n```clojure\r\n(re-frame/reg-sub\r\n ::results\r\n (fn [db]\r\n   (:roll-hx db)))\r\n```\r\n\r\nCouldn't be simpler - it just returns the value of the `:roll-hx` key from our database.  When the app starts, we initialize this `db` as defined in [`db.cljs`](https://github.com/deciduously/roll/blob/master/src/cljs/roll/db.cljs):\r\n\r\n```clojure\r\n(def default-db\r\n  {:name \"re-frame\"\r\n   :roll-hx []\r\n   :items []})\r\n```\r\n\r\nOur `::save-roll` event had the effect of attaching a new map to the `:roll-hx`.  Now it looks something like:\r\n\r\n```clojure\r\n{:name \"re-frame\"\r\n   :roll-hx [{:id 0\r\n              :time (js/Date.)\r\n              :result {:outcomes [\r\n        {:roll \"3d8\" :rolls [6,1,3]},\r\n        {:roll \"3d8\" :rolls [7,1,8]},\r\n        {:roll \"3d8\" :rolls [8,1,5]}\r\n    ]]}\r\n   ]}}]\r\n   :items []})\r\n```\r\n\r\nBecause the view is subscribed to the `:roll-hx` key of our database, it will automatically redraw to display the new data.  This is nice because the component doesn't need to know about the structure of your database - it's only concerned with that particular key.  If the database structure changes as you develop, you'd change the *subscription* logic - your view doesn't need to care.\r\n\r\nThere's nothing too surprising in the actual view - it renders this data as a list.  I won't go through the whole tree, it's pretty trivial stuff - there's no state here, it simply reflects the app db.  Here's the outer layer:\r\n\r\n\r\n```clojure\r\n(defn roll-hx\r\n  \"View full roll history\"\r\n  [hx]\r\n  [:ul.hx\r\n   (for [os (reverse hx)]\r\n     ^{:key (:id os)}\r\n  [:li [outcomes os]])])\r\n```\r\n\r\nJust functions all the way down.  We did the the thing, Re-frame style!  I'll leave killing the goblins as an exercise for the reader.",
    "title": "Stalk a Click through a Re-Frame/actix_web App"
  },
  {
    "cover_image": "https://thepracticaldev.s3.amazonaws.com/i/rwta9vb9b44e38nj3i4v.png",
    "date": "2018-11-19T13:15:03.920Z",
    "description": "Build a small web game using Yew for Rust",
    "tags": "rust, webassembly, beginners, webdev",
    "markdown": "# Wumpus Season\n\nIn this post series we'll walk through recreating the classic [Hunt the Wumpus](https://en.wikipedia.org/wiki/Hunt_the_Wumpus) game in [Yew](https://github.com/DenisKolodin/yew).  The original was played at the command line, we're going to use a webpage.  Yew allows us to define our frontend in Rust.  Our app will be compiled to [WebAssembly](https://webassembly.org/) for execution.\n\nDoes this app need this?  *No.*\n\nDoes *any* app need this?  Debatable, but probably.  Hash it out in the comments!\n\nWill we do it anyway?  **HELL YES!**\n\nThis is a beginner-level tutorial - it's helpful to be familiar with reading Rust but there's nothing too fancy going on here.  Comfort in any imperative language should be sufficient.\n\nI've split this into three parts.  This first part is designed to stand alone as a useful guide for starting your own blank project.  No wumpus hunting yet, just replace the filler text with stuff appropriate for your app.  [Part 2](https://dev.to/deciduously/lets-build-a-rust-frontend-with-yew---part-2-1ech) sets up our basic UI and mechanism for moving around the cave and [Part 3](https://dev.to/deciduously/lets-build-a-rust-frontend-with-yew---part-3-ch3) discusses the game logic.\n\nEDIT: You can play the completed app [here](https://deciduously.github.io/hunt-the-wumpus/)!\n\n## Setup\n\nRust has some great tooling popping up making this compilation pipeline relatively painless.  Yew with `cargo-web` like we use is only one of already several ways to go about it.  If you like what you find here I'd recommend the [RustWasm book](https://rustwasm.github.io/book/introduction.html) next.  It walks you through building a Game of Life `<canvas>` application without using any fancy frameworks or tools - from there you can pick and choose what you need on top of it.  You get to decide how low or high level you want to get with it.  Also be sure to check out [draco](https://github.com/utkarshkukreti/draco), an alternative client-side Rust->Wasm framework.\n\nYou'll need a nightly Rust compiler.  See [rustup](https://rustup.rs/) to get started if you need to - it's easy.  You'll also need [`cargo-web`](https://github.com/koute/cargo-web): `cargo install cargo-web`.\n\nOnce you have that installed navigate to your projects directory and issue `cargo new hunt-the-wumpus` at the terminal.  Open that folder in the text editor of your choice.  We're going to start by adding just enough to get everything compiling and running.\n\nFirst lets set up our project folder to use the built-in Rust target.  Issue the following commands:\n\n```\n$ rustup override set nightly\n$ echo 'default-target = \"wasm32-unknown-unknown\"' > Web.toml\n```\n\nThis will ensure the `cargo web` command always uses the proper target.  The `rustup override` command is directory-specific - to change it globally use `rustup default nightly`. I prefer to default to stable and only use nightly when necessary.\n\nNow make your `Cargo.toml` look like the following:\n\n```toml\n[package]\nauthors = [\"Hunter Wumpfrey <hw@bottomlesspit.net>\"]\nedition = \"2018\"\nname = \"hunt-the-wumpus\"\nversion = \"0.1.0\"\n[[bin]]\nname = \"hunt\"\npath = \"src/main.rs\"\n\n[dependencies]\nstdweb = \"0.4\"\n\n[dependencies.yew]\nversion = \"0.9.2\"\n\n[lib]\nname = \"hunt_the_wumpus\"\npath = \"src/lib.rs\"\n```\n\nMost of our code is going to live in a library and the binary is just going to mount the app to the page.\n\nNext replace your `main.rs` with the following:\n\n```rust\nextern crate hunt_the_wumpus;\nextern crate yew;\n\nuse hunt_the_wumpus::Model;\nuse yew::prelude::App;\n\nfn main() {\n    yew::initialize();\n    let app: App<Model> = App::new();\n    app.mount_to_body();\n    yew::run_loop();\n}\n```\n\nThis stub will just find our mount point and attach our program to it.  Speaking of, let's create a mount point.  Issue:\n\n```\n$ mkdir static\n$ touch static/index.html\n```\n\nWe also just need a stub here.  Add the following to that file and save it:\n\n```html\n<!DOCTYPE html>\n<html lang=\"en\">\n\n<head>\n  <meta charset=\"utf-8\">\n  <meta http-equiv=\"X-UA-Compatible\" content=\"IE=edge\">\n  <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n  <meta name=\"description\" content=\"Hunt the wumpus!\">\n  <meta name=\"author\" content=\"YOU\">\n  <title>HUNT THE WUMPUS</title>\n  <link rel=\"stylesheet\" type=\"text/css\" href=\"hunt.css\">\n  <script src=\"hunt.js\"></script>\n</head>\n\n<body>\n</body>\n\n</html>\n```\n\nWe won't need that again - it just loads up our compiled JS and our stylesheet.  This `static` directory is where your favicon will go as well - I like [this one](https://www.favicon.cc/?action=icon&file_id=701981).\n\nNow, let's add the basic Yew outline - the thing we're going to render.  Issue:\n\n```\n$ touch src/lib.rs\n```\n\nFill it with the following template:\n\n```rust\nextern crate stdweb;\n#[macro_use]\nextern crate yew;\n\nuse yew::prelude::*;\n\npub struct Model {\n  arrows: u8,\n}\n\n#[derive(Debug, Clone)]\npub enum Msg {}\n\nimpl Component for Model {\n  type Message = Msg;\n  type Properties = ();\n\n  fn create(_: Self::Properties, _: ComponentLink<Self>) -> Self {\n    Model { arrows: 5 }\n  }\n\n  fn update(&mut self, _msg: Self::Message) -> ShouldRender {\n    true\n  }\n}\n\nimpl Renderable<Model> for Model {\n  fn view(&self) -> Html<Self> {\n    html! {\n        <div class=\"hunt\",>\n            <div class=\"header\",>{\"Hunt the Wumpus\"}</div>\n            <div class=\"body\",>\n              <span class=\"arrows\",>{&format!(\"Arrows: {}\", self.arrows)}</span>\n            </div>\n        </div>\n    }\n  }\n}\n```\n\nThis is what most of our components are going to look like.  This should look somewhat familiar if you've used other frontend frameworks.  There's a `Component` trait where we can define state transformations like `create` and `update` and a `Renderable<T>` trait with a JSX-like `html!` macro for defining the view.  It then draws inspiration from tools like Elm to provide a `Msg` type which will drive our events in the `update` method.  We don't have any messages to process yet, so we're just including a stub.  To start off `update` will always return `true` for `ShouldRender`, triggering a redraw.\n\nBefore we get to coding, we need to set up the rest of the build pipeline.  We're going to use [`yarn`](https://yarnpkg.com/en/) - it's a web app, after all.\n\n```\n$ yarn init\n// answer the questions\n$ yarn add -D @babel/core @babel/preset-env autoprefixer node-sass nodemon npm-run-all postcss postcss-cli rollup rollup-plugin-babel rollup-plugin-postcss rollup-plugin-uglify rollup-plugin-wasm serve\n```\n\nThen add these scripts to your `package.json`:\n\n```json\n  \"scripts\": {\n    \"build:js\": \"rollup -c\",\n    \"build:rs\": \"cargo web deploy --release\",\n    \"build:scss\": \"node-sass --include-path scss scss/hunt.scss css/hunt.css\",\n    \"build:css\": \"postcss --use autoprefixer -o static/hunt.css css/hunt.css\",\n    \"build:style\": \"run-s build:scss build:css\",\n    \"build:copy\": \"cp target/deploy/hunt.css release/ && cp target/deploy/hunt.wasm release/ && cp target/deploy/index.html release/ && cp target/deploy/favicon.ico release/\",\n    \"build\": \"run-s clean:deploy build:rs build:js build:style build:copy\",\n    \"clean:deploy\": \"rm -rf /release\",\n    \"prod\": \"run-s build serve\",\n    \"serve\": \"serve -p 8080 release\",\n    \"watch:rs\": \"cargo web start --release\",\n    \"test\": \"echo \\\"Error: no tests!\\\" && exit 1\"\n  },\n```\n\nTo set up our app-wide stylesheet, issue:\n\n```\n$ mkdir scss\n$ touch scss/hunt.scss\n```\n\nJust to make sure it's all hooked up, put the following in it:\n\n```scss\n.arrows {\n  font-weight: bold;\n}\n```\n\nNow, let's hit the big button.  Open your terminal and issue\n\n```\n$ yarn build:style\n$ yarn watch:rs\n```\n\nFinally, point your browser to `localhost:8000`.  You should see the following:\n\nHunt the Wumpus\n**Arrows: 5**\n\nWe're up and running!  The development config works.  Let's top off our `.gitignore`:\n\n```\n/target\n**/*.rs.bk\n/node_modules\nyarn-*.log\n/css\n/static/*.css\n/release\n```\n\nLet's test our our production bundle.  First create `rollup.config.js` and save the following contents:\n\n```js\nimport babel from \"rollup-plugin-babel\"\nimport uglify from \"rollup-plugin-uglify\"\n\nexport default {\n    input: './target/deploy/hunt.js',\n    output: {\n        name: 'hunt',\n        file: './release/hunt.js',\n        format: 'es',\n    },\n    plugins: [\n        babel({\n            exclude: 'node_modules/**'\n        }),\n        uglify\n    ]\n};\n```\n\nNow make sure you exit the `watch:rs` process and then try `yarn prod`.  When the build completes you should see the same output at `localhost:8080`.\n\nOnce it's all working, commit!  `git init && git commit -m \"Initial commit`.\"\n\nSee [here](https://github.com/deciduously/hunt-the-wumpus/tree/master/part1) for the full code at the end of part 1.\n\nIf you're ready to move on to the build, see [Part 2](https://dev.to/deciduously/lets-build-a-rust-frontend-with-yew---part-2-1ech).",
    "title": "Let's Build a Rust Frontend with Yew - Part 1"
  },
  {
    "cover_image": "https://thepracticaldev.s3.amazonaws.com/i/qy9lgsrochopihygaxt0.png",
    "date": "2018-11-15T13:43:58.664Z",
    "description": "A quick webscraper to generate CSVs from your pageviews",
    "tags": "rust, beginners, meta",
    "markdown": "Here's a quick 'n' dirty way to dump your new-fangled post analytics to a CSV using Rust.  You have to save the page source to `src/page.html`.  Y'know, for graphs and stuff.  Who doesn't like graphs?\r\n\r\nThis ain't polished - It was my \"one-hour-before-my-day-job-starts\" project today.  Snag the regex for your own real version, or improve this one and show me!\r\n\r\n\r\n```rust\r\nextern crate chrono;\r\nextern crate csv;\r\n#[macro_use]\r\nextern crate lazy_static;\r\nextern crate regex;\r\nextern crate select;\r\nextern crate serde;\r\n#[macro_use]\r\nextern crate serde_derive;\r\n\r\nuse chrono::prelude::*;\r\nuse regex::Regex;\r\nuse select::{\r\n    document::Document,\r\n    predicate::{Class, Name},\r\n};\r\nuse std::{\r\n    error::Error,\r\n    fs::{File, OpenOptions},\r\n};\r\n\r\nlazy_static! {\r\n    static ref NOW: DateTime<Local> = Local::now();\r\n    static ref STAT_RE: Regex = Regex::new(\".+?([0-9]+).+//.?([0-9]+).+//.?([0-9]+).+\").unwrap();\r\n}\r\n\r\n#[derive(Debug, Serialize)]\r\nstruct Record {\r\n    time: String,\r\n    title: String,\r\n    views: i32,\r\n    reactions: i32,\r\n    comments: i32,\r\n}\r\n\r\nimpl Record {\r\n    fn new(time: String, title: String, views: i32, reactions: i32, comments: i32) -> Self {\r\n        Self {\r\n            time,\r\n            title,\r\n            views,\r\n            reactions,\r\n            comments,\r\n        }\r\n    }\r\n}\r\n\r\nfn write_entries(rs: Vec<Record>, f: File) -> Result<(), Box<Error>> {\r\n    let mut wtr = csv::Writer::from_writer(f);\r\n    for r in rs {\r\n        wtr.serialize(r)?;\r\n    }\r\n    wtr.flush()?;\r\n    Ok(())\r\n}\r\n\r\nfn scrape_page(doc: &Document) -> Result<Vec<Record>, Box<Error>> {\r\n    let mut ret = Vec::new();\r\n    for node in doc.find(Class(\"dashboard-pageviews-indicator\")) {\r\n        let text = node.text();\r\n        if STAT_RE.is_match(&text) {\r\n            let title = node\r\n                .parent()\r\n                .unwrap()\r\n                .parent()\r\n                .unwrap()\r\n                .find(Name(\"a\"))\r\n                .next()\r\n                .unwrap()\r\n                .find(Name(\"h2\"))\r\n                .next()\r\n                .unwrap()\r\n                .text();\r\n            for cap in STAT_RE.captures_iter(&text) {\r\n                let r = Record::new(\r\n                    NOW.to_rfc2822(),\r\n                    title.clone(),\r\n                    cap[1].parse::<i32>()?,\r\n                    cap[2].parse::<i32>()?,\r\n                    cap[3].parse::<i32>()?,\r\n                );\r\n                ret.push(r);\r\n            }\r\n        }\r\n    }\r\n    Ok(ret)\r\n}\r\n\r\nfn run() -> Result<(), Box<Error>> {\r\n    let doc = Document::from(include_str!(\"page.html\"));\r\n    let file = OpenOptions::new()\r\n        .write(true)\r\n        .create(true)\r\n        .append(true)\r\n        .open(\"stats.csv\")?;\r\n    let entries = scrape_page(&doc)?;\r\n    write_entries(entries, file)?;\r\n    Ok(())\r\n}\r\n\r\nfn main() {\r\n    if let Err(e) = run() {\r\n        eprintln!(\"Error: {}\", e);\r\n        ::std::process::exit(1);\r\n    }\r\n}\r\n\r\n\r\n```\r\n\r\n*edit* finished off the error handling",
    "title": "Scrape your Dev.to pageviews with Rust"
  },
  {
    "cover_image": "https://thepracticaldev.s3.amazonaws.com/i/rwta9vb9b44e38nj3i4v.png",
    "date": "2018-11-19T18:26:56.882Z",
    "description": "Build a Rust client-side application with ",
    "tags": "rust, webassembly, beginners, webdev",
    "markdown": "## **PART 2**\r\n\r\nIn the first part, we set up our development environment and ensured we can compile and run our webapp.  This part starts assuming your project folder mirrors [this one](https://github.com/deciduously/hunt-the-wumpus/tree/master/part1).  Please start with [Part 1](https://dev.to/deciduously/lets-build-a-rust-frontend-with-yew---part-1-3k2o) if you have not already done so - or you can skip this one and go right to [Part 3](https://dev.to/deciduously/lets-build-a-rust-frontend-with-yew---part-3-ch3) but you'll likely need to come back through here anyway.\r\n\r\nNow we can start modelling the logic.  We'll start by defining the cave.  The traditional game is played in a cave where each room is a vertex of a regular dodecahedron:\r\n\r\n![dodecahedron](https://upload.wikimedia.org/wikipedia/commons/3/33/Dodecahedron.png)\r\n\r\nFrom each room we are connected to exactly three other rooms.\r\n\r\nTo model this we'll simply use a function to map room IDs to available exits.  This will allow us to traverse around the cave.  Place the following in `lib.rs`, above your `Model` declaration:\r\n\r\n```rust\r\nfn room_exits(id: u8) -> Option<[u8; 3]> {\r\n  match id {\r\n    1 => Some([2, 5, 8]),\r\n    2 => Some([1, 3, 10]),\r\n    3 => Some([2, 4, 12]),\r\n    4 => Some([3, 5, 14]),\r\n    5 => Some([1, 4, 6]),\r\n    6 => Some([5, 7, 15]),\r\n    7 => Some([6, 8, 17]),\r\n    8 => Some([1, 7, 11]),\r\n    9 => Some([10, 12, 19]),\r\n    10 => Some([2, 9, 11]),\r\n    11 => Some([8, 10, 20]),\r\n    12 => Some([3, 9, 13]),\r\n    13 => Some([12, 14, 18]),\r\n    14 => Some([4, 13, 15]),\r\n    15 => Some([6, 14, 16]),\r\n    16 => Some([15, 17, 18]),\r\n    17 => Some([7, 16, 20]),\r\n    18 => Some([13, 16, 19]),\r\n    19 => Some([9, 18, 20]),\r\n    20 => Some([11, 17, 19]),\r\n    _ => None\r\n  }\r\n}\r\n```\r\n\r\nNow let's store the player's current location in the `Model`:\r\n\r\n```rust\r\npub struct Model {\r\n  arrows: u8,\r\n  current_room: u8,\r\n}\r\n```\r\n\r\nDon't forget to add it to our initial model too:\r\n\r\n```rust\r\n  fn create(_: Self::Properties, _: ComponentLink<Self>) -> Self {\r\n    Model {\r\n      arrows: 5,\r\n      current_room: 1,\r\n    }\r\n  }\r\n```\r\n\r\nNow we can start adding to our UI.  We'll need a new component that will be responsible for rendering the controls.  I like keeping all of these in a folder:\r\n\r\n```\r\n$ mkdir src/components\r\n$ touch src/components/controls.rs\r\n```\r\n\r\nWe'll start with a barebones component:\r\n\r\n```rust\r\nuse yew::prelude::*;\r\n\r\npub struct Controls {\r\n    title: String,\r\n    exits: [u8; 3],\r\n}\r\n\r\npub enum Msg {}\r\n\r\n#[derive(PartialEq, Clone)]\r\npub struct Props {\r\n    pub exits: [u8; 3],\r\n}\r\n\r\nimpl Default for Props {\r\n    fn default() -> Self {\r\n        Self { exits: [0, 0, 0] }\r\n    }\r\n}\r\n\r\nimpl Component for Controls {\r\n    type Message = Msg;\r\n    type Properties = Props;\r\n\r\n    fn create(props: Self::Properties, _: ComponentLink<Self>) -> Self {\r\n        Controls {\r\n            title: \"Controls\".into(),\r\n            exits: props.exits,\r\n        }\r\n    }\r\n\r\n    fn update(&mut self, _msg: Self::Message) -> ShouldRender {\r\n        true\r\n    }\r\n}\r\n\r\nimpl Renderable<Controls> for Controls {\r\n    fn view(&self) -> Html<Self> {\r\n        html! {\r\n            <div class=(\"container\", \"container-controls\"),>\r\n                <div class=\"title\",>{&self.title}</div>\r\n                <div class=\"exits\",>{format!(\"exits: {}, {}, {}\", self.exits[0], self.exits[1], self.exits[2])}</div>\r\n            </div>\r\n        }\r\n    }\r\n}\r\n```\r\n\r\nUnlike our top-level component, this one accepts some props - we're going to pass in the exits to the room our player is in.  A couple of \"gotchas\" - take a look at the `html!` macro in the `Renderable` impl block.  We're attaching two classes to the top-level `div` - to do so, you need to wrap them up in a tuple like shown.  Also, if you're using an attribute in your tag like `<div class=\"title\",>`, you need to include that trailing comma for the macro to work.  If you don't, you might end up with a very dense error message - check for these commas before panicking.  Rust macros tend to generate pretty opaque error info - one major drawback of the tech at this point in time.\r\n\r\nAlso of note - we *must* provide a `Default` impl for our `Props`.  I'm just setting it to `[0, 0, 0]`.\r\n\r\nLet's position it within our app.  First, we have to organize our component module:\r\n\r\n```\r\n$ echo 'pub mod controls;' > src/components/mod.rs\r\n```\r\n\r\nWhen we add new components, don't forget to add the declaration to this file.  Back up in `lib.rs`, add the module directly after your `extern crate` declarations and bring it into scope:\r\n\r\n```rust\r\nmod components;\r\n\r\nuse self::components::controls::Controls;\r\n```\r\n\r\nNow we can attach it to the app.  Down in the `html!` macro let's add the component right below our `<span>` element displaying the arrows.  We'll also section off the stats printout and display the current room.  Adjust yours to match this:\r\n\r\n```rust\r\n<div class=\"hunt\",>\r\n    <div class=\"header\",>{\"Hunt the Wumpus\"}</div>\r\n    <div class=\"body\",>\r\n      <div class=(\"container\"\"container-stats\"),>\r\n        <span class=\"title\",>{\"Stats\"}</span>\r\n        <br/>\r\n        <span class=\"arrows\",>{&format!(\"Arrows: {}\", self.arrows)}</span>\r\n        <br/>\r\n        <span class=\"current-room\",>{&format!(\"Current Room: {}\"self.current_room)}</span>\r\n      </div>\r\n      <Controls: exits=room_exits(self.current_room).unwrap(),/>\r\n    </div>\r\n</div>\r\n```\r\n\r\nOnce the rebuild completes, go back to your browser and confirm you see:\r\n\r\nStats\r\n**Arrows: 5**\r\nCurrent Room: 1\r\nControls\r\nexits: 2, 5, 8\r\n\r\nPretty plain, but just what we asked for!  Before we get too far into the logic, let's give ourselves something resembling a layout.  This is just going to be a skeleton - I'm no CSS guru.  Feel free to make this whatever you like, this should be enough to get you started.\r\n\r\nReplace `scss/hunt.scss` with the following:\r\n\r\n```scss\r\n.hunt {\r\n  display: flex;\r\n  flex-direction: column;\r\n  align-items: center;\r\n  justify-content: center;\r\n  height: 100%;\r\n  width: 100%;\r\n\r\n  .header {\r\n    flex: 0;\r\n    font-size: 36px;\r\n    font-weight: bold;\r\n    text-align: center;\r\n  }\r\n  \r\n  .window {\r\n    display: flex;\r\n    flex-direction: row;\r\n  }\r\n\r\n  .container {\r\n      border: solid 1px #000;\r\n      display: flex;\r\n      flex-direction: column;\r\n      overflow: hidden;\r\n      margin: 10px;\r\n      padding: 5px;\r\n  \r\n      >.title {\r\n          border-bottom: dashed 1px #000;\r\n          font-weight: bold;\r\n          text-align: center;\r\n      }\r\n  }\r\n}\r\n```\r\n\r\nDon't forget to run `yarn build:style` to regenerate the compiled CSS.\r\n\r\nLet's also go ahead and take the opportunity to just break out the Stats out into their own component.  Make a new file `src/components/stats.rs`:\r\n\r\n```rust\r\nuse yew::prelude::*;\r\n\r\npub struct Stats {\r\n  title: String,\r\n  arrows: u8,\r\n  current_room: u8,\r\n}\r\n\r\npub enum Msg {}\r\n\r\n#[derive(PartialEq, Clone)]\r\npub struct Props {\r\n  pub arrows: u8,\r\n  pub current_room: u8,\r\n}\r\n\r\nimpl Default for Props {\r\n  fn default() -> Self {\r\n    Self {\r\n      arrows: 0,\r\n      current_room: 0,\r\n    }\r\n  }\r\n}\r\n\r\nimpl Component for Stats {\r\n  type Message = Msg;\r\n  type Properties = Props;\r\n\r\n  fn create(props: Self::Properties, _: ComponentLink<Self>) -> Self {\r\n    Stats {\r\n      title: \"Stats\".into(),\r\n      arrows: props.arrows,\r\n      current_room: props.current_room,\r\n    }\r\n  }\r\n\r\n  fn update(&mut self, _msg: Self::Message) -> ShouldRender {\r\n    true\r\n  }\r\n}\r\n\r\nimpl Renderable<Stats> for Stats {\r\n  fn view(&self) -> Html<Self> {\r\n    html! {\r\n      <div class=(\"container\", \"container-stats\"),>\r\n        <span class=\"title\",>{&self.title}</span>\r\n        <span class=\"stat\",>{&format!(\"Arrows: {}\", self.arrows)}</span>\r\n        <br/>\r\n        <span class=\"stat\",>{&format!(\"Current Room: {}\", self.current_room)}</span>\r\n      </div>\r\n    }\r\n  }\r\n}\r\n```\r\n\r\nNew we just add it to `src/components/mod.rs`:\r\n\r\n```rust\r\npub mod controls;\r\npub mod stats;\r\n```\r\n\r\nand include it in our top level component in `lib.rs`:\r\n\r\n```rust\r\nmod components;\r\n\r\nuse self::components::{controls::Controls, stats::Stats};\r\n\r\n// down to the bottom...\r\n\r\nimpl Renderable<Model> for Model {\r\n  fn view(&self) -> Html<Self> {\r\n    html! {\r\n        <div class=\"hunt\",>\r\n            <div class=\"header\",>{\"Hunt the Wumpus\"}</div>\r\n            <div class=\"window\",>\r\n              <Stats: arrows=self.arrows, current_room=self.current_room,/>\r\n              <Controls: exits=room_exits(self.current_room).unwrap(),/>\r\n            </div>\r\n        </div>\r\n    }\r\n  }\r\n}\r\n```\r\n\r\nThis gives us a simple flexbox layout that will be easy to extend.  Re-run `yarn build:css-once` and reload `localhost:8000` in your browser to make sure the new style got picked up.\r\n\r\nNow we're ready to get **interactive** with it.\r\n\r\nOur next order of business is moving around the cave.  All of our actual update logic is going to happen in our top-level component.  When we first created `lib.rs`, we just made an empty `Msg` type:\r\n\r\n```rust\r\n#[derive(Debug, Clone)]\r\npub enum Msg {}\r\n```\r\n\r\nTo switch `current_room`, we're going to send a `Msg` containing the target room. Let's add the variant first:\r\n\r\n```rust\r\n#[derive(Debug, Clone)]\r\npub enum Msg {\r\n  SwitchRoom(u8),\r\n}\r\n```\r\n\r\nNow we have to handle that message.  Inside the `impl Component for Model` block we currently have a stub for `update()`, returning `true`.  Now lets actually use the `Self::Message` parameter it accepts:\r\n\r\n```rust\r\n  fn update(&mut self, msg: Self::Message) -> ShouldRender {\r\n    match msg {\r\n      Msg::SwitchRoom(target) => {\r\n        self.current_room = target;\r\n        true\r\n      }\r\n    }\r\n  }\r\n```\r\n\r\nDon't forget to remove the underscore from `_msg` in the parameter list!\r\n\r\nThe great thing about using an `enum` for your messages is that the compiler won't let you miss any when you `match` on them - it must be exhaustive.  We also get to easily destructure the variant.  This pattern is not unlike what Elm offers.  You just need to make sure each match arm returns a boolean - or if you like, you can simply return `true` after the `match` block.  Controlling on a per-message basis may allow for more granular performance control - some messages may not require a re-render.\r\n\r\nThis message is simple - it just switches `current_room`.  Next we need to generate these messages.  Let's dive back in to `src/components/controls.rs`.  We can use `crate::Msg` to refer to the toplevel message our buttons will generate.\r\n\r\nWe can now create a message that can be passed within this component:\r\n\r\n```rust\r\npub enum Msg {\r\n    ButtonPressed(crate::Msg)\r\n}\r\n```\r\n\r\nWe also need to add the callback to our props.  Yew has a type ready to go:\r\n\r\n```rust\r\npub struct Controls {\r\n    title: String,\r\n    exits: [u8; 3],\r\n    onsignal: Option<Callback<crate::Msg>>,\r\n}\r\n\r\n#[derive(PartialEq, Clone)]\r\npub struct Props {\r\n    pub exits: [u8; 3],\r\n    pub onsignal: Option<Callback<crate::Msg>>,\r\n}\r\n\r\nimpl Default for Props {\r\n    fn default() -> Self {\r\n        Self {\r\n            exits: [0, 0, 0],\r\n            onsignal: None,\r\n        }\r\n    }\r\n}\r\n```\r\n\r\nFinally, add it to our component initalization:\r\n\r\n```rust\r\nfn create(props: Self::Properties, _: ComponentLink<Self>) -> Self {\r\n    Controls {\r\n        title: \"Controls\".into(),\r\n        exits: props.exits,\r\n        onsignal: props.onsignal,\r\n    }\r\n}\r\n```\r\n\r\nNow we can dynamically create buttons to generate our `crate::Msg`.  We already have the room targets coming in to the component - we just need a way to create a different button for each.  We can abstract this logic out with a local closure in our `view` function:\r\n\r\n```rust\r\nimpl Renderable<Controls> for Controls {\r\n    fn view(&self) -> Html<Self> {\r\n        let move_button = |target: &u8| {\r\n            use crate::Msg::*;\r\n            let t = *target;\r\n            html! {\r\n                <span class=\"control-button\",>\r\n                    <button onclick=|_| Msg::ButtonPressed(SwitchRoom(t)),>{&format!(\"Move to {}\", target)}</button>\r\n                </span>\r\n            }\r\n        };\r\n        html! {\r\n            <div class=(\"container\", \"container-controls\"),>\r\n                <div class=\"title\",>{&self.title}</div>\r\n                <div class=\"exits\",>{ for self.exits.iter().map(move_button) }</div>\r\n            </div>\r\n        }\r\n    }\r\n}\r\n```\r\n\r\nWe then map `move_button` over the exits in our state.  Another gotcha - you've got to dereference `target` outside of the `html!` macro: `let t = *target`.  If our type wasn't `Copy` like `u8`, we'd need to clone it here.\r\n\r\nNow we need to handle the message.  Let's fill in our `update`:\r\n\r\n```rust\r\nfn update(&mut self, msg: Self::Message) -> ShouldRender {\r\n    match msg {\r\n        Msg::ButtonPressed(msg) => {\r\n            if let Some(ref mut callback) = self.onsignal {\r\n                callback.emit(msg);\r\n            }\r\n        }\r\n    }\r\n    false\r\n}\r\n```\r\n\r\nNo need to re-render on the click.  We'll handle that later when the state actually changes.  We return `false` to make sure we dont waste time on an exra render.  Now we just add the prop to `lib.rs`, down in the `view` function:\r\n\r\n```rust\r\n<Controls: exits=room_exits(self.current_room).unwrap(), onsignal=|msg| msg,/>\r\n```\r\n\r\nWhen the button is clicked the `msg` will fire and our toplevel `update` will handle changing the state.  Now we can pass any message we want up as a callback.\r\n\r\nThere's one final change to make before it all works - we need to tell any component that takes `Props` what to do when those props change.  Define these  `change` functions in the `impl Component for <...>` blocks of these respective components:\r\n\r\nFirst, `controls.rs`:\r\n\r\n```rust\r\nfn change(&mut self, props: Self::Properties) -> ShouldRender {\r\n    self.exits = props.exits;\r\n    self.onsignal = props.onsignal;\r\n    true\r\n}\r\n```\r\n\r\nThen `stats.rs`:\r\n\r\n```rust\r\nfn change(&mut self, props: Self::Properties) -> ShouldRender {\r\n  self.arrows = props.arrows;\r\n  self.current_room = props.current_room;\r\n  true\r\n}\r\n```\r\n\r\nNow make sure your `yarn watch:rs` watcher is running and open up `localhost:8000`.  You should be able to use the buttons to \"explore\" the maze.\r\n\r\nTo keep track of where we've been, let's display a running history for the player.  First, we'll add a field to our toplevel state in `lib.rs`:\r\n\r\n```rust\r\npub struct Model {\r\n  arrows: u8,\r\n  current_room: u8,\r\n  messages: Vec<String>,\r\n}\r\n\r\nimpl Component for Model {\r\n   // ..\r\n    fn create(_: Self::Properties, _: ComponentLink<Self>) -> Self {\r\n    Model {\r\n      arrows: 5,\r\n      current_room: 1,\r\n      messages: Vec::new(),\r\n    }\r\n  }\r\n  // ..\r\n}\r\n```\r\n\r\nWe'll add a new component in a new file `src/components/messages.rs`:\r\n\r\n```rust\r\nuse yew::prelude::*;\r\n\r\npub struct Messages {\r\n  title: String,\r\n  messages: Vec<String>,\r\n}\r\n\r\npub enum Msg {}\r\n\r\n#[derive(PartialEq, Clone)]\r\npub struct Props {\r\n  pub messages: Vec<String>,\r\n}\r\n\r\nimpl Default for Props {\r\n  fn default() -> Self {\r\n    Props {\r\n      messages: Vec::new(),\r\n    }\r\n  }\r\n}\r\n\r\nimpl Component for Messages {\r\n  type Message = Msg;\r\n  type Properties = Props;\r\n\r\n  fn create(props: Self::Properties, _: ComponentLink<Self>) -> Self {\r\n    Messages {\r\n      title: \"Messages\".into(),\r\n      messages: props.messages,\r\n    }\r\n  }\r\n\r\n  fn update(&mut self, _msg: Self::Message) -> ShouldRender {\r\n    true\r\n  }\r\n\r\n  fn change(&mut self, props: Self::Properties) -> ShouldRender {\r\n    self.messages = props.messages;\r\n    true\r\n  }\r\n}\r\n\r\nimpl Renderable<Messages> for Messages {\r\n  fn view(&self) -> Html<Self> {\r\n    let view_message = |message: &String| {\r\n      html! {\r\n          <li>{message}</li>\r\n      }\r\n    };\r\n    html! {\r\n        <div class=(\"container\", \"container-messages\"),>\r\n            <div class=\"title\",>{&self.title}</div>\r\n            <div class=\"scroller\",>\r\n                <ul>{ for self.messages.iter().rev().map(view_message) }</ul>\r\n            </div>\r\n        </div>\r\n    }\r\n  }\r\n}\r\n```\r\n\r\nWe're showing the messages in reverse - otherwise, this isn't too different from `controls.rs`.  Protip - I use a snippet something like this when I'm starting a new component!\r\n\r\nDon't forget to add it to `src/components/mod.rs`:\r\n\r\n```rust\r\npub mod controls;\r\npub mod messages;\r\npub mod stats;\r\n```\r\n\r\nAnd add it to `lib.rs`:\r\n\r\n```rust\r\nuse self::components::{controls::Controls, messages::Messages, stats::Stats};\r\n\r\n// ..\r\n\r\nimpl Renderable<Model> for Model {\r\n  fn view(&self) -> Html<Self> {\r\n    html! {\r\n        <div class=\"hunt\",>\r\n            <div class=\"header\",>{\"Hunt the Wumpus\"}</div>\r\n            <div class=\"window\",>\r\n              <Stats: arrows=self.arrows, current_room=self.current_room,/>\r\n              <Controls: exits=room_exits(self.current_room).unwrap(), onsignal=|msg| msg,/>\r\n            </div>\r\n            <Messages: messages=&self.messages,/> // add it down here\r\n        </div>\r\n    }\r\n  }\r\n}\r\n```\r\n\r\nNow let's add a little style in `scss/hunt.scss`.  Add the following below the `>.title` block inside the `.container` block:\r\n\r\n```scss\r\n>.scroller {\r\n    overflow: auto;\r\n}\r\n```\r\n\r\nand then add right at the end:\r\n\r\n```scss\r\n.hunt {\r\n// ..\r\n  .container-messages {\r\n    flex: 0 0 192px;\r\n    ul {\r\n      list-style-type: none;\r\n    }\r\n  }\r\n}\r\n```\r\n\r\nTo pull in the changes, run `yarn build:style`.\r\n\r\nNow let's add some messages!  We can welcome the player to their likely doom when the game initiates in `lib.rs`:\r\n\r\n```rust\r\nfn create(_: Self::Properties, _: ComponentLink<Self>) -> Self {\r\n  let mut ret = Model {\r\n    arrows: 5,\r\n    current_room: 1,\r\n    messages: Vec::new(),\r\n  };\r\n  ret.messages.push(\r\n    \"You've entered a clammy, dark cave, armed with 5 arrows.  You are very cold.\".to_string(),\r\n  );\r\n  ret\r\n}\r\n```\r\n\r\nWe'll also log each move:\r\n\r\n```rust\r\n  fn update(&mut self, msg: Self::Message) -> ShouldRender {\r\n    match msg {\r\n      Msg::SwitchRoom(target) => {\r\n        self.current_room = target;\r\n        self.messages.push(format!(\"Moved to room {}\", target));\r\n        true\r\n      }\r\n    }\r\n  }\r\n```\r\n\r\nNifty!  Our cave isn't terribly interesting though.  There's some low-hanging fruit, here - there's gotta be a wumpus to hunt!\r\n\r\nJoin me in [Part 3](https://dev.to/deciduously/lets-build-a-rust-frontend-with-yew---part-3-ch3) to make a game out of this treacherous dodecacave.\r\n\r\nTo compare, here's the completed [part 2](https://github.com/deciduously/hunt-the-wumpus/tree/master/part2) code.",
    "title": "Let's Build a Rust Frontend with Yew - Part 2"
  },
  {
    "cover_image": "http://blog.buildingengines.com/wp-content/uploads/2016/02/work-pileup_teaser.jpg",
    "date": "2018-11-16T18:48:16.161Z",
    "description": "Tell me how you use GitHub",
    "tags": "discuss, beginners",
    "markdown": "My GitHub profile is *full of crap*.  I've noticed this is not actually the case with a lot of profiles I snoop.\r\n\r\nAm I doing it wrong?\r\n\r\nI regularly use my home desktop computer, my crappy laptop, and my employer-assigned workstation to hack on the same code.  I use GitHub constantly - pretty much every scrap of code I write will end up there because it's convenient to not have to think about where the project is stored.  It's also nice to know I can pretty much fearlessly wipe my HD - my projects and dotfiles are safe and sound.\r\n\r\nI also like the little bit of gamification - it's good motivation to keep my commit streak up because otherwise I'm stuck remembering how useless I was that one gray day for a *whole year*.  This habit leads to a pretty solid-looking commit grid, but a lot of the code is throwaway quality, or experiments that I wanted to continue at home after leaving work, projects I don't intend to finish, things like that.  It's definitely not all portfolio material.\r\n\r\nA lot of folks seem to only put polished code up, code they'd want to show others or for which they are actively soliciting contributions.  \r\n\r\nWhere do you stand on publishing unpolished code?  Yes, I'm airing my dirty laundry to some extent, but it's not like I have any shame - and do people really go and sift through old crap on other people's\r\n profiles?  Does it reflect poorly on my habits?",
    "title": "How do you use GitHub?"
  },
  {
    "cover_image": "https://thepracticaldev.s3.amazonaws.com/i/rwta9vb9b44e38nj3i4v.png",
    "date": "2018-11-20T00:10:40.861Z",
    "description": "Adding game logic to a Yew skeleton app",
    "tags": "rust, webassembly, beginners, webdev",
    "markdown": "## Game On\r\n\r\nThis is the third and final part of a 3 part series.  This post starts off with a project that looks something like [this](https://github.com/deciduously/hunt-the-wumpus/tree/master/part2).  Here are links for [Part 1](https://dev.to/deciduously/lets-build-a-rust-frontend-with-yew---part-1-3k2o) and [Part 2](https://dev.to/deciduously/lets-build-a-rust-frontend-with-yew---part-2-1ech) if you need to catch up.\r\n\r\nPart 2 left us with a cave we can wander around, but not much in the way of danger.  The name of the game is \"Hunt the Wumpus\" and there's nary a wumpus in sight!\r\n\r\nOpen up `src/lib.rs`.  Let's add one to our `Model`:\r\n\r\n```rust\r\npub struct Model {\r\n  arrows: u8,\r\n  current_room: u8,\r\n  messages: Vec<String>,\r\n  wumpus: u8,\r\n}\r\n```\r\n\r\nWe need a placeholder starting position - there is no room 0, our cave rooms are 1-indexed:\r\n\r\n```rust\r\nfn create(_: Self::Properties, _: ComponentLink<Self>) -> Self {\r\n  let mut rng = thread_rng();\r\n  let mut ret = Model {\r\n    arrows: 5,\r\n    current_room: 1,\r\n    messages: Vec::new(),\r\n    wumpus: 0,\r\n  };\r\n  // ..\r\n}\r\n```\r\n\r\nWe'll place him in a moment.  That's not quite scary enough, though.  In addition to the ravenous monstrosity loafing about there are two gigantic bats.  If you end up in a room with a bat, it'll quite literally sweep you off your feet and deposit you elsewhere in the cave.\r\n\r\nNow we're gonna crank the horror up to eleven.  Forget the two chaos-inducing hellbats.  There are also two rooms that are bottomless pits.  What the flip, man. **Bottomless**.  You'll die of thirst, after three days of falling.  Gives me the crimineys, I'll tell you hwat.\r\n\r\nWe'll keep track of them too:\r\n\r\n```rust\r\npub struct Model {\r\n  arrows: u8,\r\n  current_room: u8,\r\n  messages: Vec<String>,\r\n  wumpus: u8,\r\n  bats: [u8; 2],\r\n  pits: [u8; 2],\r\n}\r\n```\r\n\r\nLet's go ahead and implement `Default` for `Model` with some zeros for everything that we can configure later:\r\n\r\n```rust\r\nimpl Default for Model {\r\n  fn default() -> Self {\r\n    Self {\r\n      arrows: 5,\r\n      current_room: 1,\r\n      messages: Vec::new(),\r\n      wumpus: 0,\r\n      bats: [0, 0],\r\n      pits: [0, 0],\r\n    }\r\n  }\r\n}\r\n```\r\n\r\nTo place the horribleness, we'll use a helper function that will generate random numbers avoiding a list that we specify.\r\n\r\nWe're going to call out out to JS to generate the random number.  First add the `#[macro_use]` annotation to the `extern crate stdweb` line in `lib.rs`:\r\n\r\n```rust\r\n#[macro_use]\r\nextern crate stdweb;\r\n#[macro_use]\r\nextern crate yew;\r\n```\r\n\r\nI don't want to clutter up `lib.rs` too much, so lets create a file called `src/util.rs`:\r\n\r\n```rust\r\nuse stdweb::unstable::TryInto;\r\n\r\npub fn js_rand(bottom: u8, top: u8) -> u8 {\r\n  let rand = js! { return Math.random(); };\r\n  let base: f64 = rand.try_into().unwrap();\r\n  (base * top as f64).floor() as u8 + bottom\r\n}\r\n\r\npub fn gen_range_avoiding(bottom: u8, top: u8, avoid: Vec<u8>) -> u8 {\r\n  let mut ret = avoid[0];\r\n  while avoid.contains(&ret) {\r\n    ret = js_rand(bottom, top);\r\n  }\r\n  ret\r\n}\r\n```\r\n\r\nThe `js_rand` function wraps up our interop so we deal with Rust types as much as we can - we only need JS for the entropy. The helper `gen_range_avoiding` will give us back a `u8` that doesn't appear in `avoid`.\r\n\r\nWe can also move `room_exits` from `lib.rs` into this file and mark it `pub`.  Don't forget to add it to the top of `lib.rs`:\r\n\r\n```rust\r\nmod components;\r\nmod util;\r\n\r\nuse self::{\r\n  components::{controls::Controls, messages::Messages, stats::Stats},\r\n  util::*,\r\n};\r\n```\r\n\r\nTo make this utility easier to use, let's give `Model` a method for it in `lib.rs`, along with a `configure_cave()` method to initiate our world and place all of our sadistic traps:\r\n\r\n```rust\r\nimpl Model {\r\n  fn configure_cave(&mut self) {\r\n    self.messages.push(\r\n      \"You've entered a clammy, dark cave, armed with 5 arrows.  You are very cold.\".to_string(),\r\n    );\r\n    self.wumpus = js_rand(1, 20);\r\n    self.bats[0] = self.get_empty_room();\r\n    self.bats[1] = self.get_empty_room();\r\n    self.pits[0] = self.get_empty_room();\r\n    self.pits[1] = self.get_empty_room();\r\n    self.warning_messages();\r\n  }\r\n\r\n  fn get_empty_room(&self) -> u8 {\r\n    gen_range_avoiding(\r\n      0,\r\n      20,\r\n      vec![\r\n        self.current_room,\r\n        self.wumpus,\r\n        self.bats[0],\r\n        self.bats[1],\r\n        self.pits[0],\r\n        self.pits[1],\r\n      ],\r\n    )\r\n  }\r\n}\r\n```\r\n\r\nNow we can rewrite our `create` function:\r\n\r\n```rust\r\nfn create(_: Self::Properties, _: ComponentLink<Self>) -> Self {\r\n  let mut ret = Model::default();\r\n  ret.configure_cave();\r\n  ret\r\n}\r\n```\r\n\r\nWith all this danger lurking around every corner, we should give the player a few warnings as they're stepping around.\r\n\r\nLet's add another method to `Model` to sniff around our surroundings.  If any of our adjacent rooms has a hazard, we'll alert the player with a spooky message.  Add this to the `impl Model` block:\r\n\r\n```rust\r\nfn warning_messages(&mut self) {\r\n  for adj in &room_exits(self.current_room).unwrap() {\r\n    let t = *adj;\r\n    if self.wumpus == t {\r\n      self\r\n        .messages\r\n        .push(\"You smell something horrific and rancid.\".into());\r\n    } else if self.pits.contains(&t) {\r\n      self\r\n        .messages\r\n        .push(\"You feel a cold updraft from a nearby cavern.\".into());\r\n    } else if self.bats.contains(&t) {\r\n      self\r\n        .messages\r\n        .push(\"You hear a faint but distinct flapping of wings.\".into());\r\n    }\r\n  }\r\n}\r\n```\r\n\r\nWe can check for nearby hazards whenever we move:\r\n\r\n```rust\r\nfn update(&mut self, msg: Self::Message) -> ShouldRender {\r\n  match msg {\r\n    Msg::SwitchRoom(target) => {\r\n      self.current_room = target;\r\n      self.messages.push(format!(\"Moved to room {}\", target));\r\n      self.warning_messages();\r\n      true\r\n    }\r\n  }\r\n}\r\n```\r\n\r\nBefore we start dealing with larger level states, let's go ahead and abstract out our `Game` from our `Model`.  Create a new file called `src/game.rs`.  We're going to pull a lot of the logic we had defined on `Model` and put it here instead.\r\n\r\n```rust\r\nuse crate::util::*;\r\n\r\npub struct Game {\r\n  pub arrows: u8,\r\n  pub current_room: u8,\r\n  pub messages: Vec<String>,\r\n  pub wumpus: u8,\r\n  bats: [u8; 2],\r\n  pits: [u8; 2],\r\n}\r\n\r\nimpl Game {\r\n  fn configure_cave(&mut self) {\r\n    self.messages.push(\r\n      \"You've entered a clammy, dark cave, armed with 5 arrows.  You are very cold.\".to_string(),\r\n    );\r\n    self.wumpus = js_rand(1, 20);\r\n    self.bats[0] = self.get_empty_room();\r\n    self.bats[1] = self.get_empty_room();\r\n    self.pits[0] = self.get_empty_room();\r\n    self.pits[1] = self.get_empty_room();\r\n    self.warning_messages();\r\n  }\r\n\r\n  fn get_empty_room(&self) -> u8 {\r\n    gen_range_avoiding(\r\n      0,\r\n      20,\r\n      vec![\r\n        self.current_room,\r\n        self.wumpus,\r\n        self.bats[0],\r\n        self.bats[1],\r\n        self.pits[0],\r\n        self.pits[1],\r\n      ],\r\n    )\r\n  }\r\n\r\n  pub fn warning_messages(&mut self) {\r\n    for adj in &room_exits(self.current_room).unwrap() {\r\n      let t = *adj;\r\n      if self.wumpus == t {\r\n        self\r\n          .messages\r\n          .push(\"You smell something horrific and rancid.\".into());\r\n      } else if self.pits.contains(&t) {\r\n        self\r\n          .messages\r\n          .push(\"You feel a cold updraft from a nearby cavern.\".into());\r\n      } else if self.bats.contains(&t) {\r\n        self\r\n          .messages\r\n          .push(\"You hear a faint but distinct flapping of wings.\".into());\r\n      }\r\n    }\r\n  }\r\n}\r\n\r\nimpl Default for Game {\r\n  fn default() -> Self {\r\n    let mut ret = Self {\r\n      arrows: 5,\r\n      current_room: 1,\r\n      messages: Vec::new(),\r\n      wumpus: 0,\r\n      bats: [0, 0],\r\n      pits: [0, 0],\r\n    };\r\n    ret.configure_cave();\r\n    ret\r\n  }\r\n}\r\n```\r\n\r\nBring everything into scope in `lib.rs`:\r\n\r\n```rust\r\nmod components;\r\nmod game;\r\nmod util;\r\n\r\nuse self::{\r\n  components::{controls::Controls, messages::Messages, stats::Stats},\r\n  game::Game,\r\n  util::*,\r\n};\r\n```\r\n\r\nWe also moved the \"new game\" setup into the `Default` implementation. We're going to have to make some changes to `lib.rs`.  First, we're going to define a few different types of `Model` we want to be able to render.  Change your `struct` to this `enum`:\r\n\r\n```rust\r\npub enum Model {\r\n  Waiting(String),\r\n  Playing(Game),\r\n}\r\n```\r\n\r\nNow we have a gamestate for when there isn't an active game.  You can remove the old `impl Model` block - that logic ll ended up in `game.rs`.  When the app starts, we're waiting to start a new game:\r\n\r\n```rust\r\nimpl Default for Model {\r\n  fn default() -> Self {\r\n    Model::Waiting(\"New Game!\".into())\r\n  }\r\n}\r\n\r\nimpl Component for Model {\r\n  // ..\r\n  fn create(_: Self::Properties, _: ComponentLink<Self>) -> Self {\r\n    Model::default()\r\n  }\r\n  // ..\r\n```\r\n\r\nWe need a message to kick off a new game:\r\n\r\n```rust\r\n#[derive(Debug, Clone)]\r\npub enum Msg {\r\n  StartGame,\r\n  SwitchRoom(u8),\r\n}\r\n```\r\n\r\nThis will require a few changes to our `update` function too.  We have a new message to handle, and we need to do some extra checking to make sure we're in a gamestate that makes sense:\r\n\r\n```rust\r\nfn update(&mut self, msg: Self::Message) -> ShouldRender {\r\n  use self::Msg::*;\r\n  match msg {\r\n    SwitchRoom(target) => match self {\r\n      Model::Playing(game) => {\r\n        game.current_room = target;\r\n        game.warning_messages();\r\n      }\r\n      _ => unreachable!(),\r\n    },\r\n    StartGame => *self = Model::Playing(Game::default()),\r\n  }\r\n  true\r\n}\r\n```\r\n\r\nWe've now got to make sure we're playing a game before switching rooms but we can send the `StartGame` message to reroll the gamestate at any time.\r\n\r\nFinally, we add a match arm for each game state in our `view`:\r\n\r\n```rust\r\nimpl Renderable<Model> for Model {\r\n  fn view(&self) -> Html<Self> {\r\n    use self::Model::*;\r\n\r\n    match self {\r\n      Waiting(s) => html! {\r\n        <div class=\"hunt\",>\r\n          <span class=\"over-message\",>{s}</span>\r\n          <button onclick=|_| Msg::StartGame,>{\"Play Again\"}</button>\r\n        </div>\r\n      },\r\n      Playing(game) => html! {\r\n          <div class=\"hunt\",>\r\n              <div class=\"header\",>{\"Hunt the Wumpus\"}</div>\r\n              <div class=\"window\",>\r\n                <Stats: arrows=game.arrows, current_room=game.current_room,/>\r\n                <Controls: exits=room_exits(game.current_room).unwrap(), onsignal=|msg| msg,/>\r\n              </div>\r\n              <Messages: messages=&game.messages,/>\r\n          </div>\r\n      },\r\n  }\r\n}\r\n```\r\n\r\nEach state has it's own `html!` macro to render.  For good measure, add a little style just below the final closing brace in `hunt.scss`:\r\n\r\n```rust\r\n.over-message {\r\n  font-size: 22px;\r\n  color: red;\r\n}\r\n```\r\n\r\nOver in `game.rs` lets flesh out everything that we want to check on a move end.  Add a new method in our `impl Game` block:\r\n\r\n```rust\r\npub fn move_effects(&mut self) -> Option<String> {\r\n  self.warning_messages();\r\n  if self.current_room == self.wumpus {\r\n    Some(\"You have been eaten slowly and painfully by the wumpus\".into())\r\n  } else if self.pits.contains(&self.current_room) {\r\n    Some(\r\n      \"You have fallen into a bottomless pit and must now wait to die, falling all the while\"\r\n        .into(),\r\n    )\r\n  } else if self.bats.contains(&self.current_room) {\r\n    // Switch us to a random room\r\n    let current = self.current_room;\r\n    let next = self.get_empty_room();\r\n    self.messages.push(format!(\r\n      \"A gigantic bat whisks you from room {} to room {} before you can even blink\",\r\n      current, next\r\n    ));\r\n    self.current_room = next;\r\n    self.warning_messages();\r\n    None\r\n  } else {\r\n    None\r\n  }\r\n}\r\n```\r\n\r\nNow we've got some actual behavior!  If we run into the wumpus or a bottomless pit, we die.  If we hit a bat, `current_room` will get a new random value, and we get a new set of warnings for our new location.\r\n\r\nI'm having this function return an `Option<String>`.  We'll use this to decide if we want to end the game - a `None` will indicate the game should continue, and a `Some(string)` will trigger the end of the game.\r\n\r\nBack in `lib.rs`, lets adjust our `update` function.  Adjust the `SwitchRoom` message handler:\r\n\r\n```rust\r\nSwitchRoom(target) => match self {\r\n       Model::Playing(game) => {\r\n         game.current_room = target;\r\n         if let Some(msg) = game.move_effects() {\r\n           *self = Model::Waiting(msg);\r\n         };\r\n       }\r\n       _ => unreachable!(),\r\n     },\r\n```\r\n\r\nGreat!  Now we can wander around the maze with advance warning of all the horrors within.  Click around a while - you'll eventually die.  Isn't that fun?\r\n\r\nOf course, one final step remains - we must be able to **shoot** this accursed beast.\r\n\r\nFirst, let's create the message for it.  Open up `lib.rs` and add the new message type:\r\n\r\n```rust\r\n#[derive(Debug, Clone)]\r\npub enum Msg {\r\n  StartGame,\r\n  ShootArrow(u8),\r\n  SwitchRoom(u8),\r\n}\r\n```\r\n\r\nThere are a few things we need to handle when the payer makes a shot.  If we hit the wumpus, the game will end and show a victory message.  If we missed and it was our last arrow - we're out of luck - the wumpus will eventually find you.  That's an immediate loss.  Also, we're not necessarily subtle - each time we shoot there's a 75% chance we spook the Wumpus into an adjacent chamber.  If that adjacent chamber happens to contain you, you're wumpus food.  Here's what that might look like in Rust - add this as a new match arm in your `update` function:\r\n\r\n```rust\r\n      ShootArrow(target) => match self {\r\n        Model::Playing(game) => {\r\n          if game.wumpus == target {\r\n            *self = Model::Waiting(\"With a sickening, satisfying thwack, your arrow finds its mark.  Wumpus for dinner tonight!  You win.\".into());\r\n          } else {\r\n            game.arrows -= 1;\r\n            game\r\n              .messages\r\n              .push(\"You arrow whistles aimlessly into the void\".into());\r\n\r\n            // If we exhausted our arrows, we lose\r\n            if game.arrows == 0 {\r\n              *self =\r\n                Model::Waiting(\"You fired your very last arrow - you are now wumpus food\".into());\r\n            } else {\r\n              // On each shot there's a 75% chance you scare the wumpus into an adjacent cell.\r\n              let rand = js_rand(1, 4);\r\n              if rand == 1 {\r\n                game.messages.push(\r\n                  \"You listen quietly for any sign of movement - but the cave remains still.\"\r\n                    .into(),\r\n                );\r\n              } else {\r\n                game\r\n                  .messages\r\n                  .push(\"You hear a deafening roar - you've disturbed the wumpus!\".into());\r\n                let wumpus_exits = room_exits(game.wumpus).unwrap();\r\n                let rand_idx = js_rand(0, 2);\r\n                game.wumpus = wumpus_exits[rand_idx as usize];\r\n                if game.wumpus == game.current_room {\r\n                  *self = Model::Waiting(\r\n                    \"You scared the wumpus right on top of you.  Good going, mincemeat\".into(),\r\n                  );\r\n                }\r\n              }\r\n            }\r\n          }\r\n        }\r\n```\r\n\r\nGreat!  Now all we need are some buttons to actually fire arrows.  Luckily, we've already got almost everything we need.  Over in `src/components/controls.rs`, lets make a little tweak to our `move_button` closure:\r\n\r\n```rust\r\nlet move_button = |target: &u8| {\r\n  use crate::Msg::*;\r\n  let t = *target;\r\n  html! {\r\n      <div class=\"control-button\",>\r\n          <button onclick=|_| Msg::ButtonPressed(SwitchRoom(t)),>{&format!(\"Move to {}\", target)}</button>\r\n          <button onclick=|_| Msg::ButtonPressed(ShootArrow(t)),>{&format!(\"Shoot {}\", target)}</button>\r\n      </div>\r\n  }\r\n};\r\n```\r\n\r\nAnd that's the way the news goes!  Happy Wumpus huntin'.  Here's the [part 3](https://github.com/deciduously/hunt-the-wumpus/tree/master/part3) code to compare.\r\n\r\nPlease show me if you improve this app!  I want to see what you come up with.",
    "title": "Let's Build a Rust Frontend with Yew - Part 3"
  },
  {
    "cover_image": "http://www.alux.com/wp-content/uploads/2014/08/Zoo-Parc-de-Beauval-France-Savana-Animals.jpg",
    "date": "2018-11-20T17:37:48.359Z",
    "description": "Tell me your favorite compile-to-JS tool",
    "tags": "healthydebate, discuss, webdev",
    "markdown": "There are *lots* of tools that promise to let you write your client-side code without touching an ounce of JavaScript.\r\n\r\nWhich ones does the Dev.to community use?  Why should we drop everything and run towards your tool of choice?  What are we gaining over just using ECMAscript?\r\n\r\nMy personal number 1 choice is [Re-Frame](https://github.com/Day8/re-frame).  The minimal (750 SLOC!) structure it imposes makes perfect sense, and it lets you avoid rolling your own architecture.  Defining UI with Clojure vectors via Reagent couldn't feel more natural, and interop is so seamless you barely notice you're doing it.  Once you learn where everything goes, you've got everything you need to build performant, scalable real-world applications.\r\n\r\nNext on my list to try is [Halogen](https://github.com/slamdata/purescript-halogen), but I haven't managed to get my head around it quite yet beyond a \"hello world\" application.  PureScript is fascinating tech, though, and I'd love to dedicate more time to learning how to use it.\r\n\r\nThe easiest one I've used so far is [ReasonReact](https://reasonml.github.io/reason-react/).  If you've used React, you can already use this tool and reap the benefits of the underlying OCaml compiler to check your code.\r\n\r\nThere's dozens I haven't mentioned - that's your job!  Sell me on something nifty.\r\n\r\nI'd also love to hear opinions about why this is all hogwash and we should just stick with what's already right in front of us.  ES6/7/next/infinite is an expressive, robust tool in its own right, drawing inspiration in many cases directly from these tools - make your case below.",
    "title": "The Compile-To-JS Zoo"
  },
  {
    "cover_image": "https://ethendras.files.wordpress.com/2012/07/numbers1.jpg",
    "date": "2018-11-21T13:10:34.560Z",
    "description": "Some personal musings about my post views",
    "tags": "thanks, meta",
    "markdown": "Sometime last night I clicked over 10k views across the articles I've posted here.  Thanks, post analytics!  While an arbitrary milestone, it was still pretty jarring to see, and on my drive into work I started trying to unpack why that is.  I'm not sure what I expected - I'm writing specifically so that other people would see it.  I never excepted to garner that much attention so quickly, though - Dev.to has completely caught me by surprise.\r\n\r\nFor one, thanks.  It's been validating as heck - one tricky thing about self-learning on your own is coming to any sort of understanding about how much you know or don't know.  I've been operating under the assumption that I know nothing - and I think that's still more or less true, but it's nice to know I've got something to show for the work I've put in thus far.\r\n\r\nSecond, I guess I've got to start taking this more seriously.  What if I *am* dead wrong about something?  If it's gone uncorrected, I likely don't realize the error myself and I'd hate to lead anyone down a wrong path.\r\n\r\nUntil I became active on this website nobody except a few bored GitHub explorers had ever seen any code I'd written or heard any thoughts I'd had about the matter.  My poor girlfriend has been subjected to a couple of rants here and there (okay, more than a couple - she could probably write her own Clojure at this point if coerced) but beyond that it's been a quiet, solitary hobby.\r\n\r\nThe simple act of publishing this writing *here* as opposed to anywhere else means that all of a sudden I'm accountable for it.  It will get seen.  That's super weird.  When writing was done for primarily my own benefit it was a very different game.  I wrote to gain a deeper understanding of tools I was using - I figured if I could explain something in English, I pretty much understood it.  In certain cases this has uncovered gaps in my understanding of concepts I thought I had a good grasp on, so the act of writing has been reward enough. It's a pretty big mental shift to write for a platform with an audience built-in.\r\n\r\nEvery time I post something, I do so with the assumption that this community knows *more* about the subject matter than I do.  I expect to be corrected when wrong, it's part of my learning process.  And I have been, occasionally, which has been really cool.  But mostly I've just thrown this stuff out there and *thousands* of you have just accepted it at face value, sometimes within just a day or two, as opposed to the *dozens* I was expecting to come through and tear everything apart.  Part of the quick uptick in attention is that I have specifically opted to write about things for which I found little to no material on when I was learning it the first time.  Like many of us, I wrote posts I wish I'd had to read and learn from myself.  This means, though, that I don't have a huge body of examples to compare to - the responsibility of authority is now mine, and I'm still grappling with how to handle that responsibility...responsibly, while still feeling I have no such actual authority to back it up.\r\n\r\nI don't have much in the way of a thrilling conclusion, but seeing that fifth digit definitely gave me cause to step back and think a little about what it means. My takeaway will be that the \"Write a Post\" button is not at all unlike getting up on a soapbox in front of 10,000 incredibly smart people, perhaps in a way that's more direct than other social blogging platforms - an interesting and intimidating opportunity, and potentially a fantastic way to learn.\r\n\r\nI can't wait to see what else you lot have to teach me.",
    "title": "Large numbers"
  },
  {
    "cover_image": "https://storage.googleapis.com/programming-idioms-pictures/idiom/149/princess-lisp.png",
    "date": "2018-11-23T15:50:18.377Z",
    "description": "How to create a reactive canvas component with ClojureScript and Vue",
    "tags": "clojure, vue, beginners, webdev",
    "markdown": "# Or How I Learned To Stop Worrying And Ditch Custom Directives\n\nSince writing my post [Reactive Canvas with TypeScript and Vue](https://dev.to/deciduously/reactive-canvas-with-typescript-and-vue-1ne9) I've discovered [`glue`](https://github.com/Gonzih/glue), a library for defining [Vue](https://vuejs.org/) components in [ClojureScript](https://clojurescript.org/).  Ever the hipster, I had to give it a spin.  This post details the same functionality as that post but using ClojureScript instead of TypeScript.\n\n## Setup\n\nTo start, you'll need to have a [JDK](https://openjdk.java.net/install/) installed.  You'll also need to obtain [`leiningen`](https://leiningen.org/) which provides package managment and build tooling for Clojure/ClojureScript.\n\nOnce you've installed the above navigate to your project directory and issue: `lein new figwheel rxcanvas-cljs`.  Navigate to your new folder `rxcanvas-cljs` and open up `project.clj`.  We just need to make one change.  Find your `:dependencies` key and make it look like this:\n\n```clojure\n\n:dependencies [[org.clojure/clojure \"1.9.0\"]\n              [org.clojure/clojurescript \"1.10.238\"]\n              [org.clojure/core.async  \"0.4.474\"]\n              [glue \"0.1.3-SNAPSHOT\"]]\n```\n\nWe've just added `glue` to the list.  Don't worry too much if your version numbers don't match exactly - this is just what the template came with on the date of this writing.\n\nNow we execute `lein figwheel`.  The first run will be the longest as it gathers dependencies.  When it loads, open your browser to `localhost:3449`.  When the page loads you should see the REPL prompt appear in your terminal - try issuing `(js/alert \"Hello from ClojureScript\")`:\n\n```\n// ...\n[Rebel readline] Type :repl/help for online help info\nClojureScript 1.10.238\ndev:cljs.user=> (js/alert \"Hello from ClojureScript\")\n```\n\nYou should see the requested alert in your browser.  Leave this running as you develop and when you're ready to close type `:cljs/quit` at the REPL prompt.\n\nIf you're new to [`figwheel`](https://figwheel.org/) take a moment to familiarize yourself with the blank project layout.  There's not too much here.  The `dev` directory just sets up some convenience functions, and our HTML and CSS will live in `resources/public`.  It has pre-populated a `.gitignore` and a `README.md` for you.  All of our logic will live in `src/rxcanvas_cljs/core.cljs`.\n\n## Add a template\n\nWe're not using Single-File Components.   This would currently involve some non-trivial DIY plumbing.  There's no `vue-loader` equivalent to do the parsing for us yet - you could write the first!  If I'm wrong about this, somebody pipe up below.\n\nWe're just going to keep our template separate.  Open up `resources/public/index.html`.  The figwheel template comes with a `div` with the id `app`.  We'll keep the div but replace the contents:\n\n```html\n<div id=\"app\">\n  <rxcanvas></rxcanvas>\n</div>\n```\n\nNow we can use the `<template>` tag to define our resizable dot component.  Place this above the `app` div, directly following the opening `<body>` tag:\n\n```html\n<template id=\"rxcanvas\">\n  <div>\n    <span>{{ size }}</span>\n    <input type=\"range\" min=\"1\" max=\"100\" step=\"5\" id=\"size\" @change=\"drawDot\">\n    <label for=\"size\">- Size</label>\n    <p><canvas id=\"rx\"></canvas></p>\n  </div>\n</template>\n```\n\nThere are two changes from the TypeScript.  For one, I've replaced `v-model=\"size\"` in the `range` tag with `@change=\"drawDot\"`.  This method will handle updating our state.  I've also ditched the custom directive in the `<canvas>` tag, instead just assigning an id.\n\n## Add some Lisp\n\nNow we get to the good stuff.  Open up `src/rxcanvas_cljs/core.cljs`.  First, we need to override the built-in `atom` with the one `glue` provides and bring the rest of the library into scope.  Add the following to your `ns` form at the top of the file:\n\n```clojure\n(ns rxcanvas-cljs.core\n    (:refer-clojure :exclude [atom])\n    (:require [glue.core :as g :refer [atom]]))\n```\n\nLeave in the `(enable-console-print!)` line at the top of the file - this allows us to use the browser console for output with `println` should we so choose - but delete everything else.\n\nWe'll start with the mount point:\n\n```clojure\n(defonce app (g/vue {:el \"#app\"})\n```\n\nThis locates the `<div id=\"app\">` from `index.html` and mounts our Vue stuff to it.  We also need to make sure it keeps itself refreshed - add the following below:\n\n```clojure\n(defn on-js-reload []\n  (g/reset-state!))\n```\n\nClojureScript is not object-oriented like TypeScript, so we'll just define a plain old function to handle the canvas drawing logic instead of a `Dot` class.  Put this above your `app` definition:\n\n```clojure\n(defn draw\n  [radius canvas]\n  (let [canvas-dim (* 2 radius)]\n    ;; resize canvas\n    (set! (.-width canvas) canvas-dim)\n    (set! (.-height canvas) canvas-dim)\n\n    ;; draw the shape\n    (let [ctx (.getContext canvas \"2d\")\n          center-x (/ (.-width canvas) 2)\n          center-y (/ (.-height canvas) 2)]\n      (set! (.-fillStyle ctx) \"rgb(0,0,0)\")\n      (.clearRect ctx 0 0 (.-width canvas) (.-height canvas))\n      (.beginPath ctx)\n      (.arc ctx center-x center-y radius 0 (* 2 (.-PI js/Math)) false)\n      (.fill ctx)\n      (.stroke ctx))))\n```\n\nInterop is dirt simple - you just put the method in the first position of the s-expression.  You can get and set properties via syntax like `(.-PI js/Math)`.  It's rather easy to get addicted to the hyper-regular syntax.\n\nNow we're ready to define the component itself.  With `glue` we use `defcomponent`, right below `draw`:\n\n```clojure\n(g/defcomponent\n  :rxcanvas\n  {:template \"#rxcanvas\"\n   :state (fn [] {:size (atom 10)})\n   :methods {:draw-dot (fn [this state _]\n      ;; update the state\n      (reset! (:size state) (.-value (.querySelector js/document \"#size\")))\n      ;; grab the new value and the canvas for drawing\n      (draw @(:size state) (.querySelector js/document \"#rx\"))\n      )}})\n```\n\nInstead of `data()` we're using the key `:state` but it still returns a function.  We've explicitly stored the `size` in an `atom`, ClojureScript's mechanism for allowing mutability in an otherwise immutable language.  This particular `atom`, as discussed, is from `glue` and has some extra goodness built in to ease use in Vue components.  Using it we can access `size` using simple forms like `(:size state)`.\n\nAlso note - in our template we style the method name `drawDot`, and in our ClojureScript it's called `draw-dot`.  This is another part of what `glue` is [handling](https://github.com/Gonzih/glue/blob/8df738c2e6256b914998bb1537f85ff4bef2e4e5/src/glue/core.cljs#L50)!\n\nWe need the `@` operator as in `@(:size state)` to get at the current value of the `atom` in our call to `draw`.\n\nThat's it!  Now our canvas will resize and redraw on each change to our slider.\n\nThe completed code can be found [here](https://github.com/deciduously/rxcanvas-cljs).",
    "title": "Reactive Canvas with ClojureScript and Vue"
  },
  {
    "cover_image": "https://clipartix.com/wp-content/uploads/2016/06/Image-of-school-building-clipart-4-college-building-clip-art.jpg",
    "date": "2018-11-26T18:09:15.373Z",
    "description": "How would you prepare if you were taking your degree again?",
    "tags": "discuss, beginners",
    "markdown": "As of this morning it's official - money has changed hands and I'm headed back to college.  I've enrolled in an online undergraduate program in Software Development which will fit around my current work schedule.  When the administrative dust settles, it's looking like a Bachelor's of Science in about two and a half to three years and I've selected a track that will result in a certificate in C++ Programming after about a year.\r\n\r\nIt's been...yikes... *lots of years* since I've been in formal schooling, and that schooling was not in software.  I'm pretty nervous - it turns out entering as an adult this time around doesn't help a ton with the whole angst shindig!  Go figure.\r\n\r\nIf you had the chance to re-take your software degree, knowing what you know now, is there anything you'd do differently?  How would you make the most use of your time during and between semesters?  Is there anything specific I should try to prepare for leading up to the start of class next January?  What surprised you starting out?\r\n\r\nIf anyone else has done an online degree while also working full time in a separate domain, I'd love some anecdotes about how you juggled everything, too!  It sounds like it's going to be a lot of work - how did you balance school, work, and everything else?",
    "title": "Back to school"
  },
  {
    "cover_image": "http://www.wopc.co.uk/images/countries/thailand/vegas-gold-111-large.jpg",
    "date": "2018-11-29T13:31:19.218Z",
    "description": "Some standard functions expressed as folds",
    "tags": "beginners, haskell, functional",
    "markdown": "Do you have a favorite function?  I do.  It's really a family of functions, but today I'd like to talk about *folds*.\r\n\r\nI'm going to be illustrating with Haskell, but this concept is not Haskell-specific nor should you need to be terribly familiar with Haskell to read the examples.  In the first section I unpack what a fold even is and in the second we re-implement a few library functions in terms of a fold.\r\n\r\n## What's A Fold?\r\n\r\nFolds are not an uncommon concept in mainstream languages - if you're good and comfy, skip this section.  If not, though, it will help to know how they work.\r\n\r\nIn a purely functional paradigm the way we take a collection of values and make sure we do something with every member of the collection is to consume the collection recursively.  That is, we're going to pass our whole collection into some sort of function which is going to do some sort of processing.  At the end of the function it's going to call itself again with a smaller part of the list as the argument - the part we haven't processed through the function yet.  It will do this again and again, calling itself with smaller and smaller parts of the collection until the whole thing is processed.  Easy peasy.  A `fold` is a specific type of recursive function that takes in a data structure, a collection of some type, and a function to use for each member - specifically the first element of the collection on each iteration.  It eventually yields just one single value after the list has been fully drained.\r\n\r\nTypes are one thing that I find easier to talk about in Haskell than English.  Here's the type signature for `foldr`:\r\n\r\n```haskell\r\nfoldr :: (a -> r -> r) -> r -> [a] -> r\r\n```\r\n\r\nIt's fine if you stared blankly at this, that's usually step one of unraveling a type signature.  They all work the same way though, so we can walk our way through.  We know this is a function that takes three arguments because everything evaluates to one value in the end - so the compiler will expect three bits of information while processing this to get to that final `r`.  Parentheses in type signatures work as you'd expect - that first part is grouped, signifying it's a single argument with the type `a -> r -> r` instead of three separate arguments.  The second unknown type is conventionally shown with a `b` - I'm using `r` to indicate it's our return type.  If you went to look this up online, you'll probably see a `b` instead.  It doesn't matter what type, it could be anything.  This second type placeholder could even be another `a` and often is, but it doesn't *have* to be for the function to be correct so we use a different letter.\r\n\r\nThe first thing is our processing function.  This itself is a function which takes two arguments.  It takes in a single element of our `[a]`, or a list of `a` types, and some value of the type that we're returning and returns a new value with our expected return type.  The next argument is a single instance of that return type - the \"destination\" so to speak.  We know we're going to be getting a single value from this fold, and we have a function that takes a cell and our current running result and gives us back the new result, so we can drop that cell from the next run through the recursion.  On the first run through, though, we need somewhere to deposit the result of the computation, so `foldr` asks for a container as the second argument of type `r` to apply the result to.  This initial value we pass in is going to be transformed every run through the function and is eventually what gets returned.\r\n\r\nIf this all was too abstract, here's a simple example that might look more familiar - let's fold some basic addition into a collection:\r\n\r\n```haskell\r\nnums :: [Int]\r\nnums = [1, 2, 3, 4, 5]\r\n\r\naddEmUp ns :: [a] -> r\r\naddEmUp ns = foldr (+) 0 ns\r\n```\r\n\r\nThat's a lot less noisy.  In this example calling `addEmUp nums` will yield `15 :: Int`.  First, I defined a `[Int]` - a list of `Int`s - called `nums`.  Then I created a function `addEmUp` which is really an alias for a specific `fold` - notice how it doesn't do anything other than specify which arguments to use with the fold.  That's why the type signature for `addEmUp` is a lot simpler - it only takes the `[a]` collection, in this case `nums`.  So our `a` is `Int`.  The first argument, the processor, is `(+)` - the addition operator.  Operators are functions and this one takes in two values and produces a third.  Let's compare to our expected type: `a -> r -> r`.  In this case `a` is `Int` and we want an `Int` at the end, so we can substitute that type in for `r` too.  If you add an `Int` to an `Int`, lo and behold, an `Int` will pop out.  So our processor, addition, has type `Int -> Int -> Int`, which fits!  It's totally fine if `a` and `r` or any two unspecified types are the same, we just note that they don't *have* to be.\r\n\r\nOur second argument was just a `0` - an `Int`.  We've just decided that's a perfectly fine `r` type so the second argument makes sense as an initializer for our return type.  That just leaves us with `[a]`.  Thankfully we've left that part of the type intact and are passing it in as the argument to `addEmUp`!  For this simple example, the fully qualified type of this `foldr` reads: `(Int -> Int -> Int) -> Int -> [Int] -> Int`.  Just a bunch of `Int`s.\r\n\r\nWhen Haskell goes to evaluate this it will start with the full collection.  When we get to the first run through the processor will grab the first cell and then look for our accumulated result.  We haven't done anything yet so it's just `0` - we told it that in the second argument.  The first value is `1`.  Our accumulator added to our base value is `1`.  Then, we recur!  Only this time we've already processed the one, so we're calling this same function again but only on the rest of the collection, and using our newly minted `1` as the accumulator instead of the base value `0`:\r\n\r\n```haskell\r\nfoldr (+) 0 [1, 2, 3, 4, 5]\r\nfoldr (+) 1 [2, 3, 4, 5]\r\n```\r\n\r\nSee what happened there?  We processed the one and dropped it so our collection got shorter and we have a running total.  Expanding:\r\n\r\n```haskell\r\n  foldr (+) 3 [3, 4, 5]\r\n= foldr (+) 6 [4, 5]\r\n= foldr (+) 10 [5]\r\n= foldr (+) 15 []\r\n= 15\r\n```\r\n\r\nWhen a recursive function tries to recur on an empty list it knows it's done and returns the final value - in this case `15`.  We've managed to iterate without looping!  Instead we folded an operation in: `[1 + 2 + 3 + 4 + 5]`.  It's almost like we replaced the commas with our operator a step at a time from right to left.  In that way, we were able to reuse the same exact function over and over again while only changing what we pass in based on the output of the previous run.  Recursion, yo.\r\n\r\nIf this sounds outrageously inefficient, calling loads and loads of functions all the time with very similar values, well, it is.  To mitigate that overhead, Haskell performs something called \"[tail-call](https://en.wikipedia.org/wiki/Tail_call) optimization\" which I won't detail here but essentially means that instead of allocating a new stack frame for each successive call it's able to reuse the same stack frame and substitute the new vals and then just jump execution back up, `GOTO`-style, provided the function recurs in \"tail position\", which means it's the last part of the function to execute.  If you're not familiar with stack frames we're getting way beyond the scope of this post - it's not required knowledge here but interesting in general and important to understand if you'd like to use a functional language in anger.  In toy programs, the elegant functional solutions are generally fine, but as your apps scale it can start to cause problems, and languages which allow a more hybrid style generally recommend you fall back to more imperative patterns at that point.  A good old `for` loop will as a rule of thumb perform better on large amounts of data than a one-liner using a `forEach` or something similar - sometimes by orders of magnitude.  In Haskell dealing with these performance problems involves other sorts of patterns as well, as there's no `for` loop to speak of.  I recommend you do some poking around!\r\n\r\nThis example could have been rewritten: `addEmUp = foldr (+) 0` - if the argument is the final term in the definition and the argument list it can be dropped.  This process is known as an [eta-reduction](https://en.wikipedia.org/wiki/Lambda_calculus#%CE%B7-conversion) in the lambda calculus lingo.  The compiler instead sees this definition as a curried function expecting one more value.  If it gets called with that value it will fully evaluate the expression.\r\n\r\n## All The World's a Fold\r\n\r\nTo illustrate how useful this function is let's rewrite some other common standard functions in terms of a fold.\r\n\r\nNow, `foldl'` may be appropriate instead here - I'm not going to get bogged down in when to prefer one over the other.  The [Haskell Wiki](https://wiki.haskell.org/Foldr_Foldl_Foldl') has more information, and for consistency's sake these will all be right folds.\r\n\r\nIf you have `ghc` installed you can follow along in `ghci`, or if you prefer put these in a file:\r\n\r\n```haskell\r\n-- stdFolds.hs\r\nmodule StdFolds where\r\n\r\n-- the functions!\r\n```\r\n\r\nThen load this module at the REPL with `:l stdFolds.hs`.\r\n\r\n### Or\r\n\r\nWe'll start with `Or`.  We want a function that can \"or\" a list - that is, return `True` if any of its members are `True` and otherwise `False`.  The type of our function is easy:\r\n\r\n```haskell\r\nmyOr :: [Bool] -> Bool\r\n```\r\n\r\nWe pass in a list of `Bool` and just want one back.  This means our accumulator parameter should just be a `Bool`.  On each element of the list, we want to compare against this accumulator and replace it with the appropriate value - the built-in `(||)` operator will do just that!  We'll only retain a `False` is both sides are `False`, and otherwise the accumulator will end up with `True` - which will *always* reutrn `True` when checked against any other boolean:\r\n\r\n```haskell\r\nmyOr :: [Bool] -> Bool\r\nmyOr = foldr (||) False\r\n```\r\n\r\nWe're using eta reduction, like above - our data structure itself is dropped from the definition.  Example output:\r\n\r\n```\r\n*StdFolds> let a = [True, False, True]\r\n*StdFolds> myOr a\r\nTrue\r\n*StdFolds> let b = [False, False, False]\r\n*StdFolds> myOr b\r\nFalse\r\n```\r\n\r\n### Any\r\n\r\nNow lets write a function that checks if any `a` in a given `[a]` satisfies a predicate `a -> Bool`:\r\n\r\n```haskell\r\nmyAny :: (a -> Bool) -> [a] -> Bool\r\n```\r\n\r\nWe're actually performing nearly the same function as with `myOr` - the only difference is that instead of just using the element of our collection, we're passing it through a predicate.  We can compose our predicate with the `(||)` operator:\r\n\r\n```haskell\r\nmyAny :: (a -> Bool) -> [a] -> Bool\r\nmyAny f = foldr ((||) . f) False\r\n```\r\n\r\nExample output:\r\n\r\n```haskell\r\n*StdFolds> let a = [0, 1, 2]\r\n*StdFolds> myAny (== 3) a\r\nFalse\r\n*StdFolds> myAny (== 1) a\r\nTrue\r\n*StdFolds>\r\n```\r\n\r\nWe can actually do better, though.  We've already dropped the collection with eta reduction, but using the super handy `flip` function we can re-arrange so our `f` is at the end too:\r\n\r\n```haskell\r\nmyAny :: (a -> Bool) -> [a] -> Bool\r\nmyAny f = flip foldr False ((||) . f)\r\n```\r\n\r\nNow we can drop it entirely by simply using function composition:\r\n\r\n```haskell\r\nmyAny :: (a -> Bool) -> [a] -> Bool\r\nmyAny = flip foldr False . ((||) .)\r\n```\r\n\r\nThis version is identical to our first attempt, just de-cluttered.\r\n\r\n### Elem\r\n\r\nThe `elem` function is just a special case of `any`, with a specific predicate.  Because we've re-arranged `myAny` to take the function in the final position we can just use that:\r\n\r\n```haskell\r\nmyElem' :: Eq a => a -> [a] -> Bool\r\nmyElem' = myAny.(==)\r\n```\r\n\r\nWe've eta-reduced out the parameter, but we can still apply the typeclass constraint of `Eq` to it.\r\n\r\nExample output:\r\n\r\n```\r\n*StdFolds> let a = [0, 1, 2]\r\n*StdFolds> myElem 3 a\r\nFalse\r\n*StdFolds> myElem 1 a\r\nTrue\r\n```\r\n\r\nWithout using `myAny` we just use the same function body:\r\n\r\n```haskell\r\nmyElem :: Eq a => a -> [a] -> Bool\r\nmyElem = flip foldr False . ((||) .) . (==)\r\n```\r\n\r\n### Map\r\n\r\nWe're going to use a similar pattern to build our own `map`.  This has a slightly different signature - given a function from `a` to `b` we want to get a `[a]` from a `[b]`:\r\n\r\n```haskell\r\nmyMap :: (a -> b) -> [a] -> [b]\r\n```\r\n\r\nThe difference from `myAny` is that instead of just accumulating into a `Boolean`, we want to construct a new list.  Instead of comparing to the accumulator with `(||)` we can use the list construction operator `(:)`:\r\n\r\n```haskell\r\nmyMap :: (a -> b) -> [a] -> [b]\r\nmyMap = flip foldr [] . ((:) .)\r\n```\r\n\r\nOtherwise, it's the same thing!  Example output:\r\n\r\n```haskell\r\n*StdFolds> let a = [0, 1, 2]\r\n*StdFolds> let f = (* 2)\r\n*StdFolds> myMap f a\r\n[0,2,4]\r\n*StdFolds>\r\n```\r\n\r\n Here's a [gist](https://gist.github.com/deciduously/8b2babeb07782c046aa0dab9f1392634).",
    "title": "Know When to Fold 'Em"
  },
  {
    "cover_image": null,
    "date": "2018-11-30T23:08:25.579Z",
    "description": "A link to a handy Advent of Code Rust helper",
    "tags": "rust, aoc",
    "markdown": "Disclaimer - **NOT** my project, I just think it's cool.\r\n\r\nI've been waffling about what language I'd like to use for AoC this year but if you've settled on Rust, you should check out [this tool](https://github.com/gobanos/cargo-aoc).\r\n\r\nIt will download your input for you and handle running and benchmarking.  It also includes with some handy macros to hook generators to solvers, tailored to the format these problems generally take.\r\n\r\nI'd gotten my heart set on F# as an intro to the MS ecosystem, but this is so dang cool.  I do love me some Rust... it's going to be hard to steer clear.",
    "title": "Check out this Advent of Code helper for Rust"
  },
  {
    "cover_image": "https://upload.wikimedia.org/wikipedia/en/thumb/d/d5/Fsharp%2C_Logomark%2C_October_2014.svg/1200px-Fsharp%2C_Logomark%2C_October_2014.svg.png",
    "date": "2018-12-03T22:27:53.357Z",
    "description": "A retrospective on my first few days with F#",
    "tags": "fsharp, beginners, retrospective",
    "markdown": "I decided to tackle this year's Advent of Code in [F#](https://fsharp.org/).  It's not only my first time using this language, it's my first time ever using .NET.  I don't know anything about using the Common Language Infrastructure at all.  I was expecting a rough, slow start as I got used to a brand new environment, and I'd be able to write about the process as I learn how to unstick myself.\r\n\r\nHasn't happened.  Turns out F# is great, highly easy to use, and I haven't gotten stuck.  In fact, it's probably the quickest I've made it from \"brand-new language\" to \"solved an AoC-type problem\", ever.  So I'm just going to write that post instead.\r\n\r\nI've certainly gotten stuck on the problems, and I'm not necessarily pleased with my implementations so far - all could be optimized - but my issues have nothing to do with F#.  The documentation is thorough, and I'm generally a single Google away from the .NET function I'm looking for.  Lots of documentation for C# will apply too if you can't find anything for F# specifically - my only trouble is not knowing any C# either, but it's Java-enough to follow along!\r\n\r\nNow, to be fair, I don't think you'd have the same experience if it were your first MLish language.  But having even just a very little bit myself in Haskell and OCaml I found nothing surprising here.\r\n\r\nAlmost everything I've needed I've found right on the [Tour of F#](https://docs.microsoft.com/en-us/dotnet/fsharp/tour) and the [Language Reference](https://docs.microsoft.com/en-us/dotnet/fsharp/language-reference/) covered everything else.\r\n\r\nThere's also this great website, downloadable as an offline ebook: [F# for Fun and Profit](https://fsharpforfunandprofit.com/).\r\n\r\nSome things I like:\r\n\r\nPipes:\r\n\r\n```fsharp\r\nutil.applyClaims fileName\r\n|> Seq.filter (fun el -> List.length el > 1)\r\n|> Seq.length\r\n```\r\n\r\nList computations:\r\n\r\n```fsharp\r\n// https://docs.microsoft.com/en-us/dotnet/fsharp/tour\r\nlet daysList = \r\n    [ for month in 1 .. 12 do\r\n          for day in 1 .. System.DateTime.DaysInMonth(2017, month) do \r\n              yield System.DateTime(2017, month, day) ]\r\n```\r\n\r\nActive patterns:\r\n\r\n```fsharp\r\n// https://fsharpforfunandprofit.com/posts/convenience-active-patterns/\r\nopen System.Text.RegularExpressions\r\nlet (|FirstRegexGroup|_|) pattern input =\r\n   let m = Regex.Match(input,pattern) \r\n   if (m.Success) then Some m.Groups.[1].Value else None  \r\n\r\n// create a function to call the pattern\r\nlet testRegex str = \r\n    match str with\r\n    | FirstRegexGroup \"http://(.*?)/(.*)\" host -> \r\n           printfn \"The value is a url and the host is %s\" host\r\n    | FirstRegexGroup \".*?@(.*)\" host -> \r\n           printfn \"The value is an email and the host is %s\" host\r\n    | _ -> printfn \"The value '%s' is something else\" str\r\n   \r\n// test\r\ntestRegex \"http://google.com/test\"\r\ntestRegex \"alice@hotmail.com\"\r\n\r\n```\r\n\r\nI've just found it nice and smooth to use.  It's not hard to get from thought to code and have it work as intended.  After a while learning all about building graphs in Rust, it's kinda nice to remember what that's like!\r\n\r\nSome things I don't like:\r\n\r\n* Compiler errors, but I'm spoiled with Rust/Reason\r\n* Having to use the CLI to add things to solutions and references to packages and things.  This is my own lack of familiarity with the ecosystem though.\r\n\r\nThat's really it, I like everything else a lot.  It's the most fun I've had with an ML language so far, at least.\r\n\r\nTry you some F#, today!\r\n\r\nAs an aside, does anyone have any experience using Clojure CLR?  Seems not too popular, but a good idea in general.\r\n\r\nThis post isn't really about AoC, but here's an \"obligatory\" [repo](https://github.com/deciduously/aoc2018) link if you'd like to play around with it.",
    "title": "F# is Pretty Cool"
  },
  {
    "cover_image": "http://theboardgamingway.com/wp-content/uploads/2015/02/Hastings-from-Bayeux-Tapestry.jpg",
    "date": "2018-12-06T00:29:19.425Z",
    "description": "A brief look back at my Advent of Code error in F#",
    "tags": "adventofcode, fsharp, beginners",
    "markdown": "# In Which Ben Learns 1 Is The Loneliest Number\r\n\r\nSo, my biggest shortcoming as a developer is my toolkit of algorithms at my fingertips by instinct.  It's not that I'm not pretty familiar with the basics, at least, but I still haven't put in the time necessary to immediately look at a problem and say \"oh, this is that that other problem\".  At least not at 7 in the morning warming up from the frigid trudge up the hill well before my shift.  Advent of Code makes fools of us all.\r\n\r\nThis is the story of how I instinctively reached for the dumb thing *even knowing it was dumb* instead of taking a second and thinking about it and wasted precious, precious leaderboard points because of it.  The humanity.\r\n\r\nThis is a beginner-level post, even if you aren't terribly comfy with F#/ML.\r\n\r\n## The Exposition\r\n\r\nDay 5 has us comparing successive characters.  If they're a *pair* of one lower case and one upper case of the same letter both are dropped from the set, and otherwise the process continues.  We're done when we're out of pairs.\r\n\r\nWe'll start with the wrong way.  Because this is my 5th problem ever in F# and it's been some time since I've used an ML, I wanted to do it recursively!  Hooray!  I just forgot that doesn't always mean the same thing.\r\n\r\nI also am on a swap week - I'm used to a cushy 90 minutes before I switch off and do numbers all morning until lunch, but this week I only had 60!  The clock was ticking on this one but I was amped from Day 4 where my first go did the trick, more or less, and went in cocky.  Luckily, I know all about how to solve stuff recursively, I have a few days of ironing out the unfamiliar edges of the languages behind me, and this problem looks like a piece of cake.  I'm not going for style on the first time through, I'm going for that sweet, sweet answer.\r\n\r\nWhat I missed at this *crucial* juncture is (as so many others noted rather quickly) that this only takes a single pass to do.  As soon as you swap a pair you should check *right then and there* if you need to swap again and keep doing that until you're through - that's all it takes!  Viola, processed.  It's not unlike the [Matching Parenthesis](http://people.cs.ksu.edu/~rhowell/DataStructures/stacks-queues/paren.html) problem - clearly the intended solution.  The example given in the problem description even does that operation right there in front of you, by the way.  You can't miss it.\r\n\r\nI made no such magical leap, though.  I missed it.  In my first instinct I just saw an operation that needed doing and tried-and-true way to ensure it got done.\r\n\r\nI knew I'd want to compare two elements at once as we go through to check if they react, and I'd need a way to tell it to *run through again* if we made changes to see if any new pairs popped up.  After all, this general pattern worked for me on Day 1, part 2:\r\n\r\n```fsharp\r\nlet rec addFreqWithState acc visited whole remaining =\r\n    match remaining with\r\n    | [] -> addFreqWithState acc visited whole whole\r\n    | head::tail ->\r\n      let newval = acc + head\r\n      if Set.contains newval visited then\r\n          newval\r\n      else\r\n          addFreqWithState newval (Set.add newval visited) whole tail\r\n```\r\n\r\nNow, if you're shaking your head by this point, good.  You should be.  Heck, I was.  I looked at the input string - it's huge.  This thing is about to do a ton of work,  I just knew it before writing any code, but I didn't think it could possibly take that long and I'd just come back later and find a better solution after I got my little happy star - winter, amirite?\r\n\r\nI'll just store what I need as parameter to the recursive function - a boolean for whether or not we're done and the original string to start over with.  In fact, I'll just drain one into the other and flop them!  How simple, how nice.  Almost warm and cozy, like a nice cup of ML should be.\r\n\r\n## The First Go\r\n\r\nI'll start by building the base case:\r\n\r\n```fsharp\r\nlet rec reactString altered result input =\r\n    match result with\r\n    | [] -> if altered then reactString false \"\" (string result |> List.ofSeq) else result\r\n```\r\n\r\nIf it made any changes on this run, then recur again resetting everything, using the new `result` to create our input list of chars.  If it didn't - so, you know, it just ran **all the way through again** doing zero work to ascertain this, it can finally give us back the damn result string.\r\n\r\nOkay.  One case in and it already hurts, but time is money.  Let's write the other part and get on with it.\r\n\r\n```fsharp\r\nlet rec reactString altered result input =\r\n    match result with\r\n    | [] -> if altered then reactString false \"\" (string result |> List.ofSeq) else result\r\n    | head::next::tail ->\r\n      if doesReact head next then\r\n        reactString true result tail\r\n      else\r\n        reactString altered (result + string head) ([next] @ tail)\r\n```\r\n\r\nI get at the first two by destructuring the `input` list and calling them `head` and `next`.  I check if they react:\r\n\r\n```fsharp\r\nlet doesReact first second =\r\n    (System.Char.ToUpper first = System.Char.ToUpper second) && first <> second\r\n\r\n```\r\n\r\nOne of the first initial gotchas right out of the gate with F# is the equality operators - instead of `==` and `!=` you're working with `=` and `<>`.\r\n\r\nIf they do react, then we make sure we note that in the boolean we're passing along and recur with `tail` - everything after the two we just checked.\r\n\r\nWe did totally move on from any new pair we created in the result, but it's cool, yo.  We'll catch 'em on the next go-round!  (oof).\r\n\r\nIf they didn't react, we're recurring through `input` again but \"draining\" it into `result` - add the `head` and keep `next` up with the input list for the next iteration.\r\n\r\nAt this point the compiler helpfully reminds me there's lists with one element, and I have to deal with that reality.  Thanks, compile-time enforced correctness!  I don't really want to think about it, so we'll \"base case\" that too - here's our final iteration:\r\n\r\n```fsharp\r\n  let rec reactString altered result input =\r\n    match input with\r\n    | [] -> if altered then reactString false \"\" (string result |> List.ofSeq) else result\r\n    | [a] -> if altered then reactString false \"\" (string result + string a |> List.ofSeq) else result + string a\r\n    | head::next::tail ->\r\n      if doesReact head next then\r\n        reactString true result tail\r\n      else\r\n        reactString altered (result + string head) ([next] @ tail)\r\n    |> Seq.length\r\n```\r\n\r\nIt's almost the same as for `[]` - it definitely won't react so we don't check - but we pass it along either back into the input list if needed or add to our accumulated `result` string.\r\n\r\nIt ain't pretty, but it'll do.\r\n\r\nAnd do it did - pretty much on the first try, which has been my favorite thing about F#.  Not first try, exactly, but the first successful compile usually does what I meant. Getting the actual problem answers just involve running this once and then running it a bunch of times on different permutations of the input, removing specific letters at a time and trying again, so here's where any real work is happening.  It did what I asked of it, and my answers were correct.\r\n\r\nI literally aged while it did it, though.  I started unlocking cabinets, I went to the bathroom, I chatted with Mike down the hall, another early-bird.  Didn't finish.  I went and grabbed the mail, filtered my emails - nothing.\r\n\r\nI left my laptop open on my desk.  It's an old laptop - late 2011 Thinkpad.  It's doing its best.  Curses!\r\n\r\nIt finishes, just twelve minutes until work begins.  I had misread the problem - it didn't want the letter that was most optimal, it wanted the resulting length of that string.  The result of that massive computation, that measly `'j'` was staring at me, taunting me.  I had to run it *again*.  Minutes were ticking by and I still didn't have what I needed - even though I did have \"the right answer\".\r\n\r\nLuckily, made the code change in under two minutes.  And started it again.\r\n\r\nEndless minutes go by.  8 AM comes.  I start work, glancing every few minutes as I get my day organized. The phone starts ringing and the emails start coming as my colleagues roll in and I don't get to check back until maybe an excruciating hour later and there it is, smug as ever - the right friggin' answer.  Ouch.\r\n\r\n## The Realization\r\n\r\nIt took not two seconds.  I opened the thread, got to the top post from @aspittel, and got two lines in to the function\r\n\r\n```python\r\ndef react(text):\r\n    stack = []\r\n```\r\n\r\n*Ohhhhh*.  Oh right.  Make a stack.  It all was so crystal clear in a moment.  But alas - the time had come.  I had a bunch of contract adjustments to do before I could dive back in.\r\n\r\n## The Fix\r\n\r\nFast-forward to lunch, and I simply translate hers:\r\n\r\n{% devcomment 7bid %}\r\n\r\nMine looks almost identical, just ML-style.  Instead of a for loop, I'm folding into an `Array`.  It doesn't take long - maybe 5 minutes to get it to compile:\r\n\r\n```fsharp\r\nlet reactQuickly input =\r\n    Seq.fold (fun s c ->\r\n      let last = if Array.length s > 0 then Some (Array.last s) else None\r\n      match last with\r\n      | Some x ->\r\n        if c <> x && (x = System.Char.ToUpper c || x = System.Char.ToLower c) then\r\n          Array.sub s 0 (Array.length s - 1)\r\n        else Array.append s [| c |]\r\n      | None -> Array.append s [| c |]) [| |] input\r\n        |> Array.length\r\n```\r\n\r\nWhile I generally like ML-type syntax, even above most other languages I've tried, I've gotta say her Python version looks very nice and clean in comparison.  They do the same thing.\r\n\r\nOn each iteration, `s` is our result array - the `stack` in her implementation. I use `c` for the character from the input we're looking at - sometimes I just prefer `el` here to convey the element of the list we're folding over.\r\n\r\nTo get at two at a time, instead of looking forward we look back into the stack.  We've got access to it right there in the function.  If it's empty we store a `None` so we know to just push whatever the string starts with on the first iteration and otherwise we check the current character against the top of the stack.\r\n\r\nInstead of `stack.pop` we just return a subset of our accumulator, which has the same effect.  That's it though.\r\n\r\nTo check if it worked, all I did was replace the word `reactString` with `reactQuickly`.  Same answers in three seconds on that old laptop, under one second on my desktop at home.\r\n\r\nIt turns out one pass is *fewer passes* than lots and lots of passes.  Go figure.\r\n\r\nSee [here](https://github.com/deciduously/aoc2018/blob/master/src/Day5/Library.fs) for the complete file.",
    "title": "A Tale of Two Functions"
  },
  {
    "cover_image": "http://www.betamaxcollectors.com/images/sonybetamaxsl-25_1.jpg",
    "date": "2018-12-07T18:38:33.140Z",
    "description": "Let's talk about obsolete things",
    "tags": "discuss",
    "markdown": "As in - what technology or tool came to prominence and then disappeared despite its technical merit?  Do you miss it?  Would you use it today or was it a product of its time?\r\n\r\nMe?  I'm a WordPerfect man.  I know it's not \"gone\", exactly - but when was the last time you came across an installation in the wild?",
    "title": "What's the Betamax of your field?"
  },
  {
    "cover_image": "https://www.gkbmachines.com/wp-content/uploads/2016/12/CB6a.jpg",
    "date": "2019-02-05T19:42:23.297Z",
    "description": "A quick Parser Combinator tutorial",
    "tags": "beginners, functional, javascript",
    "markdown": "Let's say we've been sent some brand new points.  However, the Point Guru is having a burst of 'creativity' today and has devised a crazy transmission string:\r\n\r\n```javascript\r\nconst input = '.:{([2 3]][[6 2]][[1 2])][([1 4]][[2 1])][([6 9])}:.'\r\n```\r\n\r\nThis is clearly bonkers and you shouldn't have to put up with it.  Sadly, she's your only connect for points in sets of varying sizes, though, and the points themselves look alright, so you have to roll up your sleeves and get 'em outta there.\r\n\r\nI don't know about you, but I (until now!) have always sighed and reached for a regular expression at this point, or started mucking about with string manipluations.  It'll be ugly as hell, but it'll work.   You can pull out each list with capture groups and then either use another regex on the captures or use string splitting and iterators to get what you need.  It likely won't be much fun, and will be completely illegible at a glance at the end (unless regex is really your thing).\r\n\r\nBUT WAIT!  There's another way!  And it's even easier than it sounds!\r\n![meme](https://i.imgur.com/PiOsDjV.jpg)\r\n(this is my first ever meme!)\r\n\r\nLooking at this string, we immediately see it for what it is - a list of points.  The tricky part is just telling the computer what you mean.  With parser combinators, we can!  Parser combinator libraries allow you to define little tiny parsers that you can compose in order to parse anything at all, from a string like this to a programming language.  Parser combinators can initially look complicated because of phrases like `monadic LL(infinity)` and some complex looking syntax in certain languages, but it's actually incredibly simple, and lots of fun to use.  Each little part is reusable if you keep your parts as small as possible.  This way, we really can sorta just tell JavaScript (or what have you) what we need using units tht make sense to us.\r\n\r\nI'm using the [Parsimmon](https://github.com/jneen/parsimmon) library to illustrate, but there are many others for JS and lots of other languages have libraries for this as well.\r\n\r\nWith Parsimmon, we create a \"language\" that contains mini parsers, composed of ever smaller parsers.  Here's a very basic example:\r\n\r\n```javascript\r\n// index.js\r\nconst P = require('Parsimmon')\r\n\r\nconst CrazyPointParser = P.createLanguage({\r\n    Num: () => P.regexp(/[0-9]+/).map(Number)\r\n})\r\n```\r\n\r\nWhen we first looked at this string, we immediately understood it as ultimately a list of *numbers*.  This is the very basic unit, which we grab with the `regexp` combinator to match 1 or mare characters in the specified range.  It's a much smaller regular expression that the monstrosity alluded to above - readable at a glance.  Each parser gets `map`ped over with how we want the data to be represented - in this case we want this string to be a JavaScript `Number`.\r\n\r\nThis code can be verified by using the following below:\r\n\r\n```javascript\r\nlet a = '23'\r\n\r\ntry {\r\n    console.log(CrazyPointParser.Num.tryParse(a))\r\n} catch (err) {\r\n    console.log('Oops! ' + err)\r\n}\r\n```\r\n\r\nRunning `node index.js` should output `23` - not `'23'`.  We've parsed a number!  Now we can use this parser in bigger parsers.  The next natural unit to look at is the point - `[8 76]`.  Two numbers separated by a space.\r\n\r\n```javascript\r\nconst CrazyPointParser = P.createLanguage({\r\n    Num: () => P.regexp(/[0-9]+/).map(Number),\r\n    Point: (r) => P.seq(P.string('['), r.Num, P.string(' '), r.Num, P.string(']')).map(([_open, x, _space, y, _close]) => [x, y])\r\n})\r\n```\r\n\r\nThe `P.seq()` combinator is used to chain combinators together in a sequence to match.  This time the `r` we pass as an argument is short for `rules` and allows us to refer to the other combinators defined in this language.  Then we just use the `P.string()` combinator to match the separators exactly, and use our `r.Num` combinator to handle recognizing and converting the numbers themselves.  Then over in the map, we are passed an array of each part of the match.  We ignore the brackets and the space returning by the `P.string()` combinators and just return the values our `Num` combinator took care of for us.  Change the test snippet to:\r\n\r\n```javascript\r\nlet b = '[78 3]'\r\ntry {\r\n    console.log(CrazyPointParser.Point.tryParse(b))\r\n} catch (err) {\r\n    console.log('Oops! ' + err)\r\n}\r\n```\r\n\r\nExecuting this will now return `[ 78, 3 ]`.  Now, these points are further grouped into sets of varying size and (inexplicably) separated by the string `']['`.  We can create a mini parser for just that separator and then leverage the `sepBy()` combinator to handle these sets:\r\n\r\n```javascript\r\nconst CrazyPointParser = P.createLanguage({\r\n    // ...\r\n    Sep: () => P.string(']['),\r\n    PointSet: (r) => P.seq(P.string('('), r.Point.sepBy(r.Sep), P.string(')')).map(([_open, points, _close]) => points)\r\n})\r\n```\r\n\r\nWe don't need to include the `map` portion on our `Sep` parser - we just want to return the match as is (it'll be discarded later).  In our `PointSet` parser, `r.Point.seqBy(r.Sep)` will return zero or more `Point`s separated by whtever seaparater we provide as an array, dropping the separators themselvles.  Try it out:\r\n\r\n```javascript\r\n\r\nlet c = '([2 3]][[6 2]][[1 2])'\r\n\r\ntry {\r\n    console.log(CrazyPointParser.PointSet.tryParse(c))\r\n} catch (err) {\r\n    console.log('Oops! ' + err)\r\n}\r\n```\r\n\r\nThis will output `[ [ 2, 3 ], [ 6, 2 ], [ 1, 2 ] ]`.  We're almost there!  The full string is just a bunch of `PointSet`s, separated by that same separator with some frilly caps on each end:\r\n\r\n```javascript\r\nconst CrazyPointParser = P.createLanguage({\r\n    // ...\r\n    PointSetArray: (r) => P.seq(P.string('.:{'), r.PointSet.sepBy(r.Sep), P.string('}:.')).map(([_open, pointSets, _close]) => pointSets)\r\n})\r\n```\r\n\r\nAnd that's it!  Our parser will now successfully parse the whele input string, in only a handful of lines.  Here's the whole snippet:\r\n\r\n```javascript\r\nconst P = require('Parsimmon')\r\n\r\nconst input = '.:{([2 3]][[6 2]][[1 2])][([1 4]][[2 1])][([6 9])}:.'\r\n\r\nconst CrazyPointParser = P.createLanguage({\r\n    Num: () => P.regexp(/[0-9]+/).map(Number),\r\n    Sep: () => P.string(']['),\r\n    Point: (r) => P.seq(P.string('['), r.Num, P.string(' '), r.Num, P.string(']')).map(([_open, x, _space, y, _close]) => [x, y]),\r\n    PointSet: (r) => P.seq(P.string('('), r.Point.sepBy(r.Sep), P.string(')')).map(([_open, points, _close]) => points),\r\n    PointSetArray: (r) => P.seq(P.string('.:{'), r.PointSet.sepBy(r.Sep), P.string('}:.')).map(([_open, pointSets, _close]) => pointSets)\r\n})\r\n\r\ntry {\r\n    console.log(CrazyPointParser.PointSetArray.tryParse(input))\r\n} catch (err) {\r\n    console.log('Oops! ' + err)\r\n}\r\n```\r\n\r\nOutput:\r\n\r\n```\r\n$ node index.js\r\n[ [ [ 2, 3 ], [ 6, 2 ], [ 1, 2 ] ],\r\n  [ [ 1, 4 ], [ 2, 1 ] ],\r\n  [ [ 6, 9 ] ] ]\r\n```\r\n\r\nWe can even get fancy - just replace our `Point` combinator with:\r\n\r\n```javascript \r\n    Point: (r) => P.seq(P.string('['), r.Num, P.string(' '), r.Num, P.string(']')).map(([_open, x, _space, y, _close]) => {\r\n        return {\r\n            x: x,\r\n            y: y,\r\n        };\r\n    }),\r\n```\r\n\r\nNow we get:\r\n\r\n```\r\n$ node index.js\r\n[ [ { x: 2, y: 3 }, { x: 6, y: 2 }, { x: 1, y: 2 } ],\r\n  [ { x: 1, y: 4 }, { x: 2, y: 1 } ],\r\n  [ { x: 6, y: 9 } ] ]\r\n```\r\n\r\nThis parser is easy to poke and prod at, or swap out components entirely - each part works independently of each other part.\r\n\r\nThere are libraries for parser combinators in a number of langauges - here's an example of what `PointSet` might look like in Rust using [`combine`](https://github.com/Marwes/combine), assuming we've already defined `sep()` and `point()` parsers:\r\n\r\n```rust\r\nfn point_set<I>() -> impl Parser<Input = I, Output = Vec<Point>>\r\nwhere\r\n    I: Stream<Item = char>,\r\n    I::Error: ParseError<I::Item, I::Range, I::Position>,\r\n{\r\n    (char('('), sep_by(point(), sep()), char(')')).map(|(_, points, _)| points)\r\n}\r\n```\r\n\r\nSyntax aside it's the same thing - composing arbitrary amounts of arbitrarily small parsers to parse any format you'd like.  For Rust, there's also [`nom`](https://github.com/Geal/nom) which leverages macros instead of traits but at the end of the day it's all the same good stuff.\r\n\r\nGot a favorite parser combinator library?  Let me know about it!",
    "title": "Parser Combinators are Easy"
  },
  {
    "cover_image": "https://i.imgur.com/b7yQAMB.png",
    "date": "2019-02-23T18:44:45.761Z",
    "description": "A quick tutorial for using dorothy to define and render Graphviz graphs",
    "tags": "clojure, beginners, graphviz",
    "markdown": "Quick post today - learning this made me feel like I levelled up, so I thought I'd share.\r\n\r\nI [recently decided](https://dev.to/deciduously/back-to-school-57fd) to remove the \"self\" from self-taught and go back to school for software development.  To nobody's surprise at all, my first semester includes a Discrete Mathematics class, and this week we looked at [Hasse diagrams](https://en.wikipedia.org/wiki/Hasse_diagram), used to represent [partially ordered sets](https://en.wikipedia.org/wiki/Partially_ordered_set).  This is just the sort of diagram [`graphviz`](https://graphviz.org/) is designed for!\r\n\r\nBeing a C library, Graphviz has interfaces in just about any language you could hope for.  Python is a good choice for quick one-offs like this, but it's also a natural fit for Clojure!  Also to nobody's surprise at all, the community has created a library for defining Graphviz graphs using Clojure data structures, like what [Hiccup](https://github.com/weavejester/hiccup) does for HTML.  It's called [`dorothy`](https://github.com/daveray/dorothy).\r\n\r\nTo follow along, you'll need to install [leiningen](https://leiningen.org/) and [graphviz](https://graphviz.org/download/).  Once both are installed, create a new project:\r\n\r\n```\r\n$ lein new app hasse\r\n```\r\n\r\nOpen up the `hasse` folder in your favorite text editor and find `project.clj`.  We just need to add the `dorothy` dependency.  Locate the `:dependencies` map and make it look like this:\r\n\r\n```clojure\r\n  :dependencies [[org.clojure/clojure \"1.9.0\"]\r\n                 [dorothy \"0.0.7\"]]\r\n```\r\n\r\nNow run `lein deps` to pull in the jar and open up `src/hasse/core.clj`.  Below the `(ns)` form, add the following require statements:\r\n\r\n```clojure\r\n(ns hasse.core\r\n  (:gen-class))\r\n(require '[dorothy.core :as dot])\r\n(require '[dorothy.jvm :refer (render save!)])]\r\n```\r\n\r\nTo create a graph, you just define your nodes and edges - and in this case, all we need to do is define edges.  Graphviz will take care of everything else.  Remove the body of `-main` and add a `let` binding to define our graph:\r\n\r\n```clojure\r\n  (let [g (dot/graph [\r\n    [:22 :2]\r\n    [:8 :2]\r\n    [:10 :5 :1]\r\n    [:10 :2 :1]])])\r\n```\r\n\r\nThere is also a `dot/digraph` which will create directed edges.  Each keyword is a node, and each list is an edge connecting two or more nodes.  Each node can take an attribute map as well, I'm just using the defaults for everything here.  Now that we've defined the graph, we use the `(dot/dot)` function to convert it to the Graphviz dot format.  We can then use `save!` to save our result:\r\n\r\n```clojure\r\n(-> g dot/dot (save! \"out.png\" {:format :png}))\r\n```\r\n\r\nThere is also a `show!` in `dorothy.jvm` which uses a simple Swing viewer - useful for testing.  Your full snippet should look like this:\r\n\r\n```clojure\r\n(ns hasse.core\r\n  (:gen-class))\r\n(require '[dorothy.core :as dot])\r\n(require '[dorothy.jvm :refer (render save!)])\r\n\r\n(defn -main\r\n  [& args]\r\n  (let [g (dot/graph [\r\n    [:22 :2]\r\n    [:8 :2]\r\n    [:10 :5 :1]\r\n    [:10 :2 :1]])]\r\n    (-> g dot/dot (save! \"out.png\" {:format :png}))))\r\n```\r\n\r\nNow run `lein uberjar` to compile the Clojure, execute `java -jar target/uberjar/hasse-0.1.0-SNAPSHOT-standalone.jar`, and marvel at the beauty:\r\n\r\n![graph](https://i.imgur.com/b7yQAMB.png)\r\n\r\nNifty!  That sure as heck is a Hasse diagram of the relation \"divides\" on the set {1,2,5,8,10,22}, I tell you hwat.\r\n\r\nThis is usable from ClojureScript as well, but without the rendering and saving functions - you'll need to rely on another library to get your dot format output to something visual.\r\n\r\nHappy diagrammin'!",
    "title": "Create Graphviz graphs in Clojure with dorothy"
  },
  {
    "cover_image": "https://ak4.picdn.net/shutterstock/videos/18388924/thumb/11.jpg",
    "date": "2019-02-26T14:22:33.655Z",
    "description": "A call for planning tool suggestions",
    "tags": "discuss, beginners",
    "markdown": "Any project has a certain amount of planning that's required before a single line of code can be written.  As I've learned more about the craft, the scope and complexity of my personal projects have increased to the point where my usual of M.O. of \"scribbles in a legal pad\" isn't going to cut it anymore.  What are some tools that you've found helpful in organizing your thoughts around a new project, either on your own or with a team?  Are UML-style diagrams or prototypes a must, regardless of project?\r\n\r\nWhen a brand new brilliant idea hits, what's step *one* towards realizing the goal?",
    "title": "What planning tools do you use?"
  },
  {
    "cover_image": "https://cdn-images-1.medium.com/max/2000/1*theA-BiTPVjhIlQ4njM9VQ.jpeg",
    "date": "2019-03-03T22:19:43.504Z",
    "description": "A walkthrough of a demo client and server using bs-0ocket",
    "tags": "reason, react, beginners, tutorial",
    "markdown": "In this post I'll demonstrate some real-time communication in a simple application using [ReasonML](https://reasonml.github.io/).  If you're brand new to Reason, some assumed basic comfort in JavaScript should be most of what you need, and there's a handy [cheatsheet](https://reasonml.github.io/docs/en/syntax-cheatsheet) to get you started.\r\n\r\nI'm using the [bs-socket](https://github.com/reasonml-community/bs-socket.io) bindings for [socket.io](https://socket.io/), a widely used Node.js real-time engine, and their [example](https://github.com/reasonml-community/bs-socket.io/tree/master/example) as a base.\r\n\r\nThe finished application will present each client with a set of named buttons and a dialog box to add a new button, as well as a running total of connected clients.  Clicking a button will remove it from the set, and this set will stay in sync across all connected clients.\r\n\r\n## Requirements\r\n\r\nThis is a [Node](https://nodejs.org/en/) project.  I'll be using [yarn](https://yarnpkg.com/en/) if you'd like to follow along exactly.  All other dependencies will be handled by node.\r\n\r\n## Setup\r\n\r\nFirst install the [BuckleScript](https://bucklescript.github.io/) platform if you do not already have it have it:\r\n\r\n```\r\n$ yarn global add bs-platform\r\n```\r\n\r\nNow we can use the `bsb` build tool to create a basic project:\r\n\r\n```\r\n$ bsb -init reason-buttons -theme basic-reason\r\n$ cd reason-buttons/\r\n$ yarn start\r\n```\r\n\r\nThis will start the compiler in watch mode - any changes you make to a file will immediately trigger a recompile of the resulting JavaScript, right next to the source.  Verify you see both `Demo.re` and `Demo.bs.js`. under `reason-buttons/src`.  Rename your Reason file to `ButtonServer.re` and see it immediately recompile to reflect the difference - `Demo.bs.js` is removed and the same contents now fill `ButtonServer.bs.js`.\r\n\r\nAdd a script to your newly generated `package.json` to execute this file:\r\n\r\n```json\r\n// ..\r\n\"scripts\": {\r\n  \"build\": \"bsb -make-world\",\r\n  \"serve\": \"node src/ButtonServer.bs.js\",  // <- here\r\n  \"start:re\": \"bsb -make-world -w\",\r\n  \"clean\": \"bsb -clean-world\"\r\n},\r\n// ..\r\n```\r\n\r\nI also renamed `start` to `start:re` - feel free to manage your scripts however is most comfortable.\r\n\r\nOne change I always immediately make in a Node.js app is pulling the port number out so it can be specified via environment variable.  Luckily, interop is dirt simple!  We can just use Node to grab it from an environment variable.  Create a file at `src/Extern.re` with the following contents:\r\n\r\n```ocaml\r\n[@bs.val] external portEnv: option(string) = \"process.env.PORT\";\r\n[@bs.val] external parseInt: (string, int) => int = \"parseInt\";\r\n```\r\n\r\nThe `[@bs.val]` syntax is a BuckleScript compiler directive.  There's an overview of the various syntaxes [here](https://bucklescript.github.io/docs/en/interop-cheatsheet) and the rest of that guide goes in depth about when to use each.  I won't get too far into the nuts and bolts of JS interop in this post, the docs are thorough and for the most part in find the resulting code legible.  The basic idea is that the keyword `external` is kind of like `let` except the body is a string name pointing to the external function.  This way we can incrementally strongly type the JavaScript we need and have Reason typecheck everything smoothly.\r\n\r\nThis code will also leverage the `option` [data type utilities](https://bucklescript.github.io/bucklescript/api/Belt.Option.html) for nullable values like `getWithDefault` from [`Belt`](https://bucklescript.github.io/bucklescript/api/Belt.html), the standard library that ships with Reason.  Replace the contents of `src/ButtonServer.js` with the following:\r\n\r\n```ocaml\r\nopen Belt.Option;\r\nopen Extern;\r\n\r\nlet port = getWithDefault(portEnv, \"3000\");\r\n\r\nprint_endline(\"Listening at *:\" ++ port);\r\n```\r\n\r\nI like to use `3000` for my default, you're of course welcome to use whatever you like.\r\n\r\nOver in `ButtonServer.bs.js` the compiled output is quite readable:\r\n\r\n```javascript\r\n// Generated by BUCKLESCRIPT VERSION 4.0.18, PLEASE EDIT WITH CARE\r\n'use strict';\r\n\r\nvar Belt_Option = require(\"bs-platform/lib/js/belt_Option.js\");\r\nvar Caml_option = require(\"bs-platform/lib/js/caml_option.js\");\r\n\r\nvar port = Belt_Option.getWithDefault((process.env.PORT == null) ? undefined : Caml_option.some(process.env.PORT), \"3000\");\r\n\r\nconsole.log(\"Listening at *:\" + port);\r\n\r\nexports.port = port;\r\n/* port Not a pure module */\r\n```\r\n\r\nLets verify it works.  Open up a separate terminal and type `yarn serve`.  You should see the following:\r\n\r\n```\r\n$ yarn serve\r\nyarn run v1.13.0\r\n$ node src/ButtonServer.bs.js\r\nListening at *:3000\r\nDone in 0.09s\r\n$\r\n```\r\n\r\n## Dependencies\r\n\r\nFor an example of how to use node's `Http` module manually see [this post](https://notes.maciejsmolinski.com/2018/03/02/reasonml-http-server-in-node-js/) by Maciej Smolinski.  For simplicity's sake I'll just use the community bindings for [`bs-express`](https://github.com/reasonml-community/bs-express).  We'll also pull in `bs-socket`:\r\n\r\n```\r\n$ yarn add -D bs-express https://github.com/reasonml-community/bs-socket.io.git\r\n```\r\n\r\nThen add it to `bs-config.json`:\r\n\r\n```json\r\n// ..\r\n\"bs-dependencies\": [\r\n  \"bs-express\",\r\n  \"bs-socket\"\r\n],\r\n// ..\r\n```\r\n\r\nBucklescript will take care of the rest as long as the package in question has a `bsconfig.json`.\r\n\r\n## Messages\r\n\r\nBefore we actually implement our server, though, we need to define some message types.  This will help us plan the scope of the application.  Create a new file at `src/Messages.re` with the following contents:\r\n\r\n```ocaml\r\n/* Messages */\r\n\r\ntype labelName = string;\r\ntype buttonList = list(labelName);\r\ntype numClients = int;\r\n\r\ntype msg =\r\n  | AddButton(labelName)\r\n  | RemoveButton(labelName);\r\n\r\ntype clientToServer =\r\n  | Msg(msg)\r\n  | Howdy;\r\n\r\ntype serverToClient =\r\n  | Msg(msg)\r\n  | ClientDelta(int)\r\n  | Success((numClients, buttonList));\r\n```\r\n\r\nThese are the various messages we'll be sending back and forth.  This is the biggest difference from using `socket.io` in JavaScript, where custom events are named with strings.  Here we always just emit a generic message but use ReasonML pattern matching to destructure the payload itself.  The library currently doesn't cover stringly typed events, though the one issue open is [asking about it](https://github.com/reasonml-community/bs-socket.io/issues/9).  The readme on that GitHub repo puts it succinctly:  \"The API differs a bit from socket.io's API to be more idiomatic in Reason. Generally, e.g. JavaScript's `socket.emit(\"bla\", 10)` becomes `Server.emit(socket, Bla(10))` in Reason\".\r\n\r\nTake a look at `Messages.bs.js`:\r\n\r\n```js\r\n// Generated by BUCKLESCRIPT VERSION 4.0.18, PLEASE EDIT WITH CARE\r\n/* This output is empty. Its source's type definitions, externals and/or unused code got optimized away. */\r\n```\r\n\r\nThey don't end up represented at all in our bundle - it's just a compile-time benefit.  Neat!\r\n\r\n## The Server\r\n\r\n### Express\r\n\r\nAlright - one last step before we can write our server.  Back in `src/Extern.re`, add the following typings for `Http` at the bottom of the file:\r\n\r\n```ocaml\r\nmodule Http = {\r\n  type http;\r\n  [@bs.module \"http\"] external create: Express.App.t => http = \"Server\";\r\n  [@bs.send] external listen: (http, int, unit => unit) => unit = \"\";\r\n};\r\n```\r\n\r\nNow we're ready!  Get back into `src/ButtonServer.re` and make it look like this:\r\n\r\n```ocaml\r\nopen Belt.Option;\r\nopen Express;\r\nopen Extern;\r\n\r\nlet port = getWithDefault(portEnv, \"3000\");\r\n\r\nlet app = express();\r\n\r\nlet http = Http.create(app);\r\n\r\nHttp.listen(http, port |> int_of_string, () =>\r\n  print_endline(\"Listening at *:\" ++ port)\r\n);\r\n```\r\n\r\n`|>` is the pipe operator.  In brief, `a |> b` is the same as `b(a)`.  It can be much more readable when chaining multiple functions.\r\n\r\nJust to verify it works, add a placeholder `/` endpoint, above the `Http.listen()` line.  We'll come back to the client.\r\n\r\n```ocaml\r\nApp.get(app, ~path=\"/\") @@\r\nMiddleware.from((_, _) => Response.sendString(\"<h1>HELLO, REASON</h1>\"));\r\n```\r\n\r\nAlright, I lied - there's one more bit o' syntax there.  Per [the docs](https://reasonml.github.io/api/Pervasives.html) `(@@)` is the application operator - \"g @@ f @@ x is exactly equivalent to g (f (x)).\"  If you're familiar with Haskell, it's `($)`, or if you're familiar with...math, I guess, it's `g o f(x)`.\r\n\r\nLet's make sure we're good to go:\r\n\r\n```\r\n$ yarn serve\r\n$ node src/ButtonServer.bs.js\r\nListening at *:3000\r\n```\r\n\r\nIf you point your browser, you should see **HELLO REASON**.\r\n\r\n### Socketry\r\n\r\nNow for the real-time bits!  Add the following two lines below your `/` endpoint, but above your call to `Http.listen()`:\r\n\r\n```ocaml\r\nmodule Server = BsSocket.Server.Make(Messages);\r\n\r\nlet io = Server.createWithHttp(http);\r\n```\r\n\r\nNow `socket.io` is configured to use the newly defined Message types.  To keep track of the current set of buttons and connected clients, we'll need some state:\r\n\r\n```ocaml\r\ntype appState = {\r\n  buttons: list(string),\r\n  clients: list(BsSocket.Server.socketT),\r\n};\r\n\r\nlet state = ref({buttons: [\"Click me\"], clients: []});\r\n```\r\n\r\nThe state is held inside a mutable `ref`.  We can access the current contents via `state^`, and assign to it with the assignment operator `:=`.  When the server starts up it has no clients and one default button.\r\n\r\nAlso handy is this helper function to emit a message to every client stored except the client passed:\r\n\r\n```ocaml\r\nlet sendToRest = (socket, msg) =>\r\n  state^.clients\r\n  |> List.filter(c => c != socket)\r\n  |> List.iter(c => Server.Socket.emit(c, msg));\r\n```\r\n\r\nNow everything is set up to define the real meat of the application.  Start with the following outline:\r\n\r\n```ocaml\r\nServer.onConnect(\r\n  io,\r\n  socket => {\r\n    // our code here....\r\n  },\r\n);\r\n```\r\n\r\nThe first part is how to handle a client connecting.  Replace the placeholder comment with the following:\r\n\r\n```ocaml\r\nopen Server;\r\n    print_endline(\"Client connected\");\r\n    state := {...state^, clients: List.append(state^.clients, [socket])};\r\n    sendToRest(socket, ClientDelta(1));\r\n    Socket.emit(\r\n      socket,\r\n      Success((List.length(state^.clients), state^.buttons)),\r\n    );\r\n```\r\n\r\nFor convenience we'll open our `Server` module into the local scope, and then adjust our state to include the new client.  We use the `sendToRest` function to emit the `ClientDelta` message to everyone else who may already be stored in `state.clients`, and finally send back the `Success` message, telling the newly connected client about the current state.\r\n\r\nThe next order of business is handling the disconnect.  Right below the last `Socket.emit()` call add:\r\n\r\n```ocaml\r\n    Socket.onDisconnect(\r\n      socket,\r\n      _ => {\r\n        print_endline(\"Client disconnected\");\r\n        sendToRest(socket, ClientDelta(-1));\r\n        state :=\r\n          {...state^, clients: List.filter(c => c == socket, state^.clients)};\r\n      },\r\n    );\r\n```\r\n\r\nThe client gets dropped from the app state and everyone else still connected is updated on the change.  The only part left is to handle the `clientToServer` messages we defined in `Messages.re`:\r\n\r\n```ocaml\r\nSocket.on(\r\n      socket,\r\n      fun\r\n      | Msg(msg) => {\r\n          switch (msg) {\r\n          | AddButton(name) =>\r\n            print_endline(\"Add \" ++ name);\r\n            state :=\r\n              {...state^, buttons: state^.buttons |> List.append([name])};\r\n            sendToRest(socket, Msg(AddButton(name)));\r\n          | RemoveButton(name) =>\r\n            print_endline(\"Remove \" ++ name);\r\n            state :=\r\n              {\r\n                ...state^,\r\n                buttons: state^.buttons |> List.filter(a => a == name),\r\n              };\r\n            sendToRest(socket, Msg(RemoveButton(name)));\r\n          };\r\n        }\r\n      | Howdy => {\r\n          print_endline(\"Howdy back, client\");\r\n        },\r\n    );\r\n```\r\n\r\nWhenever a button is added or removed, we adjust our state accordingly and let everyone else know about the change.  That's it for the server!  \r\n\r\n## The Client\r\n\r\n### Nuts 'n' Bolts\r\n\r\nI'd feel remiss if I didn't use the ReasonReact library for this demo.  It's excellent.  First, add the dependencies:\r\n\r\n```\r\n$ yarn add react react-dom\r\n$ yarn add -D reason-react\r\n```\r\n\r\nAlso add `reason-react` to `bsconfig.json`:\r\n\r\n```json\r\n  \"bs-dependencies\": [\r\n    \"bs-express\",\r\n    \"bs-socket\",\r\n    \"reason-react\"\r\n  ],\r\n```\r\n\r\nWhile we're in here, let's activate JSX.  Add the following entry to the top level:\r\n\r\n```json\r\n  \"reason\": {\r\n    \"react-jsx\": 2\r\n  },\r\n```\r\n\r\nTo handle bundling, I'm going to use [Parcel](https://parceljs.org/).  This is not necessary - you're welcome to use anything you're comfortable with.  To follow along, add the dependency:\r\n\r\n```\r\n$ yarn add -D parcel-bundler\r\n```\r\n\r\nAlso add a script to `package.json` to run it:\r\n\r\n```json\r\n\"scripts\": {\r\n  //..\r\n  \"start:bundle\": \"parcel watch index.html\",\r\n  //..\r\n},\r\n```\r\n\r\nWe also need to create that `index.html`.  Put it at your project root:\r\n\r\n```html\r\n<!-- https://github.com/sveltejs/template/issues/12 -->\r\n<!DOCTYPE html>\r\n<html lang=\"en\">\r\n\r\n<head>\r\n    <meta charset=\"UTF-8\">\r\n    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\r\n    <meta http-equiv=\"X-UA-Compatible\" content=\"ie=edge\">\r\n    <title>Reason Buttons</title>\r\n\r\n    <script id=\"s\"></script>\r\n    <script>\r\n        document.getElementById('s').src = \"socket.io/socket.io.js\"\r\n    </script>\r\n\r\n</head>\r\n\r\n<body>\r\n    <div id=\"app\"></div>\r\n    <script defer src=\"./src/Index.re\"></script>\r\n</body>\r\n\r\n</html>\r\n```\r\n\r\nThis stub includes a [workaround](https://github.com/sveltejs/template/issues/12) in the head for using Parcel with socket.io on the client side.  Also note that Parcel understands ReasonML - we can pass in `Index.re` for the entry point directly.  Once this file is here, open a new terminal and enter `yarn start:bundle` - this can be left running and will recompile your bundle when needed.\r\n\r\nWe now need to tell our server to serve this file instead of our placeholder string.  We'll use a little more interop from this - add the following to `Extern.re`, helpfully lifted from the [bs-socket example](https://github.com/reasonml-community/bs-socket.io/blob/master/example/ExampleServer.re):\r\n\r\n```ocaml\r\nmodule Path = {\r\n  type pathT;\r\n  [@bs.module \"path\"] [@bs.splice]\r\n  external join : array(string) => string = \"\";\r\n};\r\n\r\n[@bs.val] external __dirname : string = \"\";\r\n```\r\n\r\nNow replace the endpoint in `ButtonServer.re` with:\r\n\r\n```ocaml\r\nApp.use(\r\n  app,\r\n  {\r\n    let options = Static.defaultOptions();\r\n    Static.make(Path.join([|__dirname, \"../dist\"|]), options)\r\n    |> Static.asMiddleware;\r\n  },\r\n);\r\n\r\nApp.get(app, ~path=\"/\") @@\r\nMiddleware.from((_, _, res) =>\r\n  res |> Response.sendFile(\"index.html\", {\"root\": __dirname})\r\n);\r\n```\r\n\r\nThis sets up our static file serving and serves `dist/index.html`, which is generated by Parcel, at `/` instead of the placeholder string.\r\n\r\n### Code\r\n\r\nWe've pointed Parcel towards `src/Index.re` - might be a good idea to put a file there!  Create it with the following contents:\r\n\r\n```ocaml\r\nReactDOMRe.renderToElementWithId(<ButtonClient />, \"app\");\r\n```\r\n\r\nThis is how ReasonReact mounts to the DOM.  We're finally ready to build the component.\r\n\r\nIn a real app, this would ideally be split into several components - one for the buttons, one for the input, maybe a separate one for the counter.  For demonstration purposes I'm just throwing it all in one component, but if this app were to get much larger splitting it apart would likely be step number one.\r\n\r\nCreate a file at `src/ButtonClient.re`.  First, we'll set up our socket client at the top of the file:\r\n\r\n```ocaml\r\nmodule Client = BsSocket.Client.Make(Messages);\r\n\r\nlet socket = Client.create();\r\n```\r\n\r\nBelow that, we need to define the `state` for our component as well as the `action`s we can take to transform that state in order to create a `reducerComponent`:\r\n\r\n```ocaml\r\ntype state = {\r\n  numClients: int,\r\n  buttons: list(string),\r\n  newButtonTitle: string,\r\n};\r\n\r\ntype action =\r\n  | AddButton(string)\r\n  | ClientDelta(int)\r\n  | RemoveButton(string)\r\n  | Success((int, list(string)))\r\n  | UpdateTitle(string);\r\n\r\nlet component = ReasonReact.reducerComponent(\"ButtonClient\");\r\n```\r\n\r\nThis is pretty similar to the `socket.io` messages, with the addition of a `newButtonTitle` to allow the client to name the buttons they add.\r\n\r\nThe rest of the component will live in this skeleton:\r\n\r\n```ocaml\r\nlet make = _children => {\r\n  ...component,\r\n  initialState: _state => {numClients: 1, buttons: [], newButtonTitle: \"\"},\r\n  didMount: self => {\r\n    // socket.io message handling\r\n  },\r\n  reducer: (action, state) =>\r\n    switch (action) {\r\n      // actions\r\n    },\r\n  render: self =>\r\n    <div>\r\n      <h1> {ReasonReact.string(\"Reason Buttons\")} </h1>\r\n      <div>\r\n        // Buttons\r\n      </div>\r\n      <div>\r\n        // Add A Button\r\n      </div>\r\n      <span>\r\n        // Current Count\r\n      </span>\r\n    </div>,\r\n};\r\n```\r\n\r\nWe'll look at each section separately.  The `initialState` given here will just be used to render the component right off the bat - as soon as our client connects, it's going to receive a `Success` message which will overwrite this value.\r\n\r\nWe need to translate incoming `socket.io` messages.  I've put this in the `didMount` method to make sure our client has successfully loaded.  Replace the placeholder with:\r\n\r\n```ocaml\r\nClient.on(socket, m =>\r\n      switch (m) {\r\n      | Msg(msg) =>\r\n        switch (msg) {\r\n        | AddButton(name) => self.send(AddButton(name))\r\n        | RemoveButton(name) => self.send(RemoveButton(name))\r\n        }\r\n      | ClientDelta(amt) => self.send(ClientDelta(amt))\r\n      | Success((numClients, buttons)) =>\r\n        self.send(Success((numClients, buttons)))\r\n      }\r\n    );\r\n    Client.emit(socket, Howdy);\r\n```\r\n\r\nThe `Client.on()` portion is pattern matching on the incoming `serverToClient` messages and mapping it to the proper ReasonReact `action`.  We also send back a `Howdy` message to the server once successfully loaded.\r\n\r\nThe next order of business is our reducer.  We need to define how exactly each `action` should manipulate our `state`:\r\n\r\n```ocaml\r\nswitch (action) {\r\n| AddButton(name) =>\r\n  ReasonReact.Update({\r\n    ...state,\r\n    buttons: List.append(state.buttons, [name]),\r\n  })\r\n| ClientDelta(amt) =>\r\n  ReasonReact.Update({...state, numClients: state.numClients + amt})\r\n| RemoveButton(name) =>\r\n  ReasonReact.Update({\r\n    ...state,\r\n    buttons: List.filter(b => b != name, state.buttons),\r\n  })\r\n| Success((numClients, buttons)) =>\r\n  ReasonReact.Update({...state, numClients, buttons})\r\n| UpdateTitle(newButtonTitle) =>\r\n  ReasonReact.Update({...state, newButtonTitle})\r\n},\r\n```\r\n\r\nThe `...` spread operator is a huge help!  This code also takes advantage of a feature called \"punning\" - for instance, in `UpdateTitle(newButtonTitle)`, `newButtonTitle` is both being used as a temporary name for the message payload and the name of the field in the app `state`.  If they're named the same thing, we can use the shorthand `{...state, newButtonTitle}` instead of `{...state, newButtonTitle: newButtonTitle}`.\r\n\r\nAll that's left to define is the UI!  The list of buttons will render each button name in our `state` as a button which when clicked will signal the removal of that button:\r\n\r\n```ocaml\r\n{ReasonReact.array(\r\n  self.state.buttons\r\n  |> List.map(button =>\r\n       <button\r\n         key=button\r\n         onClick={_ => {\r\n           self.send(RemoveButton(button));\r\n           Client.emit(socket, Msg(RemoveButton(button)));\r\n         }}>\r\n         {ReasonReact.string(button)}\r\n       </button>\r\n     )\r\n  |> Array.of_list,\r\n)}\r\n```\r\n\r\nWe both send the `action` to our component's reducer as well as emit the `clientToServer` message to the server to make sure it gets removed everywhere.\r\n\r\nNext up is the box to set the name of any new button created:\r\n\r\n```ocaml\r\n<input\r\n  type_=\"text\"\r\n  value={self.state.newButtonTitle}\r\n  onChange={evt =>\r\n    self.send(UpdateTitle(ReactEvent.Form.target(evt)##value))\r\n  }\r\n/>\r\n<button\r\n  onClick={_ => {\r\n    let name = self.state.newButtonTitle;\r\n    self.send(UpdateTitle(\"\"));\r\n    self.send(AddButton(name));\r\n    Client.emit(socket, Msg(AddButton(name)));\r\n  }}>\r\n  {ReasonReact.string(\"Add button \" ++ self.state.newButtonTitle)}\r\n</button>\r\n```\r\n\r\nUpon submitting, the component will reset the field to an empty string.\r\n\r\nThe last bit is the count of total connected clients:\r\n\r\n```ocaml\r\n{ReasonReact.string(\r\n     (self.state.numClients |> string_of_int) ++ \" connected\",\r\n )}\r\n```\r\n\r\nAnd that's a wrap!  Let's fire it up.  Assuming you've had `yarn start:re` and `yarn start:bundle` running, open a new terminal and finally invoke `yarn serve`.  Now open up a couple of browser windows, point them all to `localhost:3000` and you should see them remain in sync with each other as you add and remove buttons.  Hooray!\r\n\r\nCompleted code can be found [here](https://github.com/deciduously/reason-buttons).\r\n\r\nCover image was found [here](https://blog.logrocket.com/what-makes-reasonml-so-great-c2c2fc215ccb).",
    "title": "Real-Time Communication in ReasonML with bs-socket"
  },
  {
    "cover_image": "https://res.cloudinary.com/practicaldev/image/fetch/s--iGTJRjd2--/c_imagga_scale,f_auto,fl_progressive,h_420,q_auto,w_1000/https://thepracticaldev.s3.amazonaws.com/i/teykkpgt1lebje46zar2.jpg",
    "date": "2019-03-08T04:06:13.310Z",
    "description": "Emacs is a whole thing.  It's a great tool to have in your belt, though, and nobo...",
    "tags": "beginners, emacs, tutorial",
    "markdown": "Emacs is a *whole thing*.  It's a great tool to have in your belt, though, and nobody ever sat me down and showed me what to do with it.  I think it's a damn shame I took so long to find it, so pull up a chair - we're going to set us up some editor.\n\nThis first post will go over basic usage and configuration, and next I'll go over the packages I've found most helpful.\n\nI came to Emacs, as so many do, via [Spacemacs](http://spacemacs.org/), which is a distribution of Emacs that comes preconfigured with a bunch of stuff and with its own separate abstraction over sets of packages.  It's great, actually.  It also has good integration with `evil` mode, which enable Vim keybindings, making it a lot more interesting to, well, Vim users.  I had already built some familiarity with Vim and was hesitant about undoing that progress, but far too curious about Emacs not to try it out.  Spacemacs is great, but it's a behemoth - there's a lot there, more than I'll ever need to use.  I realized after a few months that I hadn't really learned anything at all about Emacs - I was still using Vim bindings and had only ever added and removed layers from `.spacemacs` - no actual Emacsery afoot.\n\nSo, I started fresh.  I got a blank `~/.emacs.d` and set out to build the editor I wanted from scratch, and this time around I buckled down and went through the Emacs tutorial to get the \"real\" bindings under my fingers.  I now use a mix of VSCode and Emacs, but I'm glad I took the time to learn how powerful this tool really is, and still use the Emacs keybindings in VSCode instead of Vim now.\n\n...Yes, I wrote this article in Emacs.  Yeah, I heard you.\n\nIf you're planning to use Emacs in earnest, you should take the time to go through the tutorial.  Until then, here's a quick overview.\n\n## A Quick Overview\n\nEmacs is manipulated through combinations of commands.  Like Vim, it offers a scheme for controlling your text editor from the keyboard, moving away from the home row as little as possible.  Unlike Vim, which has separate *modes* that you switch in and out of, Emacs uses sequences of key combinations.  No mode switching here, you use modifier keys to indicate an editor action.  For example, we have \"Ctrl-x, Ctrl-s\" to save the current buffer, which is the current opened bit of text you're working on.  You can remember it by thinking \"execute save\" - the \"Ctrl-x\" prefix is used to *execute* a number of commands.  These sequences are so common in Emacs that there's a shorthand - this command would be written `C-x C-s`.  Capital C is Control, and the other most common is capital `M`.  This is most likely your \"alt\" key.  One great combo to keep in mind is `M-x`, which allows you to execute any Emacs command by name.  Emacs commands are just Emacs Lisp functions, and you can write your own, but there's a ton built in. Our new best friend `C-x C-s` is shorthand for the aptly named `save-buffer`, and if you've completely forgotten the combo, you can always `M-x save-buffer` in a pinch.\n\nIf all this sounds like it's going to be a lot, that's because it absolutely is.  How would you know it's called exactly that?  What else is there?  Fret not!  In the next post we're going to install a few very helpful packages that lets us explore these trees of commands visually.  It's all quite nice, I promise, [don't panic](https://proxy.duckduckgo.com/iu/?u=https%3A%2F%2Fcatallassi.files.wordpress.com%2F2014%2F04%2Fthe-hitchhikers-guide-to-the-galaxy-dont-panic-1280x1024-wallpaper_www-wall321-com_50.jpg&f=1)!\n\nHere's a few helpful commands.\n\n\n### Movement\n\n```\nC-f Move [f]orward one character\nM-f Move [f]orward one word\n\nC-b Move [b]ackward one character\nM-b Move [b]ackward one word\n\nC-n Move to the [n]ext line\nC-p Move to the [p]revious line\n\nC-a Move to the [a]ft of the line (okay that's a little forced - the beginning of the line)\nC-e Move to the [e]nd of the line\n\nM-< Move to the top of the file\nM-> Move to the bottom of the file\n```\n\n### Copy/Cut/Paste\n\n```\nMove cursor to beginning of region\n\nC-Spc to set marker\n\nMove cursor to the end of the region\n\nC-w to cut the marked region or\nM-w to copy the marked region\n\nMove cursor to target\n\nC-y to paste region\n```\n\n### File/Window/Buffer\n\n```\nC-x C-s save current buffer\nC-x C-f Open file\nC-x C-c Save and quit emacs\nC-x b List open buffers (This will let you select one of them)\nC-x 1 Delete all other open windows (This is useful for getting rid of one-off messages that spawn windows)\nC-/ Undo - keep going to keep undoing\n```\n\n### Advanced:\n\n```\nC-M-f Move forward over a balanced expression (words count!  try this one on a bunch of different kinds of files)\nC-M-b Move backward over a balanced expression\nC-M-k Kill balanced expression forward\nC-M-Spc Mark the end of the next s-expression\nC-M-n Move forward a parenthetical group\nC-M-p Move backward a parenthetical group\n```\n\nOne honorary mention: `C-k [k]ill line`.  This will kill from the cursor to the end of the line, and also pull the text into the buffer.  You can then paste what was killed with `C-y`.  As an example a common pattern for me for moving the line I'm on is `C-a C-k` to hop to the beginning and kill it, then using `C-n` or `C-p` and `C-y` to drop it somewhere else.  Self test: what does `M-< C-Spc M-> M-w` do?\n\nEach command is fairly mnemonic.  It doesn't take long to get them under your fingers.  I find myself saying the action I intend aloud in my head for a while when I'm learning a new one.  Also, the `M` version are often \"more abstracted\" versions of your favorite `C` command.  That's often a good thing to try when exploring a new library - many will define combinations with similar characteristics.\n\nSome of those require three keys - `M->` has a shift involved too.  Wacky, right?  It definitely does take some practice, but eventually you never need to leave the home row position.\n\nAlso awesome is that these key combinations show up all over the place!  If your system has `bash`, open up a terminal - `C-f`, `C-b`, `C-a`, and `C-e` all work.  Anything that uses `readline` will use a subset of these commands as well.  This might be common knowledge, but I had no idea until I tried Emacs.  Blew my mind a little at least.\n\nThis was but a touch of the commands available.  You can make windows (try `C-x 2` or `C-x 3` to split the window horizontally or vertically) and do all kinds of fun stuff (check out [`C-x z`](https://www.gnu.org/software/emacs/manual/html_node/emacs/Repeating.html)) - I cannot hope to do it all justice here so I won't try.  I definitely recommend going through the tutorial and looking at the [`manual`](https://www.gnu.org/software/emacs/manual/html_node/emacs/index.html#Top).  This post is going to focus on the config, and this all should get you up and running.  You can also fall back to the arrow keys and mouse to hop around if you need, but it's worth it to force yourself not to!\n\nNow we're going to start to dive through my personal `init.el`.  Contain your excitement, please, we've only just begun.\n\n## init.el\n\nEmacs is really a lisp interpreter with a solid text editor bundled.  I've always thought the whole \"Emacs vs. Vim\" debate was a little ridiculous - they're wildly different.  Vim is for when you would use a text editor, Emacs feels much more akin to driving a hyper-customizable IDE.  There's no \"Notepad++ vs IntelliJ\" flame war going on, why should there be one between Vim and Emacs?\n\nAnyway, the goodness starts in a file called `init.el`.  This is an ELisp file that lives in your `emacs.d` directory and is evaluated on startup.  Mine begins with a number of variables being set.  These are my preferences, season to taste:\n\n```elisp\n(setq delete-old-versions -1 ) ; delete excess backups silently\n(setq version-control t )\n(setq vc-make-backup-files t )\n(setq vc-follow-symlinks t )\n(setq backup-directory-alist `((\".\" . \"~/.emacs.d/backups\")) )\n(setq auto-save-file-name-transforms '((\".*\" \"~/.emacs.d/auto-save-list/\" t)) )\n(setq inhibit-startup-screen t )\n(setq ring-bell-function 'ignore ) ; silent bell on mistakes\n(setq coding-system-for-read 'utf-8 )\n(setq coding-system-for-write 'utf-8)\n(setq sentence-end-double-space nil)\n(setq-default fill-column 80) ; toggle wrapping text at this column\n(setq initial-scratch-message \"EEEEEEEEEEEmacs...macs...(macs)... Hi Ben.\" ) ; You should probably change this\n(global-display-line-numbers-mode t )\n(menu-bar-mode -1) ; no need for the menu bars - we've got key combos for that!\n(toggle-scroll-bar -1)\n(tool-bar-mode -1)\n```\n\n@yorodm hepfully suggests the following more complete UTF-8 config:\n\n{% devcomment 9979 %}\n\nThanks, Yoandy!\n\nRemember before when I said Emacs was a Lisp interpreter?  It's serious business.  You don't need to restart the editor to make changes, or even reload the whole buffer.  You can use `C-x C-e` with your cursor at the end of any of those parenthesized s-expressions to have Emacs evaluate it immediately.  Aww *yeah*.  Try toggling the scroll bar on and off BEFORE YOUR VERY EYES.  You can also use `M-x eval-buffer` to reload the whole thing or just mark a region and use `M-x eval-region` - you do you, you know?\n\nThis section is pretty readable.  You use `setq` to set the value of variables.  Anything set to a value of `-1` is like setting it to `false` - I'm disabling the menu bar and toolbar and all the extra stuff that's on by default.  All the functionality therein is also exposed via endless trees of keyboard commands.\n\nNow for the packages!\n\n### use-package\n\nPackages in Emacs are powerful, and with that power does come some complexity.  To tame the beast, I recommend a tool called [`use-package`](https://github.com/jwiegley/use-package).  It's a macro that lets you compartmentalize your package declarations and set per-package configurations in a neat and tidy way.  To set it up with the Emacs package manager, add the following to `init.el`:\n\n```elisp\n;; use-package setup\n(require 'package)\n(setq package-enable-at-startup nil) ; dont do it immediately\n(setq package-archives '((\"org\"       . \"http://orgmode.org/elpa/\")\n\t\t\t (\"gnu\"       . \"http://elpa.gnu.org/packages/\")\n\t\t\t (\"melpa\"     . \"https://melpa.org/packages/\")))\n(package-initialize)\n\n;; Bootstrap use-package\n(unless (package-installed-p 'use-package)\n  (package-refresh-contents) ; update archives\n  (package-install 'use-package)) ; grab the newest use-package\n\n;; Define packages\n(require 'use-package)\n\n;; Always download if not available\n(setq use-package-always-ensure t)\n```\n\nDon't forget to `M-x eval-buffer`!\n\n### Testing it out\n\nTo check that it's all working, lets add a package.  A good one to start with is [all-the-icons](https://github.com/domtronn/all-the-icons.el).  This installs a bunch of icons and fonts - no more blank squares anywhere.  Add the following:\n\n```elisp\n(use-package all-the-icons)\n```\n\nWith your cursor at the end of the line, smash that `C-x C-e` and Emacs will install the package.  It works because we have `(setq use-package-always-ensure t)` set.  This particular package has a one-time setup step - go ahead and execute `M-x all-the-icons-install-fonts` now so you never have to worry about it again.\n\nYou should be good to go!  This is a very blank slate - head to part 2 to get productive with it!\n\nOh, by the way... the self test answer from above: `M-< C-Spc M-> M-w` will copy the whole buffer.  I was going to wait for the next post but I just couldn't.  Emacs is *just so exciting*.",
    "title": "How I Emacs And So Can You"
  },
  {
    "cover_image": "https://res.cloudinary.com/practicaldev/image/fetch/s--aYHDIAyT--/c_imagga_scale,f_auto,fl_progressive,h_420,q_auto,w_1000/https://thepracticaldev.s3.amazonaws.com/i/08t3ydtxov6ym0aghmin.jpg",
    "date": "2019-03-08T14:05:05.304Z",
    "description": "In the first post we looked at some basic usage and navigation, and set up use-pa...",
    "tags": "beginners, emacs, tutorial",
    "markdown": "In the first post we looked at some basic usage and navigation, and set up `use-package` so we can easily add community packages to our Emacs installation.\n\n## Breathing Room\n\nI think I go a little overboard with this, but every time one of my `use-package` declarations goes over a single line, I like to pull it out to its own file.  That way I just have one line to comment/uncomment in `init.el` to activate/deactivate a package.  To set this up, create a directory inside `.emacs.d` - I just called mine `.emacs.d/lisp`.  We can ensure it gets evaluated by adding the following to `init.el`:\n\n```elisp\n;; Pull in ./lisp/*\n(add-to-list 'load-path (expand-file-name \"lisp\" user-emacs-directory))\n```\n\nNow any `whatever.el` elisp file we put in this directory will be visible to `init.el`.\n\nThe Emacs ecosystem is big, and there are multiple solutions and sets of solutions for any given problem.  I like to keep mine pretty minimal, this is just the set that works for me - I do urge you to explore!  The packages used in this set, notably, are not the same set that Spacemacs is based around.  When you do your own research, it sorta-kinda comes down to [`helm`](https://github.com/emacs-helm/helm) & friends vs. [`ivy/swiper/counsel`](https://github.com/abo-abo/swiper) - this is the `ivy` route.  I intentionally wanted to try something different from what I had gotten to know via Spacemacs, but it shouldn't be taken as a value judgement at all.  I've enjoyed using both greatly.\n\nThese are completion engines.  Remember the last post, when we forgot `C-x C-s` but then still miraculously knew it was `save-buffer`?  With `ivy`, you'd be able to just hit `M-x` and then frantically start typing `save` and `ivy` will find everything it possibly could be.  It will even helpfully show you the assigned key combination for a given command if there is one.  Pretty damn handy with a tool as vast as Emacs!  It's a personal always-on concierge.\n\n### Ivy/Counsel/Swiper\n\nThat's as good a place to start as any.  Ivy is the main event here, and `counsel` and `swiper` are `ivy`-imbued versions of common commands and file search, respectively.  Create a file called `init-ivy.el`:\n \n```elisp\n;;; #init-ivy.el\n;;; Commentary:\n;;; http://oremacs.com/swiper/#installation\n;;; https://sam217pa.github.io/2016/08/30/how-to-make-your-own-spacemacs/#fnref:3\n;;; https://writequit.org/denver-emacs/presentations/2017-04-11-ivy.html#fnr.2\n;;; Code:\n(use-package ivy\n  :diminish (ivy-mode . \"\")\n  :init (ivy-mode 1) ; globally at startup\n  :config\n  (setq ivy-use-virtual-buffers t)\n  (setq ivy-height 20)\n  (setq ivy-count-format \"%d/%d \"))\n(provide 'init-ivy)\n;;; init-ivy.el ends here.\n```\n\nIn this same file, I also set up `counsel`.  This package overrides some built-in Emacs commands with more user friendly versions.  Add this above the final comment:\n\n```elisp\n;; Override the basic Emacs commands\n(use-package counsel\n  :bind* ; load when pressed\n  ((\"M-x\"     . counsel-M-x)\n   (\"C-s\"     . swiper)\n   (\"C-x C-f\" . counsel-find-file)\n   (\"C-x C-r\" . counsel-recentf)  ; search for recently edited\n   (\"C-c g\"   . counsel-git)      ; search for files in git repo\n   (\"C-c j\"   . counsel-git-grep) ; search for regexp in git repo\n   (\"C-c /\"   . counsel-ag)       ; Use ag for regexp\n   (\"C-x l\"   . counsel-locate)\n   (\"C-x C-f\" . counsel-find-file)\n   (\"<f1> f\"  . counsel-describe-function)\n   (\"<f1> v\"  . counsel-describe-variable)\n   (\"<f1> l\"  . counsel-find-library)\n   (\"<f2> i\"  . counsel-info-lookup-symbol)\n   (\"<f2> u\"  . counsel-unicode-char)\n   (\"C-c C-r\" . ivy-resume)))     ; Resume last Ivy-based completion\n```\n\nDon't worry too too much about memorizing everything here right off the bat - it will be here when you need it.  For a while I had an index card with a few of the most handy ones sitting on my desk.  In the last post we covered the \"save\" action, which was a whole keypress more than you're probably used to - this is because `C-s` is reserved for searching for text in the given file.  Check out the [video demo](https://www.youtube.com/watch?v=VvnJQpTFVDc).\n\n### Interlude: Wait, There Totally Are Modes\n\nWell, yes, but they're not Vim modes!  In Emacs, a `mode` determines how Emacs semantically understands the text in the current buffer.  These fall into two categories, `major` and `minor` - each buffer has one major mode, and can have multiple minor modes.  A major mode might be something like `clojure-mode` - this text is only Clojure code, not some other type of code as well, but could have `ivy-mode` and `spellcheck-mode` enabled as well, because that functionality can stack.\n\nAlright, now that `init-ivy.el` has been added to `lisp/`, we can add it to `init.el`:\n\n```elisp\n(require 'init-ivy)\n```\n\nThat's it!  Evaluating that `require` expression with `C-x C-e` will read our new file and set up Ivy for us.\n\n### Flycheck\n\nAnother package I love is [flycheck](https://www.flycheck.org/en/latest/), which provides on the fly syntax checking.  It has indicators for problematic lines, squiggly underlines, and pop-up tooltips - all the trappings of a modern syntax checker.  This declaration is simpler:\n\n```elisp\n;;; lisp/init-flycheck.el\n(use-package flycheck\n  :init (global-flycheck-mode))\n(provide 'init-flycheck)\n```\n\nAnd in `init.el`:\n\n```elisp\n(require 'init-flycheck)\n```\n\nSome languages will require special setup, but most things will just work out of the box.\n\n### Company\n\nA perfect complement to `flycheck-mode` is [`company-mode`](https://company-mode.github.io/), which provides text-completion.  As you type, it will make suggestions.  You can scroll through them with `M-n` and `M-p`, and use the enter key to select.  There are more ways to interact with it as well - peep the docs for deets.\n\nIn `lisp/init-company.el`:\n\n```elisp\n(use-package company\n  :config\n  (add-hook 'after-init-hook 'global-company-mode))\n(provide 'init-company)\n```\n\nAnd of course `(require 'init-company)` in `init.el`.  Now we're starting to feel like a real IDE!\n\n### which-key\n\nThis is probably my favorite of the bunch.  Ivy is giving us some nice completions, but you still need to know where to start - it's not great for discovering what's available.  [Which-key](https://github.com/justbur/emacs-which-key) will pop up a window when you begin a command listing everything available.  In our `save-buffer` example, when you type the first `C-x`, you'll get a big pane detailing every combination available after `C-x`, with the combo and the command name.  This is how I find new combos to learn, and it's great for jogging your memory.\n\nMy `init-which-key.el`:\n\n```elisp\n(use-package which-key\n  :init\n  (which-key-mode)\n  :config\n  (which-key-setup-side-window-right-bottom)\n  (setq which-key-sort-order 'which-key-key-order-alpha\n\twhich-key-side-window-max-width 0.33\n\twhich-key-idle-delay 0.05)\n  :diminish which-key-mode)\n\n(provide 'init-which-key)\n```\n\nTweak these to your liking, these settings work for me.  Of course, don't forget `(require 'init-which-key)` in `init.el`!\n\n### Smartparens\n\nThis minor mode helps manage your parentheses.  It has a number of [facilities](https://github.com/Fuco1/smartparens) for manipulating parenthetical expressions - a huge help no matter what programming language you use.\n\n`lisp/init-smartparens.el`:\n\n```elisp\n(use-package smartparens\n  :config\n  (require 'smartparens-config)\n  (add-hook 'lisp-mode-hook #'smartparens-strict-mode))\n(provide 'init-smartparens)\n```\n\nI've added a hook that activates an even stricter version when I'm in a specific minor mode - this is also something you'll need to tweak for yourself!  I actually also use `smartparents-strict-mode` in `rust-mode` - we'll get to the langauge-specific stuff later.\n\nBy now you know the drill for getting it into `init.el`!\n\n### Neotree\n\nThis is my last general package.  Neotree is a habit I picked up from Vim - it shows a graphical overview of the directory tree that you can use to switch between files.  Another nicety that IDEs feel like they should have - though for the most part I find myself invoking `C-x C-f` or `C-x b` to navigate around in a project.\n\n`lisp/init-neotree.el`:\n\n```elisp\n(use-package neotree\n  :init\n  (require 'neotree)\n  :config\n  (setq neo-theme (if (display-graphic-p) 'icons 'arrow))\n  (setq neo-smart-open t)\n  )\n(provide 'init-neotree)\n```\n\nI lied - that was the second to last.  I also use [`find-file-in-project`](https://github.com/technomancy/find-file-in-project).\n\n```elisp\n(use-package find-file-in-project)\n```\n## Keybindings\n\nThe next order of business is setting up your own keybindings.  We can use `global-set-key` for this.  The first one I set is the key to activate `neotree` - add this to your `init.el`:\n\n```elisp\n(global-set-key [f8] 'neotree-project-dir)\n```\n\nTo enable this behavior, I have the following snippet stolen from the emacs wiki placed in `lisp/bl-fns.el` to facilitate NeoTree attempting to use the git project root when it opens:\n\n```elisp\n(defun neotree-project-dir ()\n  \"Open NeoTree using the git root.\"\n  (interactive)\n  (let ((project-dir (ffip-project-root))\n\t(file-name (buffer-file-name)))\n    (if project-dir\n\t(progn\n\t  (neotree-dir project-dir)\n\t  (neotree-find file-name))\n      (message \"Could not find git project root.\"))))\n\n(provide 'bl-fns)\n```\n\nPretty easy, right?  Now the F8 key will toggle the NeoTree window.  Cool.  Another keybinding I add for myself that I find useful is this:\n\n```elisp\n(global-set-key (kbd \"C-c q\") (lambda ()\n\t       \t\t       (interactive)\n   \t\t\t       (other-window -1)))\n```\n\nThe `kbd` macro lets you define combos using the handy shorthand.  This combo, `C-c q`, will switch back to the previous active window.  I generally only have two or three open and find myself using this one a lot.\n\nI also like this shorthand for `company-complete`:\n\n```elisp\n(global-set-key (kbd \"C-c h\") 'company-complete)\n```\n\n## Language-specific packages\n\n### Clojure\n\nFor clojure, I use [CIDER](https://github.com/clojure-emacs/cider):\n\n```elisp\n;; init-clojure.el\n(use-package clojure-mode)\n(use-package cider)\n(provide 'init-clojure)\n```\n\nCIDER is a whole can of worms in and of itself - I'll come back to that in a separate post sometime!\n\n### Rust\n\nRust has a little more going on to set it up with flycheck and cargo and everything:\n\n```elisp\n;; init-rust.el\n(use-package rust-mode)\n(use-package flymake-rust)\n(use-package racer)\n(use-package company)\n(use-package cargo\n  :config\n  (add-hook 'rust-mode-hook 'cargo-minor-mode))\n(use-package flycheck-rust)\n(with-eval-after-load 'rust-mode\n  (add-hook 'flycheck-mode-hook #'flycheck-rust-setup))\n(provide 'init-rust)\n```\n\nTo be completely honest, Rust was my biggest driver in migrating toward VSCode - Rust in Emacs is fantastic, Rust in VSCode is unparalleled.  The above works great, but I just can't in good faith recommend this setup *over* using the RLS from VSCode.\n\n### Some More\n\nForth, JavaScript/HTML/CSS, and Reason/OCaml I use with zero config:\n\n```elisp\n(use-package forth-mode)\n(use-package js2-mode)\n(use-package reason-mode)\n(use-package web-mode)\n(use-package ocp-indent)\n```\n\nAnd....that's all I got for ya!  This set of packages provides a complete multi-language IDE without much bloat.\n\nTo update your installed packages, run `M-x list-packages` - this will refresh the latest package list.  Then just type `U` (shift-u) to upgrade any that are outdated.",
    "title": "How I Emacs And So Can You: Packages"
  },
  {
    "cover_image": "https://res.cloudinary.com/practicaldev/image/fetch/s--q5Ws5y01--/c_imagga_scale,f_auto,fl_progressive,h_420,q_auto,w_1000/https://thepracticaldev.s3.amazonaws.com/i/9c5r1t5vumxukim530px.jpg",
    "date": "2019-04-23T18:09:21.627Z",
    "description": "I've found a great way to ensure I've grokked a thing is to write it up in Rust. ...",
    "tags": "rust, beginners, tutorial",
    "markdown": "I've found a great way to ensure I've grokked a thing is to write it up in Rust.  In that spirit, this post covers a translation of the program in [this post](http://theorangeduck.com/page/17-line-markov-chain) by [orangeduck](http://theorangeduck.com/page/about) into Rust, with a minor difference and some extra explanation including about why writing Rust is the way it is.  Depending on your comfort level it may be skimmable, especially if you already got some Rust in you.  It will only take us 70 extra lines!\n\nA [Markov chain](https://en.wikipedia.org/wiki/Markov_chain) can be used to generate realistic(ish) sounding random text based on a sample input.  The Wikipedia article is somewhat opaque, as Wikipedia can tend to be, but at its heart it's a very simple concept in which the next word is chosen based entirely on the current two words.  It's surprisingly simple (at least, I was surprised at how easy it was) and yet generates some real-sounding(ish) text with minimal effort.  For a fun example of this in action, check out the subreddit [/r/SubredditSimulator](https://www.reddit.com/r/SubredditSimulator/).  All of the posts and comments found there are generated using Markov chains using their respective subreddits as input data.\n\n# On Your Marks\n\nIf you're just here for the Markov Chain algorithm and not the Rust, skip down to \"The Algorithm\" in the **Markov!** section.\n\nThis project requires stable [Rust](https://rustup.rs/).  Go there to get it if you need, and then spin up a project:\n\n```\n$ cargo new markov\n$ cd markov/\n```\n\n# Get Set\n\nBefore hopping in, a quick 'n' dirty CLI would be nice for playing around with different inputs.  Luckily, Rust has a great option in [structopt](https://github.com/TeXitoi/structopt).  From the project root:\n\nI like to use `cargo-add` from rapid experimentation: `$ cargo install cargo-add` from any dir to add it to cargo.\n\n```\n$ cargo add structopt\n```\n\nAs the name implies this crate makes it easy to define an interface by simply defining a struct.  It uses macros to handle all the code generation required.  Add the following to the top of `src/main.rs`:\n\n```rust\nuse std::{error::Error, path::PathBuf, str::FromStr};\nuse structopt::StructOpt;\n\n#[derive(StructOpt, Debug)]\n#[structopt(name = \"markov\")]\nstruct Opt {\n    /// Input text file\n    #[structopt(short = \"i\", long = \"input\")]\n    input: Option<PathBuf>,\n    /// Output length\n    #[structopt(short = \"l\", long = \"length\")]\n    length: Option<u32>,\n}\n```\n\nWe're auto-deriving two [traits](https://doc.rust-lang.org/book/ch10-02-traits.html), `StructOpt` and `Debug`.  The latter is like `toString()` from Java, it creates a string representation of the struct, and the StructOpt one is going to give us methods like `from_args()` to instantiate it from the command line arguments automatically.  It also leverages a special custom tag `#[structopt]` which is used to configure the behavior of this macro.\n\nThe doc comments with the three slashes end up in the help string this crate will generate for us.  An example format for this struct would be something like `./markov -i poetry.txt -l 500`.  You can use cargo directly with `cargo run -- -i poetry.txt -l 500`.  The long names are used with two dashes, like `--length`.\n\nEach field has a type like `Option<T>`, which means if either is omitted when the program is invoked this struct will just hold a `None`.  If you're not used to that syntax, any time you see a single capital letter it stands for a generic type.  A real value you use would be specifically typed, such as `Option<String>`.\n\nA `PathBuf` is a fancy `String` with [cross-platform path abstractions](https://doc.rust-lang.org/std/path/index.html) built in.  You can `push()` to them and traverse them the same way in Rust code on whichever platform it runs.\n\nOtherwise, though, this is just a regular old Rust struct, it's just got a fancy custom `impl StructOpt {}` block generated for us.\n\nNow, replace the template `println!` call given in `main()` with:\n\n```rust\nfn main() {\n    let opt = Opt::from_args();\n    let filename = opt\n        .input\n        .unwrap_or_else(|| PathBuf::from_str(\"poetry.txt\").unwrap());\n    let length = opt.length.unwrap_or(350);\n\n    if let Err(e) = run(filename, length) {\n        eprintln!(\"Error: {}\", e);\n        ::std::process::exit(1);\n    };\n}\n```\n\nIf you're not new to Rust, that's probably fine and dandy.  If you are, let's unpack it a little.\n\nFirst, we generate the struct itself from whatever was passed on the command line.  In the line `let opt = Opt::from_args()`, `Opt` is the struct we defined just above, flexing its fancy code-gen'd `from_args()` method.  If this program were invoked as `cargo run -- -i poetry.txt -l 350` example from above, we now have stored in the variable `opt`:\n\n```rust\nOpt(\n    input: Some(PathBuf(inner: \"poetry.txt\")),\n    length: Some(350u32),\n)\n```\n\nAll in-memory data structures will be presented in [RON](https://github.com/ron-rs/ron).\n\nNote that the guts of `PathBuf` are omitted - it's an [`OsString`](https://doc.rust-lang.org/std/ffi/struct.OsString.html) if you're curious but we just care it's a `PathBuf`.\n\nThe first thing to do is get something more concrete from those options to pass in to the program.  Using `unwrap_or_else()` is a great way to do this.  If the value is a `Some(thing)` it returns `thing`, and if it's `None` it calls the passed closure, and it's gotta be one of those two.  If you just need a default value and not a function call, you can just use `unwrap_or()`.\n\nThat `from_str` call we do to get our default `\"poetry.txt\"` `&str` value into a `PathBuf` is part of the `FromStr` trait and only works when that trait is in scope.  It's an operation that can fail - for example, with a malformed path - so it returns a `Result<T, E>`.  This type acts like `Either` from Haskell if you're familiar, it either contains an `Ok(something: T)` or an `Err(error: E)` value.  You can get at the `T` of those with `unwrap()` if you're sure you'll have a successful `Ok` return value.  We know this one won't fail because we just made the input ourselves and it's not a malformed path, just a filename with an extension.  If you don't have something valid this will panic and crash.  It's almost always better to use something like `unwrap_or()`  or [pattern matching](https://doc.rust-lang.org/book/ch06-02-match.html) to deal with the alternative cleanly!\n\nNext we pass both in to an error-checked function.  It's good practice to take advantage of Rust's error handling for as much of your program as possible - this is a good way to force it!  The `if let` syntax is a way of capturing any error.  Our `run()` function here is also going to return a `Result<T, E>` - they're a bit of a theme in Rust.  It's sort of like a big try/catch embedded in the type system.  When called in an `if let`, if it ends up returning an `Ok(_)` nothing will happen.  If anything inside returns an error of any type (more on that in a moment) at any point, we'll execute the code path in this if block.  It uses destructuring - this line is saying that if the return value of `run()` can be destructured into an `Err(e)`, run this code.  The only alternative variant is `Ok(val)` - in which case we know everything went fine, and there's no action to take.  If we wanted to do something else, we could have included an `else {}` block as well.  This error catch will use `eprintln!` to display the specific error information returned on `stderr` and end the program with an error code of 1, indicating it was not successful.\n\nOf course, now we need a properly typed `run()` function.  Here's a stub, just to get us to compile:\n\n```rust\nfn run(input: PathBuf, length: u32) -> Result<(), Box<dyn Error>> {\n    Ok(())\n}\n```\n\nThe meat of our program expects concrete values, not `Option<T>`, and like good responsible Rustaceans we return a `Result<T, E>`, specifically a `Result<(), Box<dyn Error>`.  Our success type, `()` stands for `unit` which is the empty tuple, akin to `void`.  This demo will just be outputting our random text to `stdout`, there's no value to return.  If you wanted to store the generated text and pass it to another part of your program, this might look like `Result<String, Box<dynError>>`.  The `Box<dyn Error>` type we're using for the Error type merits a little more explaining.\n\nA [`Box<T>`](https://doc.rust-lang.org/std/boxed/index.html) is a boxed value - a basic heap-allocated value of type `T`.  Specifically the `Box` is a pointer to it, but a Rust-y smart pointer that knows about ownership and borrowing.  It's got a big name but it's just a pointer, nothing else.  This is useful because the `Box` has a size known at compile time, even if the value it points to may not.  The thing in the box with the `dyn Trait` syntax is a [*trait object*](https://doc.rust-lang.org/book/ch17-02-trait-objects.html).  `Error` from `std::error` is a trait that many different types of more specific errors types implement.  Using `dyn Error` we cover any type that implements the `Error` trait. This allows us to pass and catch all the different types of errors in one function easily.\n\nIf you're brand new to Rust and that was a little too breezy, you're in for a real treat outside the scope of this post but don't worry - this part isn't necessary to understand the Markov bits below!  It's just some Rust boilerplate for clean and happy error handling without much setup.\n\nLet's fire it up!  See if the help string is working with:\n\n```\n$ cargo run -- -h\n    Finished dev [unoptimized + debuginfo] target(s) in 0.04s\n     Running `target/debug/markov -h`\nmarkov 0.1.0\nyou <you@you.cool>\n\nUSAGE:\n    markov [OPTIONS]\n\nFLAGS:\n    -h, --help       Prints help information\n    -V, --version    Prints version information\n\nOPTIONS:\n    -i, --input <input>      Input text file\n    -l, --length <length>    Output length\n```\n\nGroovy!  Thanks, structopt.  Don't forget:\n\n```\n$ git init\n$ git add .\n$ git commit -m \"Initial commit\"\n```\n\n# Markov!\n\n## The Algorithm\n\nThe idea of this method of text generation is to choose the next word based entirely on the current two words, using only words that appear after them in the source text.  This algorithm never cares about more than two words at a time - it just knows all the possible options that come after that particular word duo.  Before we can start spewing out beautiful nonsense, then, we need to catalog the input.\n\nWe can implement this in Rust with a [HashMap](https://doc.rust-lang.org/std/collections/struct.HashMap.html) as a lookup table.  One word doesn't quite give us enough context for realistic generation, though, so the keys of this hashmap will actually be combinations of two words.  These keys can be any type that implement the [`Eq`](https://doc.rust-lang.org/std/cmp/trait.Eq.html) and [`Hash`](https://doc.rust-lang.org/std/hash/trait.Hash.html) traits, and a tuple of two [string slices](https://doc.rust-lang.org/book/ch04-03-slices.html#string-slices) `(&str, &str)` works just fine.  We'll then store for the corresponding value every word in our source text that ever follows the combination of those two.  This way we can look up words likely to come next based on the current two words we have in our text.\n\nHere's a concrete example what our hashmap might look like if built from the source text \"bears are big and bears are furry and bears are strong\":\n\n```rust\n{\n    (\"bears\", \"are\"): [\"big\", \"furry\", \"strong\"],\n    (\"and\", \"bears\"): [\"are\"],\n    (\"are\", \"big\"): [\"and\"],\n    (\"are\", \"furry\"): [\"and\"],\n    (\"big\", \"and\"): [\"bears\"],\n    (\"furry\", \"and\"): [\"bears\"],\n}\n```\n\nThis source text would not provide terribly interesting output, but it demonstrates how this will work on a larger scale.  First, you pick a random spot in the source text.  Let's go for \"bears are\" (randomly, I promise).  Stepping through a few iterations:\n\n1. Output: \"bears are\".  Look up `(\"bears\", \"are\")`.  Randomly select \"furry\" from the three stored options and append it to the output.\n\n2. Output: \"bears are furry\".  Look up `(\"are\", \"furry\")`.  The only option stored is \"and\".  Append to output.\n\n3. Output: \"bears are furry and\".  Look up `(\"big\", \"and\")`, append the only option \"bears\".\n\n4. Output: \"bears are furry and bears\".  Look up `(\"and, bears\")`, append \"are\".\n\n5. Output: \"bears are furry and bears are\". Look up `(\"bears\", \"are\")`.  Randomly select \"strong\" from the three stored options.\n\n6. Output: \"bears are furry and bears are strong\".  Look up `(\"are\", \"strong\")`, append \"and\".\n\nAnd so forth.  We generate a random output string of arbitrary length that resembles the source text.  The words will always sort of seem to make sense after one another as long as your input text did, and will actually sort of emulate the style.  Take a moment now and go back to the [orangeduck python post](http://theorangeduck.com/page/17-line-markov-chain) to grab the poetry set he created.  It's quite large (over 1.8 million lines!) and distributed as a zip file.  Unzip it into your project root as `poetry.txt`.  It's a great one because it's got a few different languages and several styles of poetry so successive runs will usually give you something pretty unique.\n\nOur next word of the randomly generated text will always be pulled from this lookup table of words that do follow our current two words in the real text, which will (often) result in real-sounding sentences getting strung together even though each run through the loop is only ever aware of exactly where it is and nothing else.  On each iteration we perform a lookup of the proper tuple and select one of the options stored there at random.  Rinse and repeat for the length of the desired text!  Boom, nonsense.  The bigger the source text, the more interesting the output.\n\n## Read Them In\n\nThe first step in building this is to read in the source text.  First, tweak your `std` imports:\n\n```rust\nuse std::{\n    collections::HashMap, error::Error, fs::OpenOptions, io::Read, path::PathBuf, str::FromStr,\n};\n```\n\nThis function will accept a `PathBuf` (which we've collected from the user already) and attempt to return the file's contents as a string:\n\n```rust\nfn read_file(filename: PathBuf) -> Result<String, Box<dyn Error>> {\n    let mut file = OpenOptions::new().read(true).open(filename)?;\n    let mut contents = String::new();\n    file.read_to_string(&mut contents)?;\n    Ok(contents)\n}\n```\n\nThat return type is familiar from up above - this operation can fail if, for instance, there is no file at the path specified, so we're wrapping it in a `Result<T, E>`.  The `T` here is the successfully read `String`, and our `E` is that nifty trait object to catch any and all error types that may get thrown along the way.\n\nAny variable that we need to mutate has to be explicitly marked as such with `mut`.  By default any attempt to mutate the value stored in a `let` binding will fail to compile.\n\nIn the first line it attempts to open the file at the path passed in with read permissions only.  It's got a question mark at the end, which is a shorthand way of saying automatically unwrapping the return value if it's an `Ok(val)` and early-returning this function with `Err(the error returned)`.  Quite handy!  The expansion would look something like:\n\n```rust\nlet file = match OpenOptions::new().read(true).open(filename) {\n    Ok(f) => f,\n    Err(e) => return Err(e),\n}\n```\n\nThis is pretty reasonable behavior as syntactic sugar goes.  It only works inside a function that returns a `Result<T, E>`, though, which justifies all this hullabaloo.  You can't use `?` in `main()`, for instance.\n\nThe `read_to_string()` method from the [`Read`](https://doc.rust-lang.org/std/io/trait.Read.html) trait also uses `?` to catch any errors that may happen.  If everything has succeeded, our source text is sitting snugly inside this massive string, so we can wrap it in an `Ok()` and get going.\n\nAs an aside, I often reach for [`BufReader`](https://doc.rust-lang.org/std/io/struct.BufReader.html) by instinct.  This is a use case in which it won't help us, and actually might slow us down.  We're just reading this very large file in once to a single `String`, so we'd rather avoid the extra allocations doing a buffered read would add.\n\nGo ahead and pop it in `run()`:\n\n```rust\nfn run(input: PathBuf, length: u32) -> Result<(), Box<dyn Error>> {\n    let file_str = read_file(input)?;\n    println!(\"{}\", file_str);\n    Ok(())\n}\n```\n\nIf you've got `poetry.txt` in place, `cargo run` should now display the entire contents, at least until you get bored and interrupt it.\n\n## Split Them Up\n\nWe can't work with just a massive `String`, though, we've got to split it in to individual words.  We want to preserve things like newlines for this operation.  As orangeduck points out, in poetry especially line endings are part of the structure the output should resemble.  To do this we'll use a regular expression via the regex crate: `$ cargo add regex`.\n\nHere's a function that will carry out this operation:\n\n```rust\nuse regex::Regex;\n//..\nfn split_words(w: &str) -> Vec<&str> {\n    let spaces_re = Regex::new(r\" +\").unwrap();\n    spaces_re.split(w).collect::<Vec<&str>>()\n}\n```\n\nThis function is going to allocate a new `Vec`, but inside we're only going to store references to our original file string.  We don't need to change the input, just look at it in order to build this vector.  By just taking a reference to the string in the argument, we don't move ownership of the input away from the original binding.  Building this list causes no new copying or allocation involved beyond the `Vec` structure itself.\n\nThe first line defines the regular expression - instead of wrapping this whole function in a `Result`, I'm just promising the compiler (and you) that `r\" +\"` constitutes a valid `Regex` and using a plain old `unwrap()` on the `Result` that `Regex::new()` returns.  Creating a new `Regex` would return an error if passed an invalid regular expression, in which case our `unwrap()` call would panic.  We know this won't panic, though, it will just match one or more spaces ignoring anything else like tabs and newlines.  Different inputs may require different regexes for optimal output.  Then we return the result of calling the `split()` method using this regex and then `collect()` to return the resulting [`Iterator`](https://doc.rust-lang.org/std/iter/index.html) as a `Vec<&str>`.\n\n## Get Organized\n\nTo build the lookup table, we want to look at three words at a time.  The first two will be used for the key, and the third will be appended to the list of possible options.  That is, we're going to want to look at the first, second, and third word, then the second, third, and fourth word, then the third, fourth, and fifth word, and so on.  The most concise way to build a nice handy iterator for this is the `izip!()` macro found in the [`itertools`](https://docs.rs/itertools/0.8.0/itertools/) crate: `$ cargo add itertools`.\n\n```rust\n#[macro_use]\nextern crate itertools;\n//..\nfn build_table(words: Vec<&str>) -> HashMap<(&str, &str), Vec<&str>> {\n    let mut ret = HashMap::new();\n    for (w0, w1, w2) in izip!(&words, &words[1..], &words[2..]) {\n        // add w2 to the key (w0, w1)\n        let current = ret.entry((*w0, *w1)).or_insert_with(Vec::new);\n        current.push(*w2);\n    }\n    ret\n}\n```\n\nWe need to pull in the `izip!()` macro with the `#[macro_use]` tag, first.  We then use slices to build sublists with the proper offsets.  This `for` loop will end up iterating through each three word triple in the source text.\n\nInside the loop we use the [`Entry API`](https://doc.rust-lang.org/std/collections/hash_map/struct.HashMap.html#method.entry) to look up the key from the first two words of the triple - `(\"bears\", \"are\")`, for example.  If no such key is found the `or_insert_with()` call will create it for us with an empty `Vec` ready to go, so that no matter wht we can `push` the third word to it in the next line.  Once this loop completes, we've built the data structure described in the step-through above.\n\nIt's possible to skip the itertools dependency if you like, but the code comes out a little clunkier - the built-in `zip` method can only zip two iterators, so you've got to call it twice and then combine everything yourself:\n\n```rust\nfn build_table_no_itertools(words: Vec<&str>) -> HashMap<(&str, &str), Vec<&str>> {\n    let mut ret = HashMap::new();\n    let all_words = &words[..];\n    let offset_1 = &words[1..];\n    let offset_2 = &words[2..];\n    for (w0, w1, w2) in all_words\n        .iter()\n        .zip(offset_1.iter())\n        .zip(offset_2.iter())\n        .map(|((a, b), c)| (a, b, c))\n    {\n        // add w2 to the key (w0, w1)\n        let current = ret.entry((*w0, *w1)).or_insert_with(Vec::new);\n        current.push(*w2);\n    }\n    ret\n}\n```\n\nThis function works as a drop-in replacement with no external dependency required but you're sacrificing readiblity - this takes much longer to stare at before you understand it's just zipping together three iterators.  I'd much rather add the dependency, `izip!()` is much nicer.\n\n## Spit Them Out\n\nNow that everything's set up, we can just perform as many lookups as specified and string everything together.  We need something to start, with though, so first we'll just select a random starting point from the source text.  We need one more crate to accomplish this: `$ cargo add rand`.\n\n```rust\nuse rand::{seq::SliceRandom, thread_rng, Rng};\n//..\nfn run(input: PathBuf, length: u32) -> Result<(), Box<dyn Error>> {\n    let file_str = read_file(input)?;\n    let words = split_words(&file_str);\n\n    let mut rng = thread_rng();\n    let i = rng.gen_range(0, words.len() - 3);\n\n    let mut w0 = words[i];\n    let mut w1 = words[i + 1];\n    let mut w2 = words[i + 2];\n}\n```\n\nWe'll reuse these variables inside the loop.\n\nThere's a gotcha in this implementation, though.  As it's written, `build_table` is taking ownership of our `words` vector.  That means that after we call it, we can't use `words` again.  Luckily, there is nothing stopping us from simply picking our starting location *before* we build the table.  We'll need to actually call the function directly below the above setup:\n\n```rust\nlet lookup = build_table(words);\n```\n\nNow everything's in place for the generation loop:\n\n```rust\n    // each iteration, print current word and then a space, and update our words\n    for _ in 0..length {\n        // append to output\n        print!(\"{} \", w2);\n\n        // choose the next word\n        w2 = &lookup[&(w0, w1)].choose(&mut rng).unwrap();\n        w0 = w1;\n        w1 = w2;\n    }\n```\n\nWe just print out whatever we've got stored in `w2`, add a space, and then use `w0` and `w1` to look up the next word.  Once we've selected in, we need to update `w0` and `w1`, advancing our cursor to the next triple.\n\nThe `unwrap()` call here is also safe because we'll never have a key corresponding to a zero-length list.  Every time we create a new key, we immediately push the following word to it.  The last iteration of the loop covers the last three words, so we'll always be able to do so.\n\nThat's the whole program - fire it up with `cargo run --release`.  We provided sane default argument values, so you don't need to use the command line options we defined unless you want to.\n\nThis is my favorite run so far on the poetry set:\n\n```\n$ cargo run --release\n   Compiling markov v0.1.0 (/home/ben/code/markov)\n    Finished release [optimized] target(s) in 0.58s\n     Running `target/release/markov`\nAn actor experiences\nOther peoples lives\nThrough a metamorphosis of mind\n\nWords sifted through a Forest, beneath the blowing gale,\nThe waves have now the year of 1897, and on like that.\nI can't abear it. I killed last night.\n\nI wonder, 'struth, I wonder if the listener please,\nA most important thing;\nBut Fortune to a thousand times, but I\n Would have him with his prophetic bill.\nThe great Colosse, erect to Memory;\nAnd what the royal feast!\nSee here the blue night, railway stations.\n\nThe water and fire his courage on despair\nAnd utter dissolution, as the love of slaughter;\nMany indeed are the men\nWith spears gathering at his feet: and my evening hours.\n\nLast evening when it rests,\nLeaves to be\nOf work may be shared by not crossing the line,\nThough that same morning officers and men.\n\nContinues yet the dream\n```\n\nContinues, yet, the dream...\n\nSee [this repo](https://github.com/deciduously/markov) for the full code.",
    "title": "Build You A Markov Chain In Rust (Or Whatever)"
  },
  {
    "cover_image": "https://res.cloudinary.com/practicaldev/image/fetch/s--6vU7yfM1--/c_imagga_scale,f_auto,fl_progressive,h_420,q_auto,w_1000/https://thepracticaldev.s3.amazonaws.com/i/5p3ouxfw3jiepppsrosu.jpg",
    "date": "2019-05-07T01:49:42.272Z",
    "description": "I just saved myself a ton of heartache by doing something a lot easier instead.\n\n...",
    "tags": "rust, beginners, lisp, help",
    "markdown": "I just saved myself a *ton* of heartache by doing something a lot easier instead.\n\nI think.  Either that, or I introduced a weird brittle workaround that I'll come to regret down the line.  Is there some sort of gut check you use to tell which is which?\n\nI'm working on translating (another) [orangeduck](http://theorangeduck.com/page/about) thing into Rust, this time his [Build Your Own Lisp](http://www.buildyourownlisp.com/) book which also functions as a great crash course in C.  Of course, C and Rust are different in some important ways, so the translation is sometimes straightforward and other times very much not.  I was following along with the book more or less without a hitch until we got to [Scoped Environments](http://www.buildyourownlisp.com/chapter12_functions#parent_environment).\n\nThis post is not a tutorial or walk-through of my translation, but the full code can be found [here](https://github.com/deciduously/blispr) for context.\n\n## The Task\n\nIt's helpful to understand the high-level overview of the program we need to write.  This program will take a string as input and attempt to evaluate the result.  We need to *parse* the string into a tree of semantically tagged lexical tokens, *read* this parse tree of tokens into a structure called an [Abstract Syntax Tree](https://en.wikipedia.org/wiki/Abstract_syntax_tree), and then *evaluate* that AST.  To do this, we'll need to semantically tag each element so that our program can methodically work its way through, understanding what each part is.\n\nIf you're not familiar with those data structures, it's not as complicated as it may sound (and I shelled parsing out to [a library](https://pest.rs/)).  For a small concrete example, let's look at the input string `+ 2 (* 3 4) 5`.  To work with this input, we need to build a an AST structure like the following:\n\n```rust\nS-Expression(\n    Symbol(\"+\"),\n    Number(2),\n    S-Expression(\n        Symbol(\"*\"),\n        Number(3),\n        Number(4),\n    ),\n    Number(5),\n)\n```\n\nThe whole program is represented as an [S-Expression](https://en.wikipedia.org/wiki/S-expression).  When our program sees one of these with multiple elements, it's going to try to execute it as a function call, looking up the function from the symbol in the first position.  First, though, it's going to recursively evaluate all of its children - so if any of them are themselves s-expressions, we'll get them into values we can work with first.  In this example, the inner S-Expression `(* 3 4)` will be evaluated first:\n\n```rust\nS-Expression(\n    Symbol(\"*\"),\n    Number(3),\n    Number(4),\n)\n```\n\nThis will be interpreted as a function call, and evaluates to:\n\n```rust\nS-Expression(\n    Symbol(\"+\"),\n    Number(2),\n    Number(12),\n    Number(5),\n)\n```\n\nNow we have an operation as the first element of the S-expression and some numbers with which to apply it.  When this evaluates, we're left with just `Number(19)`, which can be displayed to the user as the result of the computation.\n\nBut wait!  There's a missing step.  That `Symbol(\"+\")` doesn't mean a lot on its own, it's just a string.  We need to associate that with the addition function somehow.  Thus, we add in the concept of an *environment*, which is just a data structure that associates names with values.  These values can be built in functions like `\"+\"` or user-defined values and functions, they're all stored in the same manner and looked up during evaluation.\n\n## The Issue\n\nNow, this is trivial if there's only one environment.  You just make a big `HashMap`.  The book I'm translating uses two arrays with matching indices - the point is, it's not a complicated problem.  And one big global environment is sufficient to allow variable declaration:\n\n```\nlisp> def {x} 100\n()\nlisp> def {y} 200\n()\nlisp> def {a b} 5 6\n()\nlisp> + a b x y\n311\n```\n\nIt gets tricky when we start having *user-defined lambdas*:\n\n```\nlisp> def {embiggen} (\\ {x y} {^ (* x y) (+ x y)})\n()\nlisp> embiggen 2 3\n7776\nlisp> def {real-big} (embiggen 4)\n()\nlisp> real-big 2\n262144\n```\n\nThere are two distinct things going on here.  For one, we now know we need scoped environments because `x` and `y` are only supposed to make sense inside `embiggen`.  The lookup of `x` in the environment should fail if we're outside in the global scope, and if we're called inside an `embiggen` call it should find whatever was bound during the call, in the case of `embiggen 2 3` this would be `2`.\n\nThis is fine, we can handle this by building the local environment when evaluate this call, adding in these values and using this new temporary environment for this particular evaluation.  What if we want to be able to have a value like `real-big`, though?  This lambda has `x` in the environment as part of its definition, but after evaluating it it's not stored in either its arguments or its body:\n\n```\nlisp>real-big\n(\\ {y} {^ (* x y) (+ x y)})\n```\n\nThis is a function of only one argument, but it's gotta be able to look up that `x` we defined too.  It's no longer sufficient to just build the environment with what we've got at evaluation, `real-big` needed to retain this information somehow with it when you look it up in the environment.\n\n## The Solution\n\nIn C, this solution is a pointer away.  Each function value in the AST carries a pointer to an environment, and each environment carries a pointer to a parent.  You just de-reference where appropriate and everything's groovy.  Rust is not quite so forgiving.  You can store that pointer to a parent just fine:\n\n```rust\n#[derive(Debug, PartialEq)]\npub struct Lenv<'a> {\n    lookup: HashMap<String, Box<Lval>>,\n    pub parent: Option<&'a Lenv<'a>>,\n}\n```\n\nBut uh-oh - we've got an explicit lifetime.  As it turns out, you can't just casually toss that into something like `Lval`:\n\n```rust\ntype LvalChildren = Vec<Box<Lval>>;\npub type LBuiltin = fn(&mut Lval) -> BlisprResult;\n\n#[derive(Clone)]\npub enum LvalFun {\n    Builtin(String, LBuiltin), // (name, function pointer)\n    Lambda(ENVIRONMENT TYPE?!, Box<Lval>, Box<Lval>), // (env, formals, body)\n}\n\n#[derive(Debug, Clone, PartialEq)]\npub enum Lval {\n    Fun(LvalFun),\n    Num(i64),\n    Sym(String),\n    Sexpr(LvalChildren),\n    Qexpr(LvalChildren),\n}\n```\n\nThis type is recursive as heck and stuff, and there's mutable references to these babies all over this thousand-line codebase.  I went though *hell* trying to emulate the exact C code.  There were `Arc<RwLock<T>>`s, there was an arena-type allocator for a while, there were two explicit lifetimes, it was a mess.\n\nThen, I just...didn't.  I filled in that frantic `ENVIRONMENT TYPE?!` with `HashMap<String, Box<Lval>>` - the same as the innards of the environment struct but without that pesky reference and all its lifetime baggage.\n\nInstead of carrying an environment, parent reference and all, it will just carry specifically any partially applied forms.  In the `real-big` example, this `HashMap` would have just a single entry: `x: 2`.  Then it's up to the calling code to do a little extra work:\n\n```rust\nfor (k, v) in env {\n    local_env.put(k, v);\n}\n```\n\nIn most usage, this won't realistically have more than a handful of values in it.  So, yes, it's a slowdown, but it's really not that big a deal of a slowdown?  And it solves the problem, this feature works as promised.  I didn't necessarily learn anything deep about anything with it - on the contrary I probably avoided getting a better understanding of how to solve this sort of problem in the general case in Rust.\n\nBut *the thing does the thing*.  For now, at least, just as well as I need it to.  Hack or nah?",
    "title": "Solving Problems By Avoiding Them"
  },
  {
    "cover_image": "https://res.cloudinary.com/practicaldev/image/fetch/s--aId0glXB--/c_imagga_scale,f_auto,fl_progressive,h_420,q_auto,w_1000/https://thepracticaldev.s3.amazonaws.com/i/zrrpq5uedlhiguf9haid.jpg",
    "date": "2019-05-22T02:09:05.597Z",
    "description": "",
    "tags": "beginners, functional, cpp",
    "markdown": "I'm a (wannabe) functional programming zealot, and you recur all over the place when you're programming functionally.  It's often via library functions like `map` and `reduce` as opposed to writing your own recursive functions, but it's a super common theme.  It's so satisfying to get right, and leads to some wonderfully concise, elegant implementations.\n\nBut *gosh* can it be slow.  It's fine for small cases but can seriously bottleneck larger programs and inputs, and not always in ways that are easy to predict.\n\nOne way to alleviate this pain is called *tail recursion*.  This means that you can recur, but you must do it only in the tail position of the function call which means the recursive call the last thing called as the return value.  C++ has a highly optimizing compiler that can actually optimize away the recursion in this case, making tail recursive functions more performant than non-tail recursive ones.\n\nThe basic strategy for this is to reuse the stack frame.  Basically, every time a function is called, it pushes a new *frame* onto the *call stack*.  This frame contains state information for the evaluation of this function (more accurately, subroutine), such as the parameters it was called with.  This frame had to be allocated somewhere in memory and populated and then pushed onto this stack.  All of that took time and resources, especially if the values themselves are large.  In a recursive function you're asking for this to happen repeatedly, often with larger and larger parameters.  It can get nuts, especially because these frames are only popped off the call stack and de-allocated when the subroutine completed - which will be *after* all its children are done.\n\nIf you recur in tail position, though, the stack frame actually doesn't need to change for the next recursive call.  Instead, the values can just get swapped in place, and the stack frame that's already been allocated for THIS call is just recycled.  No pushing more and more frames on top of the call stack, allocating more and more memory for more and more temporary function calls.  It all just happens in place in memory.  Way faster!\n\nC++ compilers are often even smarter than that, though, and might rip our your recursion and pop a regular loop in its place, which will be even faster yet.\n\nI'm gonna keep the examples super simple.  Here's how you might define `factorial` in a recursive manner in C++:\n\n```cpp\nint factorial(int n) {\n    if (n > 1) {\n        return n * factorial(n - 1);\n    }\n    else {\n        return 1;\n    }\n}\n```\n\nThis implementation, while nice and neat and easy on the eyes, is not tail recursive - it calls factorial inside of itself *and then* multiplies that result by n.  In this case, multiplication is in the tail position, not the recursive call.  To get it to be tail recursive, that multiplication needs to happen inside the parameter list of the function call (or in some other manner before it), and to do that you can supply a default value:\n\n```cpp\nint factorial(int n, int b = 1) {\n\tif (n == 0) {\n\t\treturn b;\n        }\n\treturn factorial(n - 1, b * n);\n}\n```\n\nThis function works in almost the same way, just reorganized so that the recursive call is in tail position and the multiplication is inside the call.  Because of operator precedence (and how this function works), the multiplication is evaluated first.  We're storing the result as we recur down to 0 in this phantom b parameter.  It's kind of like carrying extra state.  The first iteration our default of 1 is multiplied by the n value supplied.   If the supplied n was zero,  we just return that one, and otherwise when eventually we have decremented n to zero, b will hold the value we want.\n\nOften the key with these is to see if you can fit your base case(s) into your parameters, or use an auxiliary function that actually recurs with all the extra information stored in its parameters.  Another common recursive function example is the Fibonacci series:\n\n```cpp\nint fibonacci(int n) {\n    if (n == 0) {\n\t\treturn 0;\n\t}\n\telse if (n == 1) {\n\t\treturn 1;\n\t}\n\telse { \n\t\treturn fibonacci(n - 1) + fibonacci(n - 2);\n\t}\n}\n```\n\nShould do the trick, non?\n\n***NON***\n\nThis will hose you so fast it's not even funny.  Toss it in a loop and watch it slow to an absolute crawl before your very eyes:\n\n```cpp\nint main() {\n\tint n;\n\tstd::cout << \"nth fibonacci\" << std::endl << \"N: \";\n\tstd::cin >> n;\n\tfor (int i = 0; i <= n; i++) {\n\t\tstd::cout << fibonacci(i) << \" \";\n\t}\n\t\n\treturn 0;\n}\n```\n\nTry `n = 200`, I dare you.\n\nLuckily, we can just refactor in those default base cases to make it tail recursive:\n\n```cpp\nint fibonacci(int n, int a = 0, int b = 1)\n{\n\tif (n == 0)\n\t\treturn a;\n\tif (n == 1)\n\t\treturn b;\n\treturn fibonacci(n - 1, b, a + b);\n}\n\n```\n\nIn this case the series is built on two base values, 0 and 1.  No matter, we can pop 'em both in the parameters and start counting up from there.  We just hop along the line by shifting the `b` parameter to `a` and building a new `b`.\n\nPop `200` in to your loop printer.  They'll all come popping out immediately, integer overflow issues and all.  Hey, it's a hell of a lot better than getting bored and copping out after after dozen iterations, right?\n\nYour move in the comments.  Let me see you shake those tail-recursive functions, or optimize these further!",
    "title": "Tail Recursion"
  },
  {
    "cover_image": "https://res.cloudinary.com/practicaldev/image/fetch/s--ivG7iUTZ--/c_imagga_scale,f_auto,fl_progressive,h_420,q_auto,w_1000/https://thepracticaldev.s3.amazonaws.com/i/rrbhyqlr8zanb3hpd3uh.JPG",
    "date": "2019-05-28T23:27:57.885Z",
    "description": "",
    "tags": "rust, beginners, tutorial, webdev",
    "markdown": "## Intro\n\nIn this post I will walk through creating a small web API using the [hyper](https://github.com/hyperium/hyper) HTTP library.  The app is an implementation of [todo-mvp](https://github.com/gypsydave5/todo-mvp), as introduced by David Wickes in his post: {% link gypsydave5/todo-mvp-or-why-you-shouldnt-use-a-web-framework---the-revenge-261l %}\n\nOne of the stipulations of the `todo-mvp` project is that each implementation should avoid \"frameworks\" and stick to libraries only.  Framework is a nebulous term, and not necessarily always easy to delineate, so I went with the rule of thumb that if the crate documentation refers to itself as a framework, it's not appropriate for use.  This greatly narrows down the available tooling, but as it turns out `hyper` is all you need to build an application like this without much incidental complexity.\n\nHyper is a lower level HTTP implementation.  It provides Client and Server types and exposes the underlying [Tokio](https://tokio.rs/) asynchronous runtime it's built on top of.  We'll also bring in a few other crates, but still nothing resembling a full-featured framework.\n\n## Setup\n\nYou'll need to obtain a stable Rust toolchain.  If you need one, see [rustup](https://rustup.rs/).  Once installed, spin up a new executable project:\n\n```\n$ cargo new simple-todo\n$ cd simple-todo\n$ cargo run\n   Compiling simple-todo v0.1.0 (/home/ben/code/simple-todo)\n    Finished dev [unoptimized + debuginfo] target(s) in 1.30s\n     Running `target/debug/simple-todo`\nHello, world!\n```\n\nOpen your new `simple-todo` directory in your favorite editor.  Before diving into code, let's define our dependencies.  Make your `Cargo.toml` look like this:\n\n```toml\n[package]\nname = \"simple-todo\"\nversion = \"0.1.0\"\nauthors = [\"You <you@yourcoolsite.com>\"]\nedition = \"2018\"\n\n[dependencies]\nfutures = \"0.1\"\nhyper = \"0.12\"\nlazy_static = \"1.3\"\nlog = \"0.4\"\npretty_env_logger = \"0.3\"\nserde = \"1.0\"\nserde_derive = \"1.0\"\ntera = \"0.11\"\n\n[dependencies.uuid]\nfeatures = [\"serde\", \"v4\"]\nversion = \"0.7\"\n```\n\nIn addition to `hyper`, we're using a couple extra helper crates.  In brief, `futures` provides zero-cost asynchronous programming primitives, `lazy_static` will let us define `static`s that require runtime initialization (like `Vec::new()`), `log` and `pretty_env_logger` provide logging, `serde` and `serde_derive` are for serialization, `tera` performs HTML templating from Jinja-like template files, and `Uuid` provides, well, uuids!  These crates provide our basic building blocks.\n\nThis is a small program which will be defined entirely in `main.rs`.  Open that file and remove the `println!` statement from the `cargo new` template and spin up the logging instead:\n\n## Entrypoint\n\n```rust\nfn main() {\n    pretty_env_logger::init();\n}\n```\n\nNote that in Rust 2018 we can omit `extern crate` declarations unless we need to import a macro.\n\nBefore we can set up the server, we need an address to bind to.  We'll just hardcode it for this demo.  Add this line right below the init:\n\n```rust\nlet addr = \"127.0.0.1:3000\".parse().unwrap();\n```\n\nThe `parse()` method will return a [`std::net::SocketAddr`](https://doc.rust-lang.org/std/net/enum.SocketAddr.html).\n\nNext, we'll need to pull in a few imports at the top of the file:\n\n```rust\nuse futures::{future, Future, Stream};\nuse hyper::{\n    client::HttpConnector, rt, service::service_fn, Body, Client, Request,\n    Response, Server\n};\n```\n\nNow we can finish off `main()`:\n\n```rust\n    rt::run(future::lazy(move || {\n        // create a Client for all Services\n        let client = Client::new();\n\n        // define a service containing the router function\n        let new_service = move || {\n            // Move a clone of Client into the service_fn\n            let client = client.clone();\n            service_fn(move |req| router(req, &client))\n        };\n\n        // Define the server - this is what the future_lazy() we're building will resolve to\n        let server = Server::bind(&addr)\n            .serve(new_service)\n            .map_err(|e| eprintln!(\"Server error: {}\", e));\n\n        println!(\"Listening on http://{}\", addr);\n        server\n    }));\n```\n\nThis won't quite typecheck - to get it to compile, you can add the following stub above for the `router` function we reference in the `service_fn` call:\n\n```rust\nfn router(req: Request<Body>, _client: &Client<HttpConnector>) -> Box<Future<Item = Response<Body>, Error = Box<dyn std::error::Error + Send + Sync>> + Send> {\n    unimplemented!()\n}\n```\n\nThis is all a little beefier, let's unpack it.  This whole tidbit lives inside a call to `rt:run()`.  Here `rt` stands for runtime, and refers to the default Tokio runtime.  Immediately our program is going to spin up and enter this async environment.\n\nInside, we call `future::lazy`, which accepts a closure and returns a `Future` that will resolve to it.  The rest of the definition is in this closure, and has a few steps.  We build a hyper `Client`, capable of making outgoing HTTP requests.\n\nThe next order of business is to create a `Service`.  This is a trait representing an asynchronous function of a request to a response - exactly what our web server needs to handle!  Instead of implementing this trait by hand, we're just going to define this function oursleves (in this case, it's `router()`), and use the `service_fn` helper to convert the function to a `Service`.  Then all we need to do is create the `Server` itself, which binds to the address we provided, and have it serve this service.\n\nThat's *pretty much it*.  Now our job is just defining the responses, which is your job anyway, framework or no!\n\n## Router\n\nFirst, though, take a look at that `router()` signature.  Gross, right?  Make a few type aliases under your imports:\n\n```rust\ntype GenericError = Box<dyn std::error::Error + Send + Sync>;\ntype ResponseFuture = Box<Future<Item = Response<Body>, Error = GenericError> + Send>;\n\n\nfn router(req: Request<Body>, _client: &Client<HttpConnector>) -> ResponseFuture {\n    unimplemented!()\n}\n```\n\nAny time we want to give a response back to a connection, it's gotta be given as a `Response` wrapped up in a `Future` wrapped up in a `Box` - it's definitely a good idea to make that easier to type!  Now we can start defining routes.  Before getting started, add `Body`, `Method`, and `StatusCode` to the list of `hyper` imports.\n\nWe can leverage Rust pattern matching to correctly dispatch responses:\n\n```rust\nmatch (req.method(), req.uri().path()) {\n    (&Method::GET, \"/\") | (&Method::GET, \"index.html\") => unimplemented!(),\n    _ => four_oh_four(),\n    }\n```\n\nWe're matching on both the method and the path at once - a POST request to \"/\" would not match this branch.  We can add as many match arms as the app requires here, and any incoming request that doesn't have a corresponding arm will get the `four_oh_four()` response:\n\n```rust\nstatic NOTFOUND: &[u8] = b\"Oops! Not Found\";\n\nfn four_oh_four() -> ResponseFuture {\n    let body = Body::from(NOTFOUND);\n    Box::new(future::ok(\n        Response::builder()\n            .status(StatusCode::NOT_FOUND)\n            .body(body)\n            .unwrap(),\n    ))\n}\n```\n\nAs expected, this function returns a `ResponseFuture`.  For the 404 page, we'll just use this static value as the body.  The `future::ok` returns a future which immediately resolves, and we use the builder pattern to build a `Response`.  There are `hyper` enums set up for things like `StatusCode` for maximum correctness!\n\n## HTML\n\nTo build an index page, we'll use [tera](https://github.com/Keats/tera) which provides Jinja2-like HTML templates.  We are going to need a macro, and this will be set up as a static, so we need a few declarations:\n\n```rust\n#[macro_use]\nextern crate lazy_static;\n#[macro_use]\nextern crate tera;\n\n// ...\n\nuse tera::{Context, Tera};\n```\n\nThe `todo-mvp` project requires each implementation use the same template.  This post isn't about Jinja2 or HTML, so I'm just gonna direct you to download it [here](https://github.com/gypsydave5/todo-mvp/blob/master/todos/rust/templates/index.html) and save it to `simple-todo/templates/index.html`.  You'll also want to save [`todo.css`](https://github.com/gypsydave5/todo-mvp/blob/master/todos/rust/src/resource/todo.css) to `simple-todo/src/resource/todo.css`.\n\nTera is incredibly easy to use.  Add the following snippet:\n\n```rust\nlazy_static! {\n    pub static ref TERA: Tera = compile_templates!(\"templates/**/*\");\n}\n```\n\nVoila, templates.  Now we can write `index()`:\n\n```rust\nfn index() -> ResponseFuture {\n    let mut ctx = Context::new();\n    let body = Body::from(TERA.render(\"index.html\", &ctx).unwrap().to_string());\n    Box::new(future::ok(Response::new(body)))\n}\n```\n\nTo inject data into a Tera template, you put it in a `tera::Context` and pass both the template path and this context to `render()`.  Then we just wrap up the resulting string in a `ResponseFuture`!  Don't forget to update the match arm in `router()` to call this function instead of `unimplemented!()`.\n\n## State\n\nThere's a problem, though - we haven't actually put any data in the context!  If you ran this program it'd crash when loading this template, complaining that `todos` and `todosLen` are not found in the context.  It's an incredibly valid complaint, they're not there.\n\nKeeping track of state in an asynchronous application like this one *could* be a complicated problem, but this is Rust.  We've got [`std::sync`](https://doc.rust-lang.org/std/sync/) to play with!  Specifically, we're going to use the combination of [`Arc`](https://doc.rust-lang.org/std/sync/struct.Arc.html) and [`RwLock`](https://doc.rust-lang.org/std/sync/struct.RwLock.html) to store our todos safely across threads without really even thinking about it.\n\nFirst, the import additions:\n\n```rust\n#[macro_use]\nextern crate serde_derive;\n\n// ...\n\nuse std::sync::{Arc, RwLock};\nuse uuid::Uuid;\n```\n\nNow, the Todo type:\n\n```rust\n#[derive(Debug, Serialize)]\npub struct Todo {\n    done: bool,\n    name: String,\n    id: Uuid,\n}\n\nimpl Todo {\n    fn new(name: &str) -> Self {\n        Self {\n            done: false,\n            name: String::from(name),\n            id: Uuid::new_v4(),\n        }\n    }\n}\n```\n\nThe `new_v4()` method will randomly generate a unique identifier for any new `Todo`.  Also add a new type alias for the list of all todos:\n\n```rust\ntype Todos = Arc<RwLock<Vec<Todo>>>;\n```\n\nNow we can instantiate it in the `lazy_static!` block:\n\n```rust\nlazy_static! {\n    pub static ref TERA: Tera = compile_templates!(\"templates/**/*\");\n    pub static ref TODOS: Todos = Arc::new(RwLock::new(Vec::new()));\n}\n```\n\nWe'll need a few helper functions to manipulate the list:\n\n```rust\nfn add_todo(t: Todo) {\n    let todos = Arc::clone(&TODOS);\n    let mut lock = todos.write().unwrap();\n    lock.push(t);\n}\n\nfn remove_todo(id: Uuid) {\n    let todos = Arc::clone(&TODOS);\n    let mut lock = todos.write().unwrap();\n    // find the index\n    let mut idx = lock.len();\n    for (i, todo) in lock.iter().enumerate() {\n        if todo.id == id {\n            idx = i;\n        }\n    }\n    // remove that element if found\n    if idx < lock.len() {\n        lock.remove(idx);\n    }\n}\n\nfn toggle_todo(id: Uuid) {\n    let todos = Arc::clone(&TODOS);\n    let mut lock = todos.write().unwrap();\n    for todo in &mut *lock {\n        if todo.id == id {\n            todo.done = !todo.done;\n        }\n    }\n}\n```\n\nWhen you call `Arc::clone()`, it creates a new pointer to the same data, increasing its reference count.  Then we grab a write lock on the underlying `RwLock`, after which we can safely manipulate the `Vec` inside.  Using these helpers, our route handlers can manipulate the state safely in a manner that's guaranteed to be thread-safe.  Finally we can build the context, back in `index()` right after you define `ctx`:\n\n```rust\nlet todos = Arc::clone(&TODOS);\nlet lock = todos.read().unwrap();\nctx.insert(\"todos\", &*lock);\nctx.insert(\"todosLen\", &(*lock).len());\n```\n\n## Handlers\n\nNow running the app and pointing your browser to `localhost:3000` should display the given HTML (sans stylesheet).\n\nThe rest of the app is easy.  We simply need to fill out the the rest of the handlers.  For instance, to load the missing stylesheet, you need a new match arm:\n\n```rust\n(&Method::GET, \"/static/todo.css\") => stylesheet(),\n```\n\nAs well as a function to build the response:\n\n```rust\nfn stylesheet() -> ResponseFuture {\n    let body = Body::from(include_str!(\"resource/todo.css\"));\n    Box::new(future::ok(\n        Response::builder()\n            .status(StatusCode::OK)\n            .header(header::CONTENT_TYPE, \"text/css\")\n            .body(body)\n            .unwrap(),\n    ))\n}\n```\n\nNothing surprising in there!  Each todo list manipulation also has an endpoint:\n\n```rust\n(&Method::POST, \"/done\") => toggle_todo_handler(req),\n(&Method::POST, \"/not-done\") => toggle_todo_handler(req),\n(&Method::POST, \"/delete\") => remove_todo_handler(req),\n(&Method::POST, \"/\") => add_todo_handler(req),\n```\n\nThese handlers all take the same format:\n\n```rust\nfn add_todo_handler(req: Request<Body>) -> ResponseFuture {\n    Box::new(\n        req.into_body()\n            .concat2() // concatenate all the chunks in the body\n            .from_err() // like try! for Result, but for Futures\n            .and_then(|whole_body| {\n                let str_body = String::from_utf8(whole_body.to_vec()).unwrap();\n                let words: Vec<&str> = str_body.split('=').collect();\n                add_todo(Todo::new(words[1]));\n                redirect_home()\n            }),\n    )\n}\n```\n\nThis is a little more complicated.  We need to read the request and then act on it.  In this case, the request body stored in `str_body` will look something like `item=TodoName`.  There are more robust solutions, but I'm just splitting on the `=` and calling the `add_todo` function on the result to add it to the list.  Then we redirect to home, and every time we go back home `index()` is called, which rebuilds the HTML from whatever the current app state is!  The `toggle` and `remove` handlers are nearly equivalent, just calling the proper function.\n\nThe redirect is also not surprising:\n\n```rust\nfn redirect_home() -> ResponseFuture {\n    Box::new(future::ok(\n        Response::builder()\n            .status(StatusCode::SEE_OTHER)\n            .header(header::LOCATION, \"/\")\n            .body(Body::from(\"\"))\n            .unwrap(),\n    ))\n}\n```\n\nThis looks like what you'd write in any toolkit.  The app also includes some SVG:\n\n```rust\n (&Method::GET, path_str) => image(path_str),\n```\n\n```rust\nfn image(path_str: &str) -> ResponseFuture {\n    let path_buf = PathBuf::from(path_str);\n    let file_name = path_buf.file_name().unwrap().to_str().unwrap();\n    let ext = path_buf.extension().unwrap().to_str().unwrap();\n\n    match ext {\n        \"svg\" => {\n            // build the response\n            let body = {\n                let xml = match file_name {\n                    \"check.svg\" => include_str!(\"resource/check.svg\"),\n                    \"plus.svg\" => include_str!(\"resource/plus.svg\"),\n                    \"trashcan.svg\" => include_str!(\"resource/trashcan.svg\"),\n                    \"x.svg\" => include_str!(\"resource/x.svg\"),\n                    _ => \"\",\n                };\n                Body::from(xml)\n            };\n            Box::new(future::ok(\n                Response::builder()\n                    .status(StatusCode::OK)\n                    .header(header::CONTENT_TYPE, \"image/svg+xml\")\n                    .body(body)\n                    .unwrap(),\n            ))\n        }\n        _ => four_oh_four(),\n    }\n}\n```\n\nThat's the whole enchilada.  To add more routes, you just add a new match arm to `router()` and write a function that returns a `ResponseFuture`.  This is a solid , performant base that's easily extensible in myriad ways, because you're not beholden to any specific predetermined pattern.  All in all, writing a server using plain `hyper` instead of a higher-level framework isn't really that much less ergonomic for simple use cases, and cuts a serious amount of overhead from your app.  My current favorite framework is `actix-web` but it's almost absurd how much bigger the binaries are and how much longer a cold compile takes.  When the end goal is simple enough, why not use simple tools?\n\nThe full implementation can be found [here](https://github.com/gypsydave5/todo-mvp/tree/master/todos/rust/src).",
    "title": "Skip the Framework: Build A Simple Rust API with Hyper"
  },
  {
    "cover_image": "https://res.cloudinary.com/practicaldev/image/fetch/s--AL977crl--/c_imagga_scale,f_auto,fl_progressive,h_420,q_auto,w_1000/https://thepracticaldev.s3.amazonaws.com/i/hpy6695aug72kxxj300s.jpg",
    "date": "2019-06-04T17:36:07.532Z",
    "description": "",
    "tags": "rust, beginners, lisp",
    "markdown": "This is a fuller walk-through of the code I talked about in a previous post, [Solving Problems by Avoiding Them](https://dev.to/deciduously/solving-problems-by-avoiding-them-58dm).\n\nThe project is a translation of [Build Your Own Lisp](http://www.buildyourownlisp.com/) by [orangeduck](http://theorangeduck.com/page/about) into [Rust](https://www.rust-lang.org/).  His book is fantastic, both as an introduction to C and an introduction to writing an interpreter.\n\nThis post is nowhere close to a replacement for that text, by a long shot - go read the book.  It's excellent.  In translating to Rust, though, there are a few necessary differences worth noting.  This post does not include the code in its entirety but rather examples of each concept, and may be useful for anyone attempting a similar project or translation of their own in Rust.  I've also removed most debug logging for clarity.  The full implementation can be found in [this repo](https://github.com/deciduously/blispr).\n\nI learned a lot about C, interpreters, and Rust from this project, and highly recommend the exercise.  For better or worse (probably worse), I've called this implementation `blispr`.\n\n## Rustyline\n\nFirst thing's first, we've got to collect us some strings.  I highly recommend [`rustyline`](https://github.com/kkawakam/rustyline), a pure-Rust `readline` implementation.  You get line editing, keyboard commands, and command history out of the box.  This is all you have to do:\n\n```rust\nfn repl(e: &mut Lenv) -> Result<()> {\n    println!(\"Blispr v0.0.1\");\n    println!(\"Use exit(), Ctrl-C, or Ctrl-D to exit prompt\");\n\n    let mut rl = Editor::<()>::new();\n    if rl.load_history(\"./.blispr-history.txt\").is_err() {\n        println!(\"No history found.\");\n    }\n\n    loop {\n        let input = rl.readline(\"blispr> \");\n\n        match input {\n            Ok(line) => {\n                rl.add_history_entry(line.as_ref());\n                print_eval_result(eval_str(e, &line));\n            }\n            Err(ReadlineError::Interrupted) => {\n                info!(\"CTRL-C\");\n                break;\n            }\n            Err(ReadlineError::Eof) => {\n                info!(\"CTRL-D\");\n                break;\n            }\n            Err(err) => {\n                warn!(\"Error: {:?}\", err);\n                break;\n            }\n        }\n    }\n    rl.save_history(\"./.blispr-history.txt\")?;\n    Ok(())\n}\n\nfn print_eval_result(v: BlisprResult) {\n    match v {\n        Ok(res) => println!(\"{}\", res),\n        Err(e) => eprintln!(\"Error: {}\", e),\n    }\n}\n\n```\n\nOne thing to note is that I'm not propagating the error that `eval_str` might throw up to the caller here with `?` - I don't want blispr evaluation errors to crash the repl.  Anything that can happen inside `eval_str()` I just want to inform the user about with `eprintln!()` and loop again.  The `&mut Lenv` getting passed through is the global environment - more on that below.\n\nThe bulk of evaluation is hinted at in the `Ok()` arm of the `match` - the meat of the work is happening in `eval_str()`:\n\n```rust\npub fn eval_str(e: &mut Lenv, s: &str) -> BlisprResult {\n    let parsed = BlisprParser::parse(Rule::blispr, s)?.next().unwrap();\n    let mut lval_ptr = lval_read(parsed)?;\n    lval_eval(e, &mut *lval_ptr)\n}\n```\n\nThis is it, this is the entire interpreter.  This function does all of the steps required to evaluate a programming language given in text string form.  The first line stores the parse tree to `parsed`.  This tags our input string with semantic grammatical tags that we'll define below.  The next line reads that tree into an AST at `lval_ptr`, which represents the whole program as a lisp value that can be evaluated recursively.  Finally we return the result of fully evaluating that AST with `lval_eval`, which ensures this there are no further evaluations that can happen.  Any errors that happened along the way were caught with the `?` operator - below we'll see what that `Result<T>` alias represents.\n\n## Lval\n\nTo represent the AST, I used a Rust `enum` called `Lval`:\n\n```rust\n// The recursive types hold their children in a `Vec`\ntype LvalChildren = Vec<Box<Lval>>;\n// This is a function pointer type\npub type LBuiltin = fn(&mut Lval) -> BlisprResult;\n\n// There are two types of function - builtin and lambda\n#[derive(Clone)]\npub enum LvalFun {\n    Builtin(String, LBuiltin), // (name, function pointer)\n    Lambda(HashMap<String, Box<Lval>>, Box<Lval>, Box<Lval>), // (environment, formals, body), both should be Qexpr\n}\n\n// The main type - all possible Blispr values\n#[derive(Debug, Clone, PartialEq)]\npub enum Lval {\n    Fun(LvalFun),\n    Num(i64),\n    Sym(String),\n    Sexpr(LvalChildren),\n    Qexpr(LvalChildren),\n}\n```\n\nEach variant carries its contents with it.  As we read the text each element is going to be converted into the proper type of `Lval`.    For example, a string like `\"4\"` is going to be parsed into `Lval::Num(4)`.  Now this value can be used in the context of a larger evaluation.  I've also implemented [`fmt::Display`](https://doc.rust-lang.org/std/fmt/trait.Display.html) for this type, which is responsible for defining the output string to be finally displayed to the user.  With the auto-derived `Debug` trait we get something like `Lval::Num(4)`, and with `Display` we just get `4`:\n\n```rust\nimpl fmt::Display for Lval {\n    fn fmt(&self, f: &mut fmt::Formatter) -> fmt::Result {\n        match self {\n            Lval::Blispr(_cells) => write!(f, \"<toplevel>\"),\n            Lval::Fun(lf) => match lf {\n                LvalFun::Builtin(name, _) => write!(f, \"<builtin: {}>\", name),\n                LvalFun::Lambda(_, formals, body) => write!(f, \"(\\\\ {} {})\", formals, body),\n            },\n            Lval::Num(n) => write!(f, \"{}\", n),\n            Lval::Sym(s) => write!(f, \"{}\", s),\n            Lval::Sexpr(cell) => write!(f, \"({})\", lval_expr_print(cell)),\n            Lval::Qexpr(cell) => write!(f, \"{{{}}}\", lval_expr_print(cell)),\n        }\n    }\n}\n\nfn lval_expr_print(cell: &[Box<Lval>]) -> String {\n    let mut ret = String::new();\n    for i in 0..cell.len() {\n        ret.push_str(&format!(\"{}\", cell[i]));\n        if i < cell.len() - 1 {\n            ret.push_str(\" \");\n        }\n    }\n    ret\n}\n```\n\nWe have numbers, symbols, functions (two different types of function - more on those later on), and two types of expression list - s-expressions and q-expressions.  S-expressions will be evaluated as code, looking for a function in the first position, and q-expressions are evaluated as just lists of data.  The whole program that's read in is going to be one big containing `Lval::Sexpr`, and we just need to evaluate it until we only have a result needing no further evaluation, either a `Num`, `Sym`, or `Qexpr`.\n\nAs a simple example, `\"+ 1 2\"` is going to get stored as `Sexpr(Sym(\"+\"), Num(1), Num(2))`.  When this `Sexpr` is evaluated, it will first look up `+` in the environment and find a function pointer to the built-in addition function: `Sexpr(Fun(Builtin(\"+\"), Num(1), Num(\"2\")))`.  Then this `Sexpr` will be evaluated as a function call, yielding `Num(3)`, which cannot be evaluated further.\n\nThis code makes use of the `Box` pointer type, which is a smart pointer to a heap-allocated value.  Because an `Lval` can hold many different types of data, the size of a given `Lval` is not known at compile-time.  By only storing pointers to values on the heap, we can build lists of them.  Because these `Box`es adhere to Rust's ownership and borrowing semantics, Rust is going to manage cleaning them up for us when they are no longer needed.  This is how we'll manage our memory over the lifetime of the program - with quite a bit less ceremony than the corresponding C!  To build a new one, we use a constructor.  For example:\n\n```rust\npub fn lval_num(n: i64) -> Box<Lval> {\n    Box::new(Lval::Num(n))\n}\n```\n\nThere's one of these for each variant.  Calling this will allocate the appropriate space with `Box::new()` on the heap and return the pointer.  No need to futz with a destructor - the `Box` will drop itself as soon as it can.\n\nThe containing types start out with an empty `Vec` of children, and can be manipulated with `lval_add` and `lval_pop`:\n\n```rust\n// Add lval x to lval::sexpr or lval::qexpr v\npub fn lval_add(v: &mut Lval, x: &Lval) -> Result<()> {\n    match *v {\n        Lval::Sexpr(ref mut children)\n        | Lval::Qexpr(ref mut children)\n        | Lval::Blispr(ref mut children) => {\n            children.push(Box::new(x.clone()));\n        }\n        _ => return Err(BlisprError::NoChildren),\n    }\n    Ok(())\n}\n\n// Extract single element of sexpr at index i\npub fn lval_pop(v: &mut Lval, i: usize) -> BlisprResult {\n    match *v {\n        Lval::Sexpr(ref mut children)\n        | Lval::Qexpr(ref mut children)\n        | Lval::Blispr(ref mut children) => {\n            let ret = (&children[i]).clone();\n            children.remove(i);\n            Ok(ret)\n        }\n        _ => Err(BlisprError::NoChildren),\n    }\n}\n```\n\nBoth of these functions mutate their first argument in place, either removing or adding a child.\n\n## Errors\n\nOne difference from the book's implementation is that I don't have a separate specific `Lval::Err` AST variant for handling errors in our program.  Instead, I built a separate error type and leverage `Result<T, E>`-style error handling throughout:\n\n```rust\n#[derive(Debug)]\npub enum BlisprError {\n    DivideByZero,\n    EmptyList,\n    FunctionFormat,\n    NoChildren,\n    NotANumber,\n    NumArguments(usize, usize),\n    ParseError(String),\n    ReadlineError(String),\n    WrongType(String, String),\n    UnknownFunction(String),\n}\n```\n\nTo simplify the type signatures used throughout, I have a few type aliases:\n\n```rust\npub type Result<T> = std::result::Result<T, BlisprError>;\npub type BlisprResult = Result<Box<Lval>>;\n```\n\nThe majority of evaluation functions are going to return a `Result<Box<Lval>, BlisprError>`, now I can just type `BlisprResult`.  The few functions here and there that don't have a success type of `Box<Lval>` can still use this new `Result<T>` alias instead of the more verbose built-in `Result<T, E>`, and the error type will automatically always be this `BlisprError`.\n\nIn order to be able to use this throughout our entire program, I've provided `impl From<E> for BlisprError` for a few other types of errors that are thrown, like `std::io::Error` and `pest::error::Error` for example:\n\n```rust\nimpl<T> From<pest::error::Error<T>> for BlisprError\nwhere\n    T: Debug + Ord + Copy + Hash,\n{\n    fn from(error: pest::error::Error<T>) -> Self {\n        BlisprError::ParseError(format!(\"{}\", error))\n    }\n}\n\nimpl From<std::io::Error> for BlisprError {\n    fn from(error: std::io::Error) -> Self {\n        BlisprError::ParseError(error.to_string())\n    }\n}\n```\n\nThis way I can still use the `?` operator on function calls that return these other error types inside functions that return a `BlisprResult`, and any errors returned will be automatically converted to the proper `BlisprError` for me.  Instead of storing specific error-type `Lval`s during our evaluation that are carried through the whole computation and finally printed out, all errors are bubbled up through the type system, but you still get the full `pest`-generated error carried along:\n\n```lisp\nblispr> eval {* 2 3)\nParse error:  --> 1:12\n  |\n1 | eval {* 2 3)\n  |            ^---\n  |\n  = expected expr\n```\n\nFull disclosure: to write the `pest::error::Error<T>` block, I just wrote what I wanted, i.e. `BlisprError::ParseError(format!(\"{}\", error))` and appeased the compiler.  There is likely a better way to go about this but it works!\n\n## Parsing\n\nThe book uses the author's own parser combinator library called [mpc](https://github.com/orangeduck/mpc).  If I were to tackle another similar problem in C, I'd likely reach for it again.  Rust, however, has its own strong ecosystem for parsing.  Some of the heavyweights in this space are [nom](https://github.com/Geal/nom), [combine](https://github.com/Marwes/combine),  and [pest](https://github.com/pest-parser/pest).  For this project I opted for pest, to stay as close to the source material as possible.  Whereas `nom` and `combine` will have you defining your own [parser combinators](https://dev.to/deciduously/parser-combinators-are-easy-4bjm), with `pest` you provide a PEG (or [Parsing Expression Grammar](https://en.wikipedia.org/wiki/Parsing_expression_grammar)), separately from your code.  Pest then uses Rust's powerful custom derive tooling to create a parse for your grammar automatically.\n\nHere's the grammar I used for this language:\n\n```pest\nCOMMENT = _{ \"/*\" ~ (!\"*/\" ~ ANY)* ~ \"*/\" }\nWHITESPACE = _{ (\" \" | NEWLINE ) }\n\nnum = @{ int }\n    int = { (\"+\" | \"-\")? ~ digit+ }\n    digit = { '0'..'9' }\n\nsymbol = @{ (letter | digit | \"_\" | arithmetic_ops | \"\\\\\" | comparison_ops | \"&\")+ }\n    letter = { 'a' .. 'z' | 'A' .. 'Z' }\n    arithmetic_ops = { \"+\" | \"-\" | \"*\" | \"/\" | \"%\" | \"^\" }\n    comparison_ops = { \"=\" | \"<\" | \">\" | \"!\" }\n\nsexpr = { \"(\" ~ expr* ~ \")\" }\n\nqexpr = { \"{\" ~ expr* ~ \"}\" }\n\nexpr = { num | symbol | sexpr | qexpr }\n\nblispr = { SOI ~ expr* ~ EOI }\n```\n\nThis is stored in its own file called `blispr.pest` alongside the source code.  Each line refines a parse rule.  I find this exceedingly readable, and easy to tweak.  Starting from the bottom, we see a unit of valid `blispr` consists of one or more `expr`s between the Start of Input (SOI) and End of Input (EOI).  An `expr` is any of the options given.  It can handle comments and whitespace for you.  I also enjoy how the grammar maintained completely separately from any Rust code.  It's easy to get this working with Rust:\n\n```rust\nuse pest::{iterators::Pair, Parser};\n\n#[cfg(debug_assertions)]\nconst _GRAMMAR: &str = include_str!(\"blispr.pest\");\n\n#[derive(Parser)]\n#[grammar = \"blispr.pest\"]\npub struct BlisprParser;\n```\n\nNow we can use the `BlisprParser` struct to parse string input into a parse tree with `parse()`.  In order to evaluate it, though, we need to build a a big `Lval` AST:\n\n```rust\nfn lval_read(parsed: Pair<Rule>) -> BlisprResult {\n    match parsed.as_rule() {\n        Rule::blispr => {\n            let mut ret = lval_blispr();\n            read_to_lval(&mut ret, parsed)?;\n            Ok(ret)\n        }\n        Rule::expr => lval_read(parsed.into_inner().next().unwrap()),\n        Rule::sexpr => {\n            let mut ret = lval_sexpr();\n            read_to_lval(&mut ret, parsed)?;\n            Ok(ret)\n        }\n        Rule::qexpr => {\n            let mut ret = lval_qexpr();\n            read_to_lval(&mut ret, parsed)?;\n            Ok(ret)\n        }\n        Rule::num => Ok(lval_num(parsed.as_str().parse::<i64>()?)),\n        Rule::symbol => Ok(lval_sym(parsed.as_str())),\n        _ => unreachable!(), // COMMENT/WHITESPACE etc\n    }\n}\n```\n\nWe pass the parse tree from `pest` into `lval_read`, which will recursively build the AST for us.  This function looks at the top-level rule and takes an appropriate action, either allocating a new `Lval` variant or adjusting the children of . Then every child in the parse tree is added as a child to this containing `Lval`, passing through `lval_read()` itself to turn it into the correct `Lval`.  The rule for `qexpr` is similar, and the other rules just create the corresponding `Lval` from the type given.  The one weird one is `Rule::expr` - this is a sort of meta-rule that matches any of the valid expression types, so it's not its own lval, just wrapping one of a more specific type.  We just use `next()` to pass the actual rule found back into `lval_read()`.\n\nThe variants contianng children use a helper which skips surrounding brackets, and just adds the actual children to the new `Lval`:\n\n```rust\nfn read_to_lval(mut v: &mut Lval, parsed: Pair<Rule>) -> Result<()> {\n    for child in parsed.into_inner() {\n        if is_bracket_or_eoi(&child) {\n            continue;\n        }\n        lval_add(&mut v, &*lval_read(child)?)?;\n    }\n    Ok(())\n}\n```\n\nThe final result of `lval_read()` will be a single `Lval` containing the entire parsed program, saved in `lval_ptr`.  Then we call `lval_eval()`, which will also return a `BlisprResult` after reducing this tree to its most evaluated form.  If the evaluation is successful we just print out the result, and if any error was raised we print that error instead.\n\n## Environment\n\nBefore we dig into how `lval_eval()` does its mojo lets pause and talk about the environment.  This is how symbols are able to correspond to functions and values - otherwise `\"+\"` would just be that character, but we need to to specifically correspond to the addition function.\n\nJury's out on whether or not I have the right idea, here, but I also handled this differently from the book.  The original text has you create a `struct` that holds two arrays and a counter, one for keys and the other for values.  To perform a lookup, you find the index of that key and then return the value at that same index in the values.  This struct is built before the program enters the loop, and is passed in manually to every single function that gets called.\n\nInstead, I've opted for a [`HashMap`](https://doc.rust-lang.org/std/collections/struct.HashMap.html) data structure instead of two separated arrays with matching indices:\n\n```rust\npub type LEnvLookup = HashMap<String, Box<Lval>>;\n\n#[derive(Debug, PartialEq)]\npub struct Lenv<'a> {\n    lookup: LEnvLookup,\n    pub parent: Option<&'a Lenv<'a>>,\n}\n```\n\nThe `Lenv` itself holds the lookup table and optionally a reference to a parent.\n\nI've got some helper methods for getting, setting, and enumerating the contents:\n\n```rust\nimpl Lenv {\n\n // ..\n\n pub fn get(&self, k: &str) -> BlisprResult {\n        match self.lookup.get(k) {\n            Some(v) => Ok(v.clone()),\n            None => {\n                // if we didn't find it in self, check the parent\n                // this will recur all the way up to the global scope\n                match &self.parent {\n                    None => Err(BlisprError::UnknownFunction(k.to_string())),\n                    Some(p_env) => p_env.get(k),\n                }\n            }\n        }\n    }\n\n    // Returns an Lval containing Symbols with each k,v pair in the local env\n    pub fn list_all(&self) -> BlisprResult {\n        let mut ret = lval_qexpr();\n        for (k, v) in &self.lookup {\n            lval_add(&mut ret, &lval_sym(&format!(\"{}:{}\", k, v)))?;\n        }\n        Ok(ret)\n    }\n\n    // add a value to the local env\n    pub fn put(&mut self, k: String, v: Box<Lval>) {\n        let current = self.lookup.entry(k).or_insert_with(|| v.clone());\n        if *v != **current {\n            // if it already existed, overwrite it with v\n            *current = v;\n        }\n    }\n}\n```\n\nGetting a value from the environment will return a brand new `Lval` with a copy of what's stored, and printing out the contents will also return a ready-made `Lval::Qexpr` containing `Symbol`s corresponding to each entry.  We'll come back to initialization after talking a bit about evaluation.\n\nEnvironments optionally hold a parent environment, and if the lookup fails in this one it will attempt the parent environment.\n\n## Eval\n\nThe `lval_eval()` function called in `eval_str()` is where the real crunching happens.  This will take an `Lval` (that is, an AST) and recursively evaluate it to a final `Lval`.  Most types of `Lval` are already evaluated fully - but any `S-Expression` found will need to be evaluated, and any `Symbol` gets looked up in the environment.\n\nBefore looking at the Rust, let's break it down in English:\n\n1. Check the type of Lval:\n\n    a. Fun | Num | Qexpr - we're done - return lval as is.\n\n    b. Symbol - Do an environment lookup with `Lenv::get()` - e.g., for `Sym(\"+\")`, see if we have a function pointer stored at name `\"+\"`.  Return result of lookup, which will already be an `Lval`.\n\n    c. Sexpr - Evaluate the S-Expression.\n\n2. If we made it to this step, we're working with an S-Expression.  Everything else has already returned. Before going further, fully evaluate all children with `lval_eval()`.\n\n3. Check the length of the S-Expression:\n\n    a. 0 - empty S-Expression - return as-is\n    \n    b. 1 - single expression - pop that expression and return the result of calling `lval_eval()` on it\n\n    c. Multiple expressions (function call) - pop the first expression and attempt to use it as a function on the rest of the children\n\nHere's what that looks like in Rust:\n\n```rust\n// Fully evaluate an `Lval`\npub fn lval_eval(e: &mut Lenv, v: &mut Lval) -> BlisprResult {\n    let child_count;\n    let mut args_eval;\n    match v {\n        Lval::Blispr(forms) => {\n            // If it's multiple, evaluate each and return the result of the last\n            args_eval = eval_cells(e, forms)?;\n            let forms_len = args_eval.len()?;\n            return Ok(lval_pop(&mut args_eval, forms_len - 1)?);\n        }\n        Lval::Sym(s) => {\n            // If it's a symbol, perform an environment lookup\n            let result = e.get(&s)?;\n            // The environment stores Lvals ready to go, we're done\n            return Ok(result);\n        }\n        Lval::Sexpr(ref mut cells) => {\n            // If it's a Sexpr, we're going to continue past this match\n            // First recursively evaluate each child with lval_eval()\n            // grab the length and evaluate the children\n            child_count = cells.len();\n            args_eval = eval_cells(e, cells)?;\n        }\n        // if it's not a sexpr, we're done, return as is\n        _ => {\n            return Ok(Box::new(v.clone()));\n        }\n    }\n    if child_count == 0 {\n        // It was a Sexpr, but it was empty.  We're done, return it\n        Ok(Box::new(v.clone()))\n    } else if child_count == 1 {\n        // Single expression\n        lval_eval(e, &mut *lval_pop(v, 0)?)\n    } else {\n        // Function call\n        // We'll pop the first element off and attempt to call it on the rest of the elements\n        let fp = lval_pop(&mut args_eval, 0)?;\n        lval_call(e, *fp, &mut *args_eval)\n    }\n}\n```\n\nThe step that fully evaluates all the children of an S-Expression before tackling the expression itself uses a helper:\n\n```rust\n// Given a slice of boxed Lvals, return a single evaluated sexpr\nfn eval_cells(e: &mut Lenv, cells: &[Box<Lval>]) -> BlisprResult {\n    cells.iter().fold(Ok(lval_sexpr()), |acc, c| {\n        match acc {\n            Ok(mut lval) => {\n                lval_add(&mut lval, &*lval_eval(e, &mut c.clone())?)?;\n                Ok(lval)\n            }\n            // it's just a Result so we can bubble errors out of the fold\n            Err(_) => unreachable!(),\n        }\n    })\n}\n```\n\nThis is written as a `fold` using an empty `Lval::Sexpr` as the accumulator, using `lval_add` to add each new result to it.\n\n## Function calling\n\nThis gets us almost all the way there - there's one last missing step, which is `lval_call()`.\n\nThis language has two kinds of functions: builtins and user-defined lambdas.  Builtins are implemented in Rust and part of the executable itself.  These are stored in the environment when it's created:\n\n```rust\nfn add_builtin(&mut self, name: &str, func: LBuiltin) {\n    self.put(name.to_string(), lval_builtin(func, name))\n}\n\npub fn new(lookup: Option<LEnvLookup>, parent: Option<&'a Lenv<'a>>) -> Self {\n        let mut ret = Self {\n            lookup: lookup.unwrap_or_default(),\n            parent,\n        };\n\n        // Register builtins\n        // The \"stub\" fns are dispatched separately - the function pointer stored is never called\n        // these are the ones the modify the environment\n\n        // Definiton\n        ret.add_builtin(\"\\\\\", builtin_lambda);\n        ret.add_builtin(\"def\", builtin_put_stub);\n\n        // etc, lots and lots of builtins\n\n        ret.add_builtin(\"max\", builtin_max);\n\n        ret\n}\n```\n\nEach name stores a function pointer to a Rust function.  These functions manipulate lvals directly.  For example, this is `builtin_head`, which returns the first element of an `Lval::Qexpr`:\n\n```rust\npub fn builtin_head(v: &mut Lval) -> BlisprResult {\n    let mut qexpr = lval_pop(v, 0)?;\n    match *qexpr {\n        Lval::Qexpr(ref mut children) => {\n            if children.is_empty() {\n                return Err(BlisprError::EmptyList);\n            }\n            debug!(\"builtin_head: Returning the first element\");\n            Ok(children[0].clone())\n        }\n        _ => Err(BlisprError::WrongType(\n            \"qexpr\".to_string(),\n            format!(\"{:?}\", qexpr),\n        )),\n    }\n}\n```\n\nMathematical operations all use the same function.  They all accept a list of any length of `Lval::Num`s and will successively apply a binary operation to a running result and the next number until the list is consumed:\n\n```rust\nfn builtin_op(mut v: &mut Lval, func: &str) -> BlisprResult {\n    let mut child_count;\n    match *v {\n        Lval::Sexpr(ref children) => {\n            child_count = children.len();\n        }\n        _ => return Ok(Box::new(v.clone())),\n    }\n\n    let mut x = lval_pop(&mut v, 0)?;\n\n    // If no args given and we're doing subtraction, perform unary negation\n    if (func == \"-\" || func == \"sub\") && child_count == 1 {\n        let x_num = x.as_num()?;\n        return Ok(lval_num(-x_num));\n    }\n\n    // consume the children until empty\n    // and operate on x\n    while child_count > 1 {\n        let y = lval_pop(&mut v, 0)?;\n        child_count -= 1;\n        match func {\n            \"+\" | \"add\" => {\n                apply_binop!(add, x, y)\n            }\n            \"-\" | \"sub\" => {\n                apply_binop!(sub, x, y)\n            }\n            \"*\" | \"mul\" => {\n                apply_binop!(mul, x, y)\n            }\n            \"/\" | \"div\" => {\n                if y.as_num()? == 0 {\n                    return Err(BlisprError::DivideByZero);\n                } else {\n                    apply_binop!(div, x, y)\n                }\n            }\n            \"%\" | \"rem\" => {\n                apply_binop!(rem, x, y)\n            }\n            \"^\" | \"pow\" => {\n                let y_num = y.as_num()?;\n                let x_num = x.as_num()?;\n                let mut coll = 1;\n                for _ in 0..y_num {\n                    coll *= x_num;\n                }\n                x = lval_num(coll);\n            }\n            \"min\" => {\n                let x_num = x.as_num()?;\n                let y_num = y.as_num()?;\n                if x_num < y_num {\n                    x = lval_num(x_num);\n                } else {\n                    x = lval_num(y_num);\n                };\n            }\n            \"max\" => {\n                let x_num = x.as_num()?;\n                let y_num = y.as_num()?;\n                if x_num > y_num {\n                    x = lval_num(x_num);\n                } else {\n                    x = lval_num(y_num);\n                };\n            }\n            _ => unreachable!(),\n        }\n    }\n    Ok(x)\n}\n```\n\nThis is a long function - but it'd be even longer without the macro I defined:\n\n```rust\nmacro_rules! apply_binop {\n    ( $op:ident, $x:ident, $y:ident ) => {\n        match (*$x, *$y) {\n            (Lval::Num(x_num), Lval::Num(y_num)) => {\n                $x = lval_num(x_num.$op(y_num));\n                continue;\n            }\n            _ => return Err(BlisprError::NotANumber),\n        }\n    };\n}\n```\n\nThis makes some of the Lval type checking quicker to type!  It handles making sure both arguments are `Lval::Num` before trying to do something numeric with them, as in `apply_binop!(add, x, y)`.  This was my first brush with defining Rust macros, and it was a serious help.\n\nThese are fairly easy to call.  Because the environment stores these ans function pointers you can simply call the function.  My solution is a little hacky, because a few builtins require access to an environment, which builtin functions don't have - these special cases are dispatched separately, and everything else is just called with `fp()`:\n\n```rust\nLvalFun::Builtin(name, fp) => match name.as_str() {\n        \"eval\" => builtin_eval(e, args),\n        \"def\" => builtin_def(e, args),\n        \"printenv\" => builtin_printenv(e),\n        // Otherwise, just apply the actual stored function pointer\n        _ => fp(args),\n},\n```\n\nCalling a `Lambda` is a little trickier.  We need to build a new environment, add any local bindings to it, and then either call the new function or return a new, partially applied lambda if not all locals were given.  The machinery here is verbose - see [this line](https://github.com/deciduously/blispr/blob/2d8aa15cf7ba8cfc624cf9663fd024dda1df9f72/src/eval.rs#L436) for the code in context.\n\nThat's all of our pieces.  With all this in place `lval_eval()` can handle a whole bunch of stuff, and this language actually approaches usable.  This language implementation is not complete, but it's a great playground for learning about how languages work!",
    "title": "Rust Your Own Lisp"
  },
  {
    "cover_image": "https://res.cloudinary.com/practicaldev/image/fetch/s--tRhwxbpp--/c_imagga_scale,f_auto,fl_progressive,h_420,q_auto,w_1000/https://thepracticaldev.s3.amazonaws.com/i/ooh3lt2f4p3al70zkhnx.jpg",
    "date": "2019-06-13T14:41:55.559Z",
    "description": "",
    "tags": "explainlikeimfive, beginners, discuss",
    "markdown": "I've been trying to get better about writing more complete tests, but often feel I'm being somewhat redundant.  Sometimes the tests I'm writing feel like they're just verifying that the language works as anticipated (if I pass in a parameter, is it accessible in the local scope?  Does this math function that accepts integer types reject non-integer inputs?), or that the framework works (If I pass in a string prop to render as a text node, does React indeed render this text node?).\n\nIn a dynamic language extra checks for proper types make sense, but in a type-safe language I'm more than happy to trust my compiler for that.  As a result, my unit tests feel sparse.  It feels more natural to write integration tests that encompass multiple parts of the application in an end-to-end or round-trip manner.\n\nHow do you decide what's worthy of a unit test and what isn't?",
    "title": "ELI5: Useful Unit Testing"
  },
  {
    "cover_image": "https://res.cloudinary.com/practicaldev/image/fetch/s--417W9fRI--/c_imagga_scale,f_auto,fl_progressive,h_420,q_auto,w_1000/https://thepracticaldev.s3.amazonaws.com/i/ozzemh45p626qkat5kau.jpg",
    "date": "2019-06-14T21:24:38.509Z",
    "description": "",
    "tags": "rust, webassembly, beginners, tutorial",
    "markdown": "# Or How I Learned To Stop Worrying And Love Macros\n\nIt's been a little while since I built a resizable dot with a slider in some esoteric stack.  Time for Chapter 3!  I guess it's a series now.\n\nThe last two demos used languages that transpile the whole app to regular ol' JavaScript to be interpreted.  This time around, we're going to be compiling our app to WebAssembly first, and then having JavaScript load that.\n\nAs per usual with these dot demos, this is overkill for this app.  This one perhaps especially so.  Roll up your sleeves, we're gonna scrob us some DOM.\n\n## The Pipeline\n\nThis section is largely copped straight outta the [RustWasm Book](https://rustwasm.github.io/docs/book/game-of-life/hello-world.html).  If you plan to do further work with Rust and WebAssembly, head straight there next (or now).  You'll need a Rust toolchain and Node/NPM to follow along.\n\nFirst, create a new library-type crate:\n\n```\n$ cargo new wasm-dot --lib\n$ cd wasm-dot\n```\n\nWe need to add `wasm-bindgen`.  This crate auto-generates all the JS <-> Rust FFI glue for us, and is much of the reason Rust is such a phenomenal choice for writing WebAssembly.  Open up `Cargo.toml` in the crate root and make it look like this:\n\n```toml\n[package]\nname = \"wasm-dot\"\ndescription = \"Demo canvas wasm app\"\nlicense = \"MIT\"\nversion = \"0.1.0\"\nauthors = [\"You <you@yourcoolsite.you>\"]\nedition = \"2018\"\n\n[lib]\ncrate-type = [\"cdylib\"]\n\n[dependencies]\nwasm-bindgen = \"0.2\"\n```\n\nThe `cdylib` crate type will produce a dynamic system library for loading into another language.  Now open up `src/lib.rs` and make it look like this:\n\n```rust\nuse wasm_bindgen::prelude::*;\n\n#[wasm_bindgen]\nextern {\n    // import the alert() js function\n    pub fn alert(s: &str);\n}\n\n// export a Rust function that uses the imported JS function\n#[wasm_bindgen]\npub fn say_hi() {\n    alert(\"Hi from Rust/Wasm!\");\n}\n```\n\nWe're importing the JavaScript `alert()` function and exporting our own `say_hi()` Rust function that calls it.  That's all we need to do, `wasm_bindgen` is taking care of the details.  This will just ensure both directions work as intended.\n\nThe rustwasm team also provides a tool called [`wasm-pack`](https://github.com/rustwasm/wasm-pack) to automate WebAssembly packaging and integration with npm.  You'll need to install it once with `cargo install wasm-pack` and then you can use it to build your package:\n\n```\n$ wasm-pack build\n[INFO]: Checking for the Wasm target...\n[INFO]: Compiling to Wasm...\n    Finished release [optimized] target(s) in 0.00s\n[INFO]: :-) Done in 0.05s\n[INFO]: :-) Your wasm pkg is ready to publish at ./pkg.\n```\n\nInside `pkg/` you'll find everything you need to deploy, ready to be imported into any npm project.  All we need now is a project in which to use it!  Because the rustwasm group thought of everything, there's a template ready to go - use it to create a new project:\n\n```\n$ npm init wasm-app www\n```\n\nThis `www` folder now contains a webpage with all the machinery set up to load your wasm library and call it from `index.js`:\n\n```js\nimport * as wasm from \"hello-wasm-pack\";\n\nwasm.greet();\n```\n\nThere's a stub included so that it will run as is, but we don't want to import from `hello-wasm-pack`, we want to use the app we're developing.  To point it in the right direction, open up `www/package.json` and add a `dependencies` key, pointing directly at the `pkg` output dir from `wasm-pack`:\n\n```json\n  // ..\n  \"dependencies\": {\n    \"wasm-dot\": \"file:../pkg\"\n  }\n```\n\nNow we can point `www/index.js` there:\n\n```js\nimport * as wasm from \"wasm-dot\";\n\nwasm.say_hi();\n```\n\nLet's see if it does the thing:\n\n```\n$ npm install // because we added a dependency - us!\n$ npm run start\n```\n\nYou should see the requested alert at`localhost:8080`:\n\n![hello wasm alert box screenshot](https://i.imgur.com/INNppw6.png)\n\nHuzzah!  Now we can iterate.  I recommend opening a second terminal at this point.  In one, run `npm run start` and keep it open, and in the other invoke `wasm-pack build` whenever you make a change to the Rust.\n\n## The Layout\n\nTo deal with the JavaScript universe, the `wasm-bindgen` project provides two important crates: `web-sys` provides bindings for all the Web APIS (!!) and `js-sys` provides all the ECMAScript stuff like `Array` and `Date` (!!).  Yeah, they already did the hard work.  It's pretty cool, you don't need to manually define a `Document.createElement` extern or anything.  Instead, just pull in what we need from `web-sys` in `Cargo.toml`:\n\n```toml\n[dependencies]\nwasm-bindgen = \"0.2\"\n\n[dependencies.web-sys]\nversion = \"0.3\"\nfeatures = [\n    \"Attr\",\n    \"CanvasRenderingContext2d\",\n    \"Document\",\n    \"Element\",\n    \"Event\",\n    \"EventTarget\",\n    \"HtmlCanvasElement\",\n    \"HtmlElement\",\n    \"HtmlInputElement\",\n    \"Node\",\n    \"Text\",\n    \"Window\"\n]\n```\n\nIt's a huge crate, so each interface is feature-gated.  You only use what you need.  If you're trying to call a function and it's telling you it doesn't exist, double check the API docs.  It always tells you which features a given method needs:\n\n![feature gate screenshot](https://i.imgur.com/thITZh3.png)\n\nTo make sure it's all groovy, we're going to build a DOM node ourselves, JS-style but, like, also Rust-style.  Remove the `alert()` test in `src/lib.rs` and add:\n\n```rust\n#[wasm_bindgen]\npub fn run() {\n    // get window/document/body\n    let window = web_sys::window().expect(\"Could not get window\");\n    let document = window.document().expect(\"Could not get document\");\n    let body = document.body().expect(\"Could not get body\");\n\n    mount_app(&document, &body);\n}\n\nfn mount_app(document: &Document, body: &HtmlElement) {\n    mount_title(&document, &body);\n}\n\n// Create a title\nfn mount_title(document: &Document, body: &HtmlElement) {\n    // create title element\n    let title = document\n        .create_element(\"h1\")\n        .expect(\"Could not create element\");\n    let title_text = document.create_text_node(\"DOT\"); // always succeeds\n    title\n        .append_child(&title_text)\n        .expect(\"Could not append child to title\");\n\n    // append to body\n    body.append_child(&title)\n        .expect(\"Could not append title to body\");\n}\n```\n\nUsing `web_sys` calls, this code manually builds a DOM node for the title and mounts it to the body of the page.\n\nNow instead of `say_hi()` we'll need to call `run()` in `www/index.js`:\n\n```js\nimport * as wasm from \"wasm-dot\";\n\nwasm.run();\n```\n\nSee if it works by running `wasm-pack build` and reloading `localhost:8080`:\n\n![dom node screenshot](https://i.imgur.com/7yiqu7f.png)\n\nWhoa.  Did you see how blazing-fast and WASM-infused that title was?!\n\nNo, you didn't, but still.  Neat.  Before moving on, let's address the error handling situation.  All of these `web-sys` calls will return a `Result<T, JsValue>`.  We're not going to deal with other types of errors in this tiny demo, so just alias that:\n\n```rust\ntype Result<T> = std::result::Result<T, JsValue>;\n```\n\nNow we can have our functions return a `Result<()>` and get to use the `?` operator instead of sprinkling `expect()` everywhere.  Refactor `run()` to leverage this:\n\n```rust\nfn get_document() -> Result<Document> {\n    let window = web_sys::window().unwrap();\n    Ok(window.document().unwrap())\n}\n\n#[wasm_bindgen]\npub fn run() -> Result<()> {\n    let document = get_document()?;\n    let body = document.body().unwrap();\n\n    mount_app(&document, &body)?;\n    Ok(())\n}\n```\n\nPulling `get_document()` out will help us define the event listener later.  First, though, we need to define the DOM tree we want.  Here's what we're aiming for in HTML:\n\n```html\n  <div id=\"rxcanvas\">\n    <span id=\"size-output\"></span>\n    <input id=\"size\" type=\"range\" min=\"1\" max=\"100\" step=\"5\">\n    <label for=\"size\">- Size</label>\n    <p>\n      <canvas id=\"dot-canvas\"></canvas>\n    </p>\n  </div>\n```\n\nIf you've ever manipulated the DOM via JavaScript, you're pretty much good to go.  In Rust, though, this is *so verbose*.  Look how big the function to create a simple `<h1>DOT</h1>` element was!  I promised up above there would be macros - here we go.\n\nFor the uninitiated, a macro is a bit of code that expands into other Rust code *before* everything is evaluated.  In Rust, they look like function calls but with an exclamation point at the end.  They aren't function calls at all though - when the compiler comes through your module, it expands all of these anywhere they find them into the full Rust code you (or a library) defined.  It's a mechanism for automatic code generation!\n\nThis syntax is the only place in Rust you'll see that `thing { () => {} }` bracket pattern.  It's its own special syntax.  The parameters are prefixed with a `$` and placed in the parens, and are copied in to the Rust code in the curly braces during expansion, right in place in your code.\n\nRust actually has another type of macro called a [procedural macro](https://blog.rust-lang.org/2018/12/21/Procedural-Macros-in-Rust-2018.html) that's *even more powerful and arcane* but for now `macro_rules!` will do us just fine.\n\nHere's a macro to append an arbitrary number of attributes to a DOM element, passed as 2-tuples:\n\n```rust\nmacro_rules! append_attrs {\n    ($document:ident, $el:ident, $( $attr:expr ),* ) => {\n        $(\n            let attr = $document.create_attribute($attr.0)?;\n            attr.set_value($attr.1);\n            $el.set_attribute_node(&attr)?;\n        )*\n    }\n}\n```\n\nEach parameter to expand is tagged with a token type - an `ident` will allow us to pass a Rust name though and an `expr` takes any Rust expression (in this case, a 2-tuple).  When called, each one will just paste this block of Rust into our function in place, using what we pass in.\n\nThis macro is variadic, meaning it can accept a variable number of arguments.  The `$( $name:expr ),*` syntax means that it will carry out this block for zero or more arguments given, pasting a copy of the code in the curly braces for each arg passed here.  Each time through, the arg we're processing gets the name `$attr`.\n\nYou can call it like this, with as many trailing tuple arguments as needed for each attribute:\n\n```rust\nappend_attrs!(document, label, (\"for\", \"size\"));\n```\n\nWe can do better, though - macros can call other macros!  We can boil everything down to the bare minimum by defining a few more helpers:\n\n```rust\nmacro_rules! append_text_child {\n    ($document:ident, $el:ident, $text:expr ) => {\n        let text = $document.create_text_node($text);\n        $el.append_child(&text)?;\n    };\n}\n\nmacro_rules! create_element_attrs {\n    ($document:ident, $type:expr, $( $attr:expr ),* ) => {{\n        let el = $document.create_element($type)?;\n        append_attrs!($document, el, $( $attr ),*);\n        el}\n    }\n}\n\nmacro_rules! append_element_attrs {\n    ($document:ident, $parent:ident, $type:expr, $( $attr:expr ),* ) => {\n        let el = create_element_attrs!($document, $type, $( $attr ),* );\n        $parent.append_child(&el)?;\n    }\n}\n\nmacro_rules! append_text_element_attrs {\n    ($document:ident, $parent:ident, $type:expr, $text:expr, $( $attr:expr ),*) => {\n        let el = create_element_attrs!($document, $type, $( $attr ),* );\n        append_text_child!($document, el, $text);\n        $parent.append_child(&el)?;\n    }\n}\n```\n\nThere are two \"top-level\" macros, `append_element_attrs` and `append_text_element_attrs`.  The former will append a childless element with the given attributes to the parent provided and the latter will include a text node child.  Note that to pass the variadic trailing arguments down you just use the same syntax inside the curly brace expansion but omit the `expr` type:\n\n```rust\nlet el = create_element_attrs!($document, $type, $( $attr ),* );\n```\n\nNow we can replace the entirety of that `mount_title()` function with a single macro invocation:\n\n```rust\nfn mount_app(document: &Document, body: &HtmlElement) -> Result<()> {\n    append_text_element_attrs!(document, body, \"h1\", \"DOT\",);\n    Ok(())\n}\n```\n\nI've also added our new return type, and as a result we now return a simple `Ok(())` at the end to signify success.  This macro expansion contains `?` operators, which will now work as expected!\n\nNote the trailing comma after `\"DOT\"` is mandatory - that's the \"zero or more\" attributes this macro accepts.  That's so much boilerplate we've avoided though.  The initial function is what the compiler sees when building the binary, we just saved ourselves the hassle of typing it all.  Thanks, macros!  Thacros.\n\nHere's the rest of the f#@%!^g owl:\n\n```rust\nfn mount_canvas(document: &Document, parent: &Element) -> Result<()> {\n    let p = create_element_attrs!(document, \"p\",);\n    append_element_attrs!(document, p, \"canvas\", (\"id\", \"dot-canvas\"));\n    parent.append_child(&p)?;\n    Ok(())\n}\n\nfn mount_controls(document: &Document, parent: &HtmlElement) -> Result<()> {\n    // containing div\n    let div = create_element_attrs!(document, \"div\", (\"id\", \"rxcanvas\"));\n    // span\n    append_text_element_attrs!(\n        document,\n        div,\n        \"span\",\n        &format!(\"{}\", STARTING_SIZE),\n        (\"id\", \"size-output\")\n    );\n    // input\n    append_element_attrs!(\n        document,\n        div,\n        \"input\",\n        (\"id\", \"size\"),\n        (\"type\", \"range\"),\n        (\"min\", \"5\"),\n        (\"max\", \"100\"),\n        (\"step\", \"5\")\n    );\n    // label\n    append_text_element_attrs!(document, div, \"label\", \"- Size\", (\"for\", \"size\"));\n    // canvas\n    mount_canvas(&document, &div)?;\n    parent.append_child(&div)?;\n    Ok(())\n}\n\nfn mount_app(document: &Document, body: &HtmlElement) -> Result<()> {\n    append_text_element_attrs!(document, body, \"h1\", \"DOT\",);\n    mount_controls(&document, &body)?;\n    Ok(())\n}\n```\n\nThe astute will notice a reference to `STARTING_SIZE` - add that constant to the top of your file, this is where the slider will start when the page renders:\n\n```rust\nconst STARTING_SIZE: u32 = 5;\n```\n\nAll the `web_sys` calls look very familiar if you're coming from JavaScript.  If you want a Web API function, just try looking for it in the [`web-sys` API docs](https://rustwasm.github.io/wasm-bindgen/api/web_sys/).  Each listing will conveniently link to the corresponding MDN page, too!  Leveraging crates or writing your own abstractions to make this smoother is both quite possible and left as an exercise for the reader.\n\nRebuild with `wasm-pack build`, and if you have `webpack-dev-server` running (via `npm run start`) you can reload `localhost:8080`:\n\n![DOM tree screenshot](https://i.imgur.com/yTLnwg0.png)\n\nGood stuff.\n\n## The Action\n\nThis doesn't do anything, though.  There's nary a dot in sight, let alone a resizable one.  The next order of business is to draw the dot to the canvas:\n\n```rust\n// draw dot\nfn update_canvas(document: &Document, size: u32) -> Result<()> {\n    // grab canvas\n    let canvas = document\n        .get_element_by_id(\"dot-canvas\")\n        .unwrap()\n        .dyn_into::<web_sys::HtmlCanvasElement>()?;\n    // resize canvas to size * 2\n    let canvas_dim = size * 2;\n    canvas.set_width(canvas_dim);\n    canvas.set_height(canvas_dim);\n    let context = canvas\n        .get_context(\"2d\")?\n        .unwrap()\n        .dyn_into::<web_sys::CanvasRenderingContext2d>()?;\n\n    // draw\n\n    context.clear_rect(0.0, 0.0, canvas.width().into(), canvas.height().into());\n    // create shape of radius 'size' around center point (size, size)\n    context.begin_path();\n    context.arc(\n        size.into(),\n        size.into(),\n        size.into(),\n        0.0,\n        2.0 * std::f64::consts::PI,\n    )?;\n    context.fill();\n    context.stroke();\n\n    Ok(())\n}\n```\n\nThis is also not too foreign if you've done this in JavaScript.  One unfamiliar element is those `dyn_into` calls.  To get this working, you need another import at the top of the file:\n\n```rust\nuse wasm_bindgen::JsCast;\n```\n\nWhen you grab an element with `Document::get_element_by_id(&str)` it returns an `Element` type.  A plain `Element` doesn't have a `width` or a `height`, though - this is specifically a `canvas` element.  The `HtmlCanvasElement` object does have these fields, so we can attempt to cast with `dyn_into()`.  If we did indeed grab the correct element this cast will succeed.  Now we can use things like `set_height()` and `get_context()`.  Note that all methods use snake_case instead of camelCase, and you can't directly modify a field with `canvas.height = 10;`, you must use a method: `canvas.set_height(10);`.  Otherwise this is a translation of equivalent JavaScript to resize the canvas to the bounding box of the circle with the given radius and then draw that circle.\n\nCool.  We'll also need to update the `<span>` we have dedicated to showing the current size:\n\n```rust\n// update the size-output span\nfn update_span(document: &Document, new_size: u32) -> Result<()> {\n    let span = document.get_element_by_id(\"size-output\").unwrap();\n    span.set_text_content(Some(&format!(\"{}\", new_size)));\n    Ok(())\n}\n```\n\nThis isn't too surprising, `set_text_content` is a setter for [`Node.textContent`](https://developer.mozilla.org/en-US/docs/Web/API/Node/textContent).  Let's bundle up these two updates:\n\n```rust\n// given a new size, sets all relevant DOM elements\nfn update_all() -> Result<()> {\n    // get new size\n    let document = get_document()?;\n    let new_size = document\n        .get_element_by_id(\"size\")\n        .unwrap()\n        .dyn_into::<web_sys::HtmlInputElement>()?\n        .value()\n        .parse::<u32>()\n        .expect(\"Could not parse slider value\");\n    update_canvas(&document, new_size)?;\n    update_span(&document, new_size)?;\n    Ok(())\n}\n```\n\nThis is going to be our onChange handler for the slider input, called inside this special FFI-interop-y `Closure`:\n\n```rust\nfn attach_listener(document: &Document) -> Result<()> {\n    // listen for size change events\n\n    update_all()?; // call once for initial render before any changes\n\n    let callback = Closure::wrap(Box::new(move |_evt: web_sys::Event| {\n        update_all().expect(\"Could not update\");\n    }) as Box<dyn Fn(_)>);\n\n    document\n        .get_element_by_id(\"size\")\n        .unwrap()\n        .dyn_into::<web_sys::HtmlInputElement>()?\n        .set_onchange(Some(callback.as_ref().unchecked_ref()));\n\n    callback.forget();\n\n    Ok(())\n}\n```\n\nThis uses a `web_sys::Closure`.  This allows you to pass Rust-defined closures through to JS to be used as event listener callbacks.  This has some definite weirdness, I'm going to direct you to [the book](https://rustwasm.github.io/wasm-bindgen/examples/closures.html) for a better run though of why this looks like it does.  That `as_ref().unchecked_ref()` chain lets you extract the `&Function` that `set_onchange` expects from the `web_sys::Closure`.\n\nNow we just need to call this after we mount the app:\n\n```rust\n#[wasm_bindgen]\npub fn run() -> Result<()> {\n    let document = get_document()?;\n    let body = document.body().unwrap();\n\n    mount_app(&document, &body)?;\n    attach_listener(&document)?;\n    Ok(())\n}\n```\n\nAnd that's it!  Recompile, reload, and rejoice as you resize.  Aww *yisss*.\n\n![finished screenshot](https://i.imgur.com/TxCIBFH.png)\n\nThe full code can be found [here](https://github.com/deciduously/wasm-dot).\n\nPhoto by Leo Rivas on Unsplash",
    "title": "Reactive Canvas with Rust/WebAssembly and web-sys"
  },
  {
    "cover_image": "https://res.cloudinary.com/practicaldev/image/fetch/s--L2_aL_----/c_imagga_scale,f_auto,fl_progressive,h_420,q_auto,w_1000/https://thepracticaldev.s3.amazonaws.com/i/r4q0qcqykmss7h59wlvo.png",
    "date": "2019-06-19T12:31:38.414Z",
    "description": "",
    "tags": "meta",
    "markdown": "Change my mind",
    "title": "Pink Theme > Any Other Theme"
  },
  {
    "cover_image": "https://res.cloudinary.com/practicaldev/image/fetch/s--s6IkvTl3--/c_imagga_scale,f_auto,fl_progressive,h_420,q_auto,w_1000/https://thepracticaldev.s3.amazonaws.com/i/3qs6h3t9dpkyonovre6m.png",
    "date": "2019-06-22T17:20:17.855Z",
    "description": "",
    "tags": "devjournal, rust, reason, beginners",
    "markdown": "One of my first posts on this site was about webapp I made to handle taking attendance:\n\n{% link deciduously/rust--reasonml---a-beginners-love-story-45a2 %}\n\nWhen I wrote that post, it had already been a while since I'd completed writing the application.  It works, too, the center has been using this daily for almost a year now, with minimal intervention on my part since I left that job.  I'm about to sit down and polish it up after not touching it for a long time, and have decided by \"polish up\" I mean rewrite most of the backend and much of the frontend entirely, again.  Record scratch, freeze frame, I bet you're wondering how I got here.\n\nThe reason this app is written...well,  silly, is not, in retrospect, because it was the best of my ability at the time and I've since learned.  No, this was a desperation application, and I'm writing this post mostly for my own benefit.  If we don't remember the mistakes of the future, we are doomed to repeat them for the first time or something.\n\nI *fully well* knew better for each one of the problems I outline here, and opted to do the lazy, quick thing in the interest of producing something that worked.  I'm a little bit peeved at Past Ben.  Let this post be a warning, Future Ben.\n\nThe application lives [here](https://github.com/deciduously/mifkad).\n\n## The Background\n\nI worked in the administrative office of a non-profit preschool.  It was little bit hectic.  It was adorable, yes, but unpredictable at times, what with the children, the teachers, the parents, you know.  The elements of a preschool and whatnot.  Administrative would be putting my duties lightly, but \"miscellaneous\" isn't really a great job posting title.  I was all over the facility for various reasons, the phone calls were frequent, an uninterrupted fifteen minutes at any given task was a rarity.  Thus, time was at a premium and every scrap of organization was to be cherished.\n\nHaving already been hobby-gramming for a while by then, I had a dislike for doing tasks that I thought were \"for computers\", even though sometimes for necessity a pencil and paper is the simplest and cheapest way to do something.  In one case, though, it *clearly* wasn't.\n\n## The Problem\n\nOne of my daily duties was collection the school's attendance and logging it in a spreadsheet.  Then, after logging any absences, I'd calculate the \"Extended Day Roster\" and email it out to everyone so that afternoon staffing could be solidified.\n\nAt 4 PM, most kids go home.  That's what's included in the base contract.  Parents had the option to keep their kids there until 6 PM instead, at a different hourly rate.  As only a fraction of families choose this, the fifteen classrooms during the day reduce down to just five.  In order to ensure we maintained appropriate staff-child ratios, the directors (and teachers) needed to know how many kids to expect in this extended part of the day, including any absences.  The more staff you can safely cut, the better!\n\nThis was all done in a small spiral notebook.  The classrooms were spread around the building, so instead of making the loop and being far from the desk if someone needed me I'd call each and ask the teacher over the phone if anyone was absent.  I'd write down the absences for each classroom.  Then, after I'd managed to connect with all fifteen (easier said than done), I'd reconcile it against the children who are contracted to stay late and those who have signed up on an ad-hoc basis to stay extra for that specific date, adding and subtracting from the expected headcount.  Then I'd type up the result in a formatted email, including the names of any additions and removals.\n\nThis took a *significant* chunk of my day.  Some days, because of poor telephone timing and various interruptions, it could be a full two hours between the first phone call and the final email.\n\n## The Solution\n\nThe application I built presents the user with a series of buttons, one per child, organized by class.  Clicking the child's name will toggle them Present or Absent, and each child that isn't already scheduled to be in Extended Day also gets a button to add them ad-hoc.  The actual Extended Day headcount email is just a function of who's in and who's extra, so it keeps a version ready to copy/paste updated at the top of the page, or download as a text file:\n\n![app screenshot](https://camo.githubusercontent.com/44596acec59b2793fc5f773271a6cc355249ad68/68747470733a2f2f692e696d6775722e636f6d2f7a6777706e6b512e706e67)\n\nThe ad-hoc sign-up forms are printed on pink copy paper, thus \"pink sheet\".  The user can specify how the core rooms funnel into the extended rooms with a simple UI:\n\n![room picker](https://camo.githubusercontent.com/ad48c887994c5276c32dd5962bdd7f9ac2b0865e/68747470733a2f2f692e696d6775722e636f6d2f494d5133356d632e706e67)\n\nThat \"Download\" button just encodes the text as base64 and embeds it right in the link:\n\n```ocaml\n\nlet make = (~school, ~refreshClicked, ~resetClicked, _children) => {\n  ...component,\n  render: _self => {\n    let dload =\n      \"data:application/octet-stream;charset=utf8;base64,\"\n      ++ btoa(Report.school(school));\n    <div>\n      // ..\n      <a href=dload> <button> {ReasonReact.string(\"Download\")} </button> </a>\n      // ..\n    </div>;\n  },\n};\n```\n\n## The Mess\n\nCarrying out this task every day really ground my gears.  I *hated* doing it, so I was eager to push out a solution that could cut down the amount of time spent.  Thus, I cut every corner I could in order to get to working.\n\n### The Scraping, Oh The Scraping\n\nThe first problem was populating the application with the rosters for the day.  Unfortunately, despite my lobbying, I am unable to query the organization's database directly, and must use pre-created Crystal Reports to pull any data out.  Now, these reports are not exactly designed for data scrobbling, and I have zero control over what they're specifically pulling out.  They're for human consumption, formatted all nicely and designed to be printed as-is or exported to a PDF.  Crystal Reports does provide the option to export to Excel, though, which is as good as it's gonna get.  The sheet you end up with is funky, there's weird rows and weird data in rows as artifacts from the nicely formatted PDF the report was intending to create.  The report designed to be printed and given to the classrooms as their daily attendance sheet does contain all the info I need to populate this app, though.\n\nGetting a nice clean Rust data structure out of this spreadsheet is not necessarily complicated, but I was rushing:\n\n```rust\npub fn scrape_enrollment(\n    day: Weekday,\n    extended_config: ExtendedDayConfig,\n    config: &Config,\n) -> Result<School> {\n    lazy_static! {\n        // Define patterns to match\n        static ref KID_RE: Regex =\n            Regex::new(r\"((@|#|&) )?(?P<last>[A-Z]+), (?P<first>[A-Z]+)\").unwrap();\n        static ref CLASS_RE: Regex = Regex::new(r\"CLASSROOM: ([A-Z])\").unwrap();\n        static ref CAPACITY_RE: Regex = Regex::new(r\"CLASS MAXIMUM: (\\d+)\").unwrap();\n    }\n\n    info!(\"Loading {:?} from {:?}\", day, &config.roster);\n    let mut school = School::new(day, extended_config);\n\n    // Use calamine to read in the input sheet\n    let mut excel: Xls<_> = open_workbook(&config.roster).unwrap();\n\n    let mut headcount = 0;\n    let mut classcount = 0;\n\n    // Try to get \"Sheet1\" as `r` - it should always exist\n    if let Some(Ok(r)) = excel.worksheet_range(\"Sheet1\") {\n        // Process each row\n        for row in r.rows() {\n            use calamine::DataType::*;\n            // Column A is either a Class or a Kid\n            let column_a = &row[0];\n            match column_a {\n                String(s) => {\n                    // If it's a class, open up a new class\n                    // If its a kid, push it to the open class\n                    // If it's anything else, ignore it.\n                    if CLASS_RE.is_match(&s) {\n                        debug!(\"MATCH CLASS: {}\", &s);\n                        let caps = CLASS_RE.captures(&s).unwrap();\n                        // the capacity is found in Column B\n                        let capacity: u8;\n                        match &row[1] {\n                            String(s2) => {\n                                let capacity_caps = CAPACITY_RE.captures(&s2).unwrap();\n                                capacity = (&capacity_caps[1])\n                                    .parse::<u8>()\n                                    .chain_err(|| \"Unable to parse capacity as u8\")?;\n                            }\n                            _ => {\n                                bail!(\"Column B of Classroom declaration contained unexpected data\")\n                            }\n                        }\n\n                        // Display the previous class headcount  -this needs to happen once againa the end, and not the first time\n                        if !school.classrooms.is_empty() {\n                            let last_class = school.classrooms[school.classrooms.len() - 1].clone();\n                            let prev_headcount = last_class.kids.len();\n                            debug!(\"Room {} headcount: {}\", last_class.letter, prev_headcount);\n                        }\n\n                        // create a new Classroom and push it to the school\n                        let new_class = Classroom::new(classcount, caps[1].to_string(), capacity);\n                        debug!(\n                            \"FOUND CLASS: {} (max {})\",\n                            &new_class.letter, &new_class.capacity\n                        );\n                        school.classrooms.push(new_class);\n                        classcount += 1;\n                    } else if KID_RE.is_match(&s) {\n                        let caps = KID_RE.captures(&s).unwrap();\n\n                        // Reformat name from LAST, FIRST to FIRST LAST\n                        let mut name = ::std::string::String::from(&caps[\"first\"]);\n                        name.push_str(\" \");\n                        name.push_str(&caps[\"last\"]);\n\n                        // init Kid datatype\n\n                        // Add schedule day\n                        let sched_idx = match day {\n                            schema::Weekday::Monday => 6,\n                            schema::Weekday::Tuesday => 7,\n                            schema::Weekday::Wednesday => 8,\n                            schema::Weekday::Thursday => 9,\n                            schema::Weekday::Friday => 10,\n                        };\n                        let sched = &row[sched_idx];\n                        let new_kid = Kid::new(headcount, name, &format!(\"{}\", sched));\n                        debug!(\n                            \"FOUND KID: {} - {} ({:?})\",\n                            new_kid.name, sched, new_kid.schedule.expected\n                        );\n                        // If the kid is scheduled, push the kid to the latest open class\n                        if new_kid.schedule.expected == Expected::Unscheduled {\n                            debug!(\n                                \"{} not scheduled on {:?} - omitting from roster\",\n                                &new_kid.name, day\n                            );\n                        } else {\n                            let mut classroom = school.classrooms.pop().expect(\n                                \"Kid found before classroom declaration - input file malformed\",\n                            );\n                            classroom.push_kid(new_kid);\n                            school.classrooms.push(classroom);\n                            headcount += 1;\n                            debug!(\"Adding to response\");\n                        }\n                    }\n                }\n                _ => continue,\n            }\n        }\n    }\n\n    // Print out the status info\n    let last_class = school.classrooms[school.classrooms.len() - 1].clone();\n    info!(\n        \"Room {} headcount: {}\",\n        last_class.letter,\n        last_class.kids.len(),\n    );\n    warn!(\n        \"Successfully loaded {:?} enrollment from {:?} - total headcount {}, total classcount {}\",\n        day, config.roster, headcount, classcount\n    );\n\n    Ok(school)\n}\n```\n\nLooking at it just *makes me upset*.  This abomination was knocked together in an afternoon to get it over with, and is not exactly maintainable.  Should the format change on me, as it's liable to do at any time without warning, this is *not* a fun refactor.  Each section of this can be broken out into helper functions that can be edited in isolation.\n\n### The Launcher\n\nThis application is designed as your standard web shindig.  There's a backend application that serves up a webpage and provides an HTTP API for futzing with the app state.  Users navigate to this page via their web browser, and use UI elements to interact with these API endpoints.\n\nI never quite got around to centralizing it, though, partially because of an overworked IT department that had little time for my hobby experiment.  They're busy doing \"real work\" or whatever.  Thus, in order to use this program, the user must launch the webserver themselves first.  It then serves on `localhost`.  To make this easier to swallow, I put together a minuscule batch file and called it a \"launcher\":\n\n```batchfile\n:: Suppress command output\nECHO OFF\n:: Launch server\nstart mifkad.exe\n:: Launch client\nstart chrome http://127.0.0.1:8080\n```\n\nSo, yeah.  It works, but, talk about janky.  This also means that everyone who uses it is running a local, isolated instance of the app.  The persistent data store that gets manipulated by this instance is indeed shared, but each app touches it independently.  Even sillier, the app is actually well-architected to avoid write collisions - as long as you have multiple connections coming to the *same* instance!  Running it like this completely bypasses that built-in safety guarantee.  Double oof.  Here's the code to actually adjust the app state:\n\n```rust\npub fn adjust_school(\n    (path, state): (Path<(String, u32)>, State<AppState>),\n) -> Box<Future<Item = Json<School>, Error = actix_web::Error>> {\n    use self::Action::*;\n    let action = Action::from_str(&path.0).unwrap();\n    let id = path.1;\n\n    {\n        // Grab a blocking write lock inside inner scope\n        let mut a = state.school.write().unwrap();\n\n        // Perform the mutation\n        match action {\n            Toggle => (*a).toggle_kid(id),\n            AddExt => (*a).addext_kid(id),\n            Collect => (*a).collect_room(id),\n            Reset => {\n                reset_db(&state.config).unwrap();\n                (*a) = init_db(&state.config).unwrap();\n            }\n        }\n        // blocking lock is dropped here\n    }\n\n    // grab a new non-blocking reader\n    let a = state.school.read().unwrap();\n\n    // Sync the on-disk DB and return the json\n    write_db(&*a).unwrap();\n    result(Ok(Json((*a).clone()))).responder()\n}\n```\n\nAll that care taken to handle concurrent writes safely, and this application is only ever used by a single connection to a local instance.  Nice going, Ben.\n\n### The JSON\n\nThe other big dumb shortcut is the data persistence.  Because multiple users will interact with the same data from different workstations (running different instances of the application), I decided to write each change to a shared network drive.  When the app launches, it checks to see if there's an already-created app state first, and populates from that instead of re-reading the roster spreadsheet.  This should likely have been implemented using a relational database off the bat, but no.  I just serialize the app state to JSON and store it as a datestamped text file, e.g. \"20190621.json\".  The app just looks up the date to see if there's a corresponding file.\n\nIt sorta works, but these files are not that helpful.  The folder where they get created is just incrementally growing for no reason, and after the day is over these are generally useless.  I could clean them up, but they're also the only record anywhere of which kids stayed for extended day, outside of their AR line.  It's helpful to have that extra backup, but digging through it means sifting through a pile of JSON with no whitespace.  That's not fun, and pretty much not happening for folks down there that aren't me.\n\nIt's also brittle - if the file for the day disappears or gets altered, its unreadable and you have to start over.  A more highly managed data interface would prevent problems like that.\n\n## The Revival\n\nI'm coming back to this project now because I wanted to try to generalize it for use in the other locations within this network.  I think I probably could slap that generalization on the current incarnation, but digging through the code again has made me feel like I need a shower, and I can't just leave it like this.\n\nAlso, since I wrote this, both the niche and new backend framework and niche and new frontend framework made significant updates.  Normally I'd not be too concerned about this, but the backend framework, `actix_web` stabilized to 1.0 over 0.7.  That's pretty nice, considering I'd like to eventually (mostly) walk away from this and have it work for them indefinitely.  ReasonReact also stabilized a much neater component syntax which I feel makes the code more readable - perfect for a project I expect to touch once every several months at most.\n\nThe frontend I don't expect to be a complicated migration.  I'm more or less pleased with it, actually, though I think there is some opportunity for cleanup.  For instance, the whole crux of this applications usefulness is the ability to look at the 15 core classrooms and pull out the 5 reduced classrooms.  This is handled via a rather opaque fold in Reason:\n\n```ocaml\nlet add_extended_room = (school, classroom) => {\n  /* This is our folding fn from get_extended_rooms below.\n     It should take a room and a school and either add the new room\n     or if a room already exists with the same letter, just add those kids */\n  let target = ref(school.classrooms);\n\n  if (Array.length(target^) == 0) {\n    target := Array.append(target^, Array.make(1, classroom));\n  } else {\n    let already_included =\n      Array.map((oldr: classroom) => oldr.letter, school.classrooms);\n    let found = ref(false);\n    let idx = ref(0) /* This will only be read later if found is toggled to true*/;\n    Array.iteri(\n      (i, l) =>\n        if (classroom.letter == l) {\n          found := true;\n          idx := i;\n        },\n      already_included,\n    );\n    if (found^) {\n      /* We've already seen this letter - mash the new kid list into the matching existing kid list */\n      let old_classroom = school.classrooms[idx^];\n      let new_classroom = {\n        ...old_classroom,\n        capacity:\n          get_extended_capacity(classroom.letter, school.extended_day_config)\n          |> int_of_string,\n        kids: ref(Array.append(old_classroom.kids^, classroom.kids^)),\n      };\n      target^[idx^] = new_classroom;\n    } else {\n      /* This is a new extended day room - add it as-is, grabbing the extended day capacity */\n      target :=\n        Array.append(\n          target^,\n          Array.make(\n            1,\n            {\n              ...classroom,\n              capacity:\n                get_extended_capacity(\n                  classroom.letter,\n                  school.extended_day_config,\n                )\n                |> int_of_string,\n            },\n          ),\n        );\n    };\n  };\n\n  {...school, classrooms: target^};\n};\n\nlet get_extended_rooms = school => {\n  /* Returns a `school` of the extended kids */\n  let s = get_extended_kids(school);\n  Array.fold_left(\n    add_extended_room,\n    {...school, classrooms: [||]},\n    s.classrooms,\n  );\n};\n```\n\nHonestly, I'm impressed it works as reliably as it does.  This just screams \"I only think I know how functional programming works\".  I don't really remember how I arrived at this particular solution, and I'm a little scared to touch it.  That's no good.\n\nThe backend is the bigger priority though.  The new stable version of `actix_web` is a significant breaking change from what I'm using now, so I will likely be rewriting at least my handlers from scratch anyway.  While I'm at it, I'm going to rip out the JSON serialization apparatus in favor of an SQLite store.  This will still be portable, as it can live inside a file on the OS in a very self-contained fashion, but much harder to accidentally corrupt.  It will also have the added benefit of being query-able - if you have to know when Albert Gore signed up for extra hours between January 2 and February 12, you can just ask that using SQL.  After making sure the base app works as intended I'd like to add a UI exposing some of this functionality.\n\nAnother new feature that can be built off a more solid base would be allowing classrooms to do their own entry.  If this app is used as intended, i.e. it exists as an always-running process that users connect to remotely instead of launching locally, there's no reason why the teachers can't just take attendance directly on it.  That would get rid of the need for them to collect it separately and then play phone tag for a while about it.  If they could navigate from their in-classroom iPad to a webpage just for their students just to mark who's in or out, the attendance for the site would basically take itself.  This whole concept requires that I move to a centralized app model, though.\n\nI'd also like to flesh out the testing story.  There are some tests present for various parts of the backend, but I would not call this a well-tested application.  The more I can do to automate ongoing maintenance of this product, the better.\n\nFinally, it's pretty clear that the UI is built by someone with a heavy phobia of any CSS beyond the bare minimum.  It doesn't *need* to be so gorram ugly.  I should probably take the opportunity to practice that skillset.\n\nIt sounds like I've got my work cut out for me still on this application, after all this time.  Little did I know when I first got the idea to give it a whirl.  Guess I'd better get going!",
    "title": "The Dumb Things I Did And How I'm Going To Fix Them"
  },
  {
    "cover_image": "https://res.cloudinary.com/practicaldev/image/fetch/s--ntbK0tBl--/c_imagga_scale,f_auto,fl_progressive,h_420,q_auto,w_1000/https://thepracticaldev.s3.amazonaws.com/i/6zimvou9gmn8fyaj2lci.jpg",
    "date": "2019-06-26T17:24:32.103Z",
    "description": "",
    "tags": "help, discuss",
    "markdown": "Last week I published a post about my plans to refactor an old project I haven't touched in about a year.  The refactor I have planned is extensive, but there's no hurry - the tool works fine right now.\n\nOf course, though, we live in a mysterious world, and a few days later the admins call me up and ask if I'd be willing to work with them on an entirely new feature.  Why now, after so long, I don't know.  I can only assume divine intervention.\n\nIn brief, keeping the classrooms appropriately staffed throughout the day is a non-trivial problem, and keeping staff around the building updated on last-minute adjustments is even more complicated.  They want a UI that will allow them to build these schedules that's aware of staff-child ratios and generate individual staff slips for the day.  Then the staff could just navigate to a webpage to see the current status, instead of relying on a big game of telephone over the walkie talkies.  Anything to cut out chaos.\n\nI'm unexpectedly torn.\n\nPros:\n\n* I was already planning to dig into this codebase anyway.\n* I believe they've correctly identified their problem, and their proposed solution would greatly help.\n* I've remained friends with these people since leaving that job - we help our friends.\n* I want to do it.  It's a neat, interesting problem, and since they've asked me my brain has been firing on overdrive about it.  I already have a good idea about how it's gonna work.\n* It's a project - you usually learn stuff doing those, and then have a bigger, more impressive portfolio.\n* One of the admins is learning how to code himself and willing to contribute and learn in the process.\n\nCons:\n\n* It will involve a major time commitment.\n* I will not be compensated for this time.\n* The aforementioned learner is *really, really new* and likely won't affect the total build time by a lot.  This is more \"neutral\" than a con, and I think a project like this is a great way to build skill anyway.\n\nReally, that's it, but I'm worried the time commitment outweighs the pros.  I'm just not positive how to quantify it.\n\nThe way I see it, time I spend building software does have some inherent value to it, but it's hard to pinpoint exactly how much.  For starters, I've never been paid a single cent for any code I've written.  Going on historical precedent alone, my time is not worth anything, but I know it's not as simple as that.  I am capable of creating value via software, because software I've written has freed up paid employees to spend more of their time on tasks that computers cannot do.  There is intrinsic value there.\n\nWho cares, though?  Knowing I'm doing a favor doesn't make the favor not worthwhile, and if I'm not currently getting paid to write any of my code, why should I care that I'm not getting paid to write *this* code either?  I deeply enjoy coding, I choose to do it as a pass-time, so why worry about value.\n\nHowever, my time is also not infinite, and there are other things I use it for.  I know myself, I'm going to want to get this done for them, and it will necessarily take time away from other endeavors.\n\nI don't feel overworked, in fact, quite the opposite, but when I start to break down how I spend my week it starts feeling a little tight:\n\nHours/week: **168** (7 days * 24 hours/day)\n\nActivities by hours:\n\n* Sleep: 56 (ish, I do strive for 8 hours/night but sometimes fall short)\n* Full-time non-tech job: 44 (including commute)\n* College classwork: 15-20 (varies by week)\n* Tech job hunt: 10-12 (resume tweaking, listing searches, cold emailing, interview practice)\n* Errands: ~3.5\n* Physical exercise: ~3.5\n\nThese are the non-negotiable items, and the using the higher bounds net me 28 hours a week of time for other stuff I want to do, or 4 hours a day.  This actually sounds pretty cushy, but disappears quickly - I have a number of side projects I'm working on, I have a girlfriend who would be annoyed she places under \"side projects\", I like playing long board games and going on big hikes and stuff - and I do feel it's pretty damn important to not let these other aspects of my life slip.  The list above is full of \"Ben is sitting at a computer\", I'm not thrilled about the prospect of sitting at a computer for the rest of my week too.\n\nI'm probably going to say yes with the caveat that it won't be quick, but I'd be curious to hear how all y'all handle requests like this.  Did it change between when you were an amateur and when you went professional?  Would *you* say yes to this project?\n\nPhoto by Djim Loic on Unsplash",
    "title": "The Value Of Your Time"
  },
  {
    "cover_image": "https://res.cloudinary.com/practicaldev/image/fetch/s--ErTy6jHH--/c_imagga_scale,f_auto,fl_progressive,h_420,q_auto,w_1000/https://thepracticaldev.s3.amazonaws.com/i/1jt49e7zuh8e70hmi7eo.jpg",
    "date": "2019-07-02T11:44:15.270Z",
    "description": "",
    "tags": "beginners, help, discuss",
    "markdown": "I've been tasked with building a small application over the next two weeks, and must use JQuery to do so.  Left to my own devices I'd probably just keep it vanilla, but leaving me to my own devices is not generally recommended.\n\nI've never used JQuery for anything larger than 200 lines, and that was circa 2012.  Is there anything I should watch out for?  Any seemingly innocuous patterns that create more problems than they solve?\n\nA quick glance through the documentation suggests I can just sort of use it as a shorthand for some common operations like grabbing DOM nodes and performing AJAX.  Should I just be building my application in much the same manner as I would be otherwise, just more concisely, or are there ways to leverage the library even more powerfully that I'm missing?\n\nThanks!\n\nPhoto by Ben White on Unsplash",
    "title": "JQuery Footguns?"
  },
  {
    "cover_image": "https://res.cloudinary.com/practicaldev/image/fetch/s--uhQkmAms--/c_imagga_scale,f_auto,fl_progressive,h_420,q_auto,w_1000/https://thepracticaldev.s3.amazonaws.com/i/bsrei93lrc5zhp2qcgg0.jpg",
    "date": "2019-07-06T15:32:07.747Z",
    "description": "",
    "tags": "haskell, beginners, functional",
    "markdown": "I don't write a lot of Haskell.  In fact, I don't really write *any* Haskell.  My total lifetime output is well under 1000 lines.  Every time I sit down to write some Haskell, though, I get reminded of why I like it so much.\n\nFunctional programming can be a tricky paradigm to get your head around, but I don't think it's fundamentally challenging.  Rather, it's at odds with the instincts you've already built.  Thus, when trying to program functionally in a more familiar language, it's quite easy to cheat.  JavaScript is a great example.  Modern JS is a great language for functional programming, but there is nothing keeping you on the rails, so to speak.  You might be leaning on imperative crutches without even realizing you're doing it.  Sure, you might be using `reduce` or newfangled stuff like `flatMap` all over the place, but the language itself doesn't care about how sound your code is, it will do almost anything you ask and never complain if you're breaking rules to make things easier on yourself.\n\nHaskell forces you stay in the box.  Its draconian compiler means that your code doesn't run unless you've done it right.  This feels like a limitation at first, but by forcing you to solve problems functionally it...well...forces you to solve problems functionally.\n\nWhat's prompting this is yesterday's Dev.to challenge:\n\n{% link thepracticaldev/daily-challenge-8-scrabble-word-calculator-41f6 %}\n\nI had a long train ride yesterday, and figured a coding challenge would be a great way to pass the time. Immediately upon reading the problem spec, I had an outline of how to solve this problem.  I've been spending most of my time over the last few weeks writing either C++ or Rust, so my mental outline was very imperative.  You'd traverse the string iteratively, increment a score based on markers that are present, and then adjust that score based on any extra bonuses. I'm reasonably certain this instinctive solution would have worked with a little massaging.\n\nWhere's the fun in that, though?\n\nSo, of course, I decided to whip out my dusty old Haskell compiler and see if I still knew how to drive it.\n\nI find the most useful one-sentence summary of \"functional programming\" to be that instead of telling the computer how to compute the result, you just tell the computer what the result *is*.  This can be easier said than done, and requires you to re-frame how you think about the problem.\n\nIn this specific problem, we are given a string and must return how high that string scores per Scrabble rules.  There are a few curveballs - the `*` character is used to double or triple scores, the `^` indicates a blank so the previous letter shouldn't be scored, and words can be appended with a multiplier like `hello(d)` or `hello(t)` to signal that the final result should be doubled or tripled.\n\nThe way to frame this is to think about what a scrabble score actually is.  Instead of building up the score a piece at a time, say, adding the letters one by one and then checking to see if it needs adjustment, we want an equation that will score *any word*.  This looks something like the following:\n\n```haskell\nrawScore * wordMultiplier + sevenLetterBonus\n```\n\nThis equation fits any input - we can just default the multiplier to 1 and the bonus to 0, so that most words that don't need these get `rawScore * 1 + 0`, which is clearly equivalent to `rawScore`.\n\nSo, that's what the answer *is*.  We just need to manipulate the string passed in so that each of these values is correctly populated by the time we get there.  The simplest part is `sevenLetterBonus`.  If the raw word is exactly 7 letters, we add 50 points.  Our input string may have extra bits like the asterisk or the multiplier suffix, so just strip those to get the actual word:\n\n```haskell\nstripMarkers :: String -> String\nstripMarkers = filter (\\c -> c /= '*' && c /= '^') $ takeWhile (/= '(')\n```\n\nGood.  Again, this function just describes what the end result is - it's the original word up to a `(` character, with the marker characters filtered out.  Quite declarative.  Then we can build the bonus:\n\n```haskell\nsevenLetterBonus = if (length $ stripMarkers w) == 7 then 50 else 0\n```\n\nPerfect, this now works on any input.  The multiplier, too, is easy.  Some inputs will have a suffix, and if so, check which.  If not, the multiplier is 1:\n\n```haskell\nwordMultiplier =\n    let\n        suffix = dropWhile (/= '(') w\n    in\n        if length suffix > 0 then\n            case suffix !! 1 of\n                't' -> 3\n                'd' -> 2\n                _   -> 1\n        else 1\n```\n\nIt only looks at any part of the string after a `(` character, and acts accordingly.  This also already handles any string we throw at it - most will hit that `else` block because there is no `(` present and get assigned a 1, which won't change the raw score.\n\nThe trickiest part of this for me functionally was handling the asterisks.  My instincts tell me to solve this with an iterative loop, but Haskell is not going to let me get away with that.  If it did, I likely would have been tempted to take the easy way out.  But, of course, I couldn't.\n\nScoring a list of letters is easy - you just replace each letter with it's numerical value, and sum the list:\n\n```haskell\nsum $ map (\\c -> scores ! c) $ word\n```\n\nThe mapping function is just performing a lookup in a mapping from characters to ints.  In order for this to work, we need to have a string containing just the letters that will be scored.  In order for this little snippet to work on any input, that input should be pre-processed to only contain letters.  Any letter we want omitted can be, well, omitted, and letters to count multiple times can just appear multiple times.  I don't know if I handled this as cleanly or as elegantly as a Haskeller would have, but this does the trick:\n\n```haskell\nexpandMarkers :: String -> String\nexpandMarkers [] = []\nexpandMarkers (c:[]) = [c]\nexpandMarkers (c:rest) =\n    case head rest of\n        '*' ->\n            if (head $ tail rest) == '*' then\n                [c] ++ [c] ++ [c] ++ (expandMarkers $ drop 2 rest) else\n                [c] ++ [c] ++ (expandMarkers $ tail rest)\n        '^' -> expandMarkers $ tail rest\n        _ -> [c] ++ expandMarkers rest\n```\n\nIt consumes the string recursively.  On each letter, it looks one forward, and then continues the process based on what it finds.  An asterisk will get removed and replaced with a copy of the letter we're on, unless the *next* one is also an asterisk, in which case it will replace both of them, and a carat will cause the character we're on to just not appear in the result.  This function turns `he*ll^o**` into `heelooo` - ready to be scored as is via the simple character-to-int substitution.\n\nThe full code just puts all this together:\n\n```haskell\nimport Data.Map (Map, (!))\nimport qualified Data.Map as Map\n\nscores :: Map Char Int\nscores = Map.fromList pairs\n    where\n        pairs = [\n            ('a', 1),\n            ('b', 3),\n            ('c', 3),\n            ('d', 2),\n            ('e', 1),\n            ('f', 4),\n            ('g', 2),\n            ('h', 4),\n            ('i', 1),\n            ('j', 8),\n            ('k', 5),\n            ('l', 1),\n            ('m', 3),\n            ('n', 1),\n            ('o', 1),\n            ('p', 3),\n            ('q', 10),\n            ('r', 1),\n            ('s', 1),\n            ('t', 1),\n            ('u', 1),\n            ('v', 4),\n            ('w', 4),\n            ('x', 8),\n            ('y', 4),\n            ('z', 10)]\n\nscoreWord :: String -> Int\nscoreWord w =\n    let\n        sevenLetterBonus = if (length $ stripMarkers w) == 7 then 50 else 0\n        wordMultiplier =\n            let\n                suffix = dropWhile (/= '(') w\n            in\n                if length suffix > 0 then\n                    case suffix !! 1 of\n                        't' -> 3\n                        'd' -> 2\n                        _ -> 1\n                else 1\n        -- \n        preparedWord = expandMarkers $ takeWhile (/= '(') w\n        rawScore = sum $ map (\\c -> scores ! c) $ preparedWord\n    in\n        rawScore * wordMultiplier + sevenLetterBonus\n\n-- transform doubles, triples, carats\n-- if we hit an asterisk, replace it with the previous letter\n-- if we hit a carat, drop the previous letter\nexpandMarkers :: String -> String\nexpandMarkers [] = []\nexpandMarkers (c:[]) = [c]\nexpandMarkers (c:rest) =\n    case head rest of\n        '*' ->\n            if (head $ tail rest) == '*' then\n                [c] ++ [c] ++ [c] ++ (expandMarkers $ drop 2 rest) else\n                [c] ++ [c] ++ (expandMarkers $ tail rest)\n        '^' -> expandMarkers $ tail rest\n        _ -> [c] ++ expandMarkers rest\n\n-- remove suffix and all markers for deciding on the 7-letter bonus\nstripMarkers :: String -> String\nstripMarkers w = filter (\\c -> c /= '*' && c /= '^') $ takeWhile (/= '(') w\n```\n\nThis solution, that pre-processes every input into something that can be easily scored the same way, bears little to no resemblance to the code I wrote in my head when I read the spec.  That's *pretty cool*, and I think it's a decent solution in any language.\n\nThat's why Haskell is worth it.  In order to make it go, you cannot fall back on instinct.  You have to actually solve the problem differently, and it won't work until it does.  I have no delusions about this being nice, idiomatic Haskell, but *it is working Haskell*, which means I've come up with a working solution that I can now bring to a more familiar environment and implement.  If I had sat down to write this in JavaScript instead, I would not have arrived in the same place without a lot more thought and self-discipline, because I would have just written it out how I thought about it first, and deprived myself of the experience of looking at the problem in a new way.  Now the next time I approach a similar problem, my toolbox has expanded and my first instinct might actually look more like this.  Thanks, Haskell!\n\nPhoto by Michal Vrba on Unsplash",
    "title": "Haskell as Training Wheels"
  },
  {
    "cover_image": null,
    "date": "2019-07-08T11:30:23.277Z",
    "description": "",
    "tags": "explainlikeimfive, beginners, compilers",
    "markdown": "What benefit is gained from making your new language's compiler self-hosting?  To me, it seems this only adds complexity to your build.  If it can generate code for your language, why does it matter what it's written in?\n\nI understand that a compiler is a good proof-of-concept program.  They're generally dependency-free and will put your language through its paces.  The exercise of writing a compiler in your new language is a good idea, I'm not arguing that point.  I'm less clear on why making that self-hosted compiler the canonical version of your language is beneficial.  Wouldn't keeping your compiler written in something like Haskell or OCaml make it more extensible and flexible, and quicker to build?",
    "title": "ELI5: Why self-host a compiler?"
  },
  {
    "cover_image": "https://res.cloudinary.com/practicaldev/image/fetch/s--dSM2R_SY--/c_imagga_scale,f_auto,fl_progressive,h_420,q_auto,w_1000/https://thepracticaldev.s3.amazonaws.com/i/okkebjgte6d7jwtps68i.jpg",
    "date": "2019-07-11T12:26:21.395Z",
    "description": "",
    "tags": "appreciation, meta, fluff",
    "markdown": "I've been looking through some older posts on my page, and am am just blown away by the volume and quality of discussion on this website, especially looking at it all at once.  Every time I throw up a simple question y'all come through with nuanced discussion, and I've learned something every single time.  Try that on Reddit.  (No, don't.)\n\nThese are some of my personal highlights:\n\n{% link deciduously/typescript-before-javascript-4m13 %}\n{% link deciduously/what-are-your-favorite-books-knk %}\n{% link deciduously/how-do-you-use-github-4j56 %}\n{% link deciduously/the-compile-to-js-zoo-3n90 %}\n{% link deciduously/what-planning-tools-do-you-use-10dp %}\n{% link deciduously/eli5-useful-unit-testing-1gon %}\n{% link deciduously/jquery-footguns-65f %}\n{% link deciduously/eli5-why-self-host-a-compiler-hll%}\n\nSeriously, ask DEV something.  It works, and nobody bites.  Have any of your posts generated some surprisingly good discussion?  Show me, I'd like to take a look!\n\nPhoto by Antenna on Unsplash",
    "title": "You Lot Are Great"
  },
  {
    "cover_image": "https://res.cloudinary.com/practicaldev/image/fetch/s--E0qFrBnr--/c_imagga_scale,f_auto,fl_progressive,h_420,q_auto,w_1000/https://thepracticaldev.s3.amazonaws.com/i/6byozbu5ld672kjcctwb.jpg",
    "date": "2019-07-17T19:02:16.237Z",
    "description": "",
    "tags": "rust, actix, discuss",
    "markdown": "EDIT: The crate maintainer has now merged the offending PR and acknowledged an understanding gap regarding what `unsafe` means in Rust.  And so the wheel turns...\n\nThe Rust community is all up in arms about the `actix-web` crate - again.  I won't rehash the problem - here's the instigating [blog post](https://64.github.io/actix/), the [reddit](https://www.reddit.com/r/rust/comments/ce09id/why_we_need_alternatives_to_actix/) discussion, and the [GitHub PR](https://github.com/actix/actix-web/pull/968) discussion that people think is problematic.\n\nLast time around, there was an uproar around what was perceived to be cavalier usage of `unsafe`.  Folks reviewed the code and found the usage to be unnecessary in a number of situations, and opened PRs to rewrite these portions using safe Rust without sacrificing performance.\n\nThis time around, the big bad is Undefined Behavior.  A PR was opened that rewrites some unsafe code using safe Rust and as a side effect avoids some potential UB.  The PR author provided an example of UB that this PR fixes.\n\nThe maintainer has opted not to merge the PR.  Cue hellfire.\n\nNow, some of this dissonance is Rust-specific.  The `actix-web` maintainer is catching all this flak because he is making design decisions that are perceived to be at odds with the core tenets of what Rust is and why people choose it over existing alternatives - namely safety.\n\nHowever, this seems to be a much more human problem than a technical one.  The crate author and maintainer - `actix-web` is *largely* the work of a single human - doesn't seem to be too concerned about this problem and can't be bothered to address it.\n\nThis begs the question: who does `actix-web` belong to?  As an artifact of its infancy, the number of robust, production-ready web crates for Rust is small, and at this point `actix-web` is the *only* option of its caliber that runs on stable  Rust.  Has this scarcity created an artificial sense of ownership on the part of the community?  Or does this maintainer now actually have the real responsibility of reviewing and merging this PR he's personally uninterested in at the community's behest?\n\nPeople are off-put by this maintainer's unwillingness to deal with this newly found UB problem.  But is the maintainer in fact obligated to do so?  Yes, the framework has a bunch o' stars and downloads, but that doesn't make it not this guy's project.  The core rust async team is working on [their own](https://github.com/rustasync/tide) web framework, and with that crate we're having a different conversation.  There is a reasonable expectation of quality from the Rust team.  Here, though, the author has decided that he knows what he's doing and can write correct, performant code using `unsafe`, and this instance of UB doesn't bother him in the context of this application.  He's also understandably standoffish after the whole `unsafe` debacle turned vitriolic and personal in nature last time around.  I'd, too, be hesitant to act at the beck and call of what seems like a toxic and demanding community, for no compensation, to fix a problem that I don't personally perceive as a problem in the first place.\n\nWhat's the solution?  Never release software?  I'd certainly hesitate to do so again were I this maintainer.  Never rely on software that isn't supported by a large team?  Often feasible, but not always, especially in a new and growing ecosystem like Rust.\n\nRegardless of how you feel about \"the spirit of Rust\" and how software *should* be architected with it, it's undeniable that `actix-web` is a good piece of software.  It's fast and easy to use, even if it doesn't look inside like code you'd write in Rust.  I don't know what the code to most libraries and frameworks I use looks like, though.  When was the last time you opened up something like [`cairo`](https://cairographics.org/), a foundational piece of software that's widely distributed.  Should its code style dictate whether or not you add it to your app's dependency tree?\n\nThis is a hard problem.  I don't think there's \"an answer\".  How do you approach these sorts of situations in the ecosystem of your choice?\n\nPhoto by Hermes Rivera on Unsplash",
    "title": "The Trials and Tribulations of actix-web and the OSS community"
  },
  {
    "cover_image": "https://res.cloudinary.com/practicaldev/image/fetch/s--5juB8G4w--/c_imagga_scale,f_auto,fl_progressive,h_420,q_auto,w_1000/https://thepracticaldev.s3.amazonaws.com/i/1fnrjap1v90ngs0q9axx.jpg",
    "date": "2019-07-21T13:10:08.682Z",
    "description": "",
    "tags": "watercooler, help",
    "markdown": "\nDisclaimer: this is more a rant than anything else.  Maybe more #crazydudewontstoptalkingavoidthewatercooler but that's unwieldy as a hashtag.  The #help part is in the TL;DR.\n\nMy girlfriend (somewhat impulsively) recently bought us a new robotic vacuum.  We'd had the idea in the back of our heads for a while but I always assumed we were talking about at least a $500+ purchase having only heard of the big name brands like Roomba.  Thanks to Lord Bezos, we got a [Eufy RoboVac 30](https://www.eufylife.com/products/variant/robovac-30/T2116111) for under $200 - selling at $270 from the manufacturer, still considerably cheaper than I had anticipated.  It's a pretty well-reviewed \"budget\" model.  I can't even bring myself to be that upset, this thing is really cool.  Dammit, Amazon, it's so hard to quit you.  Her only other purchase?  God of War for PS4.  I'm gonna keep her.\n\nI swear I'm not a Eufy shill, I'd never even heard of this brand, I'm just geeking out over our new robot.  I'm not necessarily specifically recommending this model over other similar-tier models.\n\nWe put it through its inaugural run this weekend and I am utterly fascinated by it.  That little thing is pretty clever, more so than I had anticipated, and I've just pretty much wasted my morning following it around trying to get inside its software head.  I know these things have been around a long time now, but I'd never really been around one long enough to see it do its thing, and I'm impressed at how thorough a job it's doing.\n\nIt seems to be a great example of emergent behavior from very simple parts, and I can't stop thinking about it.\n\nI admit, I was initially a total elitist.  Some cursory searching had led me to believe that the super fancy high end ones have this whole mapping feature that figures out our floor map and stores it to efficiently cover the area, using its knowledge of the layout to optimize the path whereas the cheaper ones bumble around with sensors to get the same job done but much less efficiently, and likely only to 100% coverage over multiple runs.  Not so much a replacement for normal manual vacuuming but an extra help that's pretty good for day-to-day maintenance and touch-ups.\n\nI hadn't really ever thought about the problem before, so when we opened it up I had initially thought the basic MO would be to just run in straight lines until its bumper hits something, then try a new angle.  Rinse, repeat for X amount of time, floor will be eventually cleaned.  Do it every day or multiple times a week, and over the course of a week your whole floor is clean.  Our apartment is a little funky layout-wise, and with a decent amount of floor space but odd partitions and angles in places, so I figured without some sort of stored picture of the shape of the space there was no way it could reasonably cover the area in a single 100-minute shot-in-the-dark style run.\n\nI owe the entire industry an apology for what's clearly been a gross underestimation.  I know I should have known better, there's all these different companies making all these different models.  It's the future now, and people have put some *thought* into this even (especially?) at this price point.\n\nThis thing schooled *my* ass on how to get the job done.  I'm not even ashamed to say this is likely the cleanest these floors have been since we moved in a year ago.  It's nuts that it got the job done just through an effective application of very simple movement algorithms.  If it's not 100%, it's pretty damn close.  I ended up following it around or watching it from my desk for the duration (which felt a little embarrassing, yes, but I couldn't stop looking) and don't believe a spot went untouched even if it got there in a pretty roundabout way.  It even crawled up on an area mat without complaining and handled all raised thresholds between rooms like a champ.\n\nIt likely simply has better suction than our manual vacuum to boot, but that particular unit of measure (1500Pα) doesn't mean a lot to me.  I couldn't tell you what a Pascal of suction feels like, and don't know what the other vacuum is rated.  I do know it did a seriously good job considering it's so small.\n\nWhile I don't have an uber-fancy model to compare to in the same space, this thing is leading me to believe the next level up probably wouldn't have even been worth it, at least for us.  I suppose if we had a mansion and the battery life simply wasn't long enough for all of the floors the time saved by optimizing for our specific home might be useful.  Watching it putter about, though, I actually almost believed it *was* mapping the space out.\n\nInstead, the manual and some searching around suggests it simply cycles through a few modes, based on data from its sensors.  It's all very vague, but I think that might mean it really is quite simple.  It starts by shooting off in a random direction, as expected, and turning when it detects an obstacle.  It also has an edge-tracking mode with methodically tracks an edge by continuously attempting to turn right at a low speed, and a spot cleaning mode that spirals out from a point.  You can enable each mode specifically or just let it auto-cycle, and I see no reason not to do that.\n\nI had also underestimated the number of sensors - it's not just a big front bumper like I thought.  It's got an infrared sensor on the side and a sensor on the bottom for drops, as well as a magnetic sensor to detect strips you can lay out to prevent it from going in certain areas.  The infrared sensor may be just for the remote, but I think it might be used for locating home base as well if it's not storing any locations.\n\nWhat got me to keep watching is how this cycling of simple algorithms managed to still cover *all* previously uncovered territory.  As I was watching it I kept thinking \"oh no, it doesn't know that it just missed a whole corner over here\", watching it scoot off at some random diagonal.  I actually had assumed it would be a little more methodical, tracing a zigzag across a space, but no, this thing was all random unrelated directions, which kept it interesting enough (apparently).  Inevitably ten or fifteen minutes later some other seemingly random tack across the house would bring it exactly where it needed to go.  It triggered edge mode at least once on every wall of every room and every weird nook and corner, got under all chairs and the kitchen table, found the bathroom a few times and got wherever it could fit, just really did a smashing job of it all.  We never had to intervene.\n\nThese new vectors its choosing can't be random.  It works too well.  They sure seem like they must be informed by some sort of previous understanding of found edges, but one guess I had is that it actually just tries a range of vectors over time to ensure it hits a wide range. My gut feeling is that it's actually tuned even better than that but I couldn't tell from watching the first run, and I'd be curious to learn more about that process.  I also don't know if that behavior is specific to this model, and others do take a more zig-zag approach.  Ideally I'd try it out, but I'm not ready to bring a second vacuuming robot into our lives.  I'm not *that* excessive, I swear.\n\nAs far as I can tell it's not storing where specifically it finds edges, and I did notice it repeat some work - for example, it methodically scooted along the same wall of the living room three times over the course of it's 100-minute run.  If it were storing specific edges, it wouldn't have done so, so it must have just sensed an edge and kicked in to that mode.\n\nIt must just be calibrated properly to avoid the problem.  For instance, it must know how often to kick in to edge mode to maximize for exploration and minimize repeated work without sacrificing thoroughness.  100 minutes is a long time to vacuum, but not that long if you waste 20 of it on one wall over and over again.  Most of the time it just turns away, though, and sometimes it even anticipates a wall and turns before it hits it well before (I think) any of its sensors would have noticed it.  I can't figure that out either if it's not keeping track of anything.  It still manages to activate for all the different walls, though!\n\nDue to a connecting door we keep closed for airflow purposes, in the robot's universe our unit is kind of U shaped.  We have furniture in odd places and some large open areas and some small, more fractured non-rectangular areas.  All six of the rooms we want it to cover are different shapes and sizes, and all have more than four walls due to nooks and crannies and closets of varying sizes.  Most of the doorways are your standard door size, but the living room and dining room are connected by a big opening almost as wide as the wall but not quite.  This creates even more weird edges and corners to confuse it.  Optimizing a filing path in a given time constraint by hand even with prior knowledge would probably not be simple.\n\nSomehow, amazingly, it just kept passing through rooms at different enough angles to cover the whole floor.  Sometimes it'd be stuck in a room for a while, sometimes it would get on a tack that has it passing between two rooms regularly, back and forth in a big line, but by the time it hit low power mode and returned itself to the charger it had actually hit all the spots I had made mental notes to look out for.\n\nIt even surprised me once again when I got worried it ran out of battery too far from home.  I heard it kick into low power mode, and it was in a completely different room facing the wrong way.  It did know how to orient itself towards home and try to get there, but on the way there it hit the ottoman (so, it didn't anticipate that was coming) and turned around the wrong way again.  It even still with no line of sight managed to get itself oriented towards the station, bump its way around the ottoman to a straight shot, and amble its way back onto the contact pins.  Even better, this straight shot included a bit of edge mode - which I was pleased to see still enabled even in low power mode - along the front edge of the couch.  I'd been taking note of unexplored edges and that was the only one remaining it hadn't done!\n\nOkay.  Enough gushing.  Here's the point.\n\n## TL;DR\n\nI'm fascinated by how effective this budget-end robot vacuum's seemingly simple set of algorithms is at cleaning our whole weird space.  I want to try to model the problem and implement the movement algorithms myself to see if I can replicate that emergent behavior with totally random inputs or if it requires more tuning, and what sort of tuning if so.  It's not a type of programming I have much experience with.  What would you use to explore this sort of thing?\n\nI have some general space-filling/path-finding algorithms in my toolkit to start from, but I also know that some environments are easier than others for this sort of modeling.  Some options I've heard of but don't know anything about:\n\n* [Processing](https://processing.org/) - Java (I don't really know Java, but am studying C++?  Similar-ish?)\n* The [python turtle](https://docs.python.org/3.3/library/turtle.html?highlight=turtle) - Python.  I don't know anything about turtle and very little about Python but it sounds like it can be used to explore this problem space.  Python seems like a good choice for this but I don't know the ecosystem at all.\n* I guess the [HTML canvas element](https://www.w3schools.com/html/html5_canvas.asp) but that sounds unwieldy and complicated.  Is there a framework you recommend?\n* I know Rust has some geospatial crates and image/graph crates for visualization, but nothing that I know of integrated for ease of use, experimentation and one-offs.\n* Game engines?  I've never used any, is that the right genre of tool for this?  [Love2d](https://love2d.org/) for LUA looks like it might be a good choice but it also might be overkill.\n\n...that's it, really.  Is there anything else I should be aware of?\n\nAlso, if you know more about these robot vacuums than I do and can enlighten me/us, please do!\n\nPhoto by Rock'n Roll Monkey on Unsplash",
    "title": "I Am Mesmerized By Our New Robotic Vacuum"
  },
  {
    "cover_image": "https://res.cloudinary.com/practicaldev/image/fetch/s--5FTUN3KI--/c_imagga_scale,f_auto,fl_progressive,h_420,q_auto,w_1000/https://thepracticaldev.s3.amazonaws.com/i/gsa61233wmq2k89tqaa4.jpg",
    "date": "2019-07-24T16:34:58.397Z",
    "description": "",
    "tags": "beginners, gnu, tools, cpp",
    "markdown": "# What's Make?\n\nThis post will explore the basics of [GNU Make](https://www.gnu.org/software/make/) via two small examples.  It's a surprisingly versatile build tool, if a bit archaic, and as it's so ubiquitous it's worth getting at least baseline familiar with how it does its thing.\n\nCaveat: as far as I know this is mostly relevant for Mac and Linux users.  I don't know much about build tooling or development on Windows outside of just booting up an IDE and letting it handle things, or using WSL as a crutch where available.  I do know you can get `make` via [GnuWin32](http://gnuwin32.sourceforge.net/packages/make.htm).  I have no idea how well it works or if anyone uses it.\n\nIn brief, `make` is a tool that reads a *Makefile* and turns source files into executable files.  It doesn't care what compilers are used to do so, it's just concerned with build orchestration.\n\nIf you've compiled packages from source before, you may be familiar with the following set of commands:\n\n```\n$ ./configure\n$ make\n$ sudo make install\n```\n\nA great number of *nix packages are distributed as C or C++ source code, and will be built something like this.  The first line runs a separate program to configure your Makefile for you, which is necessary in big projects which rely on system libraries.  The last line generally assumes admin rights so it can copy the executable(s) it just built onto the system path.  We don't need any of that to get started with `make`, though.  Just the middle line will do us fine.  Aptly named, isn't it?\n\nIn this post I'll walk through two different examples with different goals.  The syntax can look opaque (at last, it did to me) if you don't know what you're looking at, but once you know the very basic rules they're very straightforward.\n\n# Example One - Download A File\n\nWe'll do the simpler one first.  This Makefile only exists to download `boot`, a build tool for Clojure, to the user's current directory.  This tool exists as a shim that downloads a jarfile to handle the rest, and the shim is very tiny, so it's sometimes convenient to have it live in a project directory itself instead of the system path.\n\n```make\n.PHONY: deps help\n\nSHELL        = /bin/bash\nexport PATH := bin:$(PATH)\n\ndeps: bin/boot\n\nbin/boot:\n\t(mkdir -p bin/                                                                              && \\\n\tcurl -fsSLo bin/boot https://github.com/boot-clj/boot-bin/releases/download/latest/boot.sh  && \\\n\tchmod 755 bin/boot)\n\nhelp:\n\t@echo \"Usage: make {deps|help}\" 1>&2 && false\n```\n\nWe'll take it from the top.\n\n```make\n.PHONY deps help\n\nSHELL       = /bin/bash\n```\n\nFirst, we declare the *phony targets*.  To explain this, we need to talk about the core of what `make` is: rules.\n\nMake is for making sources into targets.  To do so, we give it rules for understanding what sources and how to feed them to compilers to get the right targets.  At the end, we should have produced all the targets needed - the compiled sources.\n\nKeeping that in mind, rules are easy to grok.  Each rule starts with the name of the target to be created, followed by a colon.  After the colon are any targets *this* target depend on, and below and indented are a series of commands, or recipes, to build the target from its dependencies.  When you invoke `make` with a target, it will make that target specifically, but when you invoke it on its own it just start evaluating the first rule it sees that doesn't begin with a `.` (like `.PHONY`).\n\nNext, we define the shell executable location,\n\nThe `$()` syntax is a Make variable.  Make is neat in that it automatically exposes every variable it finds in the environment as a make variable, so we can just use `$PATH` from `bash` with `$(PATH)`.  To define your own you just assign to the name, omitting the parens, as we do in the first line - that's an assignment to the `$(SHELL)` variable.\n\nNotably, we're using the `:=` assignment syntax for it.  This specifically defines a *simply-expanded* assignment.  This variable will be read once and that's it - any other variables inside it are expanded once immediately at assignment.\n\nThe `=` *recursively-expanded* variable instead expands anything inside whenever it's substituted.  This is powerful, but also can lead to problems like infinite loops and slow execution so it's important to be mindful of the difference.\n\nIt's important to note that this is only true for this process and any sub-process of it - this isn't permanent, it cannot alter the parent process.  Still useful if you're building inside `make`, though, and doesn't clutter up your global env!\n\nThen we get to our first rule.  In this case, the default rule is called `deps`, one of our phony targets.  No file called \"deps\" will be created.\n\n```make\ndeps: bin/boot\n```\n\nAfter the target name, you'll find a colon and then a list of *dependencies*.  These are targets that must be completed before evaluating this rule.  Before executing the block of commands for this target, Make will ensure each of the targets exists, evaluating their rules if it finds them.  In this case, the dependency is target \"bin/boot\".  There are no commands associated with this rule, all it does is call this other rule.\n\n```make\nbin/boot:\n\t(mkdir -p bin/                                                                              && \\\n\tcurl -fsSLo bin/boot https://github.com/boot-clj/boot-bin/releases/download/latest/boot.sh  && \\\n\tchmod 755 bin/boot)\n\n```\n\nThis isn't a phony target, and includes a slash, which just means a directory name.  This target, or the result of evaluating this rule, is going to end up in that directory we added to the PATH.\n\nThis rule doesn't have any dependencies - they'd all appear on the same line as the target name.  It does have commands though - this rule will create a directory, execute `curl` to downloade the file from GitHub, and execute `chmod` to make the downloaded file executable.\n\nSo, running `make` will locate the `make deps` rule, which is empty itself but has `bin/boot` as a dependency.  Make will realize `bin/boot` does not yet exist and execute that rule, which will create the file accordingly.\n\nTry running it, and then running it again:\n\n```\n$ make\n(mkdir -p bin/                                                                              && \\\ncurl -fsSLo bin/boot https://github.com/boot-clj/boot-bin/releases/download/latest/boot.sh  && \\\nchmod 755 bin/boot)\n\n$ make\nmake: Nothing to be done for 'deps'.\n```\n\nAfter evaluating this rule the first time around, a file called `boot` already existed in a directory called `./bin`.  The target was found, so `make` did no extra work.  This handy quality is known as *idempotence*.  Repeated invocations have the same effect as one invocation: `f(x);` and `f(x); f(x);` are equivalent.\n\nNeat!  Let's look at something a little more typical.\n\n## Example Two: Build Some C++\n\nThis is more complicated one.  This makefile is what I drop in to a brand new C++ project directory before thinking about it.  It's more indicative of what makefiles in the wild might look like, but still really small in scope.\n\nIt expects a `src` directory with a bunch of `.cpp` (and `.h`) files, and will create a directory called `build` with all your `.o` object files and your executable, named whatever you tell it.  You can then run that executable.\n\n```make\n.PHONY: all clean help\n\nCXX=clang++ -std=c++11\nFLAGS=-Wall -Wextra -Werror -pedantic -c -g\n\nBUILDDIR=build\nSOURCEDIR=src\nEXEC=YOUR_EXECUTABLE_NAME_HERE\nSOURCES:=$(wildcard $(SOURCEDIR)/*.cpp)\nOBJ:=$(patsubst $(SOURCEDIR)/%.cpp,$(BUILDDIR)/%.o,$(SOURCES))\n\nall: dir $(BUILDDIR)/$(EXEC)\n\ndir:\n\tmkdir -p $(BUILDDIR)\n\n$(BUILDDIR)/$(EXEC): $(OBJ)\n\t\t$(CXX) $^ -o $@\n\n$(OBJ): $(BUILDDIR)/%.o : $(SOURCEDIR)/%.cpp\n\t\t$(CXX) $(FLAGS) $< -o $@\n\nclean:\n\t\trm -rf $(BUILDDIR)/*.o $(BUILDDIR)/$(EXEC)\n \nhelp:\n\t\t@echo \"Usage: make {all|clean|help}\" 1>&2 && false\n```\n\nAt the very top we have our phony targets again - these are the targets that aren't creating real files, they're just intended to be invoked as an argument to make.\n\nNext we point it towards our C++ compiler by assigning the variables `$(CXX)` and `$(FLAGS)`:\n\n```make\nCXX=clang++ -std=c++11\nFLAGS=-Wall -Wextra -Werror -pedantic -c -g\n```\n\nThese aren't special names - you can call them whatever you like.  We'll refer to them directly in our rules.\n\nC++ compilation happens in two stages.  First, we compile all the separate `*.cpp/*.h` pairs into their own `.o` object files, and in a separate step we'll link them all up into a single executable.  The flags we pass to the compiler are only relevant when building the objects from source - linking together already-compiled objects doesn't need them!  This way we can invoke the compiler with or without this set of flags inside our rule evaluation.  I like to make my compiler as restrictive as possible - these flags turn all warnings into errors that prevent successful compilation, and enable to full suite of checks available.   The `-c` flag instructs it not to go on to the linking phase, finishing with an `.o` file, and the `-g` flag generates source-level debug info.\n\nA fancier makefile will have multiple build configurations.  This, again, is a starter kit.\n\nThe next three assignments just configure the names of everything:\n\n```make\nBUILDDIR=build\nSOURCEDIR=src\nEXEC=YOUR_EXECUTABLE_NAME_HERE\n```\n\nI think `build` for the output and `src` for the source files make sense, but you can adjust them there, and `$(EXEC)` will be the final compiled binary.\n\nBelow that we define where the sources are, and what the objects should   be called:\n\n```make\nSOURCES:=$(wildcard $(SOURCEDIR)/*.cpp)\nOBJ:=$(patsubst $(SOURCEDIR)/%.cpp,$(BUILDDIR)/%.o,$(SOURCES))\n```\n\nThe `$(SOURCES)` variable is built with the [`wildcard`](https://www.gnu.org/software/make/manual/html_node/Wildcard-Function.html#Wildcard-Function) function.  This variable collects anything with the `.cpp` extension inside `src/`.\n\nNext we use [`patsubst`](https://www.gnu.org/software/make/manual/html_node/Text-Functions.html#Text-Functions).  The syntax for this is *pattern*, *replacement*, *text*.  The `%` character in the pattern and replacement is the same, and the other part is swapped.  This substitution turns, e.g. \"game.cpp\" into \"game.o\".  For the text, we're passing in the `$(SOURCES)` variable we just defined - so the `$(OBJ)` variable will contain a corresponding `build/*.o` filename for each `src/*.cpp` filename that `make` finds.\n\nCheck out the [quick reference](https://www.gnu.org/software/make/manual/html_node/Quick-Reference.html) for a complete run-down of what's available.\n\nI've used simply-expanded variable assignment for these.  It's a good idea to do so when you know that will get you the result you need specially when using functions like `wildcard` - recursively expanding these can (but doesn't always) result in significant slowdowns.\n\nWith all our variables configured, we can start defining rules.  The first rule is our default behavior, this one is called `all`:\n\n```make\nall: dir $(BUILDDIR)/$(EXEC)\n```\n\nThis is one of our phony targets, so there's no corresponding output file called \"all\".  Also, like `deps` from the first example, this rule has no commands, only dependencies.  This one has two dependencies, `dir` and `$(BUILDDIR)/$(EXEC)`.  It will execute them in the order they are found, so lets hop over to `dir` first:\n\n```make\ndir:\n\tmkdir -p $(BUILDDIR)\n```\n\nThis one doesn't have dependencies, so it will immediately execute this command.  This is a simple one - it just makes sure the `build` directory exists.  Once that's complete, we can evaluate `$(BUILDDIR)/$(EXEC)`:\n\n```make\n$(BUILDDIR)/$(EXEC): $(OBJ)\n\t\t$(CXX) $^ -o $@\n```\n\nThis rule is starting to look a little funkier.  The target itself is not unlike `bin/boot` from the first example, just using make variables to build it.  If you've set `$(EXEC)` to `my_cool_program`, this target is named `build/my_cool_program`.  It depends on another make variable, `$(OBJ)`, which we just defined as an object file corresponding to each source file.  That will resolve first, so let's look at that rule before looking at the command:\n\n```make\n$(OBJ): $(BUILDDIR)/%.o : $(SOURCEDIR)/%.cpp\n\t\t$(CXX) $(FLAGS) $< -o $@\n```\n\nWhoa, there's *two* sets of dependencies here!  What the heck, Ben.\n\nThis is something called a *static pattern rule*.  This is what we use when we have a list of targets.  The overall target, `$(OBJ)`, consists of each one of the object files we'll be creating.  After the first colon, we need to define specifically how each individual object depends on a specific source.  Again we see the `%` used for pattern matching, not unlike up in the `patsubst` call.  Each one will have the same name as the corresponding \".cpp\" file, but with the extension flipped to \".o\".\n\nThe command block for this rule will execute for each source/target pair matched.  We're using the make variables we defined way up at the top to invoke the compiler and pass in all our flags, which includes the `-c` flag signalling to stop before the link phase, just outputting object files.\n\nThen we use some automatic variables to fill in the proper command.  `$<` corresponds to the name of the dependency we're working with, and `$@` corresonds to the name of the target.  Full expanded, this `$(CXX) $(FLAGS) $< -o $@` command will look like `clang++ -std=c++11 -Wall -Wextra -Werror -pedantic -c -g src/someClass.cpp -o build/someClass.o`.\n\nMarvelous!  Once this rule completes, every \".cpp\" file has a corresponding \".o\" file in the `build/` directory, exactly what we defined as `$(OBJ)`.  With that in place `make` will jump back up to the calling rule and finish off with the `$(CXX) $^ -o $@` command to link our objects together.\n\nThis is similar, but we're omitting our flags. We also use a different automatic variable.  `$^` corresponds to the entire list that `$(OBJ)` represents.  You could also use `$+`, which fully includes each list member - `$^` omits any duplicates.  The `$@` part is the same as previously - it stands for the target.  This might run a command something like `clang++ --std=c++11 build/someClassOne.o build/someClassTwo.o build/someClassThree.o build/main.o -o build/my_cool_project`.\n\nOnce that's done, you've got your compiled executable ready to go at `build/my_cool_project`.  Thanks, `make`!\n\nThis makefile also provides `clean`:\n\n```make\nclean:\n\t\trm -rf $(BUILDDIR)/*.o $(BUILDDIR)/$(EXEC)\n```\n\nThis is another phony target with no dependencies that just runs `rm` to clean out all the object files and the executable.  This way when you run `make` again it will have to build everything again.  Otherwise it will just build any files that have changed since your project was last built.\n\nWe've only scratched the surface, but hopefully this helps demystify these files a bit should you come across one.\n\nChallenge: write your own `make install` rule that copies the newly created target out of `build` to a cooler place!\n\nPhoto by Jason Briscoe on Unsplash",
    "title": "How To Make A Makefile"
  },
  {
    "cover_image": "https://res.cloudinary.com/practicaldev/image/fetch/s--vaxSJFUh--/c_imagga_scale,f_auto,fl_progressive,h_420,q_auto,w_1000/https://thepracticaldev.s3.amazonaws.com/i/nkecbs070xthq0kes77l.jpg",
    "date": "2019-07-28T20:09:34.328Z",
    "description": "",
    "tags": "beginners, cpp, devjournal",
    "markdown": "# Swallowing The Pill\n\n## Some Background\n\nC++ is my self-learning white whale.  I've tried many times over the years to make it a bit further though one of the big Stroustrup bibles, but inevitably flame out embarrassingly quickly.  It's just *huge*, and kinda complicated.  I was always in awe of it and *wanted* to be able to leverage its power, but as it was easier to get going with other languages I never got around to taking the time.  I never had quite enough self-discipline.\n\nI'm back in school now, so I took advantage of the opportunity and specifically enrolled in the C++-focused track.  I figured a good jolt of structured academic instruction might be just the ticket to force myself to put in the time and energy.  I'm finally doing a significant month-long final project with it, so it's my first real off-the-rails C++ test drive having now learned more about the language than I'd ever managed before.\n\nIt turns out I think I even *like* it, but boy is it an awakening coming from Rust and JavaScript and C and company.\n\n## What This Is\n\nThis is an *extremely* beginner-level look at some stuff I've learned to un-stick myself while implementing this homework assignment.  I'm making no claim that I've discovered the *best* solutions to these problems, this is more a journal of what's ended up working for me.  Si vez algo, *di* algo.\n\nThe closest language analogue I'm comfortable with now is Rust (or maybe C, I'm not sure - they're similar for different reasons), which also happens to be what I've been using the most of lately, so I'm approaching this project more or less as I would a Rust project for better or for worse.  Quickly I could tell the idioms are pretty different, but you've gotta start from somewhere.\n\nFor context, the project is a CLI game of Battleship.  The code can be found on [GitHub](https://github.com/deciduously/volley).\n\n## Using statements\n\nMy first confusion came from namespace etiquette.  I knew I didn't like `using namespace std`, so I decided to go with scope-level using statements:\n\n```cpp\nstd::string someFunc()\n{\n    using std::string;\n\n    string myString = \"\";\n}\n```\n\nThis keeps it explicit in the global scope but allows me to pull specific things into a function without sacrificing clarity - you can see where it's coming from right there.\n\nThen I got confused about `#include` statements - sometimes a header is included through multiple layers of other includes, because the preprocessor is literally just pasting code into other code resolving these.  It can be tough to see where a specific function is actually included.\n\nI was pointed to [this article](http://www.cplusplus.com/forum/articles/10627/), which is worth a read.  The biggest takeaway for me was that if you just use a pointer to a specific object, you don't need to actually include it, you can (and probably should) just forward-declare it.\n\n## Debugging\n\nUntil now, I've mostly been a `println` debugger.  I've known how to use [`gdb`](https://www.gnu.org/software/gdb/) but never saw that as easier than just adding a `debug!()` output somewhere.\n\nI have now come to *very much* appreciate `gdb`.  My programs had simply never gotten large enough.  A quick rundown of literally everything I need:\n\n1. Compile with the `-g` flag.\n\n2. Invoke `gdb my_executable`\n\n```\n→ gdb build/volley \nGNU gdb (Gentoo 8.3 vanilla) 8.3\nCopyright (C) 2019 Free Software Foundation, Inc.\nLicense GPLv3+: GNU GPL version 3 or later <http://gnu.org/licenses/gpl.html>\n// blah blah blah\nReading symbols from build/volley...\n(gdb)\n```\n\nYou enter commands at the `(gdb)` prompt.\n\n3. Break on the function you want to inspect:\n\n```\n(gdb) break runFiring\nBreakpoint 1 at 0x40e913: file src/game.cpp, line 38.\n```\n\n4. Use commands to navigate through your program:\n\na. `run`/`r`: run the loaded program for debugging until next breakpoint\nb. `next`/`n`: step through execution one line at a time, **not** stepping into functions.\nc. `step`/`s`: step through execution one line at a time, stepping into all functions\nd. `print`/`p`: print the value of a variable\ne. `examine`/`x`: examine memory of a variable\nf. `continue`/`c`: stop stepping line by line and resume execution to the next breakpoint (or program completion)\ng. `kill`/`k`: kill the program being debugged without exiting `gdb` to take it again from the top (use `quit`/`q` to get back to your shell)\n\nYou can add breakpoints any time, and remove them with `delete`.  Use the up and down arrows to access command history, and leaving it empty and hitting `Enter` will just repeat the last command - useful for stepping line by line.\n\nThere's lots and lots more, there's a great PDF cheatsheet [here](https://darkdust.net/files/GDB%20Cheat%20Sheet.pdf).  I find myself using `info locals` a lot, which shows you all the variables in the current stack frame.\n\nIt is *so much better* than adding and removing println statements and recompiling.  It's much more exploratory and interactive, and a million times more efficient.  I still only just barely know how to use it, too.\n\n\n## Clean Up After Yourself\n\nThere's a super quick way to check if you've done your job memory-leak wise: [valgrind](http://www.valgrind.org/).\n\nThis is another tool I *do not* know how to use but already get immense benefit from:\n\n```\n± |master U:13 ✗| → valgrind build/volley \n==7744== Memcheck, a memory error detector\n==7744== Copyright (C) 2002-2017, and GNU GPL'd, by Julian Seward et al.\n==7744== Using Valgrind-3.15.0 and LibVEX; rerun with -h for copyright info\n==7744== Command: build/volley\n==7744== \n\n            Battleship!!!\n\n// ... etc - play a game\n\nGame over!\n==7744== \n==7744== HEAP SUMMARY:\n==7744==     in use at exit: 672 bytes in 8 blocks\n==7744==   total heap usage: 3,970 allocs, 3,962 frees, 177,854 bytes allocated\n==7744== \n==7744== LEAK SUMMARY:\n==7744==    definitely lost: 0 bytes in 0 blocks\n==7744==    indirectly lost: 0 bytes in 0 blocks\n==7744==      possibly lost: 0 bytes in 0 blocks\n==7744==    still reachable: 672 bytes in 8 blocks\n==7744==         suppressed: 0 bytes in 0 blocks\n==7744== Rerun with --leak-check=full to see details of leaked memory\n==7744== \n==7744== For lists of detected and suppressed errors, rerun with: -s\n==7744== ERROR SUMMARY: 0 errors from 0 contexts (suppressed: 0 from 0)\n```\n  \nHold up, heap in use at exit?  Ah, of course - I'd written my destructors, but never actually call `delete` on the top-level instance anywhere!  After a quick edit:\n\n```\n$ valgrind build/volley \n==8122== Memcheck, a memory error detector\n==8122== Copyright (C) 2002-2017, and GNU GPL'd, by Julian Seward et al.\n==8122== Using Valgrind-3.15.0 and LibVEX; rerun with -h for copyright info\n==8122== Command: build/volley\n==8122== \n\n            Battleship!!!\n\n// ... etc - play a game\n\nGame over!\n==8122== \n==8122== HEAP SUMMARY:\n==8122==     in use at exit: 0 bytes in 0 blocks\n==8122==   total heap usage: 3,993 allocs, 3,993 frees, 178,686 bytes allocated\n==8122== \n==8122== All heap blocks were freed -- no leaks are possible\n==8122== \n==8122== For lists of detected and suppressed errors, rerun with: -s\n==8122== ERROR SUMMARY: 0 errors from 0 contexts (suppressed: 0 from 0)\n```\n\nThat's 672 whole bytes now present and accounted for.  Boo-yah.  All I needed was the nudge to go double-check from just running it with no options, there's also a lot more this tool can do for you.\n\n## Struct Equality\n\nOff the bat one of my problems was `std::find()`.  This is used to locate an element in a vector.  Clearly, such a function will be comparing elements for equality.  In Rust, you'd derive or hand-implement the `PartialEq` trait on a struct in order to enable that behavior.  C++ doesn't have that, but you still need to be able to define equality for structs.\n\nStructs are basically equivalent to classes, but their members are public by default.  This is something I knew from textbook-reading, but had never needed to use.\n\nWithout providing a definition, you get this somewhat opaque error from `clang`:\n\n```\nusr/lib/gcc/x86_64-pc-linux-gnu/9.1.0/include/g++-v9/bits/predefined_ops.h:241:17: error: invalid operands to binary expression ('Cell' and 'const Cell')\n        { return *__it == _M_value; }\n```\n\nThis happens because `std::find()` tried to use `==` on two structs, but we hadn't defined how to do that.  I think the problem is that it was expecting it to be passed by reference, and instead it got passed by value.\n\nYou can allow equality checks to work on structs you define by overloading the `==` operator and specifically passing a `const` reference:\n\n```cpp\n// A single cell on the board\ntypedef struct Cell\n{\n    int row;\n    char col;\n    bool operator==(const Cell &other) const\n    {\n        return row == other.col && col == other.col;\n    }\n} Cell;\n```\n\nThis looks a lot like a handwritten `impl PartialEq block` (from [the docs](https://doc.rust-lang.org/std/cmp/trait.PartialEq.html)), which also uses what's essentially the Rust-y `const &`:\n\n```rust\nstruct Book {\n    isbn: i32,\n    format: BookFormat,\n}\n\nimpl PartialEq for Book {\n    fn eq(&self, other: &Self) -> bool {\n        self.isbn == other.isbn\n    }\n}\n\n```\n\n## Constantly Const\n\nThis leads into the next point - sprinkle `const` *everywhere*.  This is something Rust has actually prepared me well for.  I essentially use it like the opposite of `mut`.  Here's one of my class headers:\n\n```cpp\nclass Board\n{\n    int dimension;\n    std::vector<Cell> receivedShots;\n    std::vector<Ship> ships;\n\npublic:\n    Board(int boardSize = BOARD_SIZE);\n    bool doesFit(ShipPlacement sp) const;\n    char getCharAt(Cell c, bool showShips) const;\n    Cell getRandomCell() const;\n    Cell promptCell(const std::string &promptStr) const;\n    void pushShip(Ship s);\n    std::vector<Cell> getAllShots() const;\n    bool receiveFire(Cell target);\n    int size() const;\n    lines toLineStrings(bool showShips) const;\n};\n```\n\nThis thing is so full of `const` it's ridiculous.  When I started coding I didn't realize quite how much it would be applicable and was hesitant to use it for fear of not understanding it.  Now my rule of thumb is to add it by default to any method, and only take it away if I'm sure I cannot have it.\n\n## My God, It's Full Of Streams\n\nC++ leans hard into the stream abstraction.  I ran into this relatively quickly when I wanted to pretty-print some data.  In Rust I'd reach for `impl Display`, in something more OOP i'd override `toString()` or something.\n\nIn C++, you actually overload the `<<` stream insertion operator.  For a simple example:\n\n```cpp\nenum Direction\n{\n    Left,\n    Down\n};\n\nstd::ostream &operator<<(std::ostream &stream, const Direction &d)\n{\n    if (d == Direction::Left)\n        return stream << \"Left\";\n    else\n        return stream << \"Down\";\n}\n```\n\nNow you can pop it right in a stream, no need to call anything:\n\n```cpp\nstd::cout << \"Direction: \" << direction << \"!\" << std::endl;\n```\n\nThis pattern was not obvious to me at first but feels a lot more natural after a few days.\n\n## Overloaded Constructors\n\nI've never worked with a language that does this, so it's still novel and neat to me.  In Rust, you use traits and it's a little more unwieldy.  In C++ I can just literally define three constructors:\n\n```cpp\nclass ShipClass\n{\n  // ..\npublic:\n    ShipClass();\n    ShipClass(char c);\n    ShipClass(ShipClassType sc);\n // ..\n}\n```\n\nThat's a pretty easy way to get yourself a flexible API.\n\n## Frustrations\n\nNot everything has been happy.  I've generally expected everything C++ has had to throw at me given prior knowledge, but there are a few outstanding things I'm still not sure how to learn to like.\n\n### Build tooling / Package Management\n\nC++ is, to me, the wild friggin' west.\n\nI haven't gotten started with things like [CMake](https://cmake.org/) and [Autotools](https://www.gnu.org/software/automake/manual/html_node/Autotools-Introduction.html), but the very fact these tools exist says a lot.  It's really hard to just use external libraries, so often projects will simply just not.  There's a lot of reinventing the wheel because package management is such a complete mess.  That's not a healthy ecosystem  to the untrained eye, but the language itself is powerful enough that maybe it makes up for it.  It also is a gigantic ecosystem despite this shortcoming, so I want to be able to explore and use it, but if it's so complicated I won't bother.\n\nThen there's things like [`boost`](https://www.boost.org/) which are just their own beasts in and of themselves.  I think it will quite literally be years until I'm able to make a reasonable and informed statement about the power and quality of the C++ ecosystem.  Until then, it's a newbie turn-off.\n\nI've already written [a post](https://dev.to/deciduously/how-to-make-a-makefile-1dep) about `make`, which I won't recreate here.  The second example I walk through in that post is the exact Makefile I'm using to build this project.\n\nThis is the very first C++ course in the curriculum, and I imagine it will be covered later on, but for this one the professor basically said \"I do not care how you build your code, just make sure I can recreate it, if you don't know what to do, here's a link to download Visual Studio\".\n\nI should probably learn Visual Studio sometime, but I think it's easier to learn one thing at a time, so I just stuck with my usual text editor and compilation via CLI.  I already knew how to use make from years of tinkering with Linux.  I don't know what the best way to go about this is.  It seems like in a professional setting CI/CD would run all the compilers anyway.\n\n### Exceptions\n\nThis wasn't difficult to pick up, being not dissimilar from exceptions in JS or Python:\n\n```cpp\ntry\n{\n    row = stoi(originStr.substr(1, originStr.size() - 1));\n}\ncatch (const std::invalid_argument &ia)\n{\n    std::cerr << \"Please enter a number as your second term.\" << endl;\n    // ..\n}\n```\n\nI guess I'm just spoiled with type-level stuff.  I don't like this, it seems like it seems to spaghetti-type code and lots of needless verbosity to catch errors for a whole app.  I also haven't really started mucking about with templates much, so it's likely this is a familiarity issue.  It does seem to work more or less the same as I expect from Python or JS.\n\n### Class vs Struct\n\nThis isn't a problem, but still doesn't really make sense to me.  In Rust, everything is a `struct`, and you can provide an `impl Struct` block to define a constructor and/or methods if needed, or just not for plain data.\n\nC++ has structs and classes, but they're almost identical.  The only difference is the default visibility: structs are public, classes are private, but through explicit annotations they're functionally equivalent otherwise.  I try to use structs for plain data and classes for anything else, but the line is blurry.  If I have a struct that just wraps an enum but has a bunch of different getters, like a `char` and a `string` and an `int`, is that a class or a struct?  Right now I have a struct which just holds a row and a column, also has some constructors and an equality method defined.  That's not that different from a class.  I don't know which, if either, is correct, or if it matters at all.  I'm just kind making a gut decision when I define a new one and not thinking about it again, it doesn't seem to make a difference.\n\nFollow-up: is that the kind of thing you'd use a `union` for?  I still don't quite know when I'd want one of those unless I'm specifically space constrained.\n\n## Conclusion\n\nI'm glad I'm finally ripping the band-aid and using C++ for something a little more substantial, but never before has the vastness of the mountain been so apparent at the outset.\n\nPhoto by Matthew Henry on Unsplash",
    "title": "Getting Cozy With C++"
  },
  {
    "cover_image": "https://res.cloudinary.com/practicaldev/image/fetch/s--dQs1e4j3--/c_imagga_scale,f_auto,fl_progressive,h_420,q_auto,w_1000/https://thepracticaldev.s3.amazonaws.com/i/lprcuq1ew8176curhwtl.jpg",
    "date": "2019-07-31T13:52:18.472Z",
    "description": "",
    "tags": "discuss, beginners, types, help",
    "markdown": "# Reading Material\n## Yet Another Static-vs-Dynamic Shindig\n\nThis week I came across a [fantastic article](https://lispcast.com/clojure-and-types/) by Eric Normand on the whole \"static vs dynamic\" debate, written by someone with the unique perspective of having worked professionally in both Clojure and Haskell.\n\nThe article is worth a read, but I want to focus one one line in particular that stuck with me.  I don't fully understand it, and am hoping DEV may be able to shed some extra light.\n\nThe author was quoting a Rich Hickey talk.  For the uninitiated, [Rich Hickey](https://purelyfunctional.tv/programmer-profiles/rich-hickey/) is the creator of [Clojure](https://clojure.org/), a dynamic functional Lisp dialect for the JVM, and current CTO of [Cognitect](https://cognitect.com/).  Part of his cult of personality has stemmed from the rather excellent and rather opinionated talks he's given discussing both Clojure specifically and his personal take on the current state of the software ecosystem and how it applies to the sorts of problems he solves.  (The rest stems from his [phenomenal hairdo](https://purelyfunctional.tv/wp-content/uploads/2016/09/Rich-Hickey.jpg).)\n\nThat's a huge takeaway, something Normand takes extra care to identify: Rich Hickey isn't talking about the merits of static vs. dynamic typing **in the general case**.  He's concerned with **how it applies to his problem space**.  This is a detail that is all too often lost when these debates flare up, but is a factor when making absolutely any technical decision at all, and is important to keep in mind when engaging in this sort of discourse.\n\n## The Efficacy of Maybe\n\nThe line in particular that caught my eye was when he's discussing the use of `Maybe` in languages like Haskell to handle the concept of optional values.  Instead of a `String`, you'd type your field `Maybe String`.  Now if can either contain a string or not and still be properly typed.  You used pattern matching and destructuring to get at that actual value when your code needs to do something with it.  You use it when you don't know for sure whether or not this value will exist at all times in a given record.\n\nRich Hickey doesn't like this.   He disagrees with this approach, stating \"you either have it or you don’t\".  It makes sense, too.  For the sorts of programs Clojure is designed to address, *everything* would be wrapped in a `Maybe`.  These are long-running systems with high fault tolerance and constantly changing business needs.  These systems do not lend themselves to hyper-rigid beautiful strongly-typed structures.  If the spec changes, you don't want to have to make structural updates across every file in your project.  You want to be able to just deal with objects of different shapes.\n\nI can understand why it may be cumbersome to explicitly include a `Maybe` on every single value, but I'm less clear on why it actually represents an inaccurate model of your system.  In fact, not knowing [Kotlin](https://kotlinlang.org/) it actually kinds seems like that's what they're approaching - reducing the overhead for a nullable type to a [single character](https://kotlinlang.org/docs/reference/null-safety.html).\n\nThat sounds like it works to me, but it also feels like there's truth to Hickey's perspective.  When your system is running and you have a record, he's right.  You don't \"optionally\" have a string here at runtime.  You've either got it or you don't.  That's just true.  It seems like the `Maybe`-based model is indeed a workaround for the convenience of the programmer, as opposed to an accurate model of a real-world phenomenon.  At the same time, though, it does seem to model the expected behavior, and at runtime you'll still need to dispatch logic based on whether or not a given field is present.\n\nDo you agree?  Disagree?  I've always felt `Maybe` to be an effective solution to this problem, and this read has made me want to step back, consider the issue more carefully, and collect some perspectives.\n\nPhoto by marc liu on Unsplash",
    "title": "You Either Have It Or You Don't"
  },
  {
    "cover_image": "https://res.cloudinary.com/practicaldev/image/fetch/s--oOapkgSo--/c_imagga_scale,f_auto,fl_progressive,h_420,q_auto,w_1000/https://thepracticaldev.s3.amazonaws.com/i/wpefgictl0bj29ir9y8d.jpg",
    "date": "2019-08-06T01:21:44.280Z",
    "description": "",
    "tags": "beginners, journal, project, career",
    "markdown": "# Harder, Better, Faster, Stronger\n\nI received a helpful bit of constructive criticism recently.  This post is about what I'm going to do about it.\n\nI've long felt insecure about my portfolio of code samples, because I had no idea what it \"should\" look like in order to look hire-able.  I had no idea if my code was a complete mess, or in the wrong languages, or bad examples, or not polished enough, or you know, any of the ways I could have mucked it up.  Side-effects of self-learning in near complete isolation, who'da thunk.  I also didn't know if it even mattered, and the jury's still deliberating on that one.\n\nAs it turns out, overall usefulness aside, I do have a fixable hole in my body of sample code.  I have a bunch of small things in a variety of tools and understand how to compare and contrast these tools along various axes, but I haven't demonstrated I can orchestrate a bunch of small things into one big thing.  My largest samples max out around 1,000-1,500 lines total.  I have a good command of the tools and can solve micro problems, but who's to say if I'm good at macro problems?\n\nI think I kind of knew that, but I don't think I understood exactly what the difference in scale represented until it was laid out in this way.\n\nIt's time to *level up*, abstraction-layer-wise.\n\n## The Remedy\n\nI think I'm ready for the challenge, but there's only one way to find out.  The project I was suggested is a simple game but occurs in stages:\n\n1. Solitaire - Terminal\n2. Solitaire - Graphical\n3. Two-player\n4. Multi-player, networked\n5. Computer player\n\nI don't anticipate a complexity issue with any of these components in isolation (except perhaps #5), and have tids and bits scattered throughout my hard drive that actually do cover a number of these various parts.  The parts I haven't solved I'm confident I can figure out, too.  I know I can solve micro problems with with the tools I have.  The problem is that I've never tried juggling a bunch of little solutions, which is exactly what I'm trying to get myself hired to do.\n\n## Choices\n\nI'm not sure what to use to build this.  Part of me wants to go basic as possible with the tools and explore the whole problem myself - full-stack JavaScript with zero frameworks for the web route, or take the opportunity to learn SDL/C++/sockets or something, to keep closer in line with my schoolwork and not get too spread out.  That way I focus on the problem, and not the tools.\n\nThat also might be shooting myself in the foot.  See?  I have no idea!  Never done it.  Maybe I should use Flask and React, and abstract away a lot of the finicky stuff and use a platform and paradigm I'm more comfortable with, but end up with a less general solution and possibly a less effective learning experience.\n\nI've got to think about it.\n\nThis will also mean neglecting two other side projects I've started recently and would like to finish someday.  Both are fun, but both are similarly small problems and neither are urgent.  I'd like to make the most of my side project time right now, and perhaps revisit when I've got a little more free energy to spend.\n\n## Our Work Is Never Over\n\nI used a mountain analogy at the end of my C++ journal post, and you may be familiar with this comic version:\n\n![mountain comic](https://3.bp.blogspot.com/-3qtcA17ygXc/Uj9CGW4GU8I/AAAAAAAABcY/lt6WBJHlZlQ/s1600/38.png)\n\n*[source](http://www.itchyfeetcomic.com/2013/09/view-from-top.html)*\n\nThis applies to all sorts of fields, not just language learning, and feels especially apt now.  I think I've hit the ridge, time to practice bouldering.  It only gets rockier from here.\n\nPhoto by Neil Rosenstech on Unsplash.",
    "title": "Towards Complexity"
  },
  {
    "cover_image": "https://res.cloudinary.com/practicaldev/image/fetch/s--yOfqZbPA--/c_imagga_scale,f_auto,fl_progressive,h_420,q_auto,w_1000/https://thepracticaldev.s3.amazonaws.com/i/9b1j8g6u6nmw13g3mqtr.jpg",
    "date": "2019-08-13T00:00:15.732Z",
    "description": "",
    "tags": "watercooler, games",
    "markdown": "# Nerd Alert\n\nWe live in the golden age of board games (so far).  It's impossible to keep up with every new hotness on the market, but I keep finding as I play new games they're often continually improving on old concepts, adding interesting twists and innovating in ever more fun ways.\n\nInstead of a \"favorites\" list, I thought it'd be more fun to talk about some of the most interesting mechanics I've come across, stuff I'd never quite seen before.  I do enjoy all these games, but that's not why they're picked.  I'd love to hear about yours in the comments!\n\n## Galaxy Trucker\n\n[Galaxy Trucker](https://czechgames.com/en/galaxy-trucker/) is a game where you assume the role of, well, a galaxy trucker.  Your job is to deliver some goods safely across space, whatever happens.  First, though, you've got to get yourself a vessel.  In the first phase everyone assembles their spaceship from a big pool of modular parts, trying to balance things like offense, defense, technology, storage space, and speed, and making sure things are configured in a way that you're ready for whatever gets thrown at you.\n\nNext, you take your weird mish-mash of ship-parts to the space-way (or such) and weather a series of random events.  For example, aliens might come at you from the left - let's hope you managed to build some lasers pointing that way!  There are all kinds of ways to be surprised, so building the perfect spaceship is never going to happen.  There's environmental hazards and loot to gather if you have the storage space to increase your payouts, but resources are limited - every choice you make in this game is tough.\n\nIt was actually tough to pick just one [Vlaada Chvátil](https://en.wikipedia.org/wiki/Vladim%C3%ADr_Chv%C3%A1til) game.  He's got a bunch of wonderful games, impressively across a wide range of styles and genres.  I think [Mage Knight](https://wizkids.com/mage-knight/) actually sits higher on my \"favorite\" list, and [Codenames](https://czechgames.com/en/codenames-xxl/) makes it to the table way more often, but Galaxy Trucker stands out to me as the most unique gameplay.\n\nThe app version is very well done if you want to check it out for much less money.\n\n## Letters from Whitechapel\n\nA little darker in nature, [Letters from Whitechapel](https://www.fantasyflightgames.com/en/products/letters-from-whitechapel/) brings us back to the Jack The Ripper murders.  One player assumes the role of cold-hearted butcher Jack, kicking off the game with Gristly Murder #1.  The remaining 1-4 players assume the role of four constables scrambling to locate the killer before he gets to his pre-selected secret hideout.  While any number of players works, it's really a two-team game, and I believe works best with 2 or 3 people.\n\nThe board is a map of Whitechapel in East London, with two separate overlapping grids.  Jack moves completely separately from the constables, in between buildings and down alleys while the constables move intersection to intersection.  They start where the murder occurred and then can try to sniff out at each intersection if Jack has sprinted through there.\n\nJack's player is sitting there at the table, silently listening to the constables strategize to find them, trying to outwit them by plotting a course they haven't thought of that still gets them home in 15 turns.  At any point, all they need to do is correctly identify that they are standing next to Jack, and call out the number to win.  Playing this one really does feel thrilling, and I find the game to be equally thrilling in either role - Jack always feels as if imminent capture is just a turn away, but the constables often spend the whole time feeling clueless as they pursue a track only to lose the scent entirely, letting Jack slip inside unnoticed.  There's nothing like the poker face situation when you've got a constable who *thinks* they're close standing adjacent to you, not sure if they want to attempt the arrest or not.\n\nThe next night, Jack's back at it but the hideout space doesn't change, only the murder location, so the constables can use knowledge they gained from the last run to try to do it again.  All in all there are four chances to catch Jack before he slips away for the last time winning the game.  Each time gets a little easier for the constables and a little harder for Jack.\n\nNo two play-throughs of this feel alike, and it's another one I haven't played anything else quite like.\n\n## Gravwell\n\n[Gravwell](https://www.renegadegamestudios.com/gravwell) is a smaller, quicker game, which is part of why I love it.  The rules are very simple.  It's a race game where everyone is a spaceship trying to get from the center all the way around the spiral and out of the gravity well.  You play numbered cards to determine your movement.\n\nThere's just one simple catch: instead of \"forwards\" and \"backwards\", you're working with \"towards\" and \"away\".  Each ship is it's own little gravitational body.  When you play a 5 movement card you're going 5 spaces towards the closest ship, which may be behind you!  Each movement card has a letter on it and movement order is resolved alphabetically, so the board may re-arrange before you have a chance to take a turn.  You've got to anticipate how your opponents will play if you want to pay a higher letter-ed card.\n\nThis game becomes a little mechanical with just 2 players, but with 4 the chaos really becomes apparent.  Turns can go in wildly different ways than you expect even after you've played several rounds.  There are also a handful of cards that push you away instead, and two that don't move you but instead pull everyone else that many spaces toward you, and it can be very satisfying to use those to your advantage.\n\nIt's quite simple to learn, which makes it a great choice to bring if you need something lighter that's quick to teach people and get going with.\n\n## Escape The Curse Of The Temple\n\nIn [Escape The Curse Of The Temple](http://escape-queen-games.com/index_en.html), you and your buddies are Indiana Jones-style action-archaeologists trapped in a tomb, to nobody's surprise.  To get out, you've got to roll dice to pass checks which can get you loot, acquire gems to weaken the curse blocking the door, or solve traps and other bad effects that can happen.\n\nThe catch to this one is that it's real-time.  It comes with a soundtrack.  When the music is playing you're all running around the board at the same time, rolling simultaneously trying to get the combinations you need without getting your dice trapped.  Twice, a gong will sound and everyone has to run back to the center before the door shuts no matter what they were doing or they permanently lose a die for the rest of the round.  After ten minutes there's a final gong.  If your crew hasn't managed to weaken the curse and roll their way out the door, you lose.\n\nIt's not a complicated game mechanics-wise, but it can't be - you don't have a lot of time to think!  You have to split your time between looting, solving the curse, and exploring to find the door, and there isn't a lot of extra time to mess around.  I like how well the real-time mechanic works, it really gets you in the game and each round is so fast.  Of course, people have made alternate versions with other music, so check out YouTube to spice it up.  The only way to make this game any more stressful is replacing the post-gong urgency music with [Yakety Sax](https://www.youtube.com/watch?v=gRXJT4lHEq4).\n\n## Pyramid Arcade\n\n[Pyramid Arcade](https://www.looneylabs.com/games/pyramid-arcade) is a pretty cool box of stuff.  It's not a game so much as an idea.  This designer has been messing around with this same set of interlocking pyramids for decades, and he and his friends have come up  with a variety of games using this same set.  They sell you sets of these pyramids and a big book full of different things to do with them.\n\nThe book is a mixed bag, to be completely honest.  There are dozens of games, which is awesome, and we've so far tried about half.  We've found six or seven that we come back to over and over again, which isn't so bad, and another five or six we liked but aren't, you know, instant classics or anything.  They do cover the gamut from simple to complex and helpfully tell you what to expect.  Some trend closer to \"activity\", but some of the games are surprisingly engaging.  There's even one in particular that's so complicated we haven't even tried to learn it yet, about space colonization.  It looks like a full-blown 4X strategy game using nothing but multi-colored pyramids.\n\nWe specifically like one with a \"volcano\" mechanic that feels a little like... checkers, I think?  Only with a depth component, and more planning ahead required.  It's a lot of fun.  There's a quicker swapping logic game I like too, and a worker placement sorta thing that's neat.  More than enough to keep coming back to, and we've still yet to try each idea.\n\nIt's from the folks who also made Fluxx.  Whether or not you enjoy Fluxx has no bearing at all whatsoever on whether you will enjoy this.  I mean it.  If you don't know what I'm talking about, don't worry about it.\n\n## Gloomhaven\n\n[Gloomhaven](http://www.cephalofair.com/gloomhaven) is a beast.  If you've heard of \"legacy\" games, where each playthrough changes mechanics permanently for subsequent playthroughs, this is that to the extreme.  This is basically DM-less tabletop RPG in a box, or at least as close as you're gonna get.  You take characters from the box, of which there are a ridiculous amount, some you're not even allowed to touch yet, and venture forth on a campaign.  Each sit-down is a few hours and comprises a \"scenario\", and successive scenarios follow a thread and features side quests and secret quests and all kinds of other random events.  Your results from each scenario might influence what paths are available to you.  You have to travel on roads and resolve events to get between scenario locations, which your party's make up may affect.  There are over 100 scenarios.  It's a really really huge game.\n\nI'm especially recommending it as a two player game.  It absolutely works with more, but starts to really take a long time.  It also specifically fits for us a two-player game.  We love playing Dungeons and Dragons but we're also adults, so we're happy to get our group together once a month, and often can't.  This is a great alternative for just the two of us if we have an afternoon to spare just ourselves.  It simulates the combat portion of a DnD session with automated enemies.  It's also very easy to insert another player into an already-in-session campaign for a one-off session, there's instructions for character creation at the appropriate level to participate.  \n\nThe hilarious thing about it to me is that a lot of the bulk comes from all these differently themed tiles.  And, like, that's *awesome*.  The art is amazing, and really draws you in to the scenario.  But from strictly a *game* standpoint?  One 6x3 hallway works just as well as another.  Yes, it is cool that there's lava and sunken ship and adobe and dungeon and all that, but that box is just silly big.  There's also all manner of detritus, and all of it just means \"obstacle\".  A computer game doesn't take up more physical space on your self to pack in those textures.  A board game does not have that luxury:\n\n![box pic](https://i.imgur.com/ZMR2dSs.jpg)\n\nThat said, I meticulously use each and every proper tile in the scenario setup as prescribed.  I'm not a heathen.  Yes, it can take a while to set up a scenario.  No, we have not been able to close it since we opened it the first time.  Yes, it's worth it.\n\n## Diplomacy\n\nEvery gamer is different, so this is not everyone's preference by far, but one thing I tend to dislike in games is luck.  I prefer strategy and control, and don't like when my plans get foiled by a series of unlucky rolls.\n\nEverything that Risk is, [Diplomacy](https://avalonhill.wizards.com/games/diplomacy) isn't.  It's superficially similar, with military units moving around on a map, but you will find not one die in the box.\n\nInstead each player will submit a list of orders every turn, one for each of their units.  These orders really just boil down to \"Move\" or \"Support\", and boats can help move armies across water.  All orders from all players are resolved as if simultaneous.  Battles happen when two units attempt to move into the same region, and whichever movement had more support wins.  If there's a tie, neither gets it and they both bounce out - which can have a cascading effect on other other orders, too.\n\nTo prevent this, before submitting orders there is a \"negotiation\" phase.  The players can talk among themselves, one on one or in small groups.  You either set a time limit or wait for a consensus on \"ready\" - doing the latter, I had a full game last 72 hours once before we finally called a draw.\n\nWhile you can talk and plan and scheme together, all orders are submitted privately and then resolved together in public.  So, you know, people lie.  You can promise a support but then move out of the way instead, or suddenly move in and take advantage of a weak spot your ally had a non-aggression pact with you about.  The tables turn quickly - the number of units you command always equals the number of starred territories you control, so as you capture more you build more and more units, and your opponents lose theirs.\n\nThe backstabbing is *ruthless*.  This game is not for the weak of heart, and truly works best with a group of exactly seven which is tricky, but is a worthwhile experience if you don't care about keeping your friends.\n\n## Parcheesi\n\nParcheesi is a classic game wherein players must roll dice to free pawns from their start and advance around their board to the home.\n\nIt is about [2000 years older](https://en.wikipedia.org/wiki/Pachisi) than any game on this list and holds up, dangnabbit.\n\nIt's a dead simple set of rules, but gameplay stays tense and makes you hate your friends.  It's brutal, absolutely brutal. Early leads aren't always significant, late comebacks aren't always successful, and it often comes right down to the wire.  Go play some Parcheesi.\n\n## Captain Sonar\n\nThis is more of an Honorable Mention because I have not played this game.  I would very much like to, though.\n\n[Captain Sonar](https://www.matagot.com/en/catalog/details/jeux-expert/1/captain-sonar/808) is another real-time game that pits two submarine crews against each other.  Each player assumes a different operational role, and they must work together covertly and simultaneously to find and destroy the other team while evading their attacks.\n\nIt says it can be played with 2-8 players, but it seems to be designed to shine with the full 8, with teams of four.\n\nI obviously can't talk too much about it but it just sounds so cool.\n\n## Your Turn\n\nPlayed something special?  Tell us why it rocks!\n\nPhoto by Christopher Paul High on Unsplash",
    "title": "Interesting Board Game Mechanics"
  },
  {
    "cover_image": "https://res.cloudinary.com/practicaldev/image/fetch/s--S9pKHEWT--/c_imagga_scale,f_auto,fl_progressive,h_420,q_auto,w_1000/https://thepracticaldev.s3.amazonaws.com/i/qanfjonqdf9a0swnj8mm.jpg",
    "date": "2019-08-19T14:02:41.762Z",
    "description": "",
    "tags": "beginners, help, discuss",
    "markdown": "In a [previous post](https://dev.to/deciduously/towards-complexity-341i), I discussed a project I'm working on to level up the complexity present in my portfolio.  After a few days of deliberation and prototyping I have decided to implement this application in Rust, rendering to an HTML5 canvas via WebAssembly.\n\nI got a prototype working with some clickable buttons using a [previous experiment](https://github.com/deciduously/dots) as an example, but it was brittle.  Every individual region had its own separate detection and handling logic - a mess to tweak or modify.  I decided I wanted a better abstraction over the canvas before going any further, for blood pressure purposes.\n\nFast forward another two days, and I've essentially outlined a UI framework.  I've decoupled the rendering from the game logic to the point where it could be separated out into its own external standalone library.   It provides a set of traits you can implement for your game's types which fully handle creating the canvas element, mounting your app to it, and handling clicks.  All you need to do is plug in the drawable widgets and it organizes your layout for you.\n\nHow does this not always happen?  Or, rather, *does* this always happen?  Does any sufficiently large project end up with its own highly decoupled bits of logic like this?  Does the fact that I'm writing one from scratch mean I should be using a \"real\" framework instead?  For this project I don't care, it's specifically an educational experience so I don't mind the extra labor, but would this sort of thing be a flag for you in a \"real\" project?  How much of this would you let yourself implement from scratch before exploring the ecosystem?  The extra control is nice, but it's time consuming, and this problem can be crowd-sourced.\n\nAdditionally, if you've found yourself with a DIY framework in the course of writing an application, what drives you to decide whether or not to actually separate and generalize it for public consumption?  I don't know if the world needs another homebrew canvas UI framework, but if I've gone and written one anyway, maybe it's worthwhile to throw it out there.  That said, it's also a whole other set of time-consuming tasks unrelated to this project.\n\n*Photo by Chris Abney on Unsplash*",
    "title": "Oops, I'm Making A Framework"
  },
  {
    "cover_image": "https://res.cloudinary.com/practicaldev/image/fetch/s--Y4hPNjmr--/c_imagga_scale,f_auto,fl_progressive,h_420,q_auto,w_1000/https://thepracticaldev.s3.amazonaws.com/i/secp1t029jvyrsftd5ew.jpg",
    "date": "2019-08-27T22:43:23.996Z",
    "description": "",
    "tags": "devjournal, rust, webassembly",
    "markdown": "# More Fun With WebAssembly\n\nIn the past week, I've fallen into the following rabbit holes wholly outside of the necessary requirements while getting my new side project off the ground. Here's how I've gotten out.\n\n## Dynamic dispatch in Rust\n\nRust binaries can bloat pretty quickly, and one way to mitigate this is to prefer dynamic dispatch (i.e. `Box<dyn Trait>`) to monomorphization (`fn<T: Trait>(obj: T) {}`). In brief, the latter generic function syntax will create a completely separate function implementation in your binary for each type it's used with, and will select the properly typed version at compile time. The former will not bind this function call at compile time, and instead merely ensure that the trait indicated is implemented. It will then _dynamically_ bind the method call at runtime for the type it's ultimately called from.\n\nI rewrote all my generic functions to take trait objects and my bundle got smaller, YMMV.\n\nAs it turns out, this is not an insignificant rewrite. One thing to note is that while a `Box<dyn Trait>` is `Sized` (because a `Box` is sized), a _trait object_ (the `dyn Trait` part) by definition cannot be. The type is unknown, all we do know is that it implements this interface, and the method calls will be dispatched dynamically at runtime. This means you'll need to do some manual plumbing if you want to automate trait-to-trait machinery, and be prepared to get up close and personal with the borrow checker. I'm still not quite sure I've got it right, but it _does_ compile.\n\nAs an example, I've got two related traits, `Drawable` and `Widget`. A `Drawable` is a type that knows how to paint itself to the canvas, and a `Widget` is an organizational component that contains a 2d grid of child `Widget`s.\n\nSome widgets are also `Drawable`, of course, so that eventually something gets drawn to the screen. The eventual idea is to provide a set of `Widget`s generic enough that games built on top of this library (or whatever) never need to manually implement `Drawable`, they can just compose `Widgets` like `Text` and `Button` and `Area` which handle all the details, and I'm using the game I'm building on top of it to drive what widgets need writing.\n\nThe easiest way I could figure out how to make this work is to have implementors of this trait write a function that returns some other type, `MountedWidget`:\n\n```rust\n/// Trait representing things that can be drawn to the canvas\npub trait Drawable {\n    /// Draw this game element with the given top left corner\n    fn draw_at(&self, top_left: Point, w: WindowPtr) -> Result<Point>;\n    /// Get the Region of the bounding box of this drawable\n    fn get_region(&self, top_left: Point, w: WindowPtr) -> Result<Region>;\n}\n\n/// Trait representing sets of 0 or more Drawables\n/// Each one can have variable number rows and elements in each row\npub trait Widget {\n    /// Make this object into a Widget\n    fn mount_widget(&self) -> MountedWidget;\n```\n\nThe `MountedWidget` provides its own `Drawable` implementation that knows how to methodically draw its way through a grid of children, and optionally contain a raw `Drawable` itself:\n\n```rust\n/// A container struct for a widget\npub struct MountedWidget {\n    children: Vec<Vec<Box<dyn Widget>>>,\n    drawable: Option<Box<dyn Drawable>>,\n}\n\n```\n\nPart of me thinks I should be able to streamline this even further and avoid allocating an intermediary struct, but this setup got me something working. The unfortunate part is that as written every widget gets re-created and dropped for every frame - clearly the way to go is to mount it all first and adjust as needed but it's a start, at least.\n\n## Crate-in-a-crate\n\nI've said it before and I'll say it again: `cargo` is the crème de la crème of package managers. Everyone else is missing out.\n\nOne way I hoped to leverage it was by pulling out my Canvas mounting and drawing stuff as its own crate, and letting incremental compilation cache the build separately. As it turns out, this was really really easy. Here's what a standard library with three modules might look like, directory-wise:\n\n```\n$ tree\n.\n├── Cargo.toml\n├── LICENSE\n├── README.md\n└── src\n    ├── drawing.rs\n    ├── game.rs\n    └── lib.rs\n\n1 directory, 6 files\n\n```\n\nTo turn your \"drawing\" module into its own crate, make it look like this:\n\n```\n.\n├── Cargo.toml\n├── LICENSE\n├── README.md\n└── src\n    ├── drawing\n    │   ├── Cargo.toml\n    │   ├── LICENSE\n    │   ├── README.md\n    │   └── src\n    │       └── lib.rs\n    ├── game.rs\n    └── lib.rs\n\n```\n\nThat's all! In `Cargo.toml` for the parent crate, just add the dependency:\n\n```toml\n[dependencies.drawing]\npath = \"src/drawing\"\n```\n\nIt could not be easier, and the efficiency gained makes a real difference especially with these hefty WASM builds. Feel free to grab that directory and plop it anywhere you like (i.e. hosted in a git repo), you can point your `Cargo.toml` where you need.\n\n## Size optimization\n\nThis [link](https://rustwasm.github.io/book/reference/code-size.html#optimizing-builds-for-code-size) in the RustWasm book has some good tips. You need to install the [Binaryen](https://github.com/WebAssembly/binaryen) toolkit to get the full benefit - it can run further speed and size optimizations on your compiled WASM output beyond what LLVM will do via `rustc`. You'll need to have [`cmake`](https://cmake.org/) installed, which is available in all major repositories (`apt`,`homebrew`,`chocolatey`, etc.)\n\n```\n$ git clone https://github.com/webassembly/binaryen\n$ cmake . && make\n```\n\nIt will take a little while. There's several frontends we won't be using, see the readme for usage. I just symlinked `wasm-opt` to my user's path:\n\n```\n$ ln -s /home/ben/code/extern/binaryen/bin/wasm-opt /home/ben/.local/bin/\n```\n\nI then wrote a script to handle the `wasm-opt` call:\n\n```sh\n#!/bin/bash\nPKGDIR='pkg'\nBINARY='fivedice_bg'\nWASM=\"$PKGDIR/$BINARY.wasm\"\n\nfunction wasm_size {\n    wc -c $1\n}\n\nfunction echo_size {\n    echo \"$(eval wasm_size $1)\"\n}\n\nfunction extract_size {\n    wasm_size $1 | sed 's/^\\([0-9]\\+\\).*/\\1/'\n}\n\n# $1 = target $2 = focus $3 = level\nfunction shrink {\n    ARG='-O'\n    if [ \"$2\" = \"size\" ]; then\n        if [ \"$3\" = \"aggro\" ]; then\n            ARG=\"${ARG}z\"\n        else\n            ARG=\"${ARG}s\"\n        fi\n    else\n        if [ \"$3\" = \"aggro\" ]; then\n            ARG=\"${ARG}3\"\n        fi\n    fi\n    COMMAND=\"wasm-opt $ARG -o $1 $WASM\"\n    echo $COMMAND\n    eval $COMMAND\n}\n\nfunction choose_smaller {\n    NORMAL='_normal'\n    AGGRO='_aggressve'\n    NORMAL_TARGET=\"${PKGDIR}/${BINARY}${NORMAL}.wasm\"\n    AGGRO_TARGET=\"${PKGDIR}/${BINARY}${AGGRO}.wasm\"\n    shrink $NORMAL_TARGET $2 $3\n    NORMAL_SIZE=\"$(eval extract_size $NORMAL_TARGET)\"\n    shrink $AGGRO_TARGET $2 $3\n    AGGRO_SIZE=\"$(eval extract_size $AGGRO_TARGET)\"\n    if [ $NORMAL_SIZE -lt $AGGRO_SIZE ]; then\n        echo \"Normal settings smaller, saving...\"; mv $NORMAL_TARGET $WASM; rm $AGGRO_TARGET;\n    else\n        echo \"Aggressive settings smaller, saving...\"; mv $AGGRO_TARGET $WASM; rm $NORMAL_TARGET;\n    fi\n}\n\n# parse args\nfor i in \"$@\"\ndo\ncase $i in\n    -f=*|--focus=*)\n    FOCUS=\"${i#*=}\"\n    shift\n    ;;\n    -l=*|--level=*)\n    LEVEL=\"${i#*=}\"\n    shift\n    ;;\n    *)\n    # unknown option\n    ;;\nesac\ndone\n# last line is target, non-opt, no equals sign\nif [ -n $1 ]; then\n    TARGET=$1\nfi\n\necho_size $WASM\nif [ -z $FOCUS ]; then\n    FOCUS_STR='speed'\nelse\n    FOCUS_STR=$FOCUS\nfi\necho \"Shrinking, optimizing for ${FOCUS_STR}.\"\nif [ \"$LEVEL\" = \"aggro\" ]; then\n    echo \"Using aggressive optimizations.\"\nfi\nif [ \"$FOCUS\" = \"size\" ]; then\n    choose_smaller $1\nelse\n    shrink $WASM $FOCUS $LEVEL\nfi\necho_size $WASM\n\nexit\n```\n\nThere's also a Makefile to call it for me:\n\n```makefile\n.PHONY: all clean help\n\nRUSTCLEAN=cargo clean\nRUST=wasm-pack build\nPKGDIR=pkg\nEXEC=fivedice_bg.wasm\nOPT=./shrink-wasm.sh -f=speed -l=aggro\n\nall: $(PKGDIR)/$(EXEC)\n    $(OPT)\n\n$(PKGDIR)/$(EXEC):\n    $(RUST)\n\nclean:\n    $(RUSTCLEAN)\n\nhelp:\n    @echo \"Usage: make {all|clean|help}\" 1>&2 && false\n```\n\nThe script passes the proper args to `wasm-opt` for either size or speed, and aggressive or normal. If you choose size, it runs it both with aggressive or not and saves the smaller of the two. To tweak it, set the options in the OPT line of the makefile. Seems like I should be able to get some mileage out of this setup for now.\n\nThis project had a rabbit-hole-in-a-rabbit-hole writing the `extract_size` function in the bash script. The `sed` call was my first solution. Then I decided for some odd reason I wanted to try to do it without a call or subshell, using string substitutions like the argument matching or something. What a waste of a morning. I'm sure there's a simple solution staring at me in the face, but I didn't find it and even if I had it would have made _no difference_. Why do we do this to ourselves?\n\n## Debugging\n\nThis is less of a rabbit hole so much as a way around them.\n\nUse [console_error_panic_hook](https://github.com/rustwasm/console_error_panic_hook). With it, when your module panics you get actual useful error output to the browser console instead of just \"Unreachable executed\". This is obviously an improvement.\n\nAlso, `wasm-pack build` runs a release build by default, with no debug symbols. When debugging, use `wasm-pack build --debug` or add `debug = true` to your `Cargo.toml`. Now your errors will actually have the name of the Rust function that tripped instead of `webassembly[37]` or some nonsense. I didn't realize this for too long and thought debugging WASM apps was just like that. It _doesn't have to be like that_.\n\n## Stay tuned\n\nEven with all this time....alternatively spent, the _thing does the thing_ and my little grid of test widgets is accurately painted to the canvas, so I chalk it up as a successful week. Up next, Ben attempts to provide a procedural macro-style DSL! This should be a _mess_, you won't want to miss it.\n\n*Photo by Gary Bendig on Unsplash*\n",
    "title": "In And Out Of Rabbit Holes"
  },
  {
    "cover_image": "https://res.cloudinary.com/practicaldev/image/fetch/s--CaCRlbFk--/c_imagga_scale,f_auto,fl_progressive,h_420,q_auto,w_1000/https://thepracticaldev.s3.amazonaws.com/i/6n0p3ps5i1mum48gh79p.jpg",
    "date": "2019-08-29T15:17:17.886Z",
    "description": "",
    "tags": "discuss, javascript, opensource, healthydebate",
    "markdown": "There has been some [discussion](https://www.reddit.com/r/javascript/comments/cvo87k/popular_javascript_library_starts_showing_ads_in/) on Reddit and likely Twitter/HN/elsewhere about this topic, but I hadn't seen it come up here yet.\n\nThe problem: [standard](https://standardjs.com/), a widely used and highly opinionated linter for JavaScript, recently started including advertisements served straight to your terminal when you install the tool, as reported by [ZDNet](https://www.zdnet.com/article/popular-javascript-library-starts-showing-ads-in-its-terminal/).  Check out that article for a screengrab of a banner that gets served, pushing [LogRocket](https://logrocket.com/).\n\nNaturally, this is *controversial*.  One one hand, some of these OSS projects are underfunded, and need to monetize more effectively if they hope to continue providing value.  On the other hand, *there's now ads in your freaking terminal too*.  Do you want these clogging up your CI/CD logs?  Is this yet another step towards the dystopia of cyberpunk hysteria?  Or, is it just not a big deal?  We can choose to use or not use this product, and should do so and move on without getting up in arms.\n\nHow do you feel about this practice?  Will you be removing `standard` from your toolset as a result?  How should the ecosystem as a whole handle this idea?\n\nI don't write a *ton* of JavaScript, but when I do I generally have used `standard`.  I'm still not sure whether or not this news will change that preference.\n\n*Photo by Darren Chan on Unsplash*",
    "title": "Ads In Your Linters"
  },
  {
    "cover_image": "https://res.cloudinary.com/practicaldev/image/fetch/s--IU8h5nAQ--/c_imagga_scale,f_auto,fl_progressive,h_420,q_auto,w_1000/https://thepracticaldev.s3.amazonaws.com/i/gyjzqdqurdyhfr6z3hsq.jpg",
    "date": "2019-09-03T23:33:41.716Z",
    "description": "",
    "tags": "devjournal, rust",
    "markdown": "Last week, I promised a dive into Rust procedural macros as I work to design a DSL for my `Widget` UI building-block trait.  What I've learned is not to ever promise things like that, because I didn't even touch that aspect this week.  You may want to scooch back off the edge of your seat for at least another week.\n\nInstead, my `Widget`s are clickable now!  A `Button` you can't click is pretty useless, so I figured I'd get that system functional before trying anything fancy on top of it.\n\n## Callbacks\n\nIn order to keep the rendering stuff decoupled from the game logic, I need users of this library to be able to define clickable functionality however they please.  The solution I settled on is a little bit Flux-ish - to create a clickable widget, you provide a callback that returns an action type.  When a click is registered, the grid dives through its children to see where exactly the click was located.  If a match is found, that action will bubble up through successive `handle_click` calls until some parent widget above it decides to handle that action.\n\nThis affords a pretty high degree of flexibility - *any* widget in your application can choose to handle a message.  This allows you to use container widgets that can handle their children as a group, and only pass up what's necessary for a global state change if needed.\n\nThe first problem was representing this callback in a way that's clone-able and easy to store in a struct.  I ended up using an [`Rc`](https://doc.rust-lang.org/std/rc/struct.Rc.html), or reference-counted smart pointer:\n\n```rust\npub struct Callback<T> {\n    f: Rc<dyn Fn() -> T>,\n}\n\nimpl<T> Callback<T> {\n    /// Call this callback\n    pub fn call(&self) -> T {\n        (self.f)()\n    }\n}\n\nimpl<T> Clone for Callback<T> {\n    fn clone(&self) -> Self {\n        Self {\n            f: Rc::clone(&self.f),\n        }\n    }\n}\n```\n\nTo construct them, you can call `Callback::from()` on a closure, as used in the demo app:\n\n```rust\nlet button = Button::new(\n    // Display name\n    &format!(\"{:?}\", self.value),\n    // Optional size, if None will calculate based on display name\n    Some((VALUES.die_dimension, VALUES.die_dimension).into()),\n    // Border color\n    Color::from_str(\"black\").unwrap(),\n    // Click action\n    Some(Callback::from(move || -> FiveDiceMessage {\n        FiveDiceMessage::HoldDie(id)\n    })),\n);\n```\n\nThe caveat is that I haven't figured out how not to require that the return type have a `'static` lifetime:\n\n```rust\nimpl<T, F: Fn() -> T + 'static> From<F> for Callback<T> {\n    fn from(func: F) -> Self {\n        Self { f: Rc::new(func) }\n    }\n}\n```\n\nThis is part of what led me towards the action-reducer type thing - the actions themselves can be just plain data like the example!  You define an enum for your messages:\n\n```rust\n#[derive(Debug, Clone, Copy)]\npub enum FiveDiceMessage {\n    HoldDie(usize),\n    RollDice,\n    StartOver,\n}\n```\n\nAnd then a reducer to handle them:\n\n```rust\nimpl Game {\n    // ..\n\n    /// Handle all incoming messages\n    fn reducer(&mut self, msg: FiveDiceMessage) {\n        use FiveDiceMessage::*;\n        match msg {\n            HoldDie(idx) => self.hold_die(idx),\n            RollDice => self.roll_dice(),\n            StartOver => self.reset(),\n        }\n    }\n\n    // ..\n}\n```\n\nIt's not a real \"reducer\", we're mutating in place instead of using pure functions, but it's a similar pattern.\n\nIdeally, it'd be nice to be able to accept more generic callbacks, and not lock users into this pattern.  I'm good with this for now though.  However, It was a little bit tricky integrating this into my `Widget` definition.  In the previous post, I gave the trait definitions I was working with:\n\n```rust\n/// Trait representing things that can be drawn to the canvas\npub trait Drawable {\n    /// Draw this game element with the given top left corner\n    /// Only ever called once mounted.  Returns the bottom right corner of what was painted\n    fn draw_at(&self, top_left: Point, w: WindowPtr) -> Result<Point>;\n    /// Get the Region of the bounding box of this drawable\n    fn get_region(&self, top_left: Point, w: WindowPtr) -> Result<Region>;\n}\n\n/// Trait representing sets of 0 or more Drawables\n/// Each one can have variable number rows and elements in each row\npub trait Widget {\n    /// Get the total of all regions of this widget\n    fn get_region(&self, top_left: Point, w: WindowPtr) -> Result<Region>;\n    /// Make this object into a Widget.  Takes an optional callback\n    fn mount_widget(&self) -> MountedWidget;\n}\n```\n\nI need to add a method to `Widget` that detects a click and bubbles up whatever the callback returns:\n\n```rust\npub trait Widget {\n    // ..\n    /// Handle a click in this region\n    fn handle_click(\n        &mut self,\n        top_left: Point,\n        click: Point,\n        w: WindowPtr,\n    ) -> Result<Option<???>>;\n}\n```\n\nThe method needs to return whatever is coming out of these stored callbacks if the passed click falls inside this widget.  Thing is, `Callback<T>` has gone and gotten itself all generic.  This poses a problem, because we can't parameterize the trait itself with this type, like this:\n\n```rust\npub trait Widget<T> {\n    // ..\n    /// Handle a click in this region\n    fn handle_click(\n        &mut self,\n        top_left: Point,\n        click: Point,\n        w: WindowPtr,\n    ) -> Result<Option<T>>;\n}\n```\n\nI need to be able to construct `Widget` trait objects, and that `T` is `Sized`.  That's no good - a trait object is a [dynamically-sized type](https://doc.rust-lang.org/nomicon/exotic-sizes.html) and *cannot* have a known size at compile time.  Depending on a monomorphized generic method means that you do have that information - you can't have your cake and eat it too.  I kinda blew past this point last time but it bears a little more explanation.\n\n## Trait Objects\n\nThis library utilizes dynamic dispatch to allow for different applications and different backends to swap in and out using a common interface.  To utilize it, you instantiate the following struct:\n\n```rust\n/// Top-level canvas engine object\npub struct WindowEngine {\n    window: Rc<Box<dyn Window>>,\n    element: Box<dyn Widget>,\n}\n```\n\nThe `Widget` and `Window` traits just define some methods that need to be available - they don't describe any specific type.  When we actually do put a real type in a `Box` to put in this struct, we completely lose the type information and only retain the trait information.  A [vtable](https://en.wikipedia.org/wiki/Virtual_method_table) is allocated instead with pointers to each method the trait specifies, and the pointer to it actually *also* contains this vtable pointer to complete the information needed to run your code.  This means, though, that we can't use monomorphized generic types behind the pointer, because we literally don't even know what type we have.  It's all handled through runtime reflection via these vtable pointers, you cannot use anything else.  This is a good thing, it lets us define `Widget`s of all different shapes and sizes (memory-wise) and use them all identically.  That's why `Widget<T>` is so problematic, though - it requires knowing all about what types are in play at compile time, which we emphatically do not.\n\n## Associated Types\n\nLuckily there's a simple, ergonomic solution.  Instead of parameterize the trait, you can just associate a type as part of the trait definition:\n\n```rust\npub trait Widget {\n    type MSG; // Associated message type\n\n    /// Handle a click in this region\n    fn handle_click(\n        &mut self,\n        top_left: Point,\n        click: Point,\n        w: WindowPtr,\n    ) -> Result<Option<Self::MSG>>;\n}\n```\n\nNow we can parameterize the instantiated struct without needing the `Widget` definition itself to carry any baggage:\n\n```rust\npub struct WindowEngine<T: 'static> {\n    window: Rc<Box<dyn Window>>,\n    element: Box<dyn Widget<MSG = T>>,\n}\n```\n\nNow when the vtable is created, it still has all the information it needs for your specific application's state management without constraining your type at all beyond `'static`.  The WindowEngine itself gets monomorphized with that type, i.e. `WindowEngine<FiveDiceMessage>`, so all `Widgets` this `WindowEngine` contains will use the same type.\n\nWhen you write this type, you just fill it in at the application level:\n\n```rust\nimpl Widget for Die {\n    type MSG = FiveDiceMessage; // Specify associated type\n    fn mount_widget(&self) -> MountedWidget<Self::MSG> {\n         // ..\n    }\n    fn get_region(&self, top_left: Point, w: WindowPtr) -> WindowResult<Region> {\n        // ..\n    }\n    fn handle_click(\n        &mut self,\n        top_left: Point,\n        click: Point,\n        w: WindowPtr,\n    ) -> WindowResult<Option<Self::MSG>> {\n        // ..\n    }\n}\n```\n\nAssociated types are a feature I knew about from using some standard library traits.   For example, [std::str::FromStr](https://doc.rust-lang.org/std/str/trait.FromStr.html) has you specify the error type to use:\n\n```rust\nimpl FromStr for Color {\n    type Err = WindowError; // Associated Err type\n\n    fn from_str(s: &str) -> std::result::Result<Self, Self::Err> {\n        match s {\n            \"black\" => Ok(Color::new(0, 0, 0)),\n            \"red\" => Ok(Color::new(255, 0, 0)),\n            \"blue\" => Ok(Color::new(0, 0, 255)),\n            \"green\" => Ok(Color::new(0, 255, 0)),\n            // ..\n        }\n    }\n}\n```\n\nI hadn't thought about a use case where I'd need to write my own trait with one of these until I fell into the situation backwards.  So it goes.\n\n### Lingering Concern - PhantomData?\n\nThere's one weird bit that I don't feel fully comfortable with.  I have a generic `Text` widget designed to just plop a string on the canvas, that's not clickable.  Its `handle_click` method doesn't return anything, so I use the `None` variant in the `Widget` impl:\n\n```rust\nimpl<T: 'static> Widget for Text<T> {\n    type MSG = T;\n    // ..\n    fn handle_click(&mut self, _: Point, _: Point, _: WindowPtr) -> Result<Option<Self::MSG>> {\n        Ok(None)\n    }\n}\n```\n\nHowever, this still requires that we parameterize `Text` with the message type of this particular widget tree, even though it's never used, because the return type still contains the `Some(T)` variant's type.  This is what gets it to stop yelling at me:\n\n```rust\n/// A widget that just draws some text\npub struct Text<T> {\n    phantom: std::marker::PhantomData<T>,\n    text: String,\n}\n\nimpl<T> Text<T> {\n    pub fn new(s: &str) -> Self {\n        Self {\n            phantom: std::marker::PhantomData,\n            text: s.into(),\n        }\n    }\n}\n```\n\nPer the [docs](https://doc.rust-lang.org/beta/std/marker/struct.PhantomData.html), `PhantomData` is a zero-sized type that just \"tells the compiler that your type acts as though it stores a value of type T, even though it doesn't really.\"  This sounds like what I'm doing here, but I don't have a good sense of whether this is a kludge that I should try to refactor or the correct way to handle this situation. \n\n## Oh, my!\n\nQuestions and doubts aside, it all works as planned.  Maybe, *juuuust* maybe, we'll hit up those procedural macros sometime.\n\n*Photo by 🇸🇮 Janko Ferlič - @specialdaddy on Unsplash*",
    "title": "Callbacks, Trait Objects & Associated Types, Oh My!"
  },
  {
    "cover_image": "https://res.cloudinary.com/practicaldev/image/fetch/s--2gu6x8BQ--/c_imagga_scale,f_auto,fl_progressive,h_420,q_auto,w_1000/https://thepracticaldev.s3.amazonaws.com/i/mp21x7f2tmfm0l6tcyhx.jpg",
    "date": "2019-09-06T11:53:07.498Z",
    "description": "",
    "tags": "rust, beginners, tutorial, patterns",
    "markdown": "# Matchmaking Like Its 2001\n\nWe're going to help John McCrea of Cake find the woman of his slightly sarcastic, oddly specific dreams.  He's a particular man:\n\n{% youtube X5KmB8Laemg %}\n\nYep, you and I both think it: this sounds like a job for the Rust compiler.  This band was truly ahead of its time.  Let's model the problem:\n\n```rust\n/// Girl type\nstruct Girl {}\n\nimpl Girl {\n    /// Construct a Girl\n    fn new() -> Self {\n        Self {}\n    }\n}\n\n/// Determine whether given girl matches spec\nfn is_dream_girl(girl: &Girl) -> bool {\n    // we don't know anything about spec yet, so odds are no\n    false\n}\n\nfn main() {\n    let girl = Girl::new();\n    println!(\"Match: {}\", is_dream_girl(&girl));\n}\n```\n\nRunning this with `cargo run` yields the expected output: `Match: false`.\n\nSo, what is it we're looking for specifically?  Luckily, our man starts right in with the preferences, on the first line he tells us he wants \"a girl with a mind like a diamond\".  Let's add a member field to test for:\n\n```rust\n#[derive(Clone, Copy, PartialEq)]\nenum Mind {\n    Computer,\n    Diamond,\n    Garden,\n    Scalpel,\n    Sieve,\n    Unknown,\n}\n\nstruct Girl {\n    mind: Mind,\n}\n\nimpl Girl {\n    fn new(mind: Mind) -> Self {\n        Self { mind }\n    }\n}\n```\n\nNow the test function can check for the requested variant:\n\n```rust\nfn is_dream_girl(girl: &Girl) -> bool {\n    girl.mind == Mind::Diamond\n}\n\nfn main() {\n    let girl = Girl::new(Mind::Diamond);\n    println!(\"Match: {}\", is_dream_girl(&girl));\n}\n```\n\nGreat!  Now we get `Match: true` when passing in this `Girl`.  Hold on, though - we've got some more criteria.  Next, we need \"a girl who knows what's best\".  That's pretty easy - either she does or she doesn't:\n\n```rust\nstruct Girl {\n    mind: Mind,\n    knows_best: bool,\n}\n\nimpl Girl {\n    fn new(mind: Mind, knows_best: bool) -> Self {\n        Self { mind, knows_best }\n    }\n}\n\nfn is_dream_girl(girl: &Girl) -> bool {\n    girl.mind == Mind::Diamond && girl.knows_best\n}\n```\n\nJust add it to the parameter list:\n\n```rust\nfn main() {\n    let girl = Girl::new(Mind::Diamond, true);\n    println!(\"Match: {}\", is_dream_girl(&girl));\n}\n```\n\nGroovy.  Now we need \"shoes that cut and eyes that burn like cigarettes\".  It sounds like we'll need to associate some pairs of strings:\n\n```rust\ntype Attribute = (String, String);\n\n/// Girl type\nstruct Girl {\n    items: Vec<Attribute>,\n    mind: Mind,\n    knows_best: bool,\n}\n```\n\nAn attribute will be a tuple like `(\"shoes\", \"cut\")`.  We can ask for the shoes and eye attributes in the constructor:\n\n```rust\nimpl Girl {\n    fn new(mind: Mind, knows_best: bool, shoes: &str, eyes: &str) -> Self {\n        let mut ret = Self {\n            items: Vec::new(),\n            mind,\n            knows_best,\n        };\n        ret.push_item(\"shoes\", shoes);\n        ret.push_item(\"eyes\", eyes);\n        ret\n    }\n\n    fn push_item(&mut self, item_name: &str, attribute: &str) {\n        self.items.push((item_name.into(), attribute.into()));\n    }\n}\n```\n\nWe'll just check through the items to make sure we get what we want:\n\n```rust\nfn is_dream_girl(girl: &Girl) -> bool {\n    let mut found_shoes = false;\n    let mut found_eyes = false;\n    for item in &girl.items {\n        if item.0 == \"shoes\" && item.1 == \"cut\" {\n            found_shoes = true;\n        } else if item.0 == \"eyes\" && item.1 == \"burn like cigarettes\" {\n            found_eyes = true;\n        }\n    }\n    girl.mind == Mind::Diamond && girl.knows_best && found_shoes && found_eyes\n}\n```\n\nAwesome!  We just need to construct the `Girl` with the new attributes:\n\n```rust\nfn main() {\n    let girl = Girl::new(Mind::Diamond, true, \"cut\", \"burn like cigarettes\");\n    println!(\"Match: {}\", is_dream_girl(&girl));\n}\n```\n\nOkay.  Hold on.  Do you see the problem here?  Let's skim ahead...\n\n```\nI want a girl with the right allocations\nWho's fast and thorough\nAnd sharp as a tack\nShe's playing with her jewelry\nShe's putting up her hair\nShe's touring the facility\nAnd picking up slack\n...\n```\n\nIt just continues from there!  This `Girl` constructor is already getting out of hand and we just barely made it out of the first stanza.  What if John changes his mind?  He might decide something's not as important, or add a new criterion.  This code is not amenable to changes like that, every call site is dependent on this exact parameter list given in this exact order, but people don't work like that.  There could be all sorts of variations.\n\n## The Pattern\n\nLet's re-implement this program leveraging the Builder Pattern.  When a `Girl` is first constructed, we just want to start with some sensible defaults:\n\n```rust\nstruct Girl {\n    items: Vec<Attribute>,\n    mind: Mind,\n    knows_best: bool,\n}\n\nimpl Girl {\n    fn new() -> Self {\n        Self::default()\n    }\n}\n\nimpl Default for Girl {\n    fn default() -> Self {\n        Self { mind: Mind::Unknown, knows_best: false, items: Vec::new() }\n    }\n}\n```\n\nEverything else is a blank slate.  This way we can just use `Girl::new()` with no parameters and get a starting point.  To add more, we can define methods:\n\n```rust\nimpl Girl {\n    // ..\n\n    fn set_mind(&mut self, mind: Mind) -> &mut Self {\n        self.mind = mind;\n        self\n    }\n}\n```\n\nThis method takes a mutable reference and returns one, so we can construct first and adjust later:\n\n```rust\nfn main() {\n    let mut girl = Girl::new();\n    girl.set_mind(Mind::Diamond);\n    println!(\"Match: {}\", is_dream_girl(&girl));\n}\n```\n\nLet's add the rest:\n\n```rust\nimpl Girl {\n    fn push_item(&mut self, item_name: &str, attribute: &str) {\n        self.items.push((item_name.into(), attribute.into()));\n    }\n\n    fn toggle_knows_best(&mut self) -> &mut Self {\n        self.knows_best = !self.knows_best;\n        self\n    }\n}\n```\n\nNow we can add them one at a time, regardless of what we know at the time of construction:\n\n```rust\nfn main() {\n    let mut girl = Girl::new();\n    girl.set_mind(Mind::Diamond);\n    girl.toggle_knows_best();\n    girl.push_item(\"shoes\", \"cut\");\n    girl.push_item(\"eyes\", \"burn like cigarettes\");\n    println!(\"Match: {}\", is_dream_girl(&girl));\n}\n```\n\nThis is so much easier to work with as the specification grows and evolves.\n\nMore complex scenarios may require you to use a separate type, like GirlBuilder, and take ownership at each step.  This will allow you to do this all in a one-liner: `let girl = GirlBuilder::new().set_mind(Mind::Diamond).toggle_knows_best();`  This does limit your configuration options, for instance if you want to conditionally call some builder method in an `if` expression.  If possible, the non-owning pattern here is more flexible.\n\nHere's hoping we can help Mr. McCrea finally settle down after all this time.\n\n## Challenge\n\nPrepare yourself for five years from now when this song is an \"oldie\".",
    "title": "The Builder Pattern"
  },
  {
    "cover_image": "https://res.cloudinary.com/practicaldev/image/fetch/s--e_TOLsXD--/c_imagga_scale,f_auto,fl_progressive,h_420,q_auto,w_1000/https://thepracticaldev.s3.amazonaws.com/i/p19v2vsk0wq1bzom1fgc.jpg",
    "date": "2019-09-12T20:51:34.779Z",
    "description": "",
    "tags": "watercooler, fluff",
    "markdown": "I used Science and Facts to determine this.  Prior to today, this household had zero (0) DEV mugs.  Now there are two (2).  Thus, I have brewed and consumed three (3) cups of tea and can empirically state the superiority of these mugs over the outright drivel previously available.\n\nBlack, Oolong, and Rooibos trials on deck, sleep schedule permitting.\n\nI'm sorry, Star Wars mug, you're not drivel, I still love you.  It's just... science.\n\n![star wars mug](https://i.imgur.com/PeCqr8S.jpg)\n\nI won't forget you...",
    "title": "Observation: Green Tea Tastes Better From A DEV Mug"
  },
  {
    "cover_image": "https://res.cloudinary.com/practicaldev/image/fetch/s--AJ9eCaT8--/c_imagga_scale,f_auto,fl_progressive,h_420,q_auto,w_1000/https://thepracticaldev.s3.amazonaws.com/i/uoal1zm230b42dzo58ca.jpg",
    "date": "2019-09-17T16:59:49.607Z",
    "description": "",
    "tags": "beginners, cpp, rust",
    "markdown": "C++ and Rust are often compared to each other.  They occupy a similar space in terms of power and flexibility - neither has a garbage collector and thus can fit in resource-constrained domains, yet both provide richer high-level tools than a language like C which increase safety and correctness.\n\nHowever, the experience of writing a program in each can be pretty different.  Once such difference beginners in Rust will run into quickly is what happens when you pass a parameter by value.  Rust handles this situation differently than C++, and it's worth exploring why.\n\n## C++\n\nIn C++, passing by value passes a **copy** of the object into the function.  This is fine for primitives like integers - my 5 is the same as your 5.  The fact that they're distinct values in memory won't ever matter for their use, because the meaning of 5 isn't context or state dependent.  Lots of other things are, though.  When an object is copied in C++, its *copy constructor* gets called.  These have a prototype that looks like this:\n\n```cpp\nclassname (const classname &obj);\n```\n\nWhen an object is passed as a parameter to a method, this constructor is used to copy the object into the function body.  Check out that keyword at the beginning of the parameter list, \"const\".  This means we can't use this constructor to make any changes to the initial object.  Instead, it's just going to create a new copy, which is what's getting used inside any function. To illustrate, here's a simple class with just a single data member, a default constructor, and a getter and setter:\n\n```cpp\nclass CoolObject\n{\n    int coolValue;\n\npublic:\n    CoolObject()\n    {\n        coolValue = 5;\n    }\n    int getCoolValue() const\n    {\n        return coolValue;\n    }\n    void setCoolValue(int val)\n    {\n        coolValue = val;\n    }\n};\n```\n\nWe'll write a function that takes one of these objects by value and sets it to 10:\n\n```cpp\n#include <iostream>\n\nvoid setCoolValueToTen(CoolObject co)\n{\n    using std::cout;\n    cout << \"Current: \" << co.getCoolValue() << \" | Setting...\\n\";\n    co.setCoolValue(10);\n    cout << \"New: \" << co.getCoolValue() << \"\\n\";\n};\n```\n\nIf we make two of these, and use this function on one, you'd expect it to stick, right?\n\n```cpp\nint main()\n{\n    using std::cout;\n    CoolObject co1;\n    CoolObject co2;\n    cout << \"co1: \" << co1.getCoolValue() << \" | co2: \" << co2.getCoolValue() << \"\\n\";\n    setCoolValueToTen(co2);\n    cout << \"co1: \" << co1.getCoolValue() << \" | co2: \" << co2.getCoolValue();\n    return 0;\n}\n```\n\nInstead, we get the following:\n\n```\nco1: 5 | co2: 5\nCurrent: 5 | Setting...\nNew: 10\nco1: 5 | co2: 5\n```\n\nThe code inside the setCoolValueToTen() function is operating on its very own copy, made from and identical to co2 when it was passed in but entirely distinct from it.  Calling the setter on this local instance has no effect on co2, because it's no longer involved.\n\nIf you pass by value, all your changes are stuck in this new local copy and never make it back to your intended target.  A reference to the original solves this problem:\n\n```cpp\nvoid reallySetCoolValueToTen(CoolObject &co) // Just take a reference - rest is identical!\n{\n    using std::cout;\n    cout << \"Current: \" << co.getCoolValue() << \" | Setting...\\n\";\n    co.setCoolValue(10);\n    cout << \"New: \" << co.getCoolValue() << \"\\n\";\n}\n\nint main()\n{\n    using std::cout;\n    CoolObject co1;\n    CoolObject co2;\n    cout << \"co1: \" << co1.getCoolValue() << \" | co2: \" << co2.getCoolValue() << \"\\n\";\n    setCoolValueToTen(co2);\n    cout << \"co1: \" << co1.getCoolValue() << \" | co2: \" << co2.getCoolValue() << \"\\n\";\n    reallySetCoolValueToTen(co2);\n    cout << \"co1: \" << co1.getCoolValue() << \" | co2: \" << co2.getCoolValue() << \"\\n\";\n    return 0;\n}\n```\n\nThe second call works as expected:\n\n```\nco1: 5 | co2: 5\nCurrent: 5 | Setting...\nNew: 10\nco1: 5 | co2: 5\nCurrent: 5 | Setting...\nNew: 10\nco1: 5 | co2: 10\n```\n\n## Rust\n\nLet's attempt to re-implement this small program in Rust.  Here's our `CoolObject`:\n\n```rust\nstruct CoolObject {\n    cool_value: i32,\n}\n\nimpl CoolObject {\n    fn get_cool_value(&self) -> i32 {\n        self.cool_value\n    }\n    fn set_cool_value(&mut self, val: i32) {\n        self.cool_value = val;\n    }\n}\n\nimpl Default for CoolObject {\n    fn default() -> Self {\n        Self { cool_value: 5 }\n    }\n}\n```\n\nWe need a function to set the value to ten, taking the parameter by value:\n\n```rust\nfn set_cool_value_to_ten(mut co: CoolObject) {\n    println!(\"Current: {} | Setting...\", co.get_cool_value());\n    co.set_cool_value(10);\n    println!(\"New: {}\", co.get_cool_value());\n}\n```\n\nWe're already starting to see a problem - we can't just mutate values without asking first, like we can in C++.  If I hadn't included that `mut` in the parameter list, the `set_cool_value()` call would complain: \"cannot borrow `co` as mutable, as it is not declared as mutable\".  We need to specifically tell the compiler that we intend to mutate the object.\n\nLet's try to emulate the first go of the C++ version:\n\n```rust\nfn main() {\n    let co1 = CoolObject::default();\n    let co2 = CoolObject::default();\n    println!(\"co1: {} | co2: {}\", co1.get_cool_value(), co2.get_cool_value());\n    set_cool_value_to_ten(co2);\n    println!(\"co1: {} | co2: {}\", co1.get_cool_value(), co2.get_cool_value());\n}\n```\n\nAttempting to compile this code will net you an error like the following:\n\n```\nerror[E0382]: borrow of moved value: `co2`\n  --> src/main.rs:34:57\n   |\n31 |     let co2 = CoolObject::new();\n   |         --- move occurs because `co2` has type `CoolObject`, which does not implement the `Copy` trait\n32 |     println!(\"co1: {} | co2: {}\", co1.get_cool_value(), co2.get_cool_value());\n33 |     set_cool_value_to_ten(co2);\n   |                           --- value moved here\n34 |     println!(\"co1: {} | co2: {}\", co1.get_cool_value(), co2.get_cool_value());\n   |                                                         ^^^ value borrowed here after move\n\nerror: aborting due to previous error\n```\n\nAnd there's the problem.  When pass by value in C++, the compiler will just assume you know what you're doing and call a copy constructor for you, even if it doesn't really make sense.  If you haven't manually defined a copy constructor, no sweat - the compiler will do it's damndest to generate one for you and call that.  After all, you've passed by value, s this must be what you want!\n\nRust pumps the brakes.  When you pass by value, it actually **moves ownership** of the original value.  It's not copying the original object in, it's actually bringing the object from outside - but the caveat is that the calling scope no longer owns this value at all, the new function does.  When `set_cool_value_to_ten()` reaches the end of its body, this value goes out of scope!  It's dropped.  When we attempt to refer to `co2` again in the next line, we can't - it's not ours to use anymore.\n\nIn Rust, any value only has one owner.  You can borrow as many immutable references as you like, which we do when we call `get_cool_value(&self)`, or we can have one single mutable reference, like with `really_set_cool_value_to_ten(co: &mut CoolObject)`, but if there's no borrow, like with `set_cool_value_to_ten(mut co: CoolObject)`, you know ownership of this value will be moving.\n\nThis skirts the common pass-by-value bug in C++ where you think you're working with an object but you're actually just working with a copy.  C++ will just silently try to make things work, and may not be on the same page as you are.  Rust is very explicit.  It even specifically tells you that if your object did implement the `Copy` trait, it would have attempted to copy the value - but of course, this still wouldn't solve this problem.  As with C++, the solution is to refer to the original instead of move the value.  In C++, you say \"take a reference\", but in Rust, you'd call it a \"mutable borrow\":\n\n```rust\nfn really_set_cool_value_to_ten(co: &mut CoolObject) {\n    println!(\"Current: {} | Setting...\", co.get_cool_value());\n    co.set_cool_value(10);\n    println!(\"New: {}\", co.get_cool_value());\n}\n```\n\nWe also need to declare `co2` itself as mutable:\n\n```rust\nfn main() {\n    let co1 = CoolObject::default();\n    let mut co2 = CoolObject::default(); // right here\n    println!(\"co1: {} | co2: {}\", co1.get_cool_value(), co2.get_cool_value());\n    really_set_cool_value_to_ten(&mut co2); // and pass a mutable reference\n    println!(\"co1: {} | co2: {}\", co1.get_cool_value(), co2.get_cool_value());\n}\n```\n\nThis illustrates one of the reasons I prefer working with Rust over C++.  In C++, the programmer just has to know all of these details about how the language operates, and the compiler has no qualms about implicit actions that it takes.  You've got no help reading through your code to figure out where you've made this mistake, and even full awareness of this issue is insufficient to avoid it in 100% of cases.  Rust, on the other hand, doesn't let you ask for stupid things.  In this situation, the compiler was able to tell me in plain English why my code was incorrect and how to fix it.\n\n*Photo by Natalia Y on Unsplash*",
    "title": "Pass-By-Value in C++ and Rust"
  },
  {
    "cover_image": "https://res.cloudinary.com/practicaldev/image/fetch/s--lcoKLHOZ--/c_imagga_scale,f_auto,fl_progressive,h_420,q_auto,w_1000/https://thepracticaldev.s3.amazonaws.com/i/r7x03d97oxqn6df9q0xa.jpg",
    "date": "2019-09-25T12:26:43.667Z",
    "description": "",
    "tags": "help, beginners, rust",
    "markdown": "Hi folks!\n\nOver the weekend I was enlisted to produce a proof of concept demo, to pitch as part of a project proposal presentation.  Perfect!\n\nI did so, and they're happy (pleased?) with the result.  The demo I've produced is a CLI application that reads an input file from the filesystem specified at runtime.  It outputs to `stdout` and takes input from `stdin`.  Very barebones demo.  I implemented this program in Rust, and suffices for this purpose.  They are planning to screenshare during the presentation to show off the capability.\n\nHowever, it would be ideal if there were some way to share this demo easily - they could just provide a URL and get something to play with.\n\nOptions I've considered:\n\n1) Refactor into a WASM module, build a very simple JS webapp with DOM elements for inputs and outputs.  I've started doing this, but it's non-trivial.\n2) Throw the whole thing on a DigitalOcean droplet and let people ssh to the box.\n3) Re-implement the whole thing in JavaScript.\n\nI will not be doing #3, this demo has a total useful life of a single day, and it's not worth the effort.  If the project is picked up, we're starting from scratch.\n\nI did take a stab at #1, but it's not straightforward.  I hadn't anticipated this need, so it's not a completely straightforward refactor to also not break the current `stdout`/`stdin` functionality.  I think this is the nicest option, but it is not simple to produce from my current code in one day.  With a little more time, this is absolutely what I would do, but I don't want to rush it.\n\nThat leaves me with #2, but I don't really know how safe or reasonable that is. What I'm thinking is that I'd just pop the compiled executable on a droplet with all the demo input files there ready to go, and then users could log in remotely and execute from there.  Is that horrendous?\n\nPressure is low - what I've produced to date will be fine, this is a nice-to-have that would be great to deliver.  I've only got this afternoon to pull it together, though, so complexity needs to be low.\n\nHow would you solve this problem?\n\n*Aside: one of my first ever billable pieces of work was in Rust and I am just over the moon about that*.\n\n*Photo by Thomas Jensen on Unsplash*",
    "title": "Shareable CLI demo?"
  },
  {
    "cover_image": "https://res.cloudinary.com/practicaldev/image/fetch/s--hXACwaGL--/c_imagga_scale,f_auto,fl_progressive,h_420,q_auto,w_1000/https://thepracticaldev.s3.amazonaws.com/i/iapx6qiql3k0z3beelsb.jpg",
    "date": "2019-10-02T11:47:01.242Z",
    "description": "",
    "tags": "beginners, cpp, functional, devjournal",
    "markdown": "# Or Just Functional Enough?\n\nHappy [5780](https://www.hebcal.com/holidays/2019-2020), DEV!\n\nI wanted to see if I could write a [fold function](https://en.wikipedia.org/wiki/Fold_(higher-order_function)) with what I've learned so far about C++.  Clearly, the afternoon got away from me.\n\nThis is a three-part post.  This first post is largely a personal reflection.  You may also know this style as a \"ramble\" or \"rant\".  The second post is by contrast brief and focused, and discusses the small C++ experiment I mention above from a merely technical standpoint.  The final post makes it generic for collections of `std::vector<T>` and demonstrates several library functions defined in terms of that fold template.  Both parts stand alone, so feel free skip either (or, you know, both, I'm not your dad).  Not everyone likes their code examples served with a side of marginally-relevant ranting, and who am I to judge.  Pick your poison.\n\n## The Situation\n\nI started by quickly jotting down what I thought this function might resemble for input collections of `std::vector<int>` in about five minutes, just to see how far that got me.  As it turns out, after a little extra research, I hit the mark with the first successful compile.  I am still quite a C++ beginner, so a working implementation of *anything* that quickly is an achievement for me.  This was something I hadn't tried and used a library feature I'd never tried, so I had emotionally prepared myself for a small-to-medium battle to even this point before sitting down.  To have a working C++ implementation pop out just a few minutes later initially surprised me.  \n\nFor those keeping score, here is precisely where I got completely derailed.  Upon further reflection, I reasoned it shouldn't have surprised me at all, and made the mistake of wondering why it did anyway.\n\n## Modern And Hard\n\nEven though I've been building actual hands-on experience with the language lately, I still harbor an outdated preconceived notion about what using C++ is like.  It's at odds with my experience, but the fact that it *actually still is hard* in some ways makes it even tougher to shake this notion.  I do sometimes struggle writing correct and complete C++ after I've \"solved\" a problem in the abstract sense.  It's probably the hardest language I have tackled to date, but somewhere along the line I had conflated \"hard\" with \"archaic\".  C++ is a large language and you actually do need to at least somewhat understand a significant portion of how it works in order to not write horribly broken code, which is hard.  Lots of languages are large, but let you write more simple programs without getting exposed to what you don't need until you need it.\n\nMy conclusion about my disconnect here is that it's a semantic problem, and I'm pretty interested by that implication.  I somehow got the idea that \"modern\" in this context just meant \"relative to really old\" and \"modern C++\" was still in essence the same beast it's always been with some new bells and whistles, ultimately archaic compared to other languages I had spent time building comfort with, so necessarily more annoying and verbose to use but worth the effort.  When used to describe \"C++\", I heard this invented connotation without actually knowing the first thing about it.\n\nNow armed with, I don't know, *anything concrete* to form an opinion from, I disagree with that characterization.  I wish I had taken the time to examine it critically in myself earlier, because it's subconsciously diminished C++ in my mind when in fact I think I always would have enjoyed it.  What's fascinating, though, is that even though my current experiences contradict it and I rationally have worked out that I feel differently, I still initially expect all new C++ problems to be complicated at the outset even when I know how to solve them using the tools provided.\n\n### What's Modern?  What's Hard?\n\nIt's important to precisely define what I mean by these terms even when making wild blanket statements about them, because while they may be irresponsible generalizations, at the very least I want them to mean more or less what I think they mean.\n\n#### Defining Modern\n\nModern is a little easier, because I think it's actually a pretty meaningless term and any specific definition does not matter.  Whatever the working definition, it means the same thing for C++ as it does for Java or Golang or whatever.  Written out this observation is obvious on its face, and I'm unsure if my personal connotation was completely made up or I learned it from somewhere.  Either way it was not based in facts, and either way I held it for over a decade.\n\n#### Defining Hard\n\nDefining what makes a language \"hard\" is inherently, well, hard.  Most definitions are partially or wholly subjective.  While that's an interesting topic as well, in this context I am specifically attempting to keep my definition as objective as I can.\n\nIn C++, you have everything you need at your disposal to very precisely and explicitly define what you need to have the computer do at a highly granular level.  It's also almost comically easy when learning C++ to write *almost* what you mean but not quite, not spot the difference, and get unexpected results that can sometimes differ significantly from what you thought you were getting.  Debuggers can help you explore what you wrote, but not what you meant to write - you still need to understand a lot of implicit machinery to sleuth out how you got what you did.  This happens to me more often as a beginner in C++ than it has learning anything else to date.\n\nThe remedy for this as far as I can tell is knowledge - the root of the problem is usually something I had either not been taught yet, forgotten about, or not spotted, but the tooling had allowed.  Of course, this process is part of learning any new language.  In C++, though, the frequency of the problem, the complexity of the issues encountered at an early stage, the subtlety of their syntactic manifestations, the background knowledge required to understand these issues and their solutions, and the lack of or misleading guidance from the tooling all help raise the threshold for a productive output vs troubleshooting/debugging ratio.\n\nPut another way, at some point you have gained sufficient knowledge to use the language to complete work and create value in a timely fashion, that also won't ultimately lose value by messing up all over the place and needing to be fixed or replaced.  Gaining that knowledge is a pretty individual process, but it's generally proportional to work put in.  If that threshold for language A is higher than for language B and takes most devs more energy to achieve, I'm calling language A harder.  Strictly by that definition C++ is the hardest thing I've personally come across.\n\nMy perception is that even if you become an expert in C++ it still objectively has a relatively high amount of language-level friction (\"hardness\"), but it feels built from parts that themselves individually excel.  You need a high level of understanding of what all the various parts are and what they do in order to use this language effectively and safely, but becoming an expert in any language requires that.  C++ starts hitting you in the face with it much faster, but also gives you all these different, powerful ways to keep yourself safe and sane while writing the code you need.\n\n#### Hard != Bad\n\nThis wealth of features to learn exists for a reason, and it's hard to imagine a problem for which C++ is completely unsuited.  C++ has been the first tool I've learned that actually feels like it imposes around the same amount of friction regardless of the paradigm you choose to approach a solution.  You're driving a manual no matter what, so just say what you need.  It's my \"desert-island\" pick - if somehow for the rest of my life I only ever can use one programming language for every new task, at least from what I've learned C++ is a no-brainer.\n\n#### Discuss: The Weird Stuff\n\nToday I'm specifically exploring functionally-flavored C++, but there is [a zoo](https://cs.lmu.edu/~ray/notes/paradigms/) of other interesting programming paradigms out there.  My gut feeling is that C++ could be a viable, if not always optimal, choice for exploring almost any of them.  I would be curious to hear your experiences or why that is or isn't actually the case, or if you have a specific counterexample.  Tried logic programming in C++?  How'd that go?\n\n### The C++11 Experience\n\nI thought in tackling C++ I had signed up for some good old-fashioned Object-Oriented concepts and design patterns, and to be sure I have received no shortage of that stuff so far.  I knew the language had received some updates since I'd used it pre-2010, though, but I didn't understand the details of what those updates contained.  Not to give too much away, but \"some updates\" is an egregious understatement.\n\nC++11 brought with it, among many other additions, ergonomic, built-in support for first-class functions through [lambdas](https://en.cppreference.com/w/cpp/language/lambda) and a huge set of explicit tools to ensure other needed traits such as immutability.  C++ compilers have also optimized for tail-call recursion since even before that, which enables a larger set of recursive solutions to be pragmatic as well as concise.  [Templates](https://en.cppreference.com/w/cpp/language/templates), not a new feature, up the flexibility even further with what you can concisely define.  Pick a paradigm,  C++ is likely flexible enough to do what you ask provided you've got the chutzpah.\n\nAlong with all these changes has come a new set of idioms that was not previously possible with standard C++ which have overhauled both how C++ is written and taught.  While I can't vouch for everything, generally the beginner material I have seen has taught using the new features and idioms from the beginning, and introducing standard classes like \"vector\" and \"string\", instead of the older C-With-Classes type code I had started from before, which is a lot easier and less frustrating to get started writing real solutions with.  You still need to learn the fundamentals of what a C-string is, but there's no reason you can't immediately start benefiting from the safer and more flexible `string` API once you do.\n\nThe details of everything this standard adds could be its own series.  To name-drop a few C++11 goodies beyond lambdas I've immediately started leveraging are things like [range-based for-loops](https://en.cppreference.com/w/cpp/language/range-for), [type inference with `auto`](https://en.cppreference.com/w/cpp/language/auto), derived class constructor [delegation syntax](https://www.ibm.com/developerworks/community/blogs/5894415f-be62-4bc0-81c5-3956e82276f3/entry/introduction_to_the_c_11_feature_delegating_constructors?lang=en), the [`nullptr`](https://en.cppreference.com/w/cpp/language/nullptr) constant, [`enum class`](https://en.cppreference.com/w/cpp/language/enum) syntax, and new UTF [string literal](https://en.cppreference.com/w/cpp/language/string_literal) syntax.  I also appreciate the curly-brace initialization syntax, having never managed to keep the nuances of that topic straight before.\n\nThat's just the core language stuff, too, and the standard library also expanded significantly and plugged some much-needed holes.  Pulling in third-party dependencies is still a friction point for me, so the more I can lean on the standard distribution the better.  As before, I've only partially explored these additions, but I've already made use of tuples and smart pointers like [`shared_ptr`](https://en.cppreference.com/w/cpp/memory/shared_ptr).  Another important addition I haven't used myself is the [atomic operations](https://en.cppreference.com/w/cpp/atomic) library for writing threaded code.\n\nBasically, it feels like using any other modern programming language I've tried.  In retrospect this really should not be surprising to me.\n\n### And, Like, It's Almost 2020 Now\n\nThis revision was approved on August 12, 2011.  I ran the numbers, and that's actually over eight years ago now.  Granted, in some domains that's not a significant time frame, but even in slow-moving worlds there's been a lot of time for the new stuff to percolate.  This revision maintains backwards-compatibility with all existing legacy-style code, but the set of new features in this version added represent an entirely new set of idioms for writing new C++ code that focus on memory safety, performance, and ergonomics.  It almost feels like a different language than what I had started tackling the very first time around.\n\nSince that revision, we've again received new and powerful changes and tools with C++14 and C++17.  C++20 is even bigger than the previous two, more on par with C++11 in scope, as it pulls together and finalizes some long-term planned work as well as new ideas.  It's within a year of becoming the new official standard.  I've barely looked at *any* of this new stuff myself yet but some of it does bring us even more functional-flavored goodies - for a single cherry-picked example, C++14 makes [lambdas even more powerful](http://open-std.org/JTC1/SC22/WG21/docs/papers/2018/p1319r0.html) with features like polymorphic lambdas and lambdas with default arguments, among others.\n\n## Prior Experiences\n\nUsing C++ so far reminds me distinctly of two prior self-learning experiments, namely Common Lisp and Scala. Each is for a slightly different reason.  I believe even the little context I have from trying each has proved directly helpful in approaching C++ now, and I'm curious now to revisit both and see if the reverse will also be true.\n\nInterestingly, I chose to attempt both of the above languages because I had learned Clojure and highly enjoyed many but not all aspects of working with it. That's a language with very little in common with C++, except perhaps in degree of versatility.  Clojure wasn't without its complexity and pitfalls for a novice, though, and not necessarily an exact fit for any of the code that I wanted to write, though, so I wanted to explore some other similar options to see if anything stuck better.  C++ was unfortunately not even on my radar at the time as a contender, which is a shame.\n\nI'm including [Rust](https://www.rust-lang.org/) as an honorable mention.  I don't personally feel these two are that similar, but some of those differences seem to be precisely what motivated Rust to exist in the first place which is also interesting.\n\n### Multi-Paradigm: Common Lisp\n\n[Common Lisp](https://common-lisp.net/) is also a truly multi-paradigm programming language.  It's like a gigantic kit of all these different tools you can use, and really has few-to-zero opinions about how you use them and so little syntax it's all pretty easy to use once you know the basics.  This is at least at the language level - the complexity is all at the library level.  Common Lisp sometimes gets shoehorned into a category with the functional-forward [Scheme](http://www.r6rs.org/)-family lisp-alikes for cosmetic reasons, but it's really not an accurate grouping.  In fact, the Common Lisp Object System is \"arguably one of the most powerful object systems available in any language.\"  True, this quote is [according to the people that wrote the book](https://lispcookbook.github.io/cl-cookbook/clos.html), but it's precisely Common Lisp's flexibility that makes this statement defensible.  You can choose to use the CLOS or not even touch it, but it's there for you along with everything else.\n\nLike C++, this property makes the language extremely powerful and due to different design trade-offs is also capable of dramatically reducing development time.  Like C++, though, it is also full of footguns and idiosyncrasies.  \"Powerful\" and \"Easy to use\" have a tendency to be tough to package up together, because adding power generally involves adding complexity in one way or another.  This is especially true when you add a few decades of history to a \"kitchen-sink\"-style mentality.\n\nThis style language is most useful if you already know pretty well what you're doing, what you want, and how to get there, so you don't want your language to tell you want you can and can't do.  I still plan to come back someday, but I generally don't know any of those things nearly well enough yet.  Notably, CL has been this feature-rich for decades before C++11 rolled along, and still maintains a small but active and dedicated community today.  It's not going anywhere any time soon.\n\n### Functionally Object-Oriented: Scala\n\nI tried Scala to get a feel for a different [JVM](https://www.javaworld.com/article/3272244/what-is-the-jvm-introducing-the-java-virtual-machine.html) language having spent a while learning [Clojure](https://clojure.org/).  In Clojure you can largely stay within the environment provided by the language to get up and running, but you can't avoid it's fundamental nature as a hosted language by design - interop with the host platform comes up quickly even for beginners.  Standard Clojure is hosted on the JVM, and I didn't know anything about the JVM yet.  ClojureScript, which basically just Clojure but hosted on JavaScript instead, was a lot easier for me at first because I understood more or less how the underlying platform worked.  A Java stacktrace was completely foreign every time I misused a Java collection type.\n\nI also had seen Scala compared to [Haskell](https://www.haskell.org/) on multiple occasions in functional programming spaces, which I also already had spent time getting comfortable with.  That's where I'd heard of it in the first place, and this similarity sold me over just going for Java.  I gravitate towards learning tools with some direct overlap to what I already know, and I really didn't know anything about OOP but did know something about fancy type systems.\n\nI didn't get very far, because it was quickly apparent to leverage Scala effectively a healthy understanding of Java is useful first.  In a similar manner, to fully and correctly leverage everything C++ has to offer you need a healthy understanding of, well, C++.  From what I did take away, though, it feels like C++ itself covers a lot of Scala's raison d'être over Java just fine.  You don't get the same level of sophistication in your type system, but if the concern is static analysis isn't the net gain for a team comparable?\n\nScala seems suited to applications that intend to blend functional and object-oriented implementation approaches, as opposed to the more standard imperative-flavored OOP.  I don't see why C++ can't be used for this as well, at least for non-academic use-cases that aren't doing type-level research.  I may be over-simplifying the pattern, but my understanding is that you use classes to provide large-scale structure but use functional method definitions over imperative and stop coupling all your data to your logic like OOP encourages.\n\n#### Discuss: Scala-flavored C++?\n\nThis question isn't about the merits of managed vs. unmanaged languages or Scala vs C++ in any specific actual context, but rather about general language analogues.  Scala is a reaction to Java within that ecosystem designed to meet a perceived unmet need, and my hypothesis is that post 2011 C++ is already adequate in the ways the Scala folks perceived Java not to be.\n\nNow, Scala predates C++11, and Java has also undergone large changes which also address some of these original shortcomings.  Basically, whether this statement is true or not has no bearing on reality.  I'm just curious if my perception is accurate that C++ is suited for the style of program that Scala was designed to facilitate.  I will be first to admit this is not a a well-informed observation, just a beginner's perception, does anyone who actually knows more have an opinion on this?\n\n### Honorable Mention: Rust\n\nRust is currently my favorite and most-used language.  Each new project I write in Rust is teaching me something I hadn't come across before about how to write Rust well, and every time I just like the language even more for it.  It's still a niche tool and will likely remain so for a long time if not forever, but at least for personal work I've yet to find something that pushes more of my buttons.\n\n Rust targets some of the same domains where C++ currently dominates, but the subjective experience of building a program in each feels much more dissimilar to me than to either of the above.  This is extremely deliberate on the part of the Rust folks, and has also been eye-opening coming from the other side.  C++ has demonstrated quite clearly why exactly some benefits I already abstractly understood Rust provided to me were useful.  Once, what I thought was a correctly-implemented medium-sized program randomly segfaulted on some innocuous test input.  It wasn't immediately obvious to me why it was broken and somehow almost offended me as a knee-jerk reaction.  Like, a segfault?  What is this, the Triassic?\n\nNo, as it turns out, it wasn't the Triassic, it was just my fault, as usual.  I had written bad code that does a bad thing with some memory that wasn't mine to touch, and it's *my* job to fix that problem and not write such code again.  I'm completely spoiled in Rust, because even though you can still write bad or logically wrong Rust, it won't ever let you make that mistake outside of `unsafe`, so I never thought about how easy it really is to introduce subtly without that check.\n\n### ¿Porque no los dos? - C++\n\nI ultimately didn't spend long learning either language, eventually outgrowing my language-hopping phase in favor of writing actual software, and fast-forward to now I have definitively chosen C++ as the \"industry tool\" I want to focus on and hone.  I always knew I'd find it useful, but I had not anticipated how much I'm actually enjoying it.  As I learn more I enjoy it more, and expect it to become one of my most-used languages for personal projects as well eventually.  There is still a lot to know, and a lot of ways to hurt yourself like I remember, but I was expecting to step back into the dark ages to get anything done in terms of expressiveness.  This has not at all been the case.\n\nYou, C++ expert, probably could have filled me in on this, it's on me for never asking.  And, to be sure, C++ is not without it's drawbacks as well.  Like Common Lisp, the programmer bears a relatively higher portion of the burden of program structure, correctness, and soundness than with other languages.  Developers need both high knowledge and discipline to write safe, effective software, and other available stack choices may offload more of that to the computer without sacrificing functionality in your domain.  If that's the case for your project, of course you should go that route.  In terms of sheer versatility, though, C++ is selling itself to me pretty dang hard.\n\n*Photo by Michał Parzuchowski on Unsplash*",
    "title": "Overly Functional C++"
  },
  {
    "cover_image": "https://res.cloudinary.com/practicaldev/image/fetch/s--vk5AiHBF--/c_imagga_scale,f_auto,fl_progressive,h_420,q_auto,w_1000/https://thepracticaldev.s3.amazonaws.com/i/zdhqlnof5w8m2eivc21l.jpg",
    "date": "2019-10-02T11:48:00.931Z",
    "description": "",
    "tags": "cpp, beginners, devjournal, help",
    "markdown": "# C++ For Hipsters\n\nThis is part two of a three-part post, but don't worry - each part stands alone.  You don't need to read any of the first post before reading this.\n\n## The Goal\n\nThis code implements a the higher-order \"fold\" function for a `std::vector<int>`, which is a variable-size one-dimensional collection of integers available in the standard library.  The actual `int`-type is system and compiler dependent, but for this toy demo that's not a concern of mine.  For trivia, mine are 32-bit `long`s.\n\nI did this to see how hard it would be.  The answer turned out to be \"not\".\n\nThe code that appears here compiles as shown using a command like `g++ --std=c++11 -o foldtest foldtest.cpp`, and should work without modification on other compilers that support C++11.\n\n## The Humble Fold\n\nIn functional programming, the [fold function](https://dev.to/deciduously/know-when-to-fold-em-1466) is a commonly-used building block.  It abstracts away the recursive part of the function definition for a very common use case - producing an accumulated result by processing each element in a collection - into a flexible, safe API.\n\nMost widely-used mainstream languages these days like JavaScript, Java, and C++ all actually allow this sort of thing, but *most* (not all) code I see in the wild tends toward an imperative pattern.  The classic `for` loop, wherein you increment a counter to use to index into an array, or its more snazzy cousin the iterator-backed `for item in collection`, become second nature quickly for many people learning how to code. It quite often can be the better option, too, depending on your needs for the code.\n\n\n### The expected output\n\nWhen implemented correctly, we should expect the following output from our test code:\n\n```\nNums: [1, 2, 3, 4, 5]\nAccumulator: 0\nSumming...\nResult: 15\n```\n\n### The implementation\n\nThe `main()` function to generate that output looks like this:\n\n```cpp\n#include <functional>\n#include <iostream>\n#include <vector>\n\n// ..\n\nint main()\n{\n    using std::cin;\n    using std::cout;\n    using std::vector;\n    vector<int> nums = {1, 2, 3, 4, 5};\n    int acc = 0;\n    cout << \"Nums: \" << nums << \"\\nAccumulator: \" << acc << \"\\nSumming...\\n\";\n    int result = fold(nums, acc, [](int acc, int curr) { return acc + curr; });\n    cout << \"Result: \" << result;\n    return 0;\n}\n```\n\nWe define a hardcoded vector `[1,2,3,4,5]`, display it to the user, and then pass it to our `fold` function with an accumulator and the lambda to use, displaying that result.\n\nBefore implementing the fold itself, I defined a quick template to pretty-print a vector like shown in the expected output, for debugging purposes:\n\n\n```cpp\n// Pretty-print a vector\ntemplate <typename T>\nstd::ostream &operator<<(std::ostream &stream, const std::vector<T> vec)\n{\n    stream << \"[\";\n    for (int i = 0; i < vec.size(); i++)\n    {\n        stream << vec[i];\n        if (i < vec.size() - 1)\n        {\n            stream << \", \";\n        }\n    }\n    stream << \"]\";\n    return stream;\n}\n```\n\nAll that's missing is the actual `fold`:\n\n\n```cpp\n// Fold a binary operation over a vector of ints\nint fold(std::vector<int> nums, int acc, std::function<int(int, int)> func)\n{\n    int length = nums.size();\n    if (length == 0)\n    {\n        // base case - empty list\n        // Sub-problem is trivial - we're already done.  The passed accumulator holds the result\n        return acc;\n    }\n    else\n    {\n        // Calculation is not complete - sub-problem is also trivial\n        // Call function on accumulator using first element in vector as operand\n        int newAcc = func(acc, nums[0]);\n        // Create a new input from the second element onward of the current input\n        std::vector<int> newInput(nums.begin() + 1, nums.end());\n        // Recur with rest of list and new accumulator\n        return fold(newInput, newAcc, func);\n    }\n}\n```\n\nThe body is simple.  The base case simply returns, and the recursive case builds the new adjusted inputs and passes them back to the function.  The one part I had to look up was [`std::function`](https://en.cppreference.com/w/cpp/utility/functional/function), used for the type of the lambda parameter.  I had written essentially what I ended up with in pseudocode, not knowing how I'd actually need to implement the working version, only to find the exact construct I wanted actually existed.  Thanks, C++.\n\nTo verify that this code performs reasonably, I replaced the hardcoded input with a loop to populate a vector with numbers from 0 through n:\n\n```cpp\nvector<int> nums;\nfor (int i = 0; i < 43642; i++)\n{\n    nums.push_back(i);\n}\n```\n\nOn my computer, this code sums this vector in just over two seconds:\n\n```\n$ time ./foldsum\nSumming...\nResult: 952290261\nreal    0m2.171s\nuser    0m0.405s\nsys     0m1.763s\n\n```\n\nHowever, any higher value dumps core.\n\n## Call For Help\n\nOne of those hashtags is not like the others... I also have a question about extending this code.  This is an extremely limited fold function, with the type of the collection to fold over fully specified as `std::vector<int>`.  This sounds like a job for a template to me, but from what I understand C++11 doesn't fully support templated lambdas yet.  Is that more or less accurate?\n\n*Photo by Kelly Sikkema on Unsplash*",
    "title": "Overly Functional C++: The Fold"
  },
  {
    "cover_image": "https://res.cloudinary.com/practicaldev/image/fetch/s--Av_bUH0n--/c_imagga_scale,f_auto,fl_progressive,h_420,q_auto,w_1000/https://thepracticaldev.s3.amazonaws.com/i/jhwnn4ryog0mjms4is8o.jpg",
    "date": "2019-10-03T12:42:43.615Z",
    "description": "",
    "tags": "beginners, cpp, functional, devjournal",
    "markdown": "# Two-Part Series, Chapter 3\n\nWhat a plot twist!  I made almost no effort to avoid [the pun](https://en.wikipedia.org/wiki/Ben_Folds_Five) and I'm only a little sorry.\n\nDespite being a trilogy now, this post stands alone if you're familiar with the concept of the `fold` or `reduce` [higher-order function](https://en.wikipedia.org/wiki/Fold_(higher-order_function)).\n\nIn [part 2](https://dev.to/deciduously/overly-functional-c-the-fold-4kid) of yesterday's minddump, I documented my first stab at a specific fold in C++.  I had gotten stuck, though, in trying to make it generic.\n\n I've [said it before](https://dev.to/deciduously/you-lot-are-great-cea) and I'll say it again: ask DEV stuff, they know things.  Thanks to [@curtisfenner](https://dev.to/curtisfenner) and [@markboer](https://dev.to/markboer) I was able to write the intended generic `fold` function I had set out to write initially with almost no modification.  This newly-generic `fold` function is a building block, and if you give a nerd a `fold`...\n\n## Five Library Functions\n\n`BenFolds` is a class with five static member functions.  It defines `BenFolds::fold()` as a generic version of the code from part 2, and then defines `or`, `any`, `elem`, and `map` in terms of this fold.  I'll walk through each, or you can grab the [gist](https://gist.github.com/deciduously/fdb8ee23b4f3d73e4340ef85359edce6).  This gist compiled and executed successfully for me using `g++ -std=c++11 -o benfolds benfolds.cpp` on g++ 9.2.0.\n\n### Fold\n\nThis is the only definition with any substance, the rest will all specify parameters to run through this fold:\n\n```cpp\ntemplate <typename T, typename R, typename BinOp>\nstatic R fold(std::vector<T> elems, R acc, BinOp func)\n{\n    int length = elems.size();\n    if (length == 0)\n        {\n            // base case - empty list\n            // Sub-problem is trivial - we're already done.  The passed accumulator holds the result\n            return acc;\n        }\n        else\n        {\n            // Calculation is not complete - sub-problem is also trivial\n            // Call function on accumulator using first element in vector as operand\n            R newAcc = func(acc, elems[0]);\n            // Create a new input from the second element onward of the current input\n            std::vector<T> newInput(elems.begin() + 1, elems.end());\n            // Recur with rest of list and new accumulator\n            return fold(newInput, newAcc, func);\n        }\n}\n```\n\nThis implementation is identical to the solution from [part 2](https://dev.to/deciduously/overly-functional-c-the-fold-4kid) apart from the parameterized types.  The other four \"backup\" functions are just specific cases of this `fold`.\n\nAs [@curtisfenner](https://dev.to/curtisfenner) pointed out, this naive implementation is needlessly expensive.  The recursion is in tail position, which the compiler does optimize for, but each call is allocating a brand new vector to swap into the stack frame.  If you needed to optimize this further, you could consider instead passing ever-smaller subslice references to the same vector, or even mutating the original vector in place instead.\n\n### foldOr\n\nThe simplest application just takes a list of booleans and tells you if any of them are `true`.  The `T` in `BenFolds::fold()` is `bool`:\n\n```cpp\nstatic bool foldOr(std::vector<bool> bools)\n{\n    return fold<bool>(bools, false, [](bool acc, bool curr) { return acc || curr; });\n}\n```\n\nThe initial accumulator is `false`.  We call `||` on this accumulator against each element of the passed collection.  At the end, if any element was `true`, the accumulator flipped to `true` and stuck.  Otherwise, nothing was found it's still `false`.\n\nTo test, I added a quick throwaway to `main()`:\n\n```cpp\nvector<bool> bools = {false, false, false, true, false};\ncout << \"Testing foldOr...\\nThis should be true: \" << bf.foldOr(bools) << \"\\n\";\n```\n\n### foldAny\n\nThe `any` function is just a generalization of `or`:\n\n```cpp\ntemplate <typename T, typename Predicate>\nstatic bool foldAny(std::vector<T> elems, Predicate p)\n{\n    return fold(elems, false, [p](bool acc, T curr) { return acc || p(curr); });\n}\n```\n\nIt's really almost the same thing.  We're still calling `||` on the accumulator and this element, but we're passing the element through some other predicate `p` before checking for truth.\n\nFor example, see if the inputs has any even numbers (it should) or anything greater than 10 (it shouldn't):\n\n```cpp\ncout << \"Testing foldAny...\\nAre there even elements in the set: \" << bf.foldAny(nums, [](int n) { return n % 2 == 0; }) << \"\\n\";\ncout << \"Are there elements greater than 10: \" << bf.foldAny(nums, [](int n) { return n > 10; }) << \"\\n\";\n```\n\n### foldElem\n\nThe `elem` function checks if an element exists in a collection, which is a specialization of `any` so we can reuse that definition:\n\n```cpp\ntemplate <typename T>\nstatic bool foldElem(std::vector<T> elems, T elem)\n{\n    return foldAny(elems, [elem](T curr) { return elem == curr; });\n}\n```\n\nIt calls `foldAny` defining the predicate as equality against a specific element.  We can test by checking for a specific number, no need to pass a lambda:\n\n```cpp\ncout << \"Testing foldElem...\\nIs the number 2 present in the set: \" << bf.foldElem(nums, 2) << \"\\n\";\ncout << \"Is the number 8 present in the set: \" << bf.foldElem(nums, 8) << \"\\n\";\n```\n\n### foldMap\n\nWe can also define a `map` function from this `fold` that builds the target vector in the accumulator:\n\n```cpp\ntemplate <typename T, typename Op>\nstatic std::vector<T> foldMap(std::vector<T> elems, Op func)\n{\n    return fold(elems, std::vector<T>(), [func](std::vector<T> acc, T curr) {\n        acc.push_back(func(curr));\n        return acc;\n    });\n}\n```\n\nI tested this one by doubling each element in the input:\n\n```cpp\ncout << \"Testing foldMap...\\nHere's each element doubled: \" << bf.foldMap(nums, [](int elem) { return elem * 2; }) << \"\\n\";\n```\n\nRunning through all the tests as defined yields this output:\n\n```\nSet: [0, 1, 2, 3, 4]\nTesting fold...\nSum: 10\nTesting foldOr...\nThis should be true: 1\nTesting foldAny...\nAre there even elements in the set: 1\nAre there elements greater than 10: 0\nTesting foldElem...\nIs the number 2 present in the set: 1\nIs the number 8 present in the set: 0\nTesting foldMap...\nHere's each element doubled: [0, 2, 4, 6, 8]\n```\n\n![Good enough](https://media1.tenor.com/images/39f958c6a71049618e89d6bbfc8e96a2/tenor.gif)\n\n*Photo by Oscar Keys on Unsplash*",
    "title": "Overly Functional C++: The BenFolds Five"
  },
  {
    "cover_image": "https://res.cloudinary.com/practicaldev/image/fetch/s---MZfjJcL--/c_imagga_scale,f_auto,fl_progressive,h_420,q_auto,w_1000/https://thepracticaldev.s3.amazonaws.com/i/v2onb6n4hgau1h2xpcfc.jpg",
    "date": "2019-10-09T20:16:29.573Z",
    "description": "",
    "tags": "watercooler, games",
    "markdown": "# Un-Productive Time\n\nAs with the board games, this isn't a \"favorites\" list but rather examples of mechanics I found unique and interesting. It's stuff I hadn't seen anything else quite like before, or at least not as well executed.  This was a trickier task than with board games because video games have a much wider range of styles and ways you interact with them.  I found that it was tough to select examples of completely never-before-seen mechanics, so for each I also talk about some other relevant examples.\n\nDisclaimer: despite having spent my afternoon writing about video games, I'm not actually much of a gamer and almost anyone is likely more qualified than I to write this post.  I tend to be *complete crap* at games.  Multiplayer competitive games and fine motor control/reflex-oriented games like first-person shooters are generally futile endeavors, so I tend towards slower, single-player puzzle-adventure-type things.  As a result all but one of these games have some sort of puzzle component, so it's probably not as holistic a list as it could be.  I don't spend much time at all playing games or researching new ones so it's entirely possible that none of these are unique at all and there are dozens of better examples.  Please do share if so!\n\n## Outer Wilds\n### Time Loop\n\n*Windows, Xbox One, PS4 (releasing Oct 15)*\n\n![Outer Wilds](https://cdn.player.one/sites/player.one/files/styles/scale_lg/public/2019/06/06/outer-wilds-level-design.jpg)\n\nIn [Outer Wilds](http://www.mobiusdigitalgames.com/outer-wilds.html), you're the newest astronaut of your alien tribe's fledgling duct-tape-and-wood-planks-style space program.  When the game begins, you get access to your very own rickety spaceship which you can use to fly anywhere in the solar system.  The whole game world exists in a big always-on physics simulation with simplified gravity and orbital mechanics - you see a moon orbit closely overhead from the home world, and it turns out you can get yourself there and walk around on that surface in under a minute.  Everything is scaled down, so the gravity of passing planets noticeably affects objects on the planet surface.\n\nThere are a handful of other planets and objects in the solar system you can fly to, and as you explore you learn about the history of the solar system and the events that lead to the game's beginning.  There's no transition between walking around and flying your ship, you just take off and are seamlessly in orbit within seconds.  On the really small planets, your ship can get ripped off the surface if something with stronger gravity passes too close, and you have to be careful when landing on the innermost planet or you'll get sucked into the sun's much stronger gravity.\n\nAfter 22 minutes the sun explodes, obliterating you and everything else.  Not to worry - you're in a time loop, and after the actions you took flash before your eyes you gasp awake again, in the exact same way as the game started.  Your ship remembers everything you learn from cycle to cycle, but almost nobody else is aware.  Your task is to incrementally explore the solar system in 22-minute bursts to figure out why you're in a time loop and if it can be stopped.  The time loop is a fascinating mechanic that I've never experienced before, and without revealing too much some of the puzzles utilize it in even more interesting and surprising ways.  After playing this I'm interested to try other games that use a similar mechanic like [Minit](https://minitgame.com/) and [The Sexy Brutale](http://www.thesexybrutalegame.com/).\n\nWhile 22 minutes sounds short, the world is designed such that you should not need more to access anything important.  You do need to formulate a plan of attack to get something complicated done away from the home planet, but there are no consequences for failing to execute or just aimlessly exploring - you'll just eventually have to fly back if you didn't finish something.  I usually end up killing myself one way or another well before the time is up, so actually surviving until the sun explodes feels like an accomplishment.  The game only saves each time you die, so if you have learned something substantial you have to either wait out the loop or kill yourself before you can quit.\n\nThat *alright just one more cycle* voice in the back of my head is dangerous.  I'm waiting until I finish to make a final judgement, but about ten hours in this already might be my favorite game I've *ever* played.\n\n### Similar - Myst, Kerbal Space Program, Subnautica\nWhen I picked this up I knew about the (much simplified) KSP-esque physics and spaceflight elements, but had no idea about the puzzle aspect.  This game feels what you get if you implement Myst inside of [Kerbal Space Program](https://www.kerbalspaceprogram.com/).\n\nThe first three games of the [Myst series](https://en.wikipedia.org/wiki/Myst_(series)) has always been right at the top of my \"all-time favorites\" list.  In these games, the world itself is the puzzle and you're encouraged to steep yourself in the world building and culture they create in order to understand how to navigate the solutions.  The closest analogue here to me is [Myst 2: Riven](https://cyan.com/games/riven/).  \n\n![Riven screenshot](https://cyan.com/wp-content/uploads/2019/08/Screenshot_Riven_A.jpg)\n\nWhereas Myst was a series of related puzzles, Riven really is just one huge world-sized puzzle, with sub-steps to solve spread across five islands.  Outer Wilds appears much the same actually, swapping islands for planets.  In both, you're dropped into a rich world with little to no instruction, and you discover the plot through exploration.  In both, the entire world is available to you immediately, though some of it you may need to figure out how to access first.  In both, the invented cultures of their respective universes are thoroughly imagined and take a leading role in world design and puzzle integration, and the plot itself.  This urges the player to try to understand and learn about the world-building in order to succeed instead of just providing a thin backdrop or a plot unrelated to the puzzles.\n\nOuter Wilds thankfully isn't as hard as Riven was designed to be, and you're given a hint on the first day for what to explore first. I ignored that on my first launch, though.  When I first got to space I just pointed at the coolest-looking thing in the sky and went there instead (and died), and I love that the game didn't have a problem with that.  The goal is to learn something on each run, dying is pretty inconsequential.  I love that style of open-ended puzzle design where the world itself provides the challenge and you learn how it works through exploration and experimentation, instead of being punished for it.\n\nI love how this game blends aesthetics, too.  Your home tribe and alien buddies are super adorable, and the folk music backdrop, colorful art style, and quirky sense of humor gives everything a very warm and cozy feeling.  The very first thing you can do upon opening your eyes is roast marshmallows or doze off at a campfire.  The environment, though, can also be terrifying.  There are no jump scares, but there is absolutely an existential horror element.  Even though I've made the mistake at least a dozen times I don't think I'll ever get used to falling through the black hole.\n\n![Brittle Hollow](https://thepracticaldev.s3.amazonaws.com/i/co35njaebgq9iwvgboe8.png)\n\nIt didn't quite make this list, but another game I've highly enjoyed that does this well is [Subnautica](https://unknownworlds.com/subnautica/).  This is a base-building game that takes place almost entirely underwater in a lushly populated alien ocean, and exploring the depths of that world in your tiny little submarine can really create a feeling of true terror.  You slowly get comfortable traversing deeper and deeper parts, but there's always a vast unknown waiting for you next.\n\n![Subnautica](https://images.pushsquare.com/screenshots/94264/large.jpg)\n\n## Crypt of the NecroDancer\n### Rhythm\n\n*Windows, Linux, OS X, Switch, PS4, Vita, iOS, Xbox One*\n\n![NecroDancer](https://thepracticaldev.s3.amazonaws.com/i/4lzr5v3zwbpqg4xyc2rz.jpg)\n\n[Crypt of the NecroDancer](https://braceyourselfgames.com/crypt-of-the-necrodancer/) is actually a pretty standard roguelike game that adds one twist: each key you tap has to be in time to the beat.  If you want to move squares or slash at a neighbor, you have to make sure you do it in time to the music playing.  The bars at the bottom are moving inwards, you have to tap keys when a bar is directly centered.  The success of the action is determined by how close to the beat you actually were.\n\nThis game is ridiculously hard, but becomes almost meditative once you know the controls and aren't thinking about what keys to press anymore.  The tricky part is not hesitating - I tend to over-analyze and try to min-max my decisions in a game like this, but the beat moves too fast do so effectively.  To succeed you need to internalize the patterns to the point where your first instinct is generally correct.\n\n### Similar - NetHack\n\nIf you strip out the dancing, this game is not dissimilar from any arbitrary roguelike.  For the uninitiated, this style of game is generally the sort of thing where you're given a single life to see how far you can get.  They tend to be high-difficulty, and ramp up quickly.  When you die, game over.  While a huge genre, for me the canonical example is [NetHack](https://www.nethack.org/).  This game has been in active development [since 1987](https://www.nethack.org/download/), with the latest release on May 7, 2019.  It's played in a console, and uses ASCII characters to render the level:\n\n![Nethack screenshot](https://upload.wikimedia.org/wikipedia/commons/0/00/Nethack_releasing_a_djinni.png)\n\nThe simple interface masks a truly incredible amount of depth and content, but actually seeing any of that content is brutally difficult.  Mistakes as small as moving a tile in the wrong direction aren't exactly tolerated.  I've never personally made it deeper than a handful of levels without dying.  One feature I find fun is that sometimes the game will store where you died and in a subsequent run insert that level into the dungeon, replete with your old dead body to loot.\n\n## Portal 2\n### Physics Puzzles\n\n*Windows, Linux, OS X, Xbox 360, PS3*\n\n![Portal 2](https://thepracticaldev.s3.amazonaws.com/i/iuuahvhrx4ao229lt3of.jpe)\n\n[Portal 2](http://www.thinkwithportals.com/) is a pretty well-known game, for good reason.  It's a puzzle game where the player is given a device that creates linked portals in walls, and must use them to traverse spaces that would otherwise be impassable in increasingly creative ways.\n\nIt's not a long game, but just long enough to feel satisfying and also includes a great two-player co-op set of levels. It also has a fantastic sense of humor throughout.  It's all funny but my personal highlights are the Cave Johnson voiceover monologues you start hearing partway through the story while you're trying to solve rooms, provided by actor J.K. Simmons.  It's some of my favorite game audio anywhere.\n\n### Similar - Well, Portal 1\n\nThe first Portal game is also great and worth a play, but it's much smaller and deviates much less from the core portal-gun concept.  It feels like a prototype of the idea, which once proven enabled Valve to make the actual game around it with Portal 2.\n\nBoth games are completely standalone, but take place in the same universe as the [Half-Life](https://en.wikipedia.org/wiki/Half-Life_(video_game)) series of first-person shooters.  The subtle universe tie-ins are fun if you've played both games.\n\n## Super Hot\n### Passage of Time\n\n*Windows, Linux, OS X, Switch, Steam VR*\n\n![Super Hot](https://superhotgame.com/wp-content/uploads/2016/02/superhot_press_screenshot_01.png)\n\nI mentioned above that I am very bad at first-person shooter games.  Similarly, I am very bad at [Super Hot](https://superhotgame.com/), but for completely different reasons.\n\nThis shooter drops you into very simple levels with a number of enemies with guns, and you have to kill everyone. The twist is that time moves as quickly as you do.  If you're standing still, everything slows to a crawl, and as you move around the level time moves forward in a way that matches your speed.   This includes bullets that have been fired - so you can dodge, but don't speed up too much to do so.  Here's an [early pre-release demo](https://superhotgame.com/play-prototype/) of the mechanic you can try for free, sans baddies, to get a better feel for the idea.\n\nIt's pretty cool.  I have no idea how to not suck at it, but it's pretty cool.\n\n### Similar - Prince of Persia: Sands of Time, I guess?\n\nIt's been years since I've played [this game](https://en.wikipedia.org/wiki/Prince_of_Persia:_The_Sands_of_Time), but it was notable for allowing the player to rewind time to retry a maneuver.  That's not quite what SuperHot is about, but it was the closest example of time-malleability I could think of.  Can you think of any other better examples?\n\n## Crusader Kings 2\n### Politics\n\n*Windows, Linux, OS X*\n\n![Crusader Kings 2](https://thepracticaldev.s3.amazonaws.com/i/3f2pfg6xiz73m7c98rdr.jpg)\n\nI have no idea how to play [Crusader Kings 2](https://www.paradoxplaza.com/crusader-kings-ii/CKCK02GSK-MASTER.html).\n\nHuge strategy games represent some of my all-time favorites.  I like the open-ended decision making a 4X (eXplore, eXploit, eXpland, eXterminate) game requires.  This is a huge genre, with dozens if not hundreds of examples. This, though, is just as much an alternate history generator as a strategy game, with an astounding level of detail in the simulation.  I've put a decent amount of time into it, but I still feel like I'm just learning how it works, and it's more accurately playing me.\n\nLike many other superficially-similar games, you're in charge of a country.  The difference here is that you actually play a person.  The game world is filled with actual people.  Over the course of the game your person will age and die, and you will assume control of their heir.  You've got ambitions and needs separate from your country's, and form and build relationships with other people, each simulated with their own personalities and motivations.  Suffice it so say I've only scratched the surface of the complexity built into this game.\n\nThe level of detail gives rise to an impressively realistic political simulation.  Running your country involves balancing the conflicting needs and wants of your empire's population, within your government, and across the globe.  I've never played anything else quite like it.\n\n### Similar - Dwarf Fortress\n\n![Dwarf Fortress](https://media.wired.com/photos/593452a2d80dd005b42b3f3e/191:100/pass/dwarffortress.jpg)\n\n[Dwarf Fortress](http://www.bay12games.com/dwarves/) is also a history generator/simulator first and game second.  I haven't played it, but I know it's also massively detailed, perhaps to an even greater extent.  This [Gamasutra interview](https://www.gamasutra.com/view/feature/131954/interview_the_making_of_dwarf_.php) with one of the creators sheds a little light on what that means - for one example about the initial world-generation stage:\n\n> It also makes a temperature map (biased by elevation and latitude) and a rainfall map (which it later biases with orographic precipitation, rain shadows, that sort of thing). The drainage map is just another fractal, with values from 0 to 100. So we can now query a square and get rainfall, temp, elevation and drainage data.\n\n*Tarn Adams for Gamasutra, 2008*\n\nThat quote is from 2008, two years after the initial 2006 release and six years from the start of development.  Dwarf Fortress remained in steady development since then with v0.44.12 released on July 18, 2018, maintaining an active devblog updated as recently as October 2, 2019 at the time of writing.  This is still a very partially-realized implementation of their vision.  Their version number is [specifically designed](https://dwarffortresswiki.org/index.php/DF2014:Version_number) to track progress towards v1.0, so, stay tuned.\n\n## HexCells\n### Well-Crafted Puzzles\n\n*Windows, Linux, OS X*\n\n![HexCells](https://thepracticaldev.s3.amazonaws.com/i/f2szgk0k4s748ovbuq0i.jpg)\n\n[HexCells](https://www.rockpapershotgun.com/game/hexcells/) is a very simple puzzle game.  Each level has a certain number of specific hexes that need to be found.  Like minesweeper, you right-click a hex to mark it if you think it's one of them, and the remaining hexes can be revealed to give you information about how many neighbors are targets.  You also get numbers around the outside to tell you how many targets are found in a given row, column, or diagonal.\n\nEach level that ships with each of the games in the series is handcrafted, and it shows.  Once you finish, the final game of the trilogy does include a procedural level generator.  The randomly-produced levels are also fun to solve, but don't quite feel as compelling.\n\n### Lineage: Minesweeper, Sudoku\n\nThis game feels a lot like a mix of the two, but I like it better than either.  Minesweeper is frustrating because you can end up with an ambiguous 50/50 choice.  In HexCells it is actually impossible to get stuck.  You *always* have enough information to make a definitively correct move.  If you don't see it, that's on you, not the game.  Knowing that property holds for every level makes a huge difference.\n\nThe fact that it's an improvement over Sudoku for me is entirely subjective. There's nothing wrong with Sudoku. I happen to like HexCells better.\n\n## The Witness\n### Creative Puzzle Design\n\n*Windows, OS X*\n\n![The Witness](https://robertheaton.com/images/the-witness-puzzle.jpg)\n\nIn [The Witness](http://the-witness.net/), you're on an island with dozens and dozens of puzzles.  Every single puzzle is based around a colored grid of dots where you have to trace the correct line.  It starts off quite literally that simple, but as you progress the game stretches and extends the concept in tons of unexpected ways that integrate the environment and force you to relearn things you know.\n\nI think it's an achievement from a game design and creativity standpoint. There is a huge variety of different twists, and amazingly there is never any sort of instruction or tutorial.  You learn the mechanics of the puzzles by solving them, seeing what works and what doesn't.  I was continually surprised by how a specific grid worked, even after I thought I had seen pretty much all the ways the game would mess with it.\n\nWhile I do usually enjoy difficult puzzle games, the payoff for solving a grid is just more grids to solve, and it just didn't quite do it for me after a while.  As cool as the concept is, I just didn't find it to be much fun in the end.\n\nThis game designer, [Jonathan Blow](http://number-none.com/blow/), was previously known for a game I haven't played but have heard good things about called [Braid](http://braid-game.com/).  It sounds very creative mechanically as well, but I obviously can't say much about it.  Has anyone played it?  He is also the original creator of the [JAI](https://github.com/BSVino/JaiPrimer/blob/master/JaiPrimer.md) programming language.\n\n## Factorio\n### Automation\n\n*Windows, Linux, OS X*\n\n![factorio](https://factorio.com/static/img/screenshots/screenshot-26.jpg)\n\n[Factorio](https://factorio.com/) is a little scary.  You've crash-landed on an alien planet, and must locate and extract local resources to build yourself a new rocket to escape.\n\nThis is a game about systems design and automation more than anything else.  It has so much crossover to software development which I think is why I find it so compelling.  You're given a set of core components and solve small problems by individually placing them into a configuration that does what you need, for example producing railroad sections from wood planks and steel pipes.  Then you can save a configuration as a \"blueprint\" and copy-paste that exact set of machines anywhere you like, letting you build at a higher level of abstraction.  You're responsible for the whole supply chain including mining raw materials, smelting or refining those resources, and producing the intermediate products required for a recipe.\n\nKeeping your factory humming feels a lot like debugging.  Your solar panel producing unit's supply of steel has trickled and can't keep up with demands, so you trace your steel lines back and notice that your steel smelters don't have enough iron coming in.  Your iron production is fine, but your belt has a split in it in between that production block, and the other side of the split was fine when you built it but has started hogging the supply.  To fix it, you're basically looking at a refactor - maybe reshape this belt loop, or reorganize how iron is produced and distributed to avoid the bottleneck entirely.  Perhaps those steel smelters should have their own dedicated iron smelters, instead of siphoning off the main supply, and the pros and cons of decisions like that are often only apparent \"in production\", once you've built it and see how it actually delivers.  Sound familiar?\n\nIt's also got great multiplayer.  The game is a massive time sink, and divying up the work can help get a factory productive much more quickly.  Multiplayer maps can also let people specialize.  If you don't like orchestrating the train schedule, someone else can handle that while you focus on defense or something.\n\nIf that's not enough, you can take it a step further.  The game provides electrical wires and combinator devices to add programmable logic.  Yep, *sigh*, it's Turing complete.  Why build a rocket when you can build a raycasting game engine:\n\n{% youtube 7lVAFcDX4eM %}\n\nThe hours I have dropped into this game outpace anything else I've ever played by a ridiculous margin.  I do burn out and not touch it for extended periods, even a year at a time, but I will probably come back and spin up a new map every so often for years to come.\n\nDespite all those hours, I've never come anywhere close to trying to build the rocket.\n\n### Lineage: MineCraft\n\nAny sandbox game will inevitably be compared to Minecraft, and there are a lot of similarities here.  While I do enjoy a little Minecraft here and there, it doesn't hook me in nearly the same way because Factorio's building blocks are so much more interesting.  Minecraft is much more like a Lego set that you can imbue with logic.  Factorio's building blocks feel more akin to your favorite programming language.  Belts and splitters are your control flow while the general-use automation machines are like functions.  Using blueprints you build yourself a \"standard library\", and then can either scale up production without worrying about implementation, or refactor the implementation in one place and use it all over your factory.  The complexity lies in the interactions between system components.  As an inspiring software dev, that's pretty fun to me.\n\n*Photo by Kelly Sikkema on Unsplash*",
    "title": "Interesting Video Game Mechanics"
  },
  {
    "cover_image": "https://res.cloudinary.com/practicaldev/image/fetch/s--EBkB7v9e--/c_imagga_scale,f_auto,fl_progressive,h_420,q_auto,w_1000/https://thepracticaldev.s3.amazonaws.com/i/nyxgurszvs5h44iepi7e.jpg",
    "date": "2019-10-23T20:53:46.695Z",
    "description": "",
    "tags": "discuss, healthydebate, watercooler, opensource",
    "markdown": "This question is prompted by this [/r/Gentoo](https://www.reddit.com/r/Gentoo/comments/dm1hsb/do_you_think_widevine_contains_malicious_code/) post.  Gentoo Linux allows you to pick and choose components ad-hoc to compile in to your software packages, and this user is curious about whether or not to opt-in to the [`widevine`](https://www.widevine.com/) component used for streaming content protection on their Chromium build.\n\nOne the one hand, content providers need to ensure they control their IP.  On the other, the ethical lines get blurry quickly, and the details are often unclear for an end user.  I'm not surprised the Gentoo subreddit falls heavily in the \"yes\" camp, but I'd like to hear what DEV thinks.\n\n*Photo by James Sutton on Unsplash*",
    "title": "Is DRM malicious code?"
  },
  {
    "cover_image": "https://res.cloudinary.com/practicaldev/image/fetch/s--9GzgvYXH--/c_imagga_scale,f_auto,fl_progressive,h_420,q_auto,w_1000/https://thepracticaldev.s3.amazonaws.com/i/do9pmhc297wl6x8pjlt0.jpg",
    "date": "2019-11-03T20:16:16.690Z",
    "description": "",
    "tags": "beginners, functional, javascript, tutorial",
    "markdown": "# Dolla Dolla Bill, Y'all\n\nCredit card companies are responsible for a high volume of highly sensitive global network traffic per minute with no margin for error. These companies need to ensure they are not wasting resources processing unnecessary requests. When a credit card is run, the processor has to look up the account to ensure it exists, then query the balance to ensure the amount requested is available. While an individual transaction is cheap and small, the scales involved are enormous.\nThere were [39.2 million transactions per day](https://www.statista.com/statistics/719708/card-payments-per-day-forecast-united-kingdom/) in the UK alone in 2016. The linked analysis projects 60 million for that region by 2026. Clearly, anything that can reduce load is necessary to explore.\n\nThis is a beginner-level post. Some familiarity with JavaScript is assumed but not necessarily functional programming.\n\n## What's In A Number\n\nAt a glance, a credit card number just appears to be a sequence of digits. You may have noticed that the major processing providers have their own prefixes. Visa cards all start with a 4, MasterCard with 5, Discover with 6, and American Express are 3 (and 15 digits instead of 16). Further, financial institutions will have their own 4-6 digit prefixes. People who work at point of sale systems or are otherwise involved with financial processing will notice these patterns quickly. For example, Discover credit cards start with 6011, a 4117 will be a Bank of America debit card, and 5417 is Chase Bank. This is known as the BIN, or Bank Identification Number. There's a [large list here](https://www.bindb.com/bin-list.html).\n\nHowever, this is all a network routing concern, and still adds to the network's load to resolve.  To try to ensure all lookup requests actually correspond to real accounts, all numbers have a **checksum** built in, which is a means of detecting errors in data. A credit card number consists of your card provider's BIN attached to your individual account number, but the final digit is a checksum digit which can be used to validate for errors without ever querying a server.\n\n### Protip\n\n\"I'm a BIN and routing number encyclopedia\" is a **terrible** party icebreaker. If you've really gotta flex this side of you, ease in with zipcodes or something first. Read the room.\n\n### Luhn algorithm\n\nThe specific type of checksum is called the [Luhn formula](https://en.wikipedia.org/wiki/Luhn_algorithm), [US Patent 2,950,048](https://patents.google.com/patent/US2950048) (but public domain since 1977). To validate a number via the Luhn algorithm, you add a check digit. Then, after performing the formula on the original number, you see if this check digit corresponds to your result.\n\n1. Split the full number into individual digits.\n\n1. Start with the rightmost _excluding_ the check digit and double every second, moving left.\n\n1. If any of those doubled digits ended up greater than 9, add the digits together (or subtract 9, if that's your jam).\n\n1. Take the sum of all the digits and the check digit.\n\n1. If the total modulo 10 equals 0, the number is valid.\n\nFor an example, the number `4012-8888-8888-1881` is a valid Visa-formatted account number, used for testing. You can't charge it, but it should validate with this algorithm.\n\n1. Split into digits: `4 0 1 2 8 8 8 8 8 8 8 8 1 8 8 1`.\n\n1. Double every second except the check digit, right to left: `8 0 2 2 16 8 16 8 16 8 16 8 2 8 16 1`.\n\n1. Add digits of any above nine: `8 0 2 2 7 8 7 8 7 8 7 8 2 8 7 1`.\n\n1. Sum the digits: `90`.\n\n1. Is it a multiple of 10? Yep!\n\nThis number checks out, it could possibly be a valid Visa card so we're clear to make the network request.\n\n## Implement\n\nTo follow along, you'll need [Node](https://nodejs.org/en/). I'm using [pnpm](https://github.com/pnpm/pnpm), feel free to use `npm` or `yarn` instead. Create a new project:\n\n```txt\n$ mkdir luhn\n$ cd luhn\n$ pnpm init\n// follow prompts\n$ touch index.js\n```\n\nThrow a stub into `index.js` to get hooked up:\n\n```js\nconst luhn = {};\n\nluhn.validate = numString => {\n  return false;\n};\n\nmodule.exports = luhn;\n```\n\n### Unit tests\n\nBefore hopping into the implementation, it's a good idea to have some unit tests ready to go. Add `mocha`:\n\n```txt\n$ pnpm install mocha\n$ mkdir test\n$ touch test/test.js\n```\n\nIn `package.json`, set the `test` script to run [`mocha`](https://mochajs.org/):\n\n```json\n\"scripts\": {\n  \"test\": \"mocha\"\n},\n```\n\nNow add the following tests to `test/test.js`:\n\n```js\nconst assert = require(\"assert\").strict;\nconst luhn = require(\"../index.js\");\n\ndescribe(\"luhn\", function() {\n  describe(\"#validate()\", function() {\n    it(\"should accept valid Visa test number\", function() {\n      assert.ok(luhn.validate(\"4012-8888-8888-1881\"));\n    });\n    it(\"should accept valid MasterCard test number\", function() {\n      assert.ok(luhn.validate(\"5105-1051-0510-5100\"));\n    });\n    it(\"should accept valid Amex test number\", function() {\n      assert.ok(luhn.validate(\"3714-496353-98431\"));\n    });\n    it(\"should reject invalid numbers\", function() {\n      assert.equal(luhn.validate(\"1234-5678-9101-2131\"), false);\n    });\n  });\n});\n```\n\nDon't worry, those aren't real accounts, just some valid test numbers from [here](https://www.paypalobjects.com/en_GB/vhelp/paypalmanager_help/credit_card_numbers.htm).\n\nAs expected, running `npm test` should confirm that our stub has some work to do:\n\n```txt\nLuhn\n  #validate()\n    1) should accept valid Visa test number\n    2) should accept valid MasterCard test number\n    3) should accept valid Amex test number\n    ✓ should reject invalid numbers\n```\n\nI'm sticking to a functional style for this implementation, wherein instead of mutating state and looping we'll get to the final result by defining transformations over data.\n\n### Split Digits\n\nThe first order of business is to get the digits out of the string we're passed. We can just discard anything that isn't a number using [`String.prototype.replace()`](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/String/replace).\n\n```js\nconst to_digits = numString =>\n  numString\n    .replace(/[^0-9]/g, \"\")\n    .split(\"\")\n    .map(Number);\n```\n\nThe regular expression uses `^` to match anything that *isn't* a digit from 0-9. The trailing `g` indicates we want to match globally and replace all matches found with nothing (removing it from the string). If omitted, only the first match is replaced and the remaining string is untouched. Then, we split into individual characters, one per digit, and convert them all from characters to numeric values.\n\n### Set The Stage\n\nBack in `luhn.validate()`, let's store our digit array using this function and hold on to the check digit for later:\n\n```diff\nluhn.validate = numString => {\n+ const digits = to_digits(numString);\n+ const len = digits.length;\n+ const luhn_digit = digits[len - 1];\n+ const total = 0; // TODO\n  return false;\n};\n```\n\nTo get to our final validation, we're going to perform a series of transformations on this digit array to reduce it to a final total. A valid number will produce a result that's a multiple of 10:\n\n```diff\nluhn.validate = numString => {\n  const digits = to_digits(numString);\n  const len = digits.length;\n  const luhn_digit = digits[len - 1];\n  const total = 0; // TODO\n- return false;\n+ return total % 10 === 0;\n};\n```\n\n### Get The Total\n\nWe already talked this through in English. Let's take a stab in pseudocode:\n\n```js\nconst total = digits\n  .doubleEveryOtherFromRightMinusCheckDigit()\n  .map(reduceMultiDigitVals)\n  .addAllDigits();\n```\n\nWe've got to do that doubling step on the correct numbers in the account number, then transform anything that ended up with multiple digits, then get the total of everything together.\n\nFor this step, we can use [`Array.prototype.slice()`](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Array/slice) to get a subset of the digits array that has everything except for the check digit. Going right-to-left can be achieved with [`Array.prototype.reverse()`](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Array/reverse):\n\n```diff\nconst total = digits\n- .doubleveryOtherFromRightMinusCheckDigit()\n+ .slice(0, -1)\n+ .reverse()\n+ .map(doubleEveryOther)\n  .map(reduceMultiDigitVals)\n  .addAllDigits();\n```\n\nThe [`Array.prototype.map()`](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Array/map) calls can just be left as-is, we can define the functions we need in a moment. The final step, adding everything together, can be handled with [`Array.prototype.reduce()`](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Array/reduce). This method produces a single result from a collection by calling a function on each element and an accumulator. By adding each element to a running total, we can produce a sum. Instead of starting from 0, though, we can just start from the checksum digit we had stored earlier:\n\n```diff\nconst total = digits\n  .slice(0, -1)\n  .reverse()\n  .map(doubleEveryOther)\n  .map(reduceMultiDigitVals)\n- .addAllDigits()\n+ .reduce((current, accumulator) => current + accumulator, luhn_digit);\n```\n\nGood to go!\n\n#### Define Transformations\n\nWe've got two operations left undefined in the above pipeline, `doubleEveryOther` and `reduceMultiDigitVals`. In both, we're going through each digit and conditionally adjusting the value there. It's either every other digit, or if a digit is greater than a certain threshold, but in both cases the basic mapping function takes the same format - it conditionally transforms:\n\n```js\nconst condTransform = (predicate, value, fn) => {\n  if (predicate) {\n    return fn(value);\n  } else {\n    return value;\n  }\n};\n```\n\nThis works somewhat like the ternary operator but as a function. Each instance of this is just a specified case of a conditional transform:\n\n```js\nconst doubleEveryOther = (current, idx) =>\n  condTransform(idx % 2 === 0, current, x => x * 2);\n\nconst reduceMultiDigitVals = current =>\n  condTransform(current > 9, current, x => x - 9);\n```\n\nBoth of these accept argument lists that are compatible with `map()`, so can be plugged in directly as-is. One includes the current element's index and one doesn't, and both just pass through to this helper transform. If the predicate is satisfied the element will be transformed per the final transforming function, and otherwise it's left untouched.\n\n## Wrapping Up\n\nPutting it all together:\n\n```js\nconst to_digits = numString =>\n  numString\n    .replace(/[^0-9]/g, \"\")\n    .split(\"\")\n    .map(Number);\n\nconst condTransform = (predicate, value, fn) => {\n  if (predicate) {\n    return fn(value);\n  } else {\n    return value;\n  }\n};\n\nconst doubleEveryOther = (current, idx) =>\n  condTransform(idx % 2 === 0, current, x => x * 2);\n\nconst reduceMultiDigitVals = current =>\n  condTransform(current > 9, current, x => x - 9);\n\nconst luhn = {};\n\nluhn.validate = numString => {\n  const digits = to_digits(numString);\n  const len = digits.length;\n  const luhn_digit = digits[len - 1];\n\n  const total = digits\n    .slice(0, -1)\n    .reverse()\n    .map(doubleEveryOther)\n    .map(reduceMultiDigitVals)\n    .reduce((current, accumulator) => current + accumulator, luhn_digit);\n\n  return total % 10 === 0;\n};\n\nmodule.exports = luhn;\n```\n\nCheck it out with `pnpm test`:\n\n```txt\n  luhn\n    #validate()\n      ✓ should accept valid Visa test number\n      ✓ should accept valid MasterCard test number\n      ✓ should accept valid Amex test number\n      ✓ should reject invalid numbers\n\n\n  4 passing (3ms)\n```\n\nThis algorithm is used for a variety of different types of data verification, not just credit card numbers. Maybe you could integrate it into your next project's design! Adding a checksum to your DB keys can help protect against data transmission errors, and very simple verification like this is easy to get started with.\n\n### Challenge\n\nExtend this code to provide a method that can add a correct Luhn checksum to any arbitrary number.  The check digit will be the number you need to add to your total to get to multiple of 10.\n\n*Photo by Clay Banks on Unsplash*",
    "title": "Validate a Credit Card Number with Functional JavaScript"
  },
  {
    "cover_image": "https://res.cloudinary.com/practicaldev/image/fetch/s---H0zdB7I--/c_imagga_scale,f_auto,fl_progressive,h_420,q_auto,w_1000/https://thepracticaldev.s3.amazonaws.com/i/pfdfanwj7jsgsnhcq2xe.jpg",
    "date": "2019-11-16T20:05:14.324Z",
    "description": "",
    "tags": "rust, beginners, tutorial, creative",
    "markdown": "# Oxidize Your Life With One Weird Trick\n\nWe're going to build a small demo with the [nannou](https://nannou.cc/) creative coding framework for [Rust](https://www.rust-lang.org/). This example itself is very simple, but specifically over-engineered to prepare to scale even further for your own project.\n\nThis is a beginner-level post but with conditions. You should be able to follow along with the logic here in a general sense with comfort in any imperative language, but if you wanted to build your own app from this base as a total newcomer to Rust, I absolutely recommend you read at least some of [The Rust Programming Language](https://doc.rust-lang.org/book/), freely available, or equivalent before tackling this framework.\n\nPart of the strength of `nannou` as a framework is that it _doesn't_ reinvent the wheel. It is instead intended to pull together and unify the best the excellent Rust ecosystem already has to offer for each subproblem in one unified package, innovating only where the need is not already met by the community. You could also get here yourself by adding these dependencies one-by-one and gluing everything together, but this is aiming to be a curated batteries-included distribution for creative coding in pure top-to-bottom Rust.\n\nThe final code can be found on [GitHub](https://github.com/deciduously/nannou_dots).\n\n## Table Of Contents\n\n- [The Motive](#the-motive)\n  - [Yes, Really, In Rust](#yes--really--in-rust)\n- [Setup](#setup)\n  - [Dependencies](#dependencies)\n  - [Set Up the Project](#set-up-the-project)\n  - [The Structure](#the-structure)\n- [Scaling Out](#scaling-out)\n  - [Defensive Refactor](#defensive-refactor)\n    - [Traits And Composition](#traits-and-composition)\n      - [Debug](#debug)\n      - [Default](#default)\n      - [Clone/Copy/PartialEq/PartialOrd](#clone-copy-partialeq-partialord)\n      - [FromStr](#fromstr)\n      - [ToString](#tostring)\n      - [From/Into](#from-into)\n    - [Quality of Life Crates](#quality-of-life-crates)\n      - [Command Line Arguments](#command-line-arguments)\n      - [Logging](#logging)\n      - [Error Handling](#error-handling)\n  - [Lots Of Dots](#lots-of-dots)\n- [Wrapping Up](#wrapping-up)\n  - [Challenges](#challenges)\n\n## The Motive\n\nI was irrationally hell-bent on modelling a problem in Rust that was perfectly suited for [Processing](https://processing.org/) or its [JavaScript](https://p5js.org/) or [Python](https://py.processing.org/) siblings. Luckily, the Rust ecosystem continues to pleasantly surprise, and it's already possible to do! This tool isn't trying to be Processing-the-library for Rust, and is still very much a work in progress, but it occupies a very similar space and is already quite usable, partially thanks to the wealth of strong component crates already available in the ecosystem to lean on.\n\n### Yes, Really, In Rust\n\nRust might seem like an oddly... _ahem_ combative choice of tool for such a dynamic and exploratory domain. I've found that after the initial learning curve, Rust's expressivity and modelling power help me get tasks done correctly efficiently, which more than outweighs however much its strict and unique semantics slow me down. My argument is essentially that the benefit of using Rust for this sort of program is that to implement your logic, you get to use Rust. This is pretty subjective argument.\n\nMy more substantive take is that it's performant by default, has a rich set of expressive, high-level basic language components and a solid standard library, and a highly helpful compiler if you've modelled your code effectively among all languages I've tried. It does impose a strict, unique mental model but once you understand how it works even that is more a positive point than a negative as well, as it gently nudges you towards better code [Pit of Success](https://blog.codinghorror.com/falling-into-the-pit-of-success/) style.\n\nTo me the biggest drawback is compilation time, which is admittedly brutal. This can be frustrating when doing such exploratory, iterative work - `nannou` ain't no Jupyter notebook. Working with this sort of code was a test of that limitation. a warm debug takes about 4 seconds and a release build takes four and a half on my 2017 i7. I generally just use the release build. The library itself has a little under 250 dependencies to build, so a cold taking about five minutes. Even with this frustration I found the balance skewed heavily toward positive, as always, your preferences and mileage may vary.\n\nThe caveat to any of my pros, also, is familiarity and experiential bias. I'd love hear why you disagree and Language X is more objectively superior for this and should be used instead!\n\n## Setup\n\nLet's get ourselves to a successful compile first.\n\n### Dependencies\n\n- Stable [Rust 2018](https://doc.rust-lang.org/edition-guide/rust-2018/index.html) - the [default installation](https://www.rust-lang.org/tools/install) is sufficient. This code was written with `rustc` version 1.39.\n\n- [Vulkan SDK](https://www.lunarg.com/vulkan-sdk/) - on Gentoo, I had to install `dev-util/vulkan-tools`, not just `dev-util/vulkan-headers`.\n\nI tested this code on Linux, and I'm not sure how to run this code on OS X and don't have access easily to try it myself.\n\n### Set Up the Project\n\nCreate a new Rust project directory:\n\n```txt\n$ cargo new nannou_dots\n$ cd nannou_dots\n```\n\nAdd the dependency:\n\n```toml\n# ..\n\n# after other metadata\n[dependencies]\n\nnannou = \"0.12\"\n```\n\nTo demonstrate the overall structure of the app, start with this simple demonstration:\n\n```rust\nuse nannou::{color::named, prelude::*};\n\nfn main() {\n    nannou::app(model).update(update).simple_window(view).run();\n}\n\nstruct Model {\n    bg_color: String,\n    x: f32,\n    y: f32,\n    radius: f32,\n}\n\nfn model(_app: &App) -> Model {\n    Model {\n        bg_color: \"honeydew\".to_string(),\n        x: 0.0,\n        y: 0.0,\n        radius: 10.0,\n    }\n}\n\nfn update(_app: &App, model: &mut Model, _update: Update) {\n    if model.radius < 500.0 {\n        model.radius += 1.0;\n    }\n}\n\nfn view(app: &App, model: &Model, frame: &Frame) {\n    let draw = app.draw();\n    draw.background()\n        .color(named::from_str(&model.bg_color).unwrap());\n    draw.ellipse()\n        .color(STEELBLUE)\n        .w(model.radius)\n        .h(model.radius)\n        .x_y(model.x, model.y);\n    draw.to_frame(app, &frame).unwrap();\n}\n```\n\nEven if you've never worked with a tool like this, take a moment to read through this code and try to understand what will happen when you run it. Once you think you've got it, give it a go with `cargo run --release` and go make a cup of tea. The first build will be intense as it compiles all the dependencies the first time, but re-compiles will be quicker! Granted, not _quick_ - this is one of Rust's definite trade-offs, but even my nine year old low-end laptop could keep up enough to iterate without losing my head after an admittedly pretty nuts initial build. Come back when your tea is cool enough to sip and see if you were right! You can kill the program by using the X button in the corner and re-run it to start the animation over from the beginning. Then kill it again, quickly. It came out unexpectedly terrifying for a \"hello, world\".\n\n### The Structure\n\nIf you're already familiar with model/view/update application structure, skip down to _Defensive Refactor_.\n\nThe `main()` function only does one thing: instantiate a `nannou` app object and immediately call it's `run()` method. It then continually draws frames based on the parameters we define. Each frame is defined by a _view_:\n\n```rust\nfn view(app: &App, model: &Model, frame: &Frame) {\n    let draw = app.draw();\n    draw.background()\n        .color(named::from_str(&model.bg_color).unwrap());\n    draw.ellipse()\n        .color(STEELBLUE)\n        .w(model.radius)\n        .h(model.radius)\n        .x_y(model.x, model.y);\n    draw.to_frame(app, &frame).unwrap();\n}\n```\n\nThis contains instructions for drawing a single frame. You can actually use `nannou` with _only_ this function if you'd like to experiment with stateless drawing ideas. Simply replace the `main()` entrypoint code with this:\n\n```rust\nfn main() {\n    nannou::sketch(view);\n}\n```\n\nWe use the library-provided `draw()` methods provided by the `app` parameter to interact with the frame. First, we set the background color and then draw an ellipse. These methods update the state of the `app` object, and then finally we draw the new state to the `frame`. We get all the parameters about what color to use and how to paint the ellipse from the _model_:\n\n```rust\nfn model(_app: &App) -> Model {\n    Model {\n        bg_color: \"honeydew\".to_string(),\n        x: 0.0,\n        y: 0.0,\n        radius: 10.0,\n    }\n}\n```\n\nThe model is the application state. Here, it's just set to these parameters: \"honeydew\" is a lovely color for the background that corresponds to one of the [defined constants](https://docs.rs/nannou/0.11.1/nannou/color/index.html#constants), and our ellipse starts off super small and at the center of the frame. Between each frame, the model might _update_:\n\n```rust\nfn update(_app: &App, model: &mut Model, _update: Update) {\n    if model.radius < 500.0 {\n        model.radius += 1.0;\n    }\n}\n```\n\nIn this function, we're given a mutable borrow of the `Model` to manipulate. This demo will check if the radius smaller than 500 pixels. If so, it's going to bump it up slightly. If not, nothing else happens.\n\nPulled all together, this app should be expected to load a mostly \"honeydew\" (off-white) screen with a small blue circle in the center that will quickly animate to grow to a slightly larger size. It then stays that way until the process ends. I know, riveting so far:\n\n![dot gif](https://thepracticaldev.s3.amazonaws.com/i/tybzj1eg0l9ik8h9duy4.gif)\n\nIt's a choppy screen record, but the actual run will be smooth. This program is already a jumping off stub for any demo using this library, feel free to ditch my larger demonstration app and go sailing forward with the [API docs](https://docs.rs/nannou/0.11.1/nannou/index.html) on your own if you already know what to write!\n\nTo implement any new functionality in our demo, we'll need to write logic that appropriately extends our model, view, and update functions to show the user what we mean.\n\n## Scaling Out\n\n### Defensive Refactor\n\nThe above demo gets us up and running, but we don't want to code directly into the main structure. This is a perfect opportunity to refactor into something that we can grow with more easily. This adds a lot of verbosity, but with Rust the more we can help the tooling the more the tooling helps us, and with a properly configured [development environment](https://marketplace.visualstudio.com/items?itemName=rust-lang.rust) it's not even that much typing. I also, er, happen to find Rust refactoring therapeutic but that's beside the point.\n\nNow, cross your fingers - we're going to wipe out this implementation in favor of a more idiomatic (and verbose) Rust approach. I'll elaborate below. For now, go ahead and replace the entire file contents of `src/main.rs` with this - there are no functional changes, ony structural:\n\n```rust\nuse nannou::{color::named, prelude::*};\nuse std::string::ToString;\n\nfn main() {\n    nannou::app(model).update(update).simple_window(view).run();\n}\n\n/// All colors used in this application\n#[derive(Debug, Clone, Copy)]\nenum Color {\n    Honeydew,\n    SteelBlue,\n}\n\nimpl ToString for Color {\n    fn to_string(&self) -> String {\n        format!(\"{:?}\", self).to_lowercase()\n    }\n}\n\n/// Type alias for nannou color type\ntype Rgb = Srgb<u8>;\n\nimpl From<Color> for Rgb {\n    fn from(c: Color) -> Self {\n        named::from_str(&c.to_string()).unwrap()\n    }\n}\n\n/// A coordinate pair - the (0,0) default is the center of the frame\n#[derive(Debug, Default, Clone, Copy)]\nstruct Point {\n    x: f32,\n    y: f32,\n}\n\nimpl Point {\n    fn new(x: f32, y: f32) -> Self {\n        Self { x, y }\n    }\n}\n\n/// Things that can be drawn to the screen\ntrait Nannou {\n    fn display(&self, draw: &app::Draw);\n    fn update(&mut self);\n}\n\n/// A circle to paint\n#[derive(Debug, Clone, Copy)]\nstruct Dot {\n    color: Color,\n    origin: Point,\n    radius: f32,\n    max_radius: f32,\n    growth_rate: f32,\n}\n\nimpl Dot {\n    fn new() -> Self {\n        Self::default()\n    }\n}\n\nimpl Nannou for Dot {\n    fn display(&self, draw: &app::Draw) {\n        draw.ellipse()\n            .w(self.radius)\n            .h(self.radius)\n            .x_y(self.origin.x, self.origin.y)\n            .color(Rgb::from(self.color));\n    }\n    fn update(&mut self) {\n        if self.radius < self.max_radius {\n            self.radius += self.growth_rate;\n        }\n    }\n}\n\nimpl Default for Dot {\n    fn default() -> Self {\n        Self {\n            color: Color::SteelBlue,\n            origin: Point::default(),\n            radius: 10.0,\n            max_radius: 200.0,\n            growth_rate: 1.0,\n        }\n    }\n}\n\n/// The application state\n#[derive(Debug)]\nstruct Model {\n    bg_color: Color,\n    current_bg: usize,\n    dot: Dot,\n}\n\nimpl Default for Model {\n    fn default() -> Self {\n        Self {\n            bg_color: Color::Honeydew,\n            current_bg: usize::default(),\n            dot: Dot::new(),\n        }\n    }\n}\n\nimpl Nannou for Model {\n    /// Show this model\n    fn display(&self, draw: &app::Draw) {\n        draw.background().color(Rgb::from(self.bg_color));\n        self.dot.display(draw);\n    }\n    /// Update this model\n    fn update(&mut self) {\n        self.dot.update();\n    }\n}\n\n//\n// Nannou interface\n//\n\n/// Nannou app model\nfn model(_app: &App) -> Model {\n    Model::default()\n}\n\n/// Nannou app update\nfn update(_app: &App, model: &mut Model, _update: Update) {\n    model.update();\n}\n\n/// Nannou app view\nfn view(app: &App, model: &Model, frame: &Frame) {\n    let draw = app.draw();\n    // Draw model\n    model.display(&draw);\n    // Render frame\n    draw.to_frame(&app, &frame).unwrap();\n}\n```\n\nAs before, I'd urge to take your time and step through this sample as well. I haven't actually changed anything at all functionally, just gotten myself organized. Start from `main()` and literally [rubber-duck](https://en.wikipedia.org/wiki/Rubber_duck_debugging) the [control flow](https://www.computerhope.com/jargon/c/contflow.htm) if you don't follow this just yet. I know, it's a lot bigger, but everything is right where it belongs. This is a much better base to build from. Running `cargo run --release` should produce an identical result to before the switch.\n\n#### Traits And Composition\n\nThe `Color` [sum type](https://en.wikipedia.org/wiki/Tagged_union) (or [Rust `enum`](https://doc.rust-lang.org/book/ch06-01-defining-an-enum.html)) is the best example of Rust-style composition:\n\n```rust\n/// All colors used in this application\n#[derive(Debug, Clone, Copy)]\nenum Color {\n    Honeydew,\n    SteelBlue,\n}\n\nimpl ToString for Color {\n    fn to_string(&self) -> String {\n        format!(\"{:?}\", self).to_lowercase()\n    }\n}\n\n/// Type alias for nannou color type\ntype Rgb = Srgb<u8>;\n\nimpl From<Color> for Rgb {\n    fn from(c: Color) -> Self {\n        named::from_str(&c.to_string()).unwrap()\n    }\n}\n```\n\nI've also defined a trait of my own:\n\n```rust\n/// Things that can be drawn to the screen\ntrait Nannou {\n    fn display(&self, draw: &app::Draw);\n    fn update(&mut self);\n}\n```\n\nIf you're already a regular Rust user, this will likely not be new - skip down to the next header. It was one of the more unfamiliar bits for me at the outset, though, and the sooner you embrace code that looks like this the sooner Rust will click. It's not nearly as complicated as it looks at first.\n\nRust does not have traditional inheritance at all, which represents an \"is-a\" relationship between related instances. Think of a `Cat` inheriting from an `Animal` superclass, because a cat \"is-a\" animal. Instead, everything is extended via composition, or a \"has-a\" relationship. Our `Cat` might know how to `speak()` and say something different than a `Dog` would with the same method, but have the `Voiced` trait provide it. Cats and dogs both \"has-a\" voice. They can manage their own behavior behind the common API instead of overriding a base class implementation. The mechanism for this is [traits](https://doc.rust-lang.org/1.8.0/book/traits.html). They fall somewhere in between (I think) a Java interface and a Haskell typeclass, and are very simple to define. For instance, `std::default::Default` is defined in the [compiler's source code](https://doc.rust-lang.org/src/core/default.rs.html#84-116) as this, omitting the doc comment and version tag:\n\n```rust\npub trait Default: Sized {\n    fn default() -> Self;\n}\n```\n\nThe trait only defines a single method that a type needs to define, returning some instance of itself that works as a default value. The trait itself doesn't care how, the compiler will decide whether a specific implementation of this trait checks out. The Rust compiler can statically OR dynamically verify whether a given object implements a trait.\n\nTraits are powerful, and in fact not only permeate Rust usage but power exactly those benefits I listed above, and the Rust compiler is powerful enough to derive many useful ones for you. If you ever do want to override that behavior, you can always provide a manual `impl Trait for Struct` block yourself that matches the prescribed API. There's a great overview of the reasoning and usage in [this blog post](https://blog.rust-lang.org/2015/05/11/traits.html) by [Aaron Turon](https://aturon.github.io/about/).\n\n##### Debug\n\n[`Debug`](https://doc.rust-lang.org/std/fmt/trait.Debug.html) provides a simple pretty-print implementation of a data structure that can be used with the `{:?}` or `{:#?}` formatters in `println!()` (etc) invocations. The default dot looks like this:\n\n```txt\nDot { color: SteelBlue, origin: Point { x: 0.0, y: 0.0 }, radius: 10.0 }\n```\n\nHere's a [playground link](https://play.rust-lang.org/?version=stable&mode=debug&edition=2018&gist=cf5af64babe1cd2523e93224862aa9bb)\n\n##### Default\n\n[`Default`](https://doc.rust-lang.org/std/default/trait.Default.html) provides a method `default()` to be used as a default constructor. When derived just calls `default()` on each member. If one or more of your members do not themselves have a `Default` implementation or you'd like to manually specify something else, you can manually define one:\n\n```rust\nimpl Default for Dot {\n    fn default() -> Self {\n        Self {\n            color: Color::SteelBlue,\n            origin: Point::default(),\n            radius: 10.0,\n        }\n    }\n}\n```\n\n##### Clone/Copy/PartialEq/PartialOrd\n\nThese aren't heavily used in this code, but are commonly found in general.\n\n1. [`Clone`](https://doc.rust-lang.org/std/clone/trait.Clone.html) - duplicate an arbitrarily nested object - potentially expensive, will call `clone()` on any child.\n1. [`Copy`](https://doc.rust-lang.org/std/marker/trait.Copy.html) - duplicate an object that's simple enough to just copy bits. My rule of thumb is that if I can have `Copy`, I take it. Must implement `Clone`.\n1. [`PartialEq`](https://doc.rust-lang.org/std/cmp/trait.PartialEq.html)/[`PartialOrd`](https://doc.rust-lang.org/std/cmp/trait.PartialOrd.html) - allow two instances of this structure to be compared for equality/magnitude respectively.\n\nThese traits are often derived, and are included in the [prelude](https://doc.rust-lang.org/std/prelude/index.html) of library functions available to all Rust modules by default.\n\n##### FromStr\n\nThis is not in the prelude and must be explicitly included:\n\n```rust\nuse std::str::FromStr;\n```\n\nYou will need to import [`FromStr`](https://doc.rust-lang.org/std/str/trait.FromStr.html) in order to use or implement it, and allows your self-defined types to [`parse()`](https://doc.rust-lang.org/std/primitive.str.html#method.parse) from string values like primitives. It's relatively straightforward to implement, but does include an associated type - I don't use it in this program but it does come up often. From the docs:\n\n```rust\n#[derive(Debug, PartialEq)]\nstruct Point {\n    x: i32,\n    y: i32\n}\n\nimpl FromStr for Point {\n    type Err = ParseIntError;\n\n    fn from_str(s: &str) -> Result<Self, Self::Err> {\n        let coords: Vec<&str> = s.trim_matches(|p| p == '(' || p == ')' )\n                                 .split(',')\n                                 .collect();\n\n        let x_fromstr = coords[0].parse::<i32>()?;\n        let y_fromstr = coords[1].parse::<i32>()?;\n\n        Ok(Point { x: x_fromstr, y: y_fromstr })\n    }\n}\n```\n\n##### ToString\n\nYou only need to import [`std::string::ToString`](https://doc.rust-lang.org/std/string/trait.ToString.html) if you plan to implement it, as I do for the `Color` enum to map to the exact string values that the library has constants for:\n\n```rust\n/// All colors used in this application\n#[derive(Debug, Clone, Copy)]\nenum Color {\n    Honeydew,\n    SteelBlue,\n}\n\nimpl ToString for Color {\n    fn to_string(&self) -> String {\n        format!(\"{:?}\", self).to_lowercase()\n    }\n}\n```\n\nThis `ToString` implementation does rely on the fact that `Debug` is also implemented for `Color`, so I can use the `{:?}` formatter on `self`.\n\n##### From/Into\n\nThis is how to convert between types within your program. Implementing [`From`](https://doc.rust-lang.org/std/convert/trait.From.html) gets you [`Into`](https://doc.rust-lang.org/std/convert/trait.Into.html) and vice versa: you get both when you implement one. You only need to directly implement `Into` if you're converting to some type outside the current crate. I use `From` to get from my special personal `Color` type to the library type the `draw` methods expect:\n\n```rust\n/// Type alias for nannou named color type\ntype Rgb = Srgb<u8>;\n\nimpl From<Color> for Rgb {\n    fn from(c: Color) -> Self {\n        named::from_str(&c.to_string()).unwrap()\n    }\n}\n```\n\nNow I can use colors I know and convert with `Rgb::from()`, but have my own control over `Color` behavior:\n\n```rust\nimpl Nannou for Model {\n    /// Show this model\n    fn display(&self, draw: &app::Draw) {\n        draw.background().color(Rgb::from(self.bg_color)); // Color::Honeydew\n        self.dot.display(draw);\n    }\n    //..\n}\n```\n\nSpecial shout-out to the aforementioned `ToString` implementation to provide `Color::to_string()`, which is where I've defined how to produce the library constants...\n\n![kronk meme](https://media.giphy.com/media/KEYEpIngcmXlHetDqz/giphy.gif)\n\n#### Quality of Life Crates\n\nWe're expecting this codebase to grow, and the Rust ecosystem has a few other tidbits that can help us spend time working on the problem, not the environment.\n\n##### Command Line Arguments\n\nI find the easiest way to get this done is [`structopt`](https://github.com/TeXitoi/structopt). This crate lets you define a struct with your options, and it custom-derives you an implementation. Add the dependency to `Cargo.toml`:\n\n```diff\n  [dependencies]\n\n  nannou = \"0.12\"\n+ structopt = \"0.3\"\n```\n\nLet's test it out by letting the user control the parameters with command-line options. Add the import tot he top and define the struct:\n\n```rust\nuse structopt::StructOpt;\n\n// ..\n\n/// A nannou demonstration application\n#[derive(StructOpt, Debug)]\n#[structopt(name = \"nannou_dots\")]\npub struct Opt {\n    /// Set dot growth rate\n    #[structopt(short, long, default_value = \"1.0\")]\n    rate: f32,\n}\n```\n\nWe want this to load when the application starts and be available everywhere. One way to accomplish this is with `lazy_static`, which lets you define static values that have some runtime initialization. This code will get run once the first time this object is accessed and cache the result for future use throughout your program. This is convenient for things like image assets, which are referred to all over the place making for some potentially sticky ownership problems, and any options passed at runtime that will be true for the entire lifetime of the program.\n\nFirst, add the dependency to `src/Cargo.toml`:\n\n```diff\n  [dependencies]\n\n+ lazy_static = \"1.4\"\n  nannou = \"0.12\"\n  structopt = \"0.3\"\n```\n\nI generally handle `lazy_static` usage that's not local to a specific function at the top of the file:\n\n```rust\nuse lazy_static::lazy_static;\n\nlazy_static! {\n    pub static ref OPT: Opt = Opt::from_args();\n}\n```\n\nCheck out where that gets us by running the auto-generated `--help/-h` flag:\n\n```txt\n$ cargo run --release -- -h\n   Compiling nannou_dots v0.1.0 (/home/ben/code/nannou_dots)\n    Finished release [optimized] target(s) in 4.83s\n     Running `target/release/nannou_dots -h`\nnannou_dots 0.1.0\nA nannou demonstration application\n\nUSAGE:\n    nannou_dots [OPTIONS]\n\nFLAGS:\n    -h, --help       Prints help information\n    -V, --version    Prints version information\n\nOPTIONS:\n    -r, --rate <rate>    Set dot growth rate [default: 1.0]\n```\n\nGood stuff. Notice how the triple-slashed doc comment for the struct member became the help string in this message, and the one for the struct itself is displayed at the top. To hook it up, make the following changes:\n\n```diff\n  impl Dot {\n      fn new() -> Self {\n-         Self::default()\n+         Self::default().set_growth_rate(OPT.rate)\n      }\n+     fn set_growth_rate(mut self, rate: f32) -> Self {\n+         self.growth_rate = rate;\n+         self\n+     }\n  }\n```\n\nI still leverage the default constructor, but instead give myself a method to set the growth rate of the model. It follows the [Builder Pattern](https://dev.to/deciduously/the-builder-pattern-249l) so that my code remains flexible for changing my mind and experimenting.\n\n##### Logging\n\nAnother way to set ourselves up for success is by hooking up the standard Rust logging tooling. Now, I'm going to toss three crates at you but don't panic, it's all just one thing. I'm using [`pretty_env_logger`](https://github.com/seanmonstar/pretty-env-logger), which dresses up the output from [`env_logger`](https://github.com/sebasmagri/env_logger) with nice colors and formatting. This itself is a wrapper around [`log`](https://docs.rs/log/0.4.8/log/), which provides a bunch of `println!()`-esque macros like `warn!()`, `debug!()`, and `info!()`. The `env_logger` crate (and thus `pretty_env_logger`) read the `RUST_LOG` environment variable at runtime to determine which statements to show without needing to recompile.  No more commenting out print statements, just pick their debug level and leave 'em all in.\n\nFirst, add some new dependencies to `Cargo.toml`:\n\n```diff\n  [dependencies]\n\n+ log = \"0.4\"\n  nannou = \"0.12\"\n+ pretty_env_logger = \"0.3\"\n```\n\nTo start it up, here's a function I just kinda copy-paste into new projects:\n\n```rust\nuse log::*;\nuse std::env::{set_var, var};\n\n/// Start env_logger\nfn init_logging(level: u8) {\n    // if RUST_BACKTRACE is set, ignore the arg given and set `trace` no matter what\n    let mut overridden = false;\n    let verbosity = if std::env::var(\"RUST_BACKTRACE\").unwrap_or_else(|_| \"0\".into()) == \"1\" {\n        overridden = true;\n        \"trace\"\n    } else {\n        match level {\n            0 => \"error\",\n            1 => \"warn\",\n            2 => \"info\",\n            3 => \"debug\",\n            _ => \"trace\",\n        }\n    };\n    set_var(\"RUST_LOG\", verbosity);\n\n    pretty_env_logger::init();\n\n    if overridden {\n        warn!(\"RUST_BACKTRACE is set, overriding user verbosity level\");\n    } else if verbosity == \"trace\" {\n        set_var(\"RUST_BACKTRACE\", \"1\");\n        trace!(\"RUST_BACKTRACE has been set\");\n    };\n    info!(\n        \"Set verbosity to {}\",\n        var(\"RUST_LOG\").expect(\"Should set RUST_LOG environment variable\")\n    );\n}\n```\n\nThis function takes a number as a level, but also checks if `RUST_BACKTRACE` is set. `RUST_BACKTRACE` will override whatever is passed to this and set `RUST_LOG` to `trace` automatically. If you pass in a `trace` level of 4 or higher it will automatically set `RUST_BACKTRACE` for you. This behavior is usually what I want.\n\nThere's a handy way to collect this information built-in to `structopt` - it can handle arguments from number of occurrences:\n\n```diff\n  fn main() {\n+     init_logging(OPT.verbosity);\n      nannou::app(model).update(update).simple_window(view).run();\n  }\n\n  /// A nannou demonstration application\n  #[derive(StructOpt, Debug)]\n  #[structopt(name = \"nannou_dots\")]\n  struct Opt {\n      /// Set dot growth rate\n      #[structopt(short, long, default_value = \"1.0\")]\n      rate: f32,\n+     /// Verbose mode (-v: warn, -vv: info, -vvv: debug, , -vvvv or more: trace)\n+     #[structopt(short, long, parse(from_occurrences))]\n+     verbosity: u8,\n  }\n```\n\nUse `cargo run --release -- -vv` to get the `info` level:\n\n![info screenshot](https://thepracticaldev.s3.amazonaws.com/i/agk7wajz6ypnduqnvzju.png)\n\nLooks like the Nannou window-handling dependency [`winit`](https://github.com/rust-windowing/winit) is onboard! You can specify per-module by setting, e.g. `RUST_LOG=nannou_dots=info` to only apply to your own included `info!()` statements.\n\nTo run it with a backtrace you can just specify 4 (or more) vs to the program with `-vvvv`:\n\n![trace screenshot](https://thepracticaldev.s3.amazonaws.com/i/2a1qfwq47vx6kcvjvx3l.png)\n\nThis allows you to basically do \"`print`\" debugging without having to comment things out and recompile. Instead, you leave everything in and just specify how much to dump out at runtime.\n\n##### Error Handling\n\nThis is more of an honorable mention, but nearly every time I write a Rust project, I end up with some enum:\n\n```rust\n#[derive(Debug)]\npub enum ProjectError {\n    ErrorOne(String),\n    ErrorTwo(u8, u8),\n    ErrorOther,\n}\n```\n\nThere's always an empty `std::error::Error` impl, a `Result<T>` alias, and a `std::fmt::Display` block so it can be used with the `{}` formatter:\n\n```rust\nimpl std::error::Error for ProjectError {}\n\npub type Result<T> = std::result::Result<T, ProjectError>;\n\nimpl std::fmt::Display for ProjectError {\n    fn fmt(&self, f: &mut std::fmt::Formatter) -> std::fmt::Result {\n        use ProjectError::*;\n        let e_str = match self {\n            ErrorOne(s) => &format!(\"{}\", s),\n            ErrorTwo(x, y) => &format!(\"expected {}, got {}\", x, y),\n            ErrorOther => \"Something went wrong!\",\n        };\n        write!(f, \"Error: {}\", e_str)\n    }\n}\n```\n\nI do this every time, and it works, and it's nice to have this control. Luckily, there's a crate for that: [`thiserror`](https://github.com/dtolnay/thiserror), which provides some custom-derive magic on it. We could replace the entire above example with this:\n\n```rust\n/// Error types\n#[derive(Error, Debug)]\nenum ProjectError {\n    #[error(\"{0}\")]\n    StringError(String),\n    #[error(\"expected {expected:?}, got {found:?}\")]\n    NumberMismatch { expected: u8, found: u8 },\n    #[error(\"Something went wrong!\")]\n    ErrorOther,\n}\n```\n\nHowever, in this app, _I'm too lazy to even muck around with that_. Who's got time for that [`anyhow`](https://github.com/dtolnay/anyhow):\n\n```diff\n  [dependencies]\n\n+ anyhow = \"1.0\"\n  lazy_static = \"1.4\"\n  log = \"0.4\"\n  nannou = \"0.12\"\n  pretty_env_logger = \"0.3\"\n  structopt = \"0.3\"\n```\n\nThen, just add `use anyhow::Result` to the top of your file and get `?` for free. If any function you write calls an operation that can fail, just make your function return this `Result<T>` and it'll just work.\n\n### Lots Of Dots\n\nLet's take our newfound structure for a spin by upping the number of dots. First, add a parameter for the user:\n\n```diff\n  /// A nannou demonstration application\n  #[derive(StructOpt, Debug)]\n  #[structopt(name = \"nannou_dots\")]\n  pub struct Opt {\n+     /// How many dots to render\n+     #[structopt(short, long, default_value = \"1\")]\n+     num_dots: u8,\n      /// Set dot growth rate\n      #[structopt(short, long, default_value = \"1.0\")]\n      rate: f32,\n      /// Verbose mode (-v: warn, -vv: info, -vvv: debug, , vvvv or more: trace)\n      #[structopt(short, long, parse(from_occurrences))]\n      verbosity: u8,\n  }\n```\n\nThe user can specify 0 through 255 dots. In the `Model`, we'll keep track of a `Vec`:\n\n```diff\n  /// The application state\n  #[derive(Debug)]\n  struct Model {\n      bg_color: Color,\n      current_bg: usize,\n-     dot: Dot,\n+     dots: Vec<Dot>,\n  }\n\n  impl Nannou for Model {\n    /// Show this model\n    fn display(&self, draw: &app::Draw) {\n        draw.background().color(Rgb::from(self.bg_color));\n-       self.dot.display(draw);\n+       self.dots.iter().for_each(|d| d.display(&draw));\n    }\n    /// Update this model\n    fn update(&mut self) {\n-       self.dot.update();\n+       self.dots.iter_mut().for_each(|d| d.update());\n    }\n  }\n```\n\nBefore we initialize them, let's flesh out the `Dot` definition to allow us to specify a start location:\n\n```diff\n  impl Dot {\n-     fn new() -> Self {\n-         Self::default().set_growth_rate(OPT.rate)\n+     fn new(point: Option<Point>) -> Self {\n+       let mut ret = Self::default();\n+       if let Some(loc) = point {\n+           ret.set_location(loc);\n+       }\n+       ret.set_growth_rate(OPT.rate)\n      }\n      fn set_growth_rate(mut self, rate: f32) -> Self {\n          self.growth_rate = rate;\n          self\n      }\n+     fn set_location(mut self, loc: Point) -> Self {\n+       self.origin = loc;\n+       self\n+    }\n  }\n```\n\nNow we can make a `Model::init_dots()` associated function that the default constructor can use:\n\n```rust\nimpl Model {\n    fn init_dots() -> Vec<Dot> {\n        let mut ret = Vec::new();\n        for _ in 0..OPT.num_dots {\n            let point_x = rand::random_range(-500.0, 500.0);\n            let point_y = rand::random_range(-500.0, 500.0);\n            ret.push(Dot::new(Some(Point::new(point_x, point_y))));\n        }\n        ret\n    }\n}\n```\n\nJust swap it in:\n\n```diff\n  impl Default for Model {\n      fn default() -> Self {\n          Self {\n              bg_color: Color::Honeydew,\n              current_bg: usize::default(),\n-             dot: Dot::new(),\n+             dots: Self::init_dots(),\n          }\n      }\n  }\n```\n\n![lots of dots](https://thepracticaldev.s3.amazonaws.com/i/j5n1dtlldrfqjp367ibc.gif)\n\n## Wrapping Up\n\nSome features I didn't touch on bundled with `nannou` include UI components, math functions, image handling, and noise generation, things you'd otherwise manually include a crate yourself for. Nannou aims to be a complete, all-in-one solution leveraging the best of the Rust ecosystem to fit this domain, and by my estimation hits the mark.\n\n### Challenges\n\nBefore moving further, my recommendation would be to split this logic into [separate modules](https://doc.rust-lang.org/book/ch07-00-managing-growing-projects-with-packages-crates-and-modules.html), instead of putting everything in `main.rs`. You do you though. Here's a few things you could try next:\n\n1. Add some sounds.\n1. Make the dots move.\n1. Make the dots different colors.\n1. Use the `noise` module to distribute the dots.\n1. Add sliders to control parameters.\n",
    "title": "Creative Coding in Rust with Nannou"
  },
  {
    "cover_image": "https://thepracticaldev.s3.amazonaws.com/i/iuakwwcexql5u0th7gtm.jpg",
    "date": "2019-12-02T12:37:02.077Z",
    "description": "Procedurally generate melodies by synthesizing your own sound waves in Rust using test-driven development.",
    "tags": "beginners, rust, tutorial, music",
    "markdown": "---\ntitle: Procedural Melody Generation in Rust\npublished: true\ndescription: Procedurally generate melodies by synthesizing your own sound waves in Rust using test-driven development.\ncover_image: https://thepracticaldev.s3.amazonaws.com/i/iuakwwcexql5u0th7gtm.jpg\ntags: beginners, rust, tutorial, music\n---\n\n## Teaching Numbers How To Sing\n\n> Everything is music. When I go home, I throw knickers in the oven and it's music. Crash, boom, bang!\n\n*- [Winona Ryder](https://en.wikipedia.org/wiki/Winona_Ryder) as [Björk](https://en.wikipedia.org/wiki/Bj%C3%B6rk) on [SNL](https://en.wikipedia.org/wiki/Saturday_Night_Live)'s [Celebrity Rock 'N' Roll Jeopardy!](https://en.wikipedia.org/wiki/Celebrity_Jeopardy!_(Saturday_Night_Live)) - [2002](https://en.wikipedia.org/wiki/2002) - [YouTube](https://youtu.be/R3V94ZtmdbQ?t=190)*\n\nIn this [post]((https://en.wikipedia.org/wiki/Blog)), we'll [throw](https://en.wikipedia.org/wiki/Throwing) something [random](https://en.wikipedia.org/wiki/Random_number_generation) into, [well](https://en.wikipedia.org/wiki/Well), a [math](https://en.wikipedia.org/wiki/Mathematics)-[oven](https://en.wikipedia.org/wiki/Subroutine) and [*viola*](https://en.wikipedia.org/wiki/Viola), [music](https://en.wikipedia.org/wiki/Music)!  We'll just skip the [crash](https://en.wikipedia.org/wiki/Crash_(computing)).\n\nIn other words, we're going to teach our [computers](https://en.wikipedia.org/wiki/Personal_computer) to [\"sing\"](https://en.wikipedia.org/wiki/Singing) using [idiomatic](https://en.wikipedia.org/wiki/Programming_idiom) [Rust](https://en.wikipedia.org/wiki/Rust_(programming_language)), backed by a little light [physics](https://en.wikipedia.org/wiki/Physics) and [music theory](https://en.wikipedia.org/wiki/Music_theory).\n\nThe [one-liner](https://en.wikipedia.org/wiki/One-liner_program) in the cover image [procedurally generates](https://en.wikipedia.org/wiki/Procedural_generation) a [melody](https://en.wikipedia.org/wiki/Melody) using [tools assumed to be present](https://en.wikipedia.org/wiki/Unix_philosophy) on a standard [desktop](https://en.wikipedia.org/wiki/Desktop_computer) [Linux distribution](https://en.wikipedia.org/wiki/Linux_distribution) like [Ubuntu](https://en.wikipedia.org/wiki/Ubuntu).  The melody produced will be composed of notes along a single [octave](https://en.wikipedia.org/wiki/Octave) in a hardcoded [key](https://en.wikipedia.org/wiki/Key_(music)) ([A major](https://en.wikipedia.org/wiki/A_major)):\n\n{% youtube uLhQQSKhTok %}\n\nBy the end of this post our program will:\n\n1. Support [86](https://en.wikipedia.org/wiki/86_(number)) different [key signatures](https://en.wikipedia.org/wiki/Key_signature) with [minimal effort](https://en.wikipedia.org/wiki/Music_and_mathematics).\n1. Support a full [108](https://en.wikipedia.org/wiki/108_(number))-key extended [piano](https://en.wikipedia.org/wiki/Piano) [keyboard](https://en.wikipedia.org/wiki/Musical_keyboard), allowing the user to pick a range.\n1. Produce any arbitrary [tone](https://en.wikipedia.org/wiki/Musical_tone) we ask for.\n1. Compile and run on [Windows](https://en.wikipedia.org/wiki/Microsoft_Windows), [MacOS](https://en.wikipedia.org/wiki/MacOS), or [Linux](https://en.wikipedia.org/wiki/Linux) with no extra code ([I tried](https://en.wikipedia.org/wiki/Nerd) all three).\n1. Encourage further [extension](https://en.wikipedia.org/wiki/Scalability) with lots of Rust-y goodness.\n\n[C# minor](https://en.wikipedia.org/wiki/C-sharp_minor) has a funky, dark kind of vibe - [Lullaby](https://en.wikipedia.org/wiki/Lullaby_(The_Cure_song)) by [The Cure](https://en.wikipedia.org/wiki/The_Cure), [Message in a Bottle](https://en.wikipedia.org/wiki/Message_in_a_Bottle_(song)) by [The Police](https://en.wikipedia.org/wiki/The_Police), [Feel It Still](https://en.wikipedia.org/wiki/Feel_It_Still) by [Portugal, The Man](https://en.wikipedia.org/wiki/Portugal._The_Man),  a bunch of [others](https://en.wikipedia.org/wiki/C-sharp_minor#Notable_songs).  Your computer could be the next [Dolly Parton](https://en.wikipedia.org/wiki/Dolly_Parton) ([Jolene](https://en.wikipedia.org/wiki/Jolene_(song))):\n\n```txt\n$ ./music -b C#2 -o 4 -s minor\n.: Cool Tunes :.\nGenerating music from the C# minor scale\nOctaves: 2 - 6\n[ C# D# E F# G# A B C# ]\n```\n\nHowever, at the end of the day, it's just the thing in the cover image.\n\nWhile the complete runnable source code is embedded within this post, the full project can also be found on [GitHub](https://github.com/deciduously/music) along with some [pre-compiled binaries](https://github.com/deciduously/music/releases/tag/v0.1.0).  Feel free to make a PR!\n\n## Table of Contents\n\n- [Preamble](#preamble)\n- [The Meme](#the-meme)\n- [The Program](#the-program)\n  - [Project Structure](#project-structure)\n        - [Dependencies](#dependencies)\n        - [Test-Driven Development](#test-driven-development)\n        - [Entry Point](#entry-point)\n        - [Traits](#traits)\n  - [Random Numbers](#random-numbers)\n  - [Mapping Numbers To Notes](#mapping-numbers-to-notes)\n        - [A Little Physics](#a-little-physics)\n          - [Sine Waves](#sine-waves)\n          - [Pitch](#pitch)\n          - [Singing](#singing)\n        - [A Little Music Theory](#a-little-music-theory)\n          - [Scientific Pitch Notation](#scientific-pitch-notation)\n          - [Intervals](#intervals)\n          - [Scales](#scales)\n          - [Key](#key)\n          - [Circle of Fifths](#circle-of-fifths)\n          - [Diatonic Modes](#diatonic-modes)\n          - [Non Heptatonic Scales](#non-heptatonic-scales)\n    - [Generating Music](#generating-music)\n      - [Cents](#cents)\n      - [Random Notes](#random-notes)\n      - [User Parameters](#user-parameters)\n- [Challenges](#challenges)\n\n## Preamble\n\n*[top](#table-of-contents)*\n\nThis tutorial is aimed at [beginners](https://en.wikipedia.org/wiki/Novice) (and up) who are comfortable solving problems with at least one [imperative](https://en.wikipedia.org/wiki/Imperative_programming), [object-oriented](https://en.wikipedia.org/wiki/Object-oriented_programming) [language](https://en.wikipedia.org/wiki/Programming_language).  It does not matter if that's [JavaScript](https://en.wikipedia.org/wiki/JavaScript) or [Python](https://en.wikipedia.org/wiki/Python_(programming_language)) or [Object Pascal](https://en.wikipedia.org/wiki/Object_Pascal), I just assume you know the [basic](https://en.wikipedia.org/wiki/Syntax_(programming_languages)) [building](https://en.wikipedia.org/wiki/Semantics_(computer_science)) [blocks](https://en.wikipedia.org/wiki/Standard_library) of [creating a program](https://en.wikipedia.org/wiki/Computer_programming) in an object-oriented style.  If you already know Rust some of this will be skimmable, but this is primarily a post about the problem space and not \"how to use Rust\".\n\nYou do not need any prior knowledge of physics or music theory, but there will be a tiny smattering of [elementary algebra](https://en.wikipedia.org/wiki/Elementary_algebra).  I promise it's quick.\n\nI have two disclaimers before getting started:\n\n1. [There are](https://en.wikipedia.org/wiki/Existence) [257](https://en.wikipedia.org/wiki/257_(number)) [links](https://en.wikipedia.org/wiki/Hyperlink) [here](https://en.wikipedia.org/wiki/Boston), [199](https://en.wikipedia.org/wiki/199_(number)) [of them](https://en.wikipedia.org/wiki/Element_(mathematics)) [to](https://en.wikipedia.org/wiki/Codomain) [Wikipedia](https://en.wikipedia.org/wiki/Main_Page).  [If](https://en.wikipedia.org/wiki/Conditional_(computer_programming)) [you're](https://en.wikipedia.org/wiki/You) [that](https://en.wikipedia.org/wiki/Autodidacticism) [kind](https://en.wikipedia.org/wiki/Impulsivity) [of](https://en.wikipedia.org/wiki/Preposition_and_postposition) [person](https://en.wikipedia.org/wiki/Person), [set](https://en.wikipedia.org/wiki/Innovation) [rules](https://en.wikipedia.org/wiki/Law).\n1. Further to Point 1, most of this I learned myself on Wikipedia, some of it while writing this post.  The rest is what I remember from [high school](https://en.wikipedia.org/wiki/High_school_(North_America)) as a [band geek](https://en.wikipedia.org/wiki/Euphonium), which was over [ten years](https://en.wikipedia.org/wiki/Decade) [ago](https://en.wikipedia.org/wiki/Past).  I do believe it's generally on the mark, but I am making no claims of authority.  If you see something, [say something](https://en.wikipedia.org/wiki/Allen_Kay#Advertisements).\n\n## The Meme\n\n*[top](#table-of-contents)*\n\nThis post was inspired by this [meme](https://en.wikipedia.org/wiki/Internet_meme) I saw when I was *attempting* to casually browse [Reddit](https://en.wikipedia.org/wiki/Reddit):\n\n![the meme](https://i.redd.it/uirqnamnjpz31.jpg)\n\nI couldn't let myself just scroll past that one, [clearly](https://en.wikipedia.org/wiki/Diatribe).  Here's a version of the [`bash`](https://en.wikipedia.org/wiki/Bash_(Unix_shell)) [pipeline](https://en.wikipedia.org/wiki/Pipeline_(Unix)) at the bottom with slightly different hard-coded values, taken from [this blog post](https://blog.robertelder.org/bash-one-liner-compose-music/) by [Robert Elder](https://www.robertelder.org/) that explores it:\n\n```bash\ncat /dev/urandom | hexdump -v -e '/1 \"%u\\n\"' | awk '{ split(\"0,2,4,5,7,9,11,12\",a,\",\"); for (i = 0; i < 1; i+= 0.0001) printf(\"%08X\\n\", 100*sin(1382*exp((a[$1 % 8]/12)*log(2))*i)) }' | xxd -r -p | aplay -c 2 -f S32_LE -r 16000\n```\n\nThe linked blog post is considerably more brief and assumes a greater degree of background knowledge than this one, but that's not to discredit it at as a fantastic source.  That write-up and Wikipedia were all I needed to complete this translation, and I had absolutely not a clue how this whole thing worked going in.\n\nI've gotta be honest - I didn't even try the `bash` and immediately dove into the pure Rust solution.  Nevertheless, it serves as a [solid](https://en.wikipedia.org/wiki/Solid) [30,000ft](https://en.wikipedia.org/wiki/Flight_level) [roadmap](https://en.wikipedia.org/wiki/Plan):\n\n1. `cat /dev/urandom`: Get a stream of random binary data.\n1. `hexdump -v -e '/1 \"%u\\n\"'`: Convert binary to 8-bit base-10 integers (0-255).\n1. `awk '{ split(\"0,2,4,5,7,9,11,12\",a,\",\"); for (i = 0; i < 1; i+= 0.0001) printf(\"%08X\\n\", 100*sin(1382*exp((a[$1 % 8]/12)*log(2))*i)) }'`: Map integers to pitches and return sound wave samples.\n1. `xxd -r -p`: Convert hexadecimal samples back to binary.\n1. `aplay -c 2 -f S32_LE -r 16000`: Play back binary samples as sound wave.\n\nDon't worry at all if some or all of this is incomprehensible.  You don't need to have a clue how any of it works yet.  This program is not a direct translation of that [code](https://en.wikipedia.org/wiki/Source_code), and I'm not going to elaborate much on what any of the specific commands in the pipeline mean (read the linked post for that), just the relevant logic.   By the time we're done, you'll be able to pick apart the whole thing yourself.\n\nIf you'd like the challenge of implementing this yourself from scratch in your own language, **stop right here**.  If you get stuck, this should all apply to whatever you've got going unless you've gone real funky with it - in which case, it sounds cool and you should show me.\n\n[¡Vámonos!](https://en.wikipedia.org/wiki/Party)\n\n## The Program\n\n*[top](#table-of-contents)*\n\n### Project Structure\n\n*[top](#table-of-contents)*\n\nBefore getting started, ensure you have at least the default stable Rust toolchain [installed](https://www.rust-lang.org/tools/install).  If you've previously installed `rustup` at any point, just issue `rustup update` to grab the latest stable build.  This code was written with `rustc` [version 1.39.0](https://blog.rust-lang.org/2019/11/07/Rust-1.39.0.html) (released [November 4](https://en.wikipedia.org/wiki/November_4), [2019](https://en.wikipedia.org/wiki/2019)), but should compile on any version compatible with [Rust 2018](https://doc.rust-lang.org/edition-guide/rust-2018/index.html).  \n\nThen, spin up a new library project:\n\n```txt\n$ cargo new music --lib\n```\n\nOpen your new `music` project directory in the environment of your choice.  If you're not already sure what to use with Rust, I recommend [Visual Studio Code](https://code.visualstudio.com/) with the [Rust Language Server](https://github.com/rust-lang/rls) installed for in-editor development support.  If you have `rustup` present, the [VS Code RLS extension](https://marketplace.visualstudio.com/items?itemName=rust-lang.rust) has a one-click set up that's worked for me without a hitch on both Linux and Windows 10.\n\n#### Dependencies\n\n*[top](#table-of-contents)*\n\nWe'll use a few crates, which is the Rust term for external libraries.  Two of them give us functionality not found in the Rust standard library:\n\n* [`rand`](https://docs.rs/rand/0.7.2/rand/) - [Random number generation](https://en.wikipedia.org/wiki/Random_number_generation)\n* [`rodio`](https://docs.rs/rodio/0.10.0/rodio/) - [Audio signal playback](https://en.wikipedia.org/wiki/Audio_signal)\n\n`rand` is in place of [`/dev/urandom`](https://en.wikipedia.org/wiki//dev/random), and `rodio` will cover  and [`aplay`](https://linux.die.net/man/1/aplay).  We can replace [`hexdump`](https://en.wikipedia.org/wiki/Hex_dump), [`xxd`](https://www.systutorials.com/docs/linux/man/1-xxd/), and the `awk` logic built-in stuff.  The `rand` crate provides several different random number generators (RNGs), and the one perfect for this application isn't included by default.  We have to specifically add it to the configuration, so its declaration is split out to deifne multiple keys.\n\nThe other two are just for programmer comfort.  I also use [`pretty_assertions`](https://docs.rs/pretty_assertions/0.6.1/pretty_assertions/) to make the [test runner](https://en.wikipedia.org/wiki/Unit_testing) output a little prettier and [`structopt`](https://github.com/TeXitoi/structopt) to get a minimal-effort CLI.\n\nIn `Cargo.toml`:\n\n```toml\n[dependencies]\n\nrodio = \"0.10\"\nstructopt = \"0.3\"\n\n# the section below is equivalent TOML to:\n# rand = { features = [ \"small_rng\" ], version = \"0.7\" }\n# it's a style preference\n[dependencies.rand]\n\nfeatures = [ \"small_rng\" ]\nversion = \"0.7\"\n\n[dev-dependencies]\n\npretty_assertions = \"0.6\"\n```\n\n#### Test Driven Development\n\n*[top](#table-of-contents)*\n\nCargo has auto-created a file at `src/lib.rs` to define your library, but hold on - we're going to write this program using [Test-Driven Development](https://en.wikipedia.org/wiki/Test-driven_development), or TDD.  This means we're going to define the expected behavior of new functionality *before* attempting the implementation.  Here's an example of a test we'll write later:\n\n```rust\n#[test]\nfn test_add_interval() {\n    use Interval::*;\n    assert_eq!(Unison + Unison, Unison);\n    assert_eq!(Unison + Maj3, Maj3);\n    assert_eq!(Maj2 + Min3, Perfect4);\n    assert_eq!(Octave + Octave, Unison);\n    assert_eq!(Tritone + Tritone, Unison);\n    assert_eq!(Maj7 + Min3, Maj2);\n}\n```\n\nEach test is just a plain Rust function.  In it we use a feature of our library and assert that the result matches the expected result that we hardcode.  In this test, we're specifying the expected behavior when adding musical intervals together with the `+` operator.  This way, we can tell immediately if the code we write actually matches the specification.  As our code evolves we'll immediately notice if we break functionality that worked previously.\n\nThe Rust toolchain has a test runner built-in, so this all works out of the box.  Every function marked `#[test]` will be executed during an invocation of `cargo test`, so we can see anywhere our expectations are not met in the whole program.\n\nAll of our tests will live in their own separate module.  Create a new file at `src/test.rs`:\n\n```rust\nuse super::*;\nuse pretty_assertions::assert_eq;\n\n#[test]\nfn test_cool_greeting() {\n    assert_eq!(GREETING, \".: Cool Tunes :.\");\n}\n```\n\nIf the two arguments to `assert_eq!()` are not equal, this test will fail and you'll get pretty-printed output showing you the difference between the two.  I generally put the test code in the first argument and the hardcoded expected value in the second.\n\nThis test is importing a constant, `GREETING`, from our library, and expecting it to be the string `Cool Tunes (tm)`.  This code will fail to compile, though - there's no such `super::GREETING` constant available to test!  The `super` part means \"one module higher\" - `test` is a child module of the `music` library we're writing, so the crate root in `lib.rs` corresponds to `super` here.  You could also say `crate::*` or `music::*`.  Now open up `src/lib.rs` and replace the contents with this:\n\n```rust\n#[cfg(test)]\nmod test;\n\npub const GREETING: &str = \".: Cool Tunes :.\\n\";\n```\n\nThe `#[cfg(test)]` tag tells the compiler to only build the `test` module when we're using the test runner.  The compiler won't even look at it when using `cargo run`.\n\nNow we can give `cargo test` a go - the first build will take the longest as it gathers and builds dependencies for the first time:\n\n![test fail](https://thepracticaldev.s3.amazonaws.com/i/4wgtozis0bfoxnmedvrp.png)\n\nWhoops - no need to include a newline with the greeting string, we'll pass it to [`println!()`](https://doc.rust-lang.org/std/macro.println.html) in the program which includes one:\n\n```diff\n  #[cfg(test)]\n  mod test;\n\n- pub const GREETING: &str = \".: Cool Tunes :.\\n\";\n+ pub const GREETING: &str = \".: Cool Tunes :.\";\n```\n\nLet's try this again:\n\n![test pass](https://thepracticaldev.s3.amazonaws.com/i/ajubi9o41dsfvkfwcnqa.png)\n\nGood to go!  Throughout this post new sections of code will be preceded by a test with he `#[test]` tag that defines the behavior we're aiming for.  These tests should all go in `src/test.rs`.\n\n#### Entry Point\n\n*[top](#table-of-contents)*\n\nFinally, create a directory called `src/bin`.  This optional module is where Cargo will by default expect an executable, if present.  Place a file at `src/bin/music.rs` - this filename will be the name of the executable, so when distributed you'd execute `./music` to run the code in `main()`:\n\n```rust\nuse music::*;\n\nfn main() {\n    println!(\"{}\", GREETING);\n}\n```\n\nGive it a go with `cargo run`:\n\n```txt\n$ cargo run\n   Compiling music-rebuild v0.1.0 (/home/you/code/music)\n    Finished dev [unoptimized + debuginfo] target(s) in 0.16s\n     Running `target/debug/music`\n.: Cool Tunes :.\n```\n\nThe *coolest* tunes.  You can see right above the output the actual name of the executable file being run - you can find it right in your project's `target` directory:\n\n![executable screenshot](https://thepracticaldev.s3.amazonaws.com/i/15gwbnp3j15lb2a8fhps.png)\n\nYour `music/src` directory should look like the following:\n\n```txt\n~/code/music $ tree src\nsrc\n├── bin\n│   └── music.rs\n├── lib.rs\n└── test.rs\n\n1 directory, 3 files\n```\n\nThis is a good time for an initial commit:\n\n```txt\n$ git add .\n$ git commit -m \"Initial Commit\"\n```\n\nYou can run a faster compilation pass with `cargo check` if you just want the compiler to verify your code's integrity, not produce a binary.\n\n#### Traits\n\nIf you're already familiar with developing in Rust, you can probably skip right to [Random Numbers](#random-numbers).\n\nIf you are brand new to the language, you should expect to spend a little longer with the code in this post to extract the relevant bits.  I'm not going to devote much time in general to Rust-specific topics, as there is a vast amount of great material already available devoted to that, but out of all of Rust's interesting properties this is the big one you'll need to know about to follow along with this program.\n\nMost of this code is compartmentalized using [Rust traits](https://doc.rust-lang.org/book/ch10-02-traits.html), which collect bits of composable functionality (my type \"has-a\" `ScreenWidget` trait that implements those methods).  It's OOP, Jim, [but not as we know it](https://en.wikipedia.org/wiki/Star_Trekkin%27).  In this post, you can think of them like interfaces in more traditional [class-based OOP](https://en.wikipedia.org/wiki/Class-based_programming) languages.  They're a little more powerful, but that analogy does fit and is enough to get you up and running.\n\nOne big difference from \"regular\" object-oriented programming is that this is all we get.  There's no such thing as inheritance (my type \"is-a\" more specific `ScreenWidget` type and inherits or overrides those methods).  As a result, composition of functionality features heavily in Rust code in the form of `impl SomeTrait for MyType {}` blocks, with collections of method definitions inside.\n\nThe compiler can infer types in many situations, and can auto-fill these trait implementations for us in many cases with a `#[derive(..)]` tag.  In this case, the default `value` is also the `Default` value for the primitive type `i32`, which for all the numeric types is `0` (or `0.0`).  When that's what we want in this context too, we can ask the compiler to auto-generate the above code with this syntax:\n\n```rust\n#[derive(Default)]\nstruct MyType {\n    value: i32,\n}\n```\n\nWriting this code is nearly equivalent to the former in terms of the output machine code.  This syntax is a [macro](https://en.wikipedia.org/wiki/Macro_(computer_science)) that will expand to the full Rust code for any `impl Trait` block being derived blocks before your program is compiled as if it had been fully written out.  In general, a struct can derive a trait as long as all of its members implement that trait, either derived or hand-implemented, because the compiler will just call that method for whatever type it needs.  The auto-derived `Default` implementation looks like this when your code reaches the compiler:\n\n```rust\nimpl Default for MyType {\n    fn default() -> Self {\n        Self { value: i32::default() }\n    }\n}\n```\n\nNow we can use `MyType::default()` to construct an object of this type - the following two statements store the same object to `obj`:\n\n```rust\nlet obj = MyType::default();\n// or\nlet obj: MyType = MyType { value: 0 }\n```\n\nIt's up to the specific type to decide what happens, as long as the input and output types match.  Whenever you get lost just remember - it's [traits all the way down](https://en.wikipedia.org/wiki/Turtles_all_the_way_down).\n\nWe can also define methods that aren't associated with any trait with, e.g.:\n\n```rust\nimpl MyType {\n    fn some_specific_thing(&self) {\n        // ..\n    }\n}\n```\n\n### Random Numbers\n\n*[top](#table-of-contents)*\n\nThe first part of the one-liner is  `cat /dev/urandom | hexdump -v -e '/1 \"%u\\n\"'`, which gets a source of random bytes (8-bit binary values) and shows them to the user formatted as base-10 integers.\n\nWhen I sat down to write this program, I decided to knock out this functionality first mostly because I immediately knew how.  The `rand` crate can give us random 8-bit integers out of the box by using the so-called [\"turbofish\"](https://docs.serde.rs/syn/struct.Turbofish.html) syntax to specify a type: `random::<u8>()` will produce a random [unsigned](https://en.wikipedia.org/wiki/Signedness) [8 bit](https://en.wikipedia.org/wiki/8-bit) integer ([`u8`](https://doc.rust-lang.org/nightly/std/primitive.u8.html)) with the default generator settings.\n\nTo match the one-liner exactly, we could write an [`Iterator`](https://doc.rust-lang.org/std/iter/index.html) implementation with a `next()` method like this - no need to copy this code to your project, we don't use it again:\n\n```rust\nimpl Iterator for RandomBytes {\n    type Item = u8;\n\n    fn next(&mut self) -> Option<Self::Item> {\n        Some(random::<Self::Item>())\n    }\n}\n```\n\nIf we endlessly call this method, we'll get output that matches `cat /dev/urandom | hexdump -v -e '/1 \"%u\\n\"'` exactly:\n\n```rust\nfn main() {\n    let mut rands = RandomBytes::new();\n    loop {\n        println!(\"{}\", rands.next().unwrap());\n    }\n}\n```\n\nI'm not bothering to show you the full runnable snippet - try to build the `RandomBytes` struct yourself if you'd like.  In a `bash` one-liner you've got to take your randomness where you can get it, but the `rand` crate provides a richer set of tools.  Before streaming in something random, we need to think about what exactly it is we're randomizing.\n\nIn this application, we want to pick a musical note from a set of valid choices at random.  The `awk` code does this with the modulo operator:  `list[n % listLength]`.  That will take a random index that's ensured to be a valid list member.  See if you can spot the corresponding section of the cover image code.\n\n\nWe get to use the [`rand::seq::SliceRandom`](https://docs.rs/rand/0.7.2/rand/seq/trait.SliceRandom.html) trait here.  This gives us a `choose()` method that we can call on any [slice](https://doc.rust-lang.org/std/slice/index.html) to pull a random member.\n\nSo, there's no need for a `RandomBytes` iterator.  Instead, we need to define a list of notes and call `[notes].choose(&mut RNG)` on it to get a specific note to play.\n\n### Mapping Numbers To Notes\n\n*[top](#table-of-contents)*\n\nTake a closer look at step 3 of the pipeline.  This code closely resembles the core logic we ultimately end up with:\n\n```bash\nsplit(\"0,2,4,5,7,9,11,12\",a,\",\");\nfor (i = 0; i < 1; i += 0.0001)\n    printf(\"%08X\\n\",\n           100 * sin(1382 * exp((a[$1 % 8] / 12) * log(2)) * i))\n```\n\nThis is probably still not too helpful for most - there's [magic numbers](https://en.wikipedia.org/wiki/Magic_number_(programming)) and [sines](https://en.wikipedia.org/wiki/Sine) and [logarithms](https://en.wikipedia.org/wiki/Logarithm) (oh, my) - and its written in freakin' [`AWK`](https://en.wikipedia.org/wiki/AWK).  Don't despair if this still doesn't mean much (or literally anything) to you.\n\nWe can glean a bit of information at a glance, though, and depending on your current comfort with this domain you may be able to kind of understand the general idea here.  It looks like we're going to tick up floating point values by ten-thousandths from zero to one (`0.0`, `0.0001`, `0.0002`, etc.) with `for (i = 0; i < 1; i += 0.0001)`, and do... I don't know, some math on each value.  In that math we're using both `i`, the current fractional part from 0 to 1, and `$1`, which is the random 8-bit integer being piped in.  Specifically, we're indexing into a list `a`:  `a[$1 % 8]`.  In other words, we're using the random byte `0-255` to select an index `0-7` from this list.\n\nThe list is defined with `split(\"0,2,4,5,7,9,11,12\",a,\",\");`, which means split the first parameter string input by the third parameter  `\",\"`, and store the resulting list of elements to the second parameter `a` (`awk` is terse).  After we do the math, we're going to print it out as an 8-digit hex number: `printf(\"%08X\\n\", someResult)` - this [`printf`](https://en.wikipedia.org/wiki/Printf_format_string) formatter means we want a [0-padded](https://en.wikipedia.org/wiki/Npm_(software)#Notable_breakages) number that's 8 digits long in [upper-case](https://en.wikipedia.org/wiki/Letter_case) [hexadecimal](https://en.wikipedia.org/wiki/Hexadecimal).  The [base 10](https://en.wikipedia.org/wiki/Decimal) integer [`42`](https://en.wikipedia.org/wiki/Phrases_from_The_Hitchhiker%27s_Guide_to_the_Galaxy#Answer_to_the_Ultimate_Question_of_Life,_the_Universe,_and_Everything_(42)) would be printed as `0000002A`.\n\nTL;DR for each ten-thousandth between 0 and 1 `i`, select a value `n` from `[0,2,4,5,7,9,11,12]` and return the result of `100 * sin(1382 * exp((n / 12) * log(2) * i)`.\n\nIf you recognize this formula, awesome!  You can probably skim the next section.  If not, it's still [not time to panic](https://en.wikipedia.org/wiki/Phrases_from_The_Hitchhiker%27s_Guide_to_the_Galaxy#Don't_Panic).  We just need to get some fundamentals out of the way.\n\n#### A Little Physics\n\n*[top](#table-of-contents)*\n\n[Sound](https://en.wikipedia.org/wiki/Sound) is composed physically of [vibrations](https://en.wikipedia.org/wiki/Vibration).  These vibrations cause perturbations in some [medium](https://en.wikipedia.org/wiki/Transmission_medium), which radiate out from the source of the vibration, and those perturbations cause [tiny oscillating variations](https://en.wikipedia.org/wiki/Sound_pressure) in local atmospheric pressure.  These variations are what we experience as sound.  When we're talking about [hearing](https://en.wikipedia.org/wiki/Hearing) a sound with our [ears](https://en.wikipedia.org/wiki/Ear), the medium is usually [air](https://en.wikipedia.org/wiki/Atmosphere_of_Earth).\n\n##### Sine Waves\n\n*[top](#table-of-contents)*\n\nSound propagates as a [wave](https://en.wikipedia.org/wiki/Wave).  In [reality](https://en.wikipedia.org/wiki/Reality) a sound contains many components but for this program we can talk about a super-simplified version that can be represented as a single [sine wave](https://en.wikipedia.org/wiki/Sine_wave):\n\n![sine waves](https://upload.wikimedia.org/wikipedia/commons/6/6d/Sine_waves_different_frequencies.svg)\n\nIf the x-axis is time, a sine wave represents a recurring action with a smooth (or analog) oscillation between peaks.  Lots of physical phenomena are analog in nature - picture a ball getting tossed, rising and then falling.  The ball passes through every point in between the highest point it hits and the ground, so we can measure at any arbitrary instant an exact fractional height.  It doesn't fall from 8 meters to 7 meters all at once, it passes through 7.9, 7.8, 7.7, and all infinitesimally small heights in between too.  It's the same with sound.\n\nInstead of height above the ground on the y axis, we have a [pressure gradient](https://en.wikipedia.org/wiki/Sound_pressure) from an equilibrium.  The air is getting rapidly pushed and pulled by this vibration across space as a wave.  It's still a physical phenomenon - a pressure gradient rises to a peak and then falls back to equilibrium and then below to an opposite peak, oscillating back and forth.  It doesn't just magically become a different higher value all at once.  A guitar string wobbling passes through each point in space between the two extremes it's tensing to and from, so the vibrations it causes oscillate in kind.\n\nYou can actually use [math](https://en.wikipedia.org/wiki/Fourier_transform) to represent multi-component sound waves as a single wave - the ability to do so is what enables the whole field of [telecommunications](https://en.wikipedia.org/wiki/Telecommunication).  We're not going to touch that today, partially because I don't actually know how to perform a Fourier transform myself (yet).  One single sine wave is enough of a signal to produce a tone, so we can keep it simple.\n\nThere are two interesting properties of a sine wave: the [amplitude](https://en.wikipedia.org/wiki/Amplitude), which measures the current deviation from the 0 axis for a given *x*, and the [frequency](https://en.wikipedia.org/wiki/Frequency), which is how close together these peaks at maximal amplitudes are, or how frequently this recurring thing happens.  The combination of the two dictate how we perceive the sound.  The amplitude will be perceived as [volume](https://en.wikipedia.org/wiki/Loudness) and the frequency as [pitch](https://en.wikipedia.org/wiki/Pitch_(music)).\n\nYou can do cool things like frequency modulation and amplitude modulation to encode your signal as modulations of one of these properties:\n\n![modulation](https://upload.wikimedia.org/wikipedia/commons/a/a4/Amfm3-en-de.gif)\n\nThis is how FM and AM radio process incoming sound signals to broadcast them to your radio, which can then perform the reverse and play back the original sound.   We also don't do any of that today, but you could experiment with these functions with this as a base.\n\n##### Pitch\n\n*[top](#table-of-contents)*\n\nThe standard unit for frequency is the [Hertz](https://en.wikipedia.org/wiki/Hertz), abbreviated `Hz`, which measures the *number of cycles per second*.  One cycle here is the distance (or time) between two peaks on the graph, or the time it takes to go all the way around the circle once:\n\n![cycle gif](https://media.giphy.com/media/F5rQlfTXqCJ8c/giphy.gif)\n\nAccording to my super scientific smartphone stopwatch observations, this gif is chugging along at a whopping 0.2Hz.\n\nRecall above that we saw we're going to run a loop like this:  `for (i = 0; i < 1; i += 0.0001)`.  In that loop, the math we process includes the function `sin()`.  If one were to, say, calculate a bunch of points along a single cycle of a sine wave like this one, it sure seems like just such a loop could get the job done.\n\nThe higher the frequency, or closer together the peaks representing maximum positive amplitudes, the higher the pitch.\n\n![frequency](https://upload.wikimedia.org/wikipedia/commons/e/ea/Wave_frequency.gif)\n\nSound is a continuous spectrum of frequency, but when we make music we tend to prefer [notes](https://en.wikipedia.org/wiki/Musical_note) at set frequencies, or pitches.  I'm using [fundamental frequency](https://en.wikipedia.org/wiki/Fundamental_frequency) and pitch interchangeably, because for this application specifically they are, but go Wiki-diving if you want to learn about the distinction and nuance at play here.  The nature of sound is super cool but super complex and outside of the scope of this post - we just want to hear some numbers sing, we don't need to hear a full orchestra.\n\nOne of the super cool things about it is the [octave](https://en.wikipedia.org/wiki/Octave).  Octaves just sound related, you know?\n\nIt turns out the relationship is physical - to increase any pitch by an octave, you double the frequency.  Not only that, this fixed ratio actually holds for any arbitrary smaller or larger interval as well.  This system is called [\"equal temperament\"](https://en.wikipedia.org/wiki/Equal_temperament) - every pair of adjacent notes has the same ratio, regardless of how you define \"adjacent\".  To get halfway to the next octave, you multiply by 1.5 instead of 2.\n\nTo start working with concrete numbers, we need some sort of standard to start multiplying from.   Some of the world has settled on [440Hz](https://en.wikipedia.org/wiki/A440_(pitch_standard)) - it's [ISO](https://en.wikipedia.org/wiki/International_Organization_for_Standardization) [16](https://www.iso.org/standard/3601.html), at least.  It's also apparently called \"The Stuttgart Pitch\", which is funny.\n\n![stuttgart](https://i.imgflip.com/3h0y3g.jpg)\n\nWe can keep track of Hertz with a double-precision floating-point value:\n\n```rust\n#[derive(Debug, Default, Clone, Copy, PartialEq, PartialOrd)]\npub struct Hertz(f64);\n```\n\nThis is just a floating point value, but I didn't just assign an alias like `type Hertz = f64`.   Instead, I made my very own fully-fledged new type.  A lot of this program will involve type conversions and unit conversions, but they will all be explicit and defined in places we expect.  When manipulating our increasing set of abstractions we don't want to have to think about things like floating point accuracy - it should just work as we expect.  The [tuple struct](https://doc.rust-lang.org/1.37.0/book/ch05-01-defining-structs.html#using-tuple-structs-without-named-fields-to-create-different-types) syntax is perfect for this, when the underlying value is just a single value but there may be complex relationships with other types.\n\nLuckily, the compiler can actually derive a number of things for us straight from the inner value.  For the rest, we'll provide our own implementations that destructure the tuple:\n\n```rust\n#[test]\nfn test_subtract_hertz() {\n    assert_eq!(Hertz(440.0) - Hertz(1.0), Hertz(439.0))\n}\n```\n\n```rust\nuse std::ops::Sub;\n\nimpl Sub for Hertz {\n    type Output = Self;\n    fn sub(self, rhs: Self) -> Self::Output {\n        Self(self.0 - rhs.0)\n    }\n}\n```\n\nThis allows us to subtract two `Hertz` values with the subtraction operator `-`, and get a `Hertz` back.  We can also give ourselves some more helpful conversion traits - this gets us both the defined `from()` and the type-inferred `into()` in both directions with `f64`:\n\n```rust\nimpl From<Hertz> for f64 {\n    fn from(h: Hertz) -> Self {\n        h.0\n    }\n}\n\nimpl From<f64> for Hertz {\n    fn from(f: f64) -> Self {\n        Self(f)\n    }\n}\n```\n\nThere are a lot of unit conversions throughout this program but *all* of them are explicit and defined where we expect them.  This does add to our boilerplate, but reduces the element of surprise - my LEAST favorite element in programming.  Next, we need a way to represent a pitch:\n\n```rust\n#[derive(Debug, Clone, Copy, PartialEq, PartialOrd)]\npub struct Pitch(Hertz);\n```\n\nI didn't take `Default` this time - the default pitch is not 0Hz.  We want our new `Pitch` type to default to A440, but also accept any arbitrary value:\n\n```rust\n#[test]\nfn test_new_pitch() {\n    assert_eq!(Pitch::default(), Pitch(Hertz(440.0)));\n    assert_eq!(Pitch::new(MIDDLE_C), Pitch(Hertz(261.626)));\n}\n```\n\nThe following code gets us there:\n\n```rust\npub const STANDARD_PITCH: Hertz = Hertz(440.0);\npub const MIDDLE_C: Hertz = Hertz(261.626);\n\n// ..\n\n#[derive(Debug, Clone, Copy, PartialEq, PartialOrd)]\npub struct Pitch(Hertz);\n\nimpl Pitch {\n    pub fn new(frequency: Hertz) -> Self {\n        Self(frequency)\n    }\n}\n\nimpl Default for Pitch {\n    fn default() -> Self {\n        Self(STANDARD_PITCH)\n    }\n}\n```\n\nVerify it all with `cargo test`:\n\n```txt\nrunning 3 tests\ntest test::test_cool_greeting ... ok\ntest test::test_subtract_hertz ... ok\ntest test::test_new_pitch ... ok\n\ntest result: ok. 3 passed; 0 failed; 0 ignored; 0 measured; 0 filtered out\n```\n\nI won't keep prompting you to do so, but the prevailing wisdom is to run it after adding every test and watch it fail even before adding the implementation.  Then you can watch it fail in incrementally different ways as you get closer to the correct code.\n\n##### Singing\n\n*[top](#table-of-contents)*\n\nKnowing what frequency to use to produce a given pitch is all well and good, but we need to actually make the sound.  When we sing with our [voice](https://en.wikipedia.org/wiki/Human_voice), our [speech organs](https://en.wikipedia.org/wiki/Speech_organ) vibrate to produce complex multiple-component sound waves of differing frequencies.  We can program ourselves a little one-frequency \"speechbox\" that produces a wave programmatically instead of by physically vibrating.\n\nTo do so, we're going to perform an [analog-to-digital conversion](https://en.wikipedia.org/wiki/Analog-to-digital_converter).  That's a super fancy term for something that isn't that complicated conceptually.  We're going to [graph](https://en.wikipedia.org/wiki/Graph_of_a_function) the function of a single cycle of the target sine wave and [sample](https://en.wikipedia.org/wiki/Sampling_(signal_processing)) it.  If you already know how we're doing this part, feel free to skip this explanation.\n\nA sine wave, as we've seen, is smooth.  However, what's a graph but a visualization of a function.  There's some function `mySineWave(x)` that's this wave when we put in a bunch of fractional numbers between *0* and *1*.  The  `for (i = 0; i < 1; i += 0.0001)` loop is doing exactly that, calculating a series of adjacent points at a fixed interval (`0.0001`) that satisfy the function of this wave.  That's our analog-to-digital conversion  - we've taken something smooth, a sine wave, and made it digital, or made up of discrete points.  For `Pitch::default()`, this cycle repeats 440 times each second.\n\nThe [sample rate](https://en.wikipedia.org/wiki/Sampling_(signal_processing)#Sampling_rate) of an audio stream is how many points to store for each one of these cycles, or is how high-fidelity this \"digital snapshot\" of the wave is.  Lots of applications use a [44.1KHz](https://en.wikipedia.org/wiki/44,100_Hz) sample rate - a bit higher than 10KHz like the example.  According to the [sampling theorem](https://en.wikipedia.org/wiki/Nyquist%E2%80%93Shannon_sampling_theorem), the threshold for ensuring you've captured a sufficient sample from an analog signal is that the sample rate must be greater than twice the frequency you you're sampling.  Humans can hear about 20Hz to 20,000Hz.  This means we need at least 40,000 samples, and 44,100 exceeds that.  The `rodio` crate defaults to 48KHz, which per that same link is the standard for professional digital audio equipment.\n\nThe maximum amplitude this struct can represent is the maximum wave that fits in whatever type is used for the sample, because that's the biggest *x* will ever be in either direction - `1` or `-1`.  This code uses an `f32`, or single-precision 4-byte float.\n\nThe `rodio` crate actually has a built-in [`rodio::source::SineWave`](https://docs.rs/rodio/0.10.0/rodio/source/struct.SineWave.html) that takes a frequency in Hertz but as an unsigned integer.  Go ahead and throw a quick conversion in for our `Pitch` type:\n\n```rust\n// lib.rs\nuse rodio::source::SineWave;\n\nimpl From<Pitch> for f64 {\n    fn from(p: Pitch) -> Self {\n        p.0.into()\n    }\n}\n\nimpl From<Pitch> for SineWave {\n    fn from(p: Pitch) -> Self {\n        SineWave::new(f64::from(p) as u32)\n    }\n}\n```\n\nThis code should produce an A440 tone when executed with `cargo run`:\n\n```rust\n// bin/music.rs\nuse rodio::{Sink, source::SineWave, default_output_device};\n\nfn main() {\n    let device = default_output_device().unwrap();\n    let sink = Sink::new(&device);\n    let source =  SineWave::from(Pitch::default());\n    sink.append(source);\n    sink.sleep_until_end();\n}\n```\n\nI'll briefly cover the other tidbits: `default_output_device()` attempts to find the running system's currently configured default audio device, and a [`Sink`](https://docs.rs/rodio/0.10.0/rodio/struct.Sink.html) is an abstraction for handling multiple sounds.  It works like an audio track.  You can `append()` a new `Source` of sound, and the first one appended starts the track.  A newly appended track will play after whatever is playing finishes, but a `rodio::source::SineWive` is an infinite source.\n\nFinally, we have to `sleep_until_end()` the thread until the sound completes playing (which for `SineWave` is never), or else the program will move right along and exit.  You'll have to kill this run with `Ctrl-C`, this sound will play forever.\n\nBy simply modulating the pitch passed to `SineWave`, we could generate any pitch we want.  That's what the one-liner does, it's selecting an offset to pass from the list `[0,2,4,5,7,9,11,12]`, so we know that sequence works. And, like, *cool*, I guess.  We can do a lot better, though.  What's so special about these numbers?\n\n#### A Little Music Theory\n\n*[top](#table-of-contents)*\n\nWhile it's great to have a voice we can sing with with, I'm sure we'd all prefer it if our program learned how to sing on key.  To get oriented, A440 is the A above Middle C on a piano:\n\n![piano](https://upload.wikimedia.org/wikipedia/commons/thumb/2/2e/Piano_Frequencies.svg/2560px-Piano_Frequencies.svg.png)\n\n##### Scientific Pitch Notation\n\n*[top](#table-of-contents)*\n\nInstead of frequencies in Hertz, it's much easier to manipulate pitches in terms of [Scientific Pitch Notation](https://en.wikipedia.org/wiki/Scientific_pitch_notation), another fancy name for a simple concept.  The piano keyboard above was labelled according to this standard.  The A440 pitch is denoted `\"A4\"` in this system.  We're going to want to parse them from strings:\n\n```rust\n#[test]\nfn test_new_piano_key() {\n    use Accidental::*;\n    use NoteLetter::*;\n    assert_eq!(\n        PianoKey::default(),\n        PianoKey {\n            note: Note {\n                letter: C,\n                accidental: None\n            },\n            octave: 0\n        }\n    );\n    assert_eq!(\n        PianoKey::new(\"A4\").unwrap(),\n        PianoKey {\n            note: Note {\n                letter: A,\n                accidental: None\n            },\n            octave: 4\n        }\n    );\n    assert_eq!(\n        PianoKey::new(\"G♭2\").unwrap(),\n        PianoKey {\n            note: Note {\n                letter: G,\n                accidental: Some(Flat)\n            },\n            octave: 2\n        }\n    );\n    assert_eq!(\n        PianoKey::new(\"Gb2\").unwrap(),\n        PianoKey {\n            note: Note {\n                letter: G,\n                accidental: Some(Flat)\n            },\n            octave: 2\n        }\n    );\n    assert_eq!(\n        PianoKey::new(\"F#8\").unwrap(),\n        PianoKey {\n            note: Note {\n                letter: F,\n                accidental: Some(Sharp)\n            },\n            octave: 8\n        }\n    );\n}\n```\n\nWe also want to reject invalid letters - we can use `#[should_panic]` to indicate that a panic is the expected behavior.  No need to bother defining a real match:\n\n```rust\n#[test]\n#[should_panic]\nfn test_reject_piano_key_too_high() {\n    assert_eq!(PianoKey::new(\"A9\").unwrap(), PianoKey::default());\n}\n\n#[test]\n#[should_panic]\nfn test_reject_piano_key_invalid_letter() {\n    assert_eq!(PianoKey::new(\"Q7\").unwrap(), PianoKey::default());\n}\n```\n\nAdditionally, we want to go the other way.  We need a `to_string()` or some such:\n\n```rust\n#[test]\nfn test_piano_key_to_str() {\n    assert_eq!(PianoKey::default().to_string(), \"C0\".to_string());\n    assert_eq!(PianoKey::new(\"A#4\").unwrap().to_string(), \"A#4\".to_string());\n    assert_eq!(PianoKey::new(\"Bb5\").unwrap().to_string(), \"B♭5\".to_string())\n}\n```\n\nA more robust system would also accept multiple accidentals and coerce, e.g. `E#` -> `F`, but this gets us going.\n\nTo implement this, it's easiest to start at the bottom.  With `NoteLetter`, we also want to assign a numeric index but it's not as simple as with the intervals - these don't all have the same value.  We will store an index:\n\n```rust\nuse std::io;\nuse std::str::FromStr;\n\n#[derive(Debug, Clone, Copy, PartialEq)]\nenum NoteLetter {\n    C = 0,\n    D,\n    E,\n    F,\n    G,\n    A,\n    B,\n}\n\nimpl Default for NoteLetter {\n    fn default() -> Self {\n        NoteLetter::C\n    }\n}\n\nimpl FromStr for NoteLetter {\n    type Err = io::Error;\n\n    fn from_str(s: &str) -> Result<Self, Self::Err> {\n        match s.to_uppercase().as_str() {\n            \"A\" => Ok(NoteLetter::A),\n            \"B\" => Ok(NoteLetter::B),\n            \"C\" => Ok(NoteLetter::C),\n            \"D\" => Ok(NoteLetter::D),\n            \"E\" => Ok(NoteLetter::E),\n            \"F\" => Ok(NoteLetter::F),\n            \"G\" => Ok(NoteLetter::G),\n            _ => Err(io::Error::new(\n                io::ErrorKind::InvalidInput,\n                format!(\"{} is not a valid note\", s),\n            )),\n        }\n    }\n}\n```\n\nThe notes are C-indexed, for better or for worse, so `NoteLetter::default()` should return that variant.  We'll talk more about why it's C and not A after learning about Modes below.   Don't worry, it's suitably disappointing.\n\nNext up we have a `Note` which consists of a letter and optionally an accidental:\n\n```rust\n#[derive(Default, Debug, Clone, Copy, PartialEq)]\npub struct Note {\n    accidental: Option<Accidental>,\n    letter: NoteLetter,\n}\n```\n\nFor this one, we only want to display a character for an accidental if there's anything there:\n\n```rust\nimpl fmt::Display for Note {\n    fn fmt(&self, f: &mut fmt::Formatter) -> fmt::Result {\n        let acc_str = if let Some(a) = self.accidental {\n            format!(\"{}\", a)\n        } else {\n            \"\".to_string()\n        };\n        write!(f, \"{:?}{}\", self.letter, acc_str)\n    }\n}\n```\n\nThere's a little more logic to pull them out of strings:\n\n```rust\nimpl FromStr for Note {\n    type Err = io::Error;\n    fn from_str(s: &str) -> Result<Self, Self::Err> {\n        let char_strs = char_strs(s);\n        let mut char_strs = char_strs.iter();\n        // note will be first\n        if let Some(letter) = char_strs.next() {\n            let letter = NoteLetter::from_str(letter)?;\n            if let Some(accidental) = char_strs.next() {\n                // check if it's valid\n                let accidental = Accidental::from_str(accidental)?;\n                return Ok(Self {\n                    letter,\n                    accidental: Some(accidental),\n                });\n            } else {\n                return Ok(Self {\n                    letter,\n                    accidental: None,\n                });\n            }\n        }\n        Err(io::Error::new(\n            io::ErrorKind::InvalidInput,\n            format!(\"{} is not a valid note\", s),\n        ))\n    }\n}\n```\n\nThis uses one helper function I defined:\n\n```rust\n#[test]\nfn test_char_strs() {\n        assert_eq!(char_strs(\"Hello\"), [\"H\", \"e\", \"l\", \"l\", \"o\"])\n}\n```\n\nIf anyone has a cleaner solution I'm all ears:\n\n```rust\nfn char_strs<'a>(s: &'a str) -> Vec<&'a str> {\n    s.split(\"\")\n        .skip(1)\n        .take_while(|c| *c != \"\")\n        .collect::<Vec<&str>>()\n}\n```\n\nThe missing piece is the `Accidental`.  [Accidentals](https://en.wikipedia.org/wiki/Accidental_(music)) are represented in strings as `♭` for flat or `#` for sharp, which lower or raise the note by one semitone (or `Interval::Min2`) respectively.  This does produce 14 possible values for 12 possible semitones - the exceptions are wherever there's no black key in between two white keys.\n\n```rust\n#[derive(Debug, Clone, Copy, PartialEq)]\nenum Accidental {\n    Flat,\n    Sharp,\n}\n\nimpl fmt::Display for Accidental {\n    fn fmt(&self, f: &mut fmt::Formatter) -> fmt::Result {\n        use Accidental::*;\n        let acc_str = match self {\n            Flat => \"♭\",\n            Sharp => \"#\",\n        };\n        write!(f, \"{}\", acc_str)\n    }\n}\n\nimpl FromStr for Accidental {\n    type Err = io::Error;\n\n    fn from_str(s: &str) -> Result<Self, Self::Err> {\n        match s {\n            \"b\" | \"♭\" => Ok(Accidental::Flat),\n            \"#\" => Ok(Accidental::Sharp),\n            _ => Err(io::Error::new(\n                io::ErrorKind::InvalidInput,\n                format!(\"{} is not a valid accidental\", s),\n            )),\n        }\n    }\n}\n```\n\nThere is third accidental called \"natural\", `♮`, which cancels these out.  To represent a pitch in data we don't need it - we can get each of the piano keys with just `Accidental::Sharp`.  We really just include `Accidental::Flat` for a smooth user experience - people expect those to be valid notes, even though they represent the same pitch.  The natural symbol is generally used for overriding a [key signature](https://en.wikipedia.org/wiki/Key_signature), which defines the default accidental for all the notes within a scale on [sheet music](https://en.wikipedia.org/wiki/Staff_(music)).  There are a series of accidentals on the margin of the staff that apply to all notes, which is how we ensure we play notes within a single given scale, or [key](https://en.wikipedia.org/wiki/Key_(music)).  However, you may choose to compose a melody that contains a note outside this key.  If encounter the note `F#♮` on your sheet, you play an F.  This program isn't (yet) smart enough to work with these.\n\nNow we can finally define a specific tone on a full piano.  A standard pitch, in our program a `PianoKey`, is composed of two components: a `Note` and a 0-indexed octave:\n\n```rust\n#[derive(Default, Debug, Clone, Copy, PartialEq)]\npub struct PianoKey {\n    note: Note,\n    octave: u8,\n}\n```\n\nTo show them, we just want to print them out next to each other:\n\n```rust\nimpl fmt::Display for PianoKey {\n    fn fmt(&self, f: &mut fmt::Formatter) -> fmt::Result {\n        write!(f, \"{}{}\", self.note, self.octave)\n    }\n}\n```\n\nThis one also has a little more logic to pull out of a string, building from the constituent components:\n\n```rust\nimpl FromStr for PianoKey {\n    type Err = io::Error;\n\n    fn from_str(s: &str) -> Result<Self, Self::Err> {\n        // It makes sense to get the letter to Intervals\n        if let Some(octave) = char_strs(s).last() {\n            if let Ok(octave) = octave.parse::<u8>() {\n                let note = Note::from_str(&s[0..s.len() - 1])?;\n                if octave <= Self::max_octave() {\n                    Ok(Self { note, octave })\n                } else {\n                    Err(io::Error::new(\n                        io::ErrorKind::InvalidInput,\n                        format!(\"{} is too high!\", octave),\n                    ))\n                }\n            } else {\n                Err(io::Error::new(\n                    io::ErrorKind::InvalidInput,\n                    format!(\"{} is too high for this keyboard\", octave),\n                ))\n            }\n        } else {\n            Err(io::Error::new(\n                io::ErrorKind::InvalidInput,\n                format!(\"{} is not a valid note\", s),\n            ))\n        }\n    }\n}\n```\n\nThe octave just starts at 0 and won't ever realistically rise above 255, so a `u8` is fine.  We can give ourselves a few convenience methods:\n\n```rust\nimpl PianoKey {\n    pub fn new(s: &str) -> Result<Self, io::Error> {\n        Self::from_str(s)\n    }\n    fn max_octave() -> u8 {\n        8\n    }\n}\n```\n\nThanks to all the nested `Default` blocks, the `Default` implementation that the compiler derives for `PianoKey` corresponds to the official base pitch of this system, `C0`, specified in the first assertion of the test.  Speaking of which, `test_new_pitch()` should now pass.  \n\n##### Intervals\n\nThe cyan key is Middle C, and A440 is highlighted in yellow.  The octaves on an 88-key piano are numbered as shown, so often A440 is simply denoted \"A4\" especially when dealing with a keyboard.  You may own a tuner that marks 440Hz/A4 specifically if you're a musician.  This pitch is used for calibrating musical instruments and tuning a group, as well as a baseline constant for calculating frequencies.\n\nNote how each octave starts at C, not A, so A4 is actually higher in pitch than C4.  Octaves are \"C-indexed\" and base 8: `C D E F G A B C` is the base unmodified scale.\n\nThe smallest of interval between notes on a piano (and most of Western music) is called a [semitone](https://en.wikipedia.org/wiki/Semitone), also called a minor second or half step.  We'll need to keep track of these as the basic unit of a keyboard interval:\n\n```rust\n#[derive(Debug, Default, Clone, Copy, PartialEq)]\npub struct Semitones(i8);\n\nimpl From<i8> for Semitones {\n    fn from(i: i8) -> Self {\n        Self(i)\n    }\n}\n\nimpl From<Semitones> for i8 {\n    fn from(s: Semitones) -> Self {\n        s.0\n    }\n}\n```\n\nTake a look back at that piano diagram above - one semitone is the distance between two adjacent keys.  A *whole* step, or a [major second](https://en.wikipedia.org/wiki/Major_second), is equal to two semitones, or two adjacent white keys that pass over a black key.  To play from C4 to C5, you'll use 12 keys (count all the white and black keys in a bracket), so octaves are divided into 12 equal semitones.  There's a name for [each interval](https://en.wikipedia.org/wiki/Interval_(music)#Main_intervals):\n\n```rust\n#[derive(Debug, Clone, Copy, PartialEq, PartialOrd)]\npub enum Interval {\n    Unison = 0,\n    Min2,\n    Maj2,\n    Min3,\n    Maj3,\n    Perfect4,\n    Tritone,\n    Perfect5,\n    Min6,\n    Maj6,\n    Min7,\n    Maj7,\n    Octave,\n}\n```\n\nBy including a numeric index with `Unison = 0`, each variant also gets assigned the next successive ID.  This way we can refer to each by name but also get an integer corresponding to the number of semitones when needed: `Interval::Maj2 as i8` returns `2_i8`.\n\nTwo identical notes are called a [unison](https://en.wikipedia.org/wiki/Unison), with 0 cents.  These intervals are defined within a single octave, so any of them apply across octaves as well - A4 and A5 are in unison just like A4 and another A4, and C4 and A5 is still a major sixth.  The terms \"major\", \"minor\", and \"perfect\" are not arbitrary, but that discussion is outside the scope of this post.  I will note that the [tritone](https://en.wikipedia.org/wiki/Tritone), representing 3 whole tones or 6 semitones like `F-B`, is the only one that's none of the three.\n\nIf interested, I recommend [harmony](https://en.wikipedia.org/wiki/Harmony) for your next rabbit hole.  The tritone takes a leading role in [dissonance](https://en.wikipedia.org/wiki/Consonance_and_dissonance), and to hear it in action you should check out what the [Locrian mode](https://en.wikipedia.org/wiki/Locrian_mode) we defined sounds like with this program.  The C major scale has a perfect fifth, 5 semitones at the [dominant](https://en.wikipedia.org/wiki/Dominant_(music)) scale [degree](https://en.wikipedia.org/wiki/Degree_(music)) - and the Locrian mode has a tritone which is one extra semitone.\n\nThese all map to numbers, but we don't want to have to think about the rules when adding and subtracting.  Let's do a little plumbing:\n\n```rust\n#[test]\nfn test_add_interval() {\n    use Interval::*;\n    assert_eq!(Unison + Unison, Unison);\n    assert_eq!(Unison + Maj3, Maj3);\n    assert_eq!(Maj2 + Min3, Perfect4);\n    assert_eq!(Octave + Octave, Unison);\n    assert_eq!(Tritone + Tritone, Unison);\n    assert_eq!(Maj7 + Min3, Maj2);\n}\n\n#[test]\nfn test_sub_interval() {\n    use Interval::*;\n    assert_eq!(Unison - Unison, Unison);\n    assert_eq!(Unison - Maj3, Min6);\n    assert_eq!(Maj2 - Min3, Maj7);\n    assert_eq!(Octave - Octave, Unison);\n    assert_eq!(Tritone - Tritone, Unison);\n    assert_eq!(Maj7 - Min3, Min6);\n}\n```\n\nFirst, a little plumbing:\n\n```rust\nimpl From<Interval> for i8 {\n    fn from(i: Interval) -> Self {\n        Semitones::from(i).into()\n    }\n}\n\nimpl From<Semitones> for Interval {\n    fn from(s: Semitones) -> Self {\n        use Interval::*;\n        let int_semitones = i8::from(s);\n        match int_semitones {\n            0 => Unison,\n            1 => Min2,\n            2 => Maj2,\n            3 => Min3,\n            4 => Maj3,\n            5 => Perfect4,\n            6 => Tritone,\n            7 => Perfect5,\n            8 => Min6,\n            9 => Maj6,\n            10 => Min7,\n            11 => Maj7,\n            12 | _ => Interval::from(Semitones(int_semitones % Octave as i8)),\n        }\n    }\n}\n\nimpl From<Interval> for Semitones {\n    fn from(i: Interval) -> Self {\n        Semitones(i as i8)\n    }\n}\n```\n\nNow we can define `Add` and `Sub`:\n\n```rust\nuse std::ops::{Add, Sub};\n\nimpl Add for Interval {\n    type Output = Self;\n    fn add(self, rhs: Self) -> Self {\n        Interval::from(Semitones(\n            i8::from(self) + i8::from(rhs) % Interval::Octave as i8,\n        ))\n    }\n}\n\nimpl Sub for Interval {\n    type Output = Self;\n    fn sub(self, rhs: Self) -> Self {\n        let mut delta = i8::from(self) - i8::from(rhs);\n        if delta < 0 {\n            delta += Interval::Octave as i8;\n        };\n        Interval::from(Semitones(delta))\n    }\n}\n```\n\nThat gets us `+` and `-`, but we're going to want `+=` later too and that's really easy now:\n\n```rust\nuse std::ops::AddAssign;\n\nimpl AddAssign for Interval {\n    fn add_assign(&mut self, rhs: Self) {\n        *self = *self + rhs;\n    }\n}\n```\n\nWe can also relate Notes to Intervals pretty well:\n\n```rust\n#[test]\nfn test_get_note_interval_from_c() {\n    use Interval::*;\n    assert_eq!(Note::from_str(\"A\").unwrap().interval_from_c(), Maj6);\n    assert_eq!(Note::from_str(\"A#\").unwrap().interval_from_c(), Min7);\n    assert_eq!(Note::from_str(\"Bb\").unwrap().interval_from_c(), Min7);\n    assert_eq!(Note::from_str(\"B\").unwrap().interval_from_c(), Maj7);\n    assert_eq!(Note::from_str(\"C\").unwrap().interval_from_c(), Unison);\n    assert_eq!(Note::from_str(\"C#\").unwrap().interval_from_c(), Min2);\n    assert_eq!(Note::from_str(\"D\").unwrap().interval_from_c(), Maj2);\n    assert_eq!(Note::from_str(\"D#\").unwrap().interval_from_c(), Min3);\n    assert_eq!(Note::from_str(\"E\").unwrap().interval_from_c(), Maj3);\n    assert_eq!(Note::from_str(\"F\").unwrap().interval_from_c(), Perfect4);\n    assert_eq!(Note::from_str(\"F#\").unwrap().interval_from_c(), Tritone);\n    assert_eq!(Note::from_str(\"G\").unwrap().interval_from_c(), Perfect5);\n    assert_eq!(Note::from_str(\"G#\").unwrap().interval_from_c(), Min6);\n}\n\n#[test]\nfn test_get_note_offset() {\n    use Interval::*;\n    let a = Note::from_str(\"A\").unwrap();\n    assert_eq!(Note::from_str(\"A\").unwrap().get_offset(a), Unison);\n    assert_eq!(Note::from_str(\"A#\").unwrap().get_offset(a), Min2);\n    assert_eq!(Note::from_str(\"B\").unwrap().get_offset(a), Maj2);\n    assert_eq!(Note::from_str(\"C\").unwrap().get_offset(a), Min3);\n    assert_eq!(Note::from_str(\"C#\").unwrap().get_offset(a), Maj3);\n    assert_eq!(Note::from_str(\"D\").unwrap().get_offset(a), Perfect4);\n    assert_eq!(Note::from_str(\"D#\").unwrap().get_offset(a), Tritone);\n    assert_eq!(Note::from_str(\"E\").unwrap().get_offset(a), Perfect5);\n    assert_eq!(Note::from_str(\"F\").unwrap().get_offset(a), Min6);\n    assert_eq!(Note::from_str(\"F#\").unwrap().get_offset(a), Maj6);\n    assert_eq!(Note::from_str(\"G\").unwrap().get_offset(a), Min7);\n    assert_eq!(Note::from_str(\"G#\").unwrap().get_offset(a), Maj7);\n}\n\n#[test]\nfn test_add_interval_to_note() {\n    use Interval::*;\n    let a = Note::from_str(\"A\").unwrap();\n    assert_eq!(a + Unison, a);\n    assert_eq!(a + Min2, Note::from_str(\"A#\").unwrap());\n    assert_eq!(a + Maj2, Note::from_str(\"B\").unwrap());\n    assert_eq!(a + Min3, Note::from_str(\"C\").unwrap());\n    assert_eq!(a + Maj3, Note::from_str(\"C#\").unwrap());\n    assert_eq!(a + Perfect4, Note::from_str(\"D\").unwrap());\n    assert_eq!(a + Tritone, Note::from_str(\"D#\").unwrap());\n    assert_eq!(a + Perfect5, Note::from_str(\"E\").unwrap());\n    assert_eq!(a + Min6, Note::from_str(\"F\").unwrap());\n    assert_eq!(a + Maj6, Note::from_str(\"F#\").unwrap());\n    assert_eq!(a + Min7, Note::from_str(\"G\").unwrap());\n    assert_eq!(a + Maj7, Note::from_str(\"G#\").unwrap());\n}\n```\n\nThis all works with the logic we've already modelled:\n\n```rust\nimpl From<Interval> for Note {\n    // Take an interval from C\n    fn from(i: Interval) -> Self {\n        use Interval::*;\n        let mut offset = Unison;\n        // That's a series of Min2\n        let scale = Scale::Chromatic.get_intervals();\n        scale.iter().take(i as usize).for_each(|i| offset += *i);\n        Note::default() + offset\n    }\n}\n\nimpl Add<Interval> for Note {\n    type Output = Self;\n\n    fn add(self, rhs: Interval) -> Self {\n        let semitones = Semitones::from(rhs);\n        let mut ret = self;\n        for _ in 0..i8::from(semitones) {\n            ret.inc();\n        }\n        ret\n    }\n}\n\nimpl AddAssign<Interval> for Note {\n    fn add_assign(&mut self, rhs: Interval) {\n        *self = *self + rhs;\n    }\n}\n```\n\nFor `Add<Interval> for Note` to work, we need to add some extra helper methods:\n\n```rust\nimpl NoteLetter {\n    // ..\n    fn inc(self) -> Self {\n        use NoteLetter::*;\n        match self {\n            C => D,\n            D => E,\n            E => F,\n            F => G,\n            G => A,\n            A => B,\n            B => C,\n        }\n    }\n}\n\nimpl Note {\n    fn interval_from_c(self) -> Interval {\n        use Accidental::*;\n        let ret = self.letter.interval_from_c();\n        if let Some(acc) = self.accidental {\n            match acc {\n                Flat => return Interval::from(Semitones::from(i8::from(Semitones::from(ret)) - 1)),\n                Sharp => return ret + Interval::Min2,\n            }\n        };\n        ret\n    }\n    fn get_offset_from_interval(self, other: Interval) -> Interval {\n        let self_interval_from_c = self.interval_from_c();\n        self_interval_from_c - other\n    }\n    fn get_offset(self, other: Self) -> Interval {\n        let self_interval_from_c = self.interval_from_c();\n        let other_interval_from_c = other.interval_from_c();\n        self_interval_from_c - other_interval_from_c\n    }\n    fn inc(&mut self) {\n        use Accidental::*;\n        use NoteLetter::*;\n        if let Some(acc) = self.accidental {\n            self.accidental = None;\n            match acc {\n                Sharp => {\n                    self.letter = self.letter.inc();\n                }\n                Flat => {}\n            }\n        } else {\n            // check for special cases\n            if self.letter == B || self.letter == E {\n                self.letter = self.letter.inc();\n            } else {\n                self.accidental = Some(Sharp);\n            }\n        }\n    }\n}\n```\n\nHold on, though - this won't compile yet.  The `impl From<Interval> for Note` block depends on the intervals for `Scale::Chromatic`, and we haven't talked about scales yet.\n\n##### Scales\n\n*[top](#table-of-contents)*\n\nA [scale](https://en.wikipedia.org/wiki/Scale_(music)) is a series of notes (frequencies) defined in terms of successive intervals from a base note.  We'll start with the [major scale](https://en.wikipedia.org/wiki/Major_scale):\n\n```rust\n#[derive(Debug, Clone, Copy, PartialEq)]\npub enum Scale {\n    Major,\n}\n\nimpl Default for Scale {\n    fn default() -> Self {\n        Scale::Major\n    }\n}\n```\n\nClearly, there isn't a black key between every white key - there must be a method to the madness.  The piano is designed to play notes from a category of scales called [diatonic scales](https://en.wikipedia.org/wiki/Diatonic_scale), where the full range of an octave consists of five whole steps and two half steps.  That's why our `NoteLetter` indices needed some extra logic - while each pair of adjacent keys is one semitone, that doesn't always mean a white key to a black key or vice versa - the note pairs B/C and E/F are both only separated by one semitone.\n\nWe can see this visually on the keyboard - it has the same 8-length whole/half step pattern all the way through.  The distribution pattern begins on C, but the keyboard itself starts at A0 and ends at C8.  A piano is thus designed because it can play music across the full range of diatonic scales.  This is where we get those base 8 sequences - just start on a different note.\n\nThat base pattern is the C [major scale](https://en.wikipedia.org/wiki/Major_scale).  Start at Middle C, the one highlighted in cyan above, and count up to the next C key, eight white keys to the left.  Each time you skip a black key is a whole step and if the two white keys are adjacent it's a half step.  These are the steps you get counting up to the next C, when the pattern repeats.  This totals 12 semitones per octave:\n\n```txt\nwhole, whole, half, whole, whole, whole, half\n  2  +  2   +  1  +   2   +  2  +   2  +  1   =  12  \nC    D     E      F       G      A     B     C\n```\n\nWe can hardcode this sequence in Rust as a `Vec<Interval>`:\n\n```rust\nimpl Scale {\n    fn get_intervals(self) -> Vec<Interval> {\n        use Interval::*;\n        use Scale::*;\n        match self {\n            Major => vec![Maj2, Maj2, Min2, Maj2, Maj2, Maj2, Min2],\n        }\n    }\n}\n```\n\nWe need a method to map to exact intervals:\n\n```rust\n#[test]\nfn test_note_letter_to_interval() {\n    use Interval::*;\n    use NoteLetter::*;\n    assert_eq!(C.interval_from_c(), Unison);\n    assert_eq!(D.interval_from_c(), Maj2);\n    assert_eq!(E.interval_from_c(), Maj3);\n    assert_eq!(F.interval_from_c(), Perfect4);\n    assert_eq!(G.interval_from_c(), Perfect5);\n    assert_eq!(A.interval_from_c(), Maj6);\n    assert_eq!(B.interval_from_c(), Maj7);\n}\n```\n\nCheck out that interval sequence - we've seen something like this somewhere before:\n\n```bash\nsplit(\"0,2,4,5,7,9,11,12\",a,\",\");\n```\n\nAha!  It's was a major scale over one octave this whole time, as a series of semitone offsets:\n\n```txt\nwhole, whole, half, whole, whole, whole, half\n  2  +  2   +  1  +   2   +  2  +   2  +  1\n0    2     4      5      7      9     11     12\nUn. Min2  Maj2  Perf4  Perf5   Maj6 Maj7   Octave\nA4    B4   C#5    D5     E5    F#5   G#5    A5\n```\n\nLuckily *we already told Rust about this* when we defined the major scale.  Now our modelling efforts are finally beginning to pay off:\n\n```rust\nimpl NoteLetter {\n    fn interval_from_c(self) -> Interval {\n        use Interval::Unison;\n        Scale::default()\n            .get_intervals()\n            .iter()\n            .take(self as usize)\n            .fold(Unison, |acc, i| acc + *i)\n    }\n}\n```\n\nWe can work with scales using the Rust [iterator methods](https://doc.rust-lang.org/std/iter/trait.Iterator.html)!  This function takes the first n intervals of a scale, and then uses the special `impl Add for Interval` logic we defined to total everything up.  For instance, to calculate `F`, this function grabs the first 3 intervals, `[Maj2, Maj2, Min2]`, and then sums them up, using `Unison`, or 0, as the base.  This calculates the sum of `[2,2,1]`, which is `5` semitones, or `Interval::Perfect4`.\n\nDoing the same exercise with the same intervals starting on a different while key will also produce a major scale but you will start using the black keys to do so.  C is the note that allows you to stick to only white keys with this interval pattern, or has no sharps or flats in the key signature.  Before we start generating sequences of notes, though, we need a way to represent a note.\n\n##### Key\n\n*[top](#table-of-contents)*\n\nFor context, once again here's the original line we're dealing with:\n\n```bash\nsplit(\"0,2,4,5,7,9,11,12\",a,\",\");\n```\n\nWe've now discovered that that list represents the list of semitone offsets from A4 that represent an A major scale.  The random notes that get produced will all be frequencies that correspond to these offsets from 440Hz.\n\nWe way, way overshot this in the process of modelling the domain.  We can now automatically generate sequences of `PianoKey` structs that correspond to keys on an 88-key piano to select from: `[C4 D4 E4 F4 G4 A5 B5 C5]`.  If we want a different scale, we can just ask.\n\nWe don't necessarily want to stick within a single octave, though. We want to make available the full 108 keys from C0 to B8 (even larger than the standard piano from the diagram), letting the user decide how many octaves to pick from, but only use notes in the key.\n\n```rust\n#[derive(Debug, Default, Clone, Copy, PartialEq)]\npub struct Key {\n    base_note: PianoKey,\n    octaves: u8,\n    scale: Scale,\n}\n\nimpl Key {\n    pub fn new(scale: Scale, base_note: PianoKey, octaves: u8) -> Self {\n        let octaves = if base_note.octave + octaves > 8 {\n            PianoKey::max_octave() - base_note.octave\n        } else {\n            octaves\n        };\n        Self {\n            base_note,\n            octaves,\n            scale,\n        }\n    }\n    fn all_keys(self) -> Vec<PianoKey> {\n            let notes = self.get_notes();\n            let mut ret = Vec::new();\n            for i in 0..self.octaves {\n                notes.iter().for_each(|n| {\n                    ret.push(\n                        PianoKey::from_str(&format!(\"{}{}\", *n, i + self.base_note.octave)).unwrap_or_else(|_|\n                            PianoKey::from_str(&format!(\"{}{}\", *n, PianoKey::max_octave())).unwrap(),\n                        ),\n                    )\n                });\n            }\n            ret\n        }\n}\n```\n\nThese will be displayed as simply the octave-less notes in the scale:\n\n```rust\n#[test]\nfn test_c_major() {\n    assert_eq!(\n        &Key::new(Scale::default(), PianoKey::default(), 1).to_string(),\n        \"[ C D E F G A B C ]\"\n    )\n}\n\n#[test]\nfn test_a_major() {\n    assert_eq!(\n        &Key::new(Scale::default(), PianoKey::from_str(\"A4\").unwrap(), 1).to_string(),\n        \"[ A B C# D E F# G# A ]\"\n    )\n}\n\n#[test]\nfn test_g_major() {\n    assert_eq!(\n        &Key::new(Scale::default(), PianoKey::from_str(\"G4\").unwrap(), 1).to_string(),\n        \"[ G A B C D E F# G ]\"\n    )\n}\n```\n\nTo produce all the notes in a given key, we need to calculate them from the scale and the base note:\n\n```rust\nimpl Key {\n    // ..\n    pub fn get_notes(self) -> Vec<Note> {\n        let mut ret = vec![self.base_note.note];\n        let mut offset = Interval::Unison;\n        self.scale.get_intervals().iter().for_each(|i| {\n            offset += *i;\n            ret.push(self.base_note.note + offset)\n        });\n        ret\n    }\n}\n```\n\n```rust\nimpl fmt::Display for Key {\n    fn fmt(&self, f: &mut fmt::Formatter) -> fmt::Result {\n        let notes = self.get_notes();\n        let mut ret = String::from(\"[ \");\n        notes.iter().for_each(|n| ret.push_str(&format!(\"{} \", *n)));\n        ret.push_str(\"]\");\n        write!(f, \"{}\", ret)\n    }\n}\n```\n\nThis uses the `impl Add for Interval` logic we'd previous defined to count up successive intervals across a scale, resulting in a more concrete set of notes.  Now we can add the `Display` implementation used in the test code -  this trait also provides the `to_string()` method:\n\n```rust\nimpl fmt::Display for Key {\n    fn fmt(&self, f: &mut fmt::Formatter) -> fmt::Result {\n        let notes = self.get_notes();\n        let mut ret = String::from(\"[ \");\n        notes.iter().for_each(|n| ret.push_str(&n.to_string()));\n        ret.push_str(\"]\");\n        write!(f, \"{}\", ret)\n    }\n}\n```\n\n##### Circle of Fifths\n\n*[top](#table-of-contents)*\n\nWith `Key` defined, we can start talking about other scales.\n\nUsing the same intervals as the C major scale starting on a different note will also produce a major scale but you will start using the black keys.  This is called the key signature, and there's one for each variant of the major scale starting from each black key.  They're related by the [circle of fifths](https://en.wikipedia.org/wiki/Circle_of_fifths):\n\n![circle](https://upload.wikimedia.org/wikipedia/commons/3/33/Circle_of_fifths_deluxe_4.svg)\n\nThe C major scale has all white keys.  To find the version of the major scale that adds one single black key to augment a tone, you go up a perfect fifth, or 7 semitones: [`Interval::Perfect5`](https://en.wikipedia.org/wiki/Perfect_fifth).  This has a ratio 3:2.\n\nOne perfect fifth up from `C` is `G`, so the next scale around the circle is [G major](https://en.wikipedia.org/wiki/G_major).  It has one sharp: A.  Go [back up](#a-little-music-theory) to the piano diagram and count up the major scale sequence from G, for example one note below the yellow A4.  You'll need the `F#` black key at the last step right before G5, but all the other hops white stick to the white keys.  [D major](https://en.wikipedia.org/wiki/D_major) will need two black keys, `F#` and `C#`.  If you continue incrementing a fifth (remember, octave is irrelevant here), you'll hit all 12 possible patterns before getting back to C.  To get through all the key signatures incrementally, one accidental at a time, you keep going up by perfect fifths.  Once you come all the way back to C, you'll have hit all 12 keys, encompassing all possible key signatures.\n\nThis diagram also shows the [relative natural minor](https://en.wikipedia.org/wiki/Relative_key) for each.  That's a sneak preview of the Aeolian mode in the next section!\n\nIt's true that, e.g. `D#` and `E♭` represent the same pitch - what's different is why we got there.  After the midway point, it's easier to denote 5 flats than 7 sharps, even though they mean the same tones - there's only 5 black keys to choose from, after all.\n\nTo go counter-clockwise, go up by a perfect fourth every time, which is 5 semitones.  This is known as \"circle of fourths\", and is more commonly associated with [jazz](https://en.wikipedia.org/wiki/Jazz) music whereas fifths are seen in more [classical](https://en.wikipedia.org/wiki/Classical_music) contexts.\n\nThis program doens't use it, but we can generate all of them by just passing each note into `Key::new()`:\n\n```rust\nimpl Scale {\n    pub fn circle_of_fifths() -> Vec<Key> {\n        let mut ret = Vec::new();\n        // Start with C\n        let mut current_base = Note::default();\n        // Increment by fifths and push to vector\n        for _ in 0..ScaleLength::Dodecatonic as usize {\n            ret.push(Key::new(Scale::default(), &current_base.to_string()));\n            current_base += Interval::Perfect5;\n        }\n        ret\n    }\n}\n```\n\nThat's twelve scales for free:\n\n```txt\n[ C D E F G A B C ]\n[ G A B C D E F# G ]\n[ D E F# G A B C# D ]\n[ A B C# D E F# G# A ]\n[ E F# G# A B C# D# E ]\n[ B C# D# E F# G# A# B ]\n[ F# G# A# B C# D# F F# ]\n[ C# D# F F# G# A# C C# ]\n[ G# A# C C# D# F G G# ]\n[ D# F G G# A# C D D# ]\n[ A# C D D# F G A A# ]\n[ F G A A# C D E F ]\n```\n\nThis implementation isn't smart enough to switch to flats halfway through to represent the black keys used - could be a fun mini-challenge!  Maybe you could extend this to hop to different scales around the circle periodically.\n\n##### Diatonic Modes\n\n*[top](#table-of-contents)*\n\nNow we can produce the 12 transpositions of major scale from C - just pick any note of the keyboard and count up the same intervals.  However, this pattern of white and black repeats all the way up and down the whole length of the keyboard - what if we didn't start at C to set the base of the black-key/white-key pattern?  Why not use `A B C D E F G A`?\n\nIf you start on any other white key and count up one octave skipping all the black keys, you will get a *different* diatonic scale than a major scale.  These scale variations are called [Modes](https://en.wikipedia.org/wiki/Mode_(music)#Modern_modes), and while high-school me was terrified of and terrible at whipping out arbitrary ones on a brass instrument from memory (mental math is *not* one of my talents), they're easy to work with programmatically (and much less stressful).\n\nThe major scale is also known as the [Ionian mode](https://en.wikipedia.org/wiki/Ionian_mode).  This is the base mode, each other is some offset from this scale.  As we've seen, the key you need to start on to play this mode with no black keys (accidentals) is C.\n\nThe natural minor scale, is obtained by starting at A4 and counted up white keys, is called the [Aeolian mode](https://en.wikipedia.org/wiki/Aeolian_mode).  Try it yourself on the diagram - march on up the white keys from A4 to A5:\n\n```txt\nwhole, half, whole, whole, half, whole, whole\n```\n\nThis should look like the C major scale, no sharps or flats, but with `A` at the beginning:\n\n```rust\n#[test]\nfn test_a_minor() {\n    use Mode::*;\n    use Scale::*;\n    assert_eq!(\n        &Key::new(Diatonic(Aeolian), PianoKey::from_str(\"A4\").unwrap(), 1).to_string(),\n        \"[ A B C D E F G A ]\"\n    )\n}\n```\n\nIt's the same pattern, just starting at a different offset.  You can play a corresponding minor scale using only the white keys by simply starting at the sixth note of the C major scale (or incrementing a major sixth), which is A.  Try counting it out yourself up from A4.\n\nThere's an absurdly fancy name for each offset:\n\n```rust\n#[derive(Debug, Clone, Copy, PartialEq, PartialOrd)]\npub enum Mode {\n    Ionian = 0,\n    Dorian,\n    Phrygian,\n    Lydian,\n    Mixolydian,\n    Aeolian,\n    Locrian,\n}\n```\n\nWe'll hardcode the C major sequence as the base:\n\n```txt\nwhole, whole, half, whole, whole, whole, half\n  2  +  2   +  1  +   2   +  2  +   2  +  1\n```\n\n```rust\nimpl Mode {\n    fn base_intervals() -> Vec<Interval> {\n        use Interval::*;\n        vec![Maj2, Maj2, Min2, Maj2, Maj2, Maj2, Min2]\n    }\n}\n```\n\nLet's also hardcode the scale length:\n\n```rust\n#[derive(Debug, Clone, Copy, PartialEq)]\npub enum ScaleLength {\n    Heptatonic = 7,\n}\n```\n\nNow we can make our scales a little smarter:\n\n```diff\n  #[derive(Debug, Clone, Copy, PartialEq)]\n  pub enum Scale {\n-     Major,\n      Diatonic(Mode),\n  }\n  \n  impl Default for Scale {\n      fn default() -> Self {\n-         Scale::Major\n+         Scale::Diatonic(Mode)\n      }\n  }\n\n  impl Scale {\n    fn get_intervals(self) -> Vec<Interval> {\n            use Interval::*;\n            use Scale::*;\n            match self {\n-               Major => vec![Maj2, Maj2, Min2, Maj2, Maj2, Maj2, Min2],\n+               Diatonic(mode) => Mode::base_intervals()\n+                   .iter()\n+                   .cycle()\n+                   .skip(mode as usize)\n+                   .take(ScaleLength::Heptatonic as usize)\n+                   .copied()\n+                   .collect::<Vec<Interval>>(),\n+           }\n        }\n  }\n```\n\nNow we've got seven modes for each of twelve keys on the keyboard - that's 84 distinct key signatures.  The `Ionian` and `Aeolian` modes have nicknames, the rest we'll just work with as the mode names:\n\n```rust\nimpl FromStr for Scale {\n    type Err = io::Error;\n    fn from_str(s: &str) -> Result<Self, Self::Err> {\n        use Mode::*;\n        use Scale::*;\n        match s.to_uppercase().as_str() {\n            \"IONIAN\" | \"MAJOR\" => Ok(Diatonic(Ionian)),\n            \"DORIAN\" => Ok(Diatonic(Dorian)),\n            \"PHRYGIAN\" => Ok(Diatonic(Phrygian)),\n            \"LYDIAN\" => Ok(Diatonic(Lydian)),\n            \"MIXOLYDIAN\" => Ok(Diatonic(Mixolydian)),\n            \"AEOLIAN\" | \"MINOR\" => Ok(Diatonic(Aeolian)),\n            \"LOCRIAN\" => Ok(Diatonic(Locrian)),\n            _ => Err(io::Error::new(io::ErrorKind::InvalidInput, \"Unknown scale\")),\n        }\n    }\n}\n\nimpl fmt::Display for Scale {\n    fn fmt(&self, f: &mut fmt::Formatter) -> fmt::Result {\n        use Scale::*;\n        let s = match self {\n            Diatonic(mode) => {\n                use Mode::*;\n                match mode {\n                    Aeolian => \"minor scale\".into(),\n                    Ionian => \"major scale\".into(),\n                    _ => format!(\"{:?} mode\", mode),\n                }\n            }\n        };\n        write!(f, \"{}\", s)\n    }\n}\n```\n\nThe fact that Ionian Mode/C Major is Offset 0 is actually somewhat arbitrary - though definitely not completely.  There's a reason C major is so commonly found in music - it sounds good.\n\nI did a [bare-minimum](https://lmgtfy.com/?q=why+does+it+start+from+C+not+A) amount of research and found it's an [\"unfortunate historical accident\"](https://music.stackexchange.com/questions/893/why-is-c-the-base-note-of-standard-notation-and-keys).  In a sentence, the concept of \"mode\" in an equally tempered system predates the modern scales and `C == 0` is a historical artifact.  The letters were originally numbered from A, of course, but got mapped to frequencies well before the modern modes we use now were honed and refined from previous systems.  The system eventually came to be based around the [C major scale](https://en.wikipedia.org/wiki/C_major), not A major.  By then the fact that what's now Middle C was 261.626Hz was long done and over with.\n\n##### Non Heptatonic Scales\n\n*[top](#table-of-contents)*\n\nOkay, Ben.  Ben, okay.  Okay, Ben.  We've arrived at the version from the blog post, great.  You also promised 86 in the introduction, not 84.  This whole time, though, the line from the meme image has had something different:\n\n```bash\nsplit(\"4,5,7,11\",a,\",\");\n```\n\nThe diatonic scales we've been working with are a subset of the [heptatonic scales](https://en.wikipedia.org/wiki/Heptatonic_scale), with seven notes each.  These tones are naturally further apart than we've been using.  Let's add a couple others scale lengths to play with:\n\n```diff\n  #[derive(Debug, Clone, Copy, PartialEq)]\n  pub enum ScaleLength {\n+     Tetratonic = 4,\n      Heptatonic = 7,\n+     Dodecatonic = 12,\n  }\n```\n\nInterestingly, the scale shown is [tetratonic](https://en.wikipedia.org/wiki/Tetratonic_scale), given as octave-less notes, intervals from base, and offsets from A440:\n\n```txt\n[C#, D, E, G#]\n[Min2, Maj2, Maj3]\n[4, 5, 7, 11]\n```\n\nOddly, this scale is primarily associated with pre-historic music and not often found since.  Was `AWK` passed down from the before-times? I also don't understand how that snippet works, because it's still indexed with `a[$1 % 8]`, but I'm too lazy to find out why.\n\nThe only dodecatonic scale is the [chromatic scale](https://en.wikipedia.org/wiki/Chromatic_scale) is just all the notes:\n\n```txt\n[A, A#, B, C, C#, D, D#, E, F, F#, G, G#]\n[Min2, Min2, Min2, Min2, Min2, Min2, Min2, Min2, Min2, Min2, Min2]\n[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]\n```\n\nWho needs key signatures anyhow, that's a waste of all these other keys!  This one throws 'em all in the mix.\n\n```rust\n#[derive(Debug, Clone, Copy, PartialEq)]\npub enum Scale {\n    Chromatic,\n    // ..\n}\n```\n\nThe chromatic scale is for people who don't have time to muck about with petty concerns like sounding good, and don't want to waste any piano keys - it's just 11 successive minor 2nds, giving you every note.\n\n```txt\nhalf, half, half, half, half, half, half, half, half, half, half\nA    A#    B     C     C#    D     D#    E     F     F#    G    G#\n```\n\nOr, in Rust:\n\n```rust\n#[test]\nfn test_chromatic_intervals() {\n    use Interval::Min2;\n    assert_eq!(\n        Scale::Chromatic.get_intervals(),\n        vec![Min2, Min2, Min2, Min2, Min2, Min2, Min2, Min2, Min2, Min2, Min2]\n    );\n}\n```\n\n\n```diff\n  #[derive(Debug, Clone, Copy, PartialEq)]\n  pub enum Scale {\n+     Chromatic,\n      Diatonic(Mode),\n+     Tetratonic,\n  }\n\n  impl Scale {\n    // ..\n    fn get_intervals(self) -> Vec<Interval> {\n        use Interval::*;\n        use Scale::*;\n        match self {\n+           Chromatic => [Min2]\n+               .iter()\n+               .cycle()\n+               .take(ScaleLength::Dodecatonic as usize)\n+               .copied()\n+               .collect::<Vec<Interval>>(),\n            Diatonic(mode) => Mode::base_intervals()\n                .iter()\n                .cycle()\n                .skip(mode as usize)\n                .take(ScaleLength::Heptatonic as usize)\n                .copied()\n                .collect::<Vec<Interval>>(),\n+           Tetratonic => vec![Min2, Maj2, Maj3],\n          }\n      }\n  }\n\n  impl FromStr for Scale {\n      type Err = io::Error;\n      fn from_str(s: &str) -> Result<Self, Self::Err> {\n          use Mode::*;\n          use Scale::*;\n          match s.to_uppercase().as_str() {\n              \"IONIAN\" | \"MAJOR\" => Ok(Diatonic(Ionian)),\n              \"DORIAN\" => Ok(Diatonic(Dorian)),\n              \"PHRYGIAN\" => Ok(Diatonic(Phrygian)),\n              \"LYDIAN\" => Ok(Diatonic(Lydian)),\n              \"MIXOLYDIAN\" => Ok(Diatonic(Mixolydian)),\n              \"AEOLIAN\" | \"MINOR\" => Ok(Diatonic(Aeolian)),\n              \"LOCRIAN\" => Ok(Diatonic(Locrian)),\n+             \"CHROMATIC\" => Ok(Chromatic),\n+             \"TETRATONIC\" => Ok(Tetratonic),\n              _ => Err(io::Error::new(io::ErrorKind::InvalidInput, \"Unknown scale\")),\n          }\n      }\n  }\n\n\n  impl fmt::Display for Scale {\n    fn fmt(&self, f: &mut fmt::Formatter) -> fmt::Result {\n        use Scale::*;\n        let s = match self {\n+           Chromatic | Tetratonic => format!(\"{:?} scale\", self).to_lowercase(),\n            Diatonic(mode) => {\n                use Mode::*;\n                match mode {\n                    Aeolian => \"minor scale\".into(),\n                    Ionian => \"major scale\".into(),\n                    _ => format!(\"{:?} mode\", mode),\n                }\n            }\n        };\n        write!(f, \"{}\", s)\n    }\n}\n```\n\nThis could be a potential natural application of [dependent types](https://en.wikipedia.org/wiki/Dependent_type), a programming language feature that Rust does not support.  Few languages do.  One example is [Idris](https://en.wikipedia.org/wiki/Idris_(programming_language)#Dependent_types), which is like [Haskell](https://en.wikipedia.org/wiki/Haskell_(programming_language))++.  A dependent type codifies a type restraint that's dependent on a *value* of that type.  The linked example describes a function that appends a list of `m` elements to a list `n` which specifies as part of the return type that the returned list has length `n + m`.  A caller can then trust this fact implicitly, because the compiler won't build a binary if it's not true.  I think this could be applied here to verify that a scale's intervals method returns an octave, regardless of length.  That can be tested for in code with Rust, of course, but not encoded into the type signature directly.\n\nThose are just two examples, I bet you could find some other interesting patterns on the keyboard diagram.  For instance, what happens if you ignore the white keys and *only* use the black keys?\n\n#### Generating Music\n\n*[top](#table-of-contents)*\n\nIt's finally time to make some music.  We've now built ourselves a toolkit for working with piano keys and intervals, and a separate type for dealing with a frequency in Hertz, and they both know how to interact with the same `Interval` variants.  Now we need to get from `PianoKey` obtects to `Pitch`es.\n\n##### Cents\n\n*[top](#table-of-contents)*\n\nDiscrete units like `Semitones` are useful for working with a keyboard, but as we know, sound is analog and continuous.  We need to subdivide these intervals even more granularly, and because of equal temperament we're free to do so at any arbitrary level.\n\nBeyond the twelve 12 semitones in an octave, each semitone is divided into 100 [cents](https://en.wikipedia.org/wiki/Cent_(music)).  This means a full octave, representing a 2:1 ratio in frequency, spans 1200 cents, and each cent can be divided without losing the ratio as well if needed:\n\n```rust\n#[derive(Debug, Default, Clone, Copy, PartialEq)]\npub struct Cents(f64);\n```\n\nWe need to do a little plumbing to let ourselves work at this higher level of abstraction.  We need to be able to translate our discrete `Semitones` into `Cents` ergonomically:\n\n```rust\n#[test]\nfn test_semitones_to_cents() {\n    assert_eq!(Cents::from(Semitones(1)), Cents(100.0));\n    assert_eq!(Cents::from(Semitones(12)), Cents(1200.0));\n}\n```\n\nWe can give ourselves some conversions to the inner primitive:\n\n```rust\nimpl From<f64> for Cents {\n    fn from(f: f64) -> Self {\n        Cents(f)\n    }\n}\n\nimpl From<Cents> for f64 {\n    fn from(c: Cents) -> Self {\n        c.0\n    }\n}\n```\n\nNow we can encode the conversion factor:\n\n```rust\nconst SEMITONE_CENTS: Cents = Cents(100.0);\n\nimpl From<Semitones> for Cents {\n    fn from(s: Semitones) -> Self {\n        Cents(i8::from(s) as f64 * f64::from(SEMITONE_CENTS))\n    }\n}\n```\n\nWith that in place, we're ready to start working with intervals directly and have Rust understand them in terms of cents:\n\n```rust\n#[test]\nfn test_interval_to_cents() {\n    use Interval::*;\n    assert_eq!(Cents::from(Unison), Cents(0.0));\n    assert_eq!(Cents::from(Min2), Cents(100.0));\n    assert_eq!(Cents::from(Octave), Cents(1200.0));\n}\n```\n\nWe need `Interval` variants to map directly to `Semitones` instead of plain integers, to make sure they're always turned into `Cents` correctly:\n\nWith that, it's easy to map `Interval`s to `Cents`:\n\n```rust\nimpl From<Interval> for Cents {\n    fn from(i: Interval) -> Self {\n        Semitones::from(i).into()\n    }\n}\n```\n\nPhew!  Lots of code, but now we can operate directly in terms of `Interval` variants or anything in between and everything stays contextually tagged.  Verify with `cargo test` that everything checks out.\n\nThere's one more step to get from our brand new floating point `Cents` to frequencies in `Hertz` though.  Remember how Middle C was some crazy fraction, 261.626Hz?  This is because cents are a [logarithmic](https://en.wikipedia.org/wiki/Logarithmic_scale) unit, standardized around the point 440.0.  While a 2:1 ratio is nice and neat, we've been subdividing that arbitrarily wherever it makes sense to us.  Now the arithmetic isn't always so clean.  Doubling 440.0Hz will get 880.0Hz, but how would we add a semitone?\n\nWe know that to increase by one octave we double the frequency: `440 * 2`.  We'd need to increase by a 12th of what doubling the number would do for a single semitone: `440 * 2^(1/12)`.  Looks innocuous enough, but my calculator gives me 466.164, Rust gives me 466.1637615180899 - not enough to perceptually matter, but enough that it's important that the standard is the interval ratio and not the specific amount of Hertz to add or subtract.  Those amounts will only be precise in floating point decimal representations at exact octaves from the base note, because that's integral factor after multiplying by 1 in either direction, 2 or 1/2.\n\nOtherwise stated, the ratio between frequencies separated by a single cent is the 1200th root of 2, or 2^(1/1200).  In decimal, it's about 1.0005777895.  You wouldn't be able to hear a distinction between two tones a single cent apart.  Using this math, it works out to just shy of 4 cents to cause an increase of 1Hz, more precisely around 3.9302 for a base frequency of 440.0.\n\nLogarithmic units are helpful when the range of the y axis, in our case frequency, increases exponentially.  We know the graph of frequency to pitch does because to jump by any single octave, we double what we have - we're multiplying at each step, not adding (which results in a linear graph).  A4 is 440Hz, A5 is 880Hz, and by A6 we're already at 1,760Hz.  The graph `f(x) = x^2` looks like this:\n\n![x_squared](https://thepracticaldev.s3.amazonaws.com/i/mkh095mgcasg1soygrb7.png)\n\nA [logarithm](https://en.wikipedia.org/wiki/Logarithm) is the inverse of an [exponent](https://en.wikipedia.org/wiki/Exponentiation).  Our ratio had an exponent that was \"1 divided by n\", which is the inverse of raising something to the power of \"n divided by 1\", such as squaring it (n=2).  This is otherwise written as an \"nth root\", in the case of a cent *n* being 1,200.  This counteracts the rapid growing curve we get by constantly squaring the frequency into a more linear scaled subdivision between octaves:\n\n![cent graph](https://upload.wikimedia.org/wikipedia/commons/thumb/3/3f/Music_intervals_frequency_ratio_equal_tempered_pythagorean_comparison.svg/550px-Music_intervals_frequency_ratio_equal_tempered_pythagorean_comparison.svg.png)\n\nNotice it's not a straight diagonal.  We haven't removed the fact that frequencies are being multiplied, merely adjusted for it. We're taking a logarithm of something that has been squared, the frequency.  This tames the steep increase but the line is still slightly curved.\n\nFractional cents and tones are a much better way to deal with intervals than by concrete frequency deltas.  Knowing all this we can translate back to the frequency in Hertz of a desired pitch if we know both a base frequency and the number of cents to increase by:\n\n![cents formula](https://wikimedia.org/api/rest_v1/media/math/render/svg/920411bb22d357b13f69a76fa33557c707f7cb57)\n\nHere, *a* is the initial frequency in Hertz, *b* is the target frequency, and *n* is the number of cents by which to increase *a*.\n\nLets try to increase the standard pitch by single Hertz using the value above:\n\n```rust\n#[test]\nfn test_add_cents_to_pitch() {\n    let mut pitch = Pitch::default();\n    pitch += Cents(3.9302);\n    assert_eq!(pitch, Pitch::new(Hertz(441.0)));\n}\n```\n\nIt looks like we're going to need to divide some `Cents`, leveraging the `impl From<Cents> for f64` blocks we already defined:\n\n```rust\nuse std::ops::Div;\n\nimpl Div for Cents {\n    type Output = Self;\n\n    fn div(self, rhs: Self) -> Self {\n        Cents(f64::from(self) / f64::from(rhs))\n    }\n}\n```\n\nThis is just performing floating point division on the inner value, but keeps it wrapped up in the `Cents` context for us so we can directly use `Cents(x) / Cents(y)`.  We now know enough to manipulate a `Pitch` directly.\n\nThe [`AddAssign`](https://doc.rust-lang.org/std/ops/trait.AddAssign.html) trait gets us the `+=` operator, and can define it for any type we want on the right hand side:\n\n```rust\nuse std::ops::AddAssign\n\nimpl AddAssign<Cents> for Pitch {\n    #[allow(clippy::suspicious_op_assign_impl)] // needed to stop clippy from yelling\n    fn add_assign(&mut self, rhs: Cents) {\n        self.0 *= 2.0f64.powf((rhs / Cents::from(Interval::Octave)).into())\n    }\n}\n```\n\nOops, we also need to `*=` an `f64` to a `Hertz`:\n\n```rust\nuse std::ops::MulAssign;\n\nimpl MulAssign<f64> for Hertz {\n    fn mul_assign(&mut self, rhs: f64) {\n        self.0 *= rhs;\n    }\n}\n```\n\nCoincidentally, an `impl MulAssign<f64> for Frequency` in Hertz is the exact example on the official [`MulAssign`](https://doc.rust-lang.org/std/ops/trait.MulAssign.html) docs.  Their style might be better.  I don't know, you tell me?\n\nIf that's not quite clear, this is the exact equation shown above with a bit of extra noise.  Dividing `cents` by `Cents::from(Interval::Octave)` leaves us with a `Cents` type, per the above `impl Div for Cents` block.  However, we then want to pass the result to `2.0.powf(cents_ratio)`.  The compiler knows it's an `f64` here because we explicitly specified it with `2.0_f64` to use as a base for [`powf()`](https://doc.rust-lang.org/std/primitive.f64.html#method.powf).\n\nSadly, though, `cargo test` tells us we have a problem:\n\n![fail float](https://thepracticaldev.s3.amazonaws.com/i/bu70ahx1w5rfln6sa3jq.png)\n\nFloating point arithmetic is not precise.  However, a delta of as much as a whole Hertz, or almost 4 cents, isn't large enough for any human to perceive.   The [just-noticeable difference](https://en.wikipedia.org/wiki/Just-noticeable_difference) is about 5 or 6 cents, or 5*2^(1/1200).  In this type we just care that it's \"close enough\".  At a glance we can look at those results and understand that we got where we need to be.  To convince Rust we're good to go, we can override the compiler-derived [`PartialEq`](https://doc.rust-lang.org/std/cmp/trait.PartialEq.html) behavior for this type:\n\n```diff\n- #[derive(Debug, Clone, Copy, PartialEq, PartialOrd)]\n+ #[derive(Debug, Clone, Copy, PartialOrd)]\n  pub struct Pitch {\n       frequency: Hertz,\n  }\n```\n\nWe can specify a tolerance for equality in code.  I'm arbitrarily deciding that if two `Pitch` objects are within a tenth of a Hertz of each other, they're functionally equivalent:\n\n```rust\nimpl Hertz {\n    fn abs(self) -> Self {\n        Self(self.0.abs())\n    }\n}\n\nimpl PartialEq for Pitch {\n    fn eq(&self, other: &Pitch) -> bool {\n        let tolerance = Hertz(0.1);\n        let difference = (self.0 - other.0).abs();\n        difference < tolerance\n    }\n}\n```\n\nThere's no trait to define to get absolute values with `abs()`, but we can plop whatever method we want directly on `Hertz` too.  Now the test we wrote will pass.  Try it out!\n\nInstead of adding single cents at a time, it's easier to work by semitone:\n\n```rust\n#[test]\nfn test_add_semitones_to_pitch() {\n    use Interval::Octave;\n    let mut pitch = Pitch::default();\n    pitch += Semitones::from(Octave);\n    assert_eq!(pitch, Pitch::new(Hertz(880.0)))\n}\n```\n\nThat's pretty easy with the work we've already done:\n\n```rust\nimpl AddAssign<Semitones> for Pitch {\n    fn add_assign(&mut self, rhs: Semitones) {\n        *self += Cents::from(rhs)\n    }\n}\n```\n\nIn fact, why not just go straight for intervals:\n\n```rust\n#[test]\nfn test_add_interval_to_pitch() {\n    use Interval::Min2;\n    let mut pitch = Pitch::default();\n    pitch += Min2;\n    assert_eq!(pitch, Pitch::new(Hertz(466.1)))\n}\n```\n\nNaturally, this is also trivial:\n\n```rust\nimpl AddAssign<Interval> for Pitch {\n    fn add_assign(&mut self, rhs: Interval) {\n        *self += Cents::from(rhs)\n    }\n}\n```\n\nGreat - now we can add `Cents` to a `Pitch` and it automatically multiplies the `Hertz` correctly.  However, we're not working with `Pitch` objects to generate key signatures.  Our key signatures are sequences of `PianoKey`s.  We need to convert to and from these two systems.  Luckily, while they're based on  different core unit, the both use the same `Interval` relationship, and we can use that as a go-between.\n\nIt's defined at a set frequency:\n\n```rust\npub const C_ZERO: Hertz = Hertz(16.352);\n```\n\nThis is super low - most humans bottom out around 20Hz.  The 88-key piano's lowest note is up at A0, a 9-semitone [`major sixth`](https://en.wikipedia.org/wiki/Major_sixth) higher.  Note how even though this is a different abstraction for working with pitches, the frequencies baked in to the standard are still pinned to the A440 scale.\n\nWe want to be able to convert from piano keys to pitches and have the frequencies work out for both standards:\n\n```rust\n#[test]\nfn test_piano_key_to_pitch() {\n    assert_eq!(Pitch::from(PianoKey::new(\"A4\").unwrap()), Pitch::default());\n    assert_eq!(Pitch::from(PianoKey::default()), Pitch::new(C_ZERO));\n}\n```\n\nTo get there, we can add octaves and smaller intervals up from `C0` to whatever note we need;\n\n```rust\nimpl From<PianoKey> for Pitch {\n    fn from(sp: PianoKey) -> Self {\n        use Interval::*;\n        let mut ret = Pitch::new(C_ZERO);\n        // Add octaves\n        for _ in 0..sp.octave {\n            ret += Octave;\n        }\n        // Add note offset\n        ret += sp.note.letter.interval_from_c();\n        ret\n    }\n}\n```\n\n##### Random Notes\n\n*[top](#table-of-contents)*\n\nThe only missing thing is picking what notes to play we just need to pick the notes to play.\n\nCheck out this section of the [source code](https://docs.rs/rodio/0.10.0/src/rodio/source/sine.rs.html#24) from the `rodio` crate for the `rodio::source::SineWave` we used above to check our A440 tone:\n\n```rust\nimpl Iterator for SineWave {\n    type Item = f32;\n\n    #[inline]\n    fn next(&mut self) -> Option<f32> {\n        self.num_sample = self.num_sample.wrapping_add(1);\n\n        let value = 2.0 * 3.14159265 * self.freq * self.num_sample as f32 / 48000.0;\n        Some(value.sin())\n    }\n}\n```\n\nThis `impl Iterator` block is handling the `for` loop in the cover image.  It's calculating the exact amplitude of a sine wave at some fractional point between 0 and 1.\n\nThe math, in other words, is `440.0 * Pi * (current sample / total samples)`, multiplied by some value, in this case `2.0`.  This code is calculating the sine wave at a given point within a cycle - for 0 to 1, there are 48,000 points to collect, so the current point is the sine wave of this frequency at whatever point we're at, stored as `self.num_sample`, between 0 and 1.\n\nFor some reason they've hardcoded [Pi](https://en.wikipedia.org/wiki/Pi), there are constants available like [`std::f32::consts::PI`](https://doc.rust-lang.org/std/f64/consts/constant.PI.html).  I'd be interested to know if anyone would know why that's a good choice instead of relying on the language constant!\n\nThe `SineWave` struct reliably produces a single tone infinitely, but we want to change the pitch.  The actual wave calculation is the same, though, we just need to add some extra logic to change up the pitch being produced.\n\nWe can actually use the linked source code as a template to provide our own `rodio::Source` implementation to append to the `Sink`.\n\nSet up a data structure to hold on to some of the hardcoded values found in the above library snipper:\n\n```rust\npub const SAMPLE_RATE: Hertz = Hertz(48_000.0);\npub type Sample = f32;\n\npub struct MusicMaker {\n    key: Key,\n    current_note: PianoKey,\n    current_sample: usize,\n    sample_rate: Hertz,\n    volume: f32,\n}\n\nimpl Default for MusicMaker {\n    fn default() -> Self {\n        Self {\n            key: Key::default(),\n            current_note: PianoKey::from_str(\"C4\").unwrap(),\n            current_sample: usize::default(),\n            sample_rate: SAMPLE_RATE,\n            volume: 2.0,\n        }\n    }\n}\n\nimpl MusicMaker {\n    pub fn new() -> Self {\n        Self::default()\n    }\n    fn get_frequency(&mut self) -> Sample {\n        let pitch = Pitch::from(self.current_note);\n        pitch.into()\n    }\n}\n```\n\nTo perform the wave sampling, we can actually pretty much copy-paste the `impl Iterator for SineWave` code, just using our struct's values:\n\n```rust\nuse std::f32::consts::PI;\n\nimpl Iterator for MusicMaker {\n    type Item = Sample; // Sampled amplitude\n    fn next(&mut self) -> Option<Self::Item> {\n        self.current_sample = self.current_sample.wrapping_add(1); // will cycle\n\n        let value = self.volume\n            * PI\n            * self.get_frequency()\n            * self.current_sample as Sample\n            / f64::from(self.sample_rate) as Sample;\n\n        if self.current_sample as f64 >= f64::from(self.sample_rate) {\n            self.current_sample = 0;\n            self.new_note();  // Hmm...\n        }\n        Some(value.sin())\n    }\n}\n```\n\nIn order to use as a sound source we can pass to a `rodio::Sink`, we implement the `rodio::Source` trait, which can be implemented for any type that implements `Iterator`, so long as the `Item` associated type is valid as a sample:\n\n```rust\nuse core::time::Duration;\nuse rodio::Source;\n\nimpl Source for MusicMaker {\n    #[inline]\n    fn current_frame_len(&self) -> Option<usize> {\n        None\n    }\n\n    #[inline]\n    fn channels(&self) -> u16 {\n        1\n    }\n\n    #[inline]\n    fn sample_rate(&self) -> u32 {\n        f64::from(self.sample_rate) as u32\n    }\n\n    #[inline]\n    fn total_duration(&self) -> Option<Duration> {\n        None\n    }\n}\n```\n\nThe `current_frame_len()` and `total_duration()` bodies indicate that this source is infinite - there's no finite duration to return.  You'll need to kill the process some other way.  The `channels` method returns the number of frequencies in the signal, and we're just working with a single wave, so a single channel is all we need.\n\nNow we're finally ready to call that `choose()` method on something.  First, though, we need to select a random seed from the `rand` crate.  We don't are about cryptographic soundness here, we just need random numbers, but speed is useful.  The [`rand::rngs::SmallRng`](https://docs.rs/rand/0.7.2/rand/rngs/struct.SmallRng.html) random number generator is ideal for that.  We can initialize it using `from_entropy()` to ultimately source it from the operating system - so, sorta in a roundabout way it actually is `dev/urandom`, or similar.\n\n```diff\n+  use rand::{rngs::SmallRng, seq::SliceRandom, SeedableRng};\n\n   pub struct MusicMaker {\n       key: Key,\n+      seed: SmallRng,\n       current_note: PianoKey,\n       current_sample: usize,\n       sample_rate: Hertz,\n       volume: f32,\n}\n\n   impl Default for MusicMaker {\n       fn default() -> Self {\n           Self {\n               key: Key::default(),\n+              seed: SmallRng::from_entropy(),\n               current_note: PianoKey::from_str(\"C4\").unwrap(),\n               current_sample: usize::default(),\n               sample_rate: SAMPLE_RATE,\n               volume: 2.0,\n           }\n       }\n   }\n\n   impl MusicMaker {\n     pub fn new() -> Self {\n         Self::default()\n     }\n     fn get_frequency(&mut self) -> Sample {\n         let pitch = Pitch::from(self.current_note);\n         println!(\"{:?}\", pitch);\n         pitch.into()\n     }\n+    fn new_note(&mut self) {\n+        let keys = self.key.all_keys();\n+        self.current_note = *keys.iter().choose(&mut self.seed).unwrap();  // There it is!  This whole time\n+    }\n  }\n```\n\nNow our `MusicMaker` can plug right into an audio output track.  Replace your entry point `main()` function in `src/bin/music.rs` with this:\n\n```rust\nfn main() {\n    println!(\"{}\", GREETING);\n\n    let device = default_output_device().unwrap();\n    let sink = Sink::new(&device);\n    let music = MusicMaker::new(PianoKey::new(\"A4\").unwrap(), Scale::default(), 1);\n    sink.append(music);\n    sink.sleep_until_end();\n}\n```\n\nRunning this with `cargo run` will essentially match the output from the original `bash` one-liner.\n\n![sad party](https://thepracticaldev.s3.amazonaws.com/i/82lipncvy6806zyjpg2r.gif)\n\n##### User Parameters\n\n*[top](#table-of-contents)*\n\nThere are several elements of this that are tweakable - the program that runs is a little lackluster given all the capability we've defined internally.  Let's expose some options to the user at runtime.\n\nLet's give a `base note`, a `scale` option, and a number of octaves to span upwards to define the valid notes, as well as a boolean to choose to instead just play a single tone:\n\n```rust\n// src/bin/music.rs\nuse structopt::StructOpt;\n\n/// music is a procedural single-tone melody generator\n#[derive(StructOpt, Debug)]\n#[structopt(name = \"music\")]\nstruct Opt {\n    /// Single-pitch mode\n    #[structopt(short, long)]\n    pitch_mode: bool,\n    /// The base note to calculate the scale from\n    #[structopt(short, long, default_value = \"C4\")]\n    base_note: PianoKey,\n    /// The series of intervals from the base note to use per octave\n    #[structopt(short, long, default_value = \"Ionian\")]\n    scale: Scale,\n    /// Number of octaves over which to range, anything over 8 gets parsed as 8\n    #[structopt(short, long, default_value = \"1\")]\n    octaves: u8\n}\n```\n\n```diff\n// src/lib.rs\n  impl MusicMaker {\n-     pub fn new() -> Self\n-         Self::default()\n+     pub fn new(opt: Opt) -> Self {\n+         Self::default().set_base_note(opt.base_note).set_scale(opt.scale).set_octaves(opt.octaves)\n      }\n      fn get_frequency(&mut self) -> Sample {\n          let pitch = Pitch::from(self.current_note);\n          pitch.into()\n      }\n      fn new_note(&mut self) {\n          let keys = self.key.all_keys();\n          self.current_note = *keys.iter().choose(&mut self.seed).unwrap();\n      }\n+     fn set_base_note(mut self, base_note: Note) -> Self {\n+         self.key = Key::new(self.key.scale, &base_note.to_string());\n+         self\n+     }\n+     fn set_scale(mut self, scale: Scale) -> Self {\n+         self.key = Key::new(scale, &self.key.base_note.to_string());\n+         self\n+     }\n  }\n```\n\nWe have to dispatch a few different paths now - replace `main()` with the following:\n\n```rust\nfn main() {\n    // Read arguments, greet user\n    let opt = Opt::from_args();\n    println!(\"{}\", GREETING);\n\n    // Set up audio playback\n    let device = default_output_device().unwrap();\n    let sink = Sink::new(&device);\n\n    // Define music source from Opt\n    if opt.pitch_mode {\n        let wave = SineWave::from(Pitch::from(opt.base_note));\n        println!(\"Playing single tone {}\", opt.base_note);\n        // Play sine wave\n        sink.append(wave);\n    } else {\n        // Init procedural generator\n        let music = MusicMaker::new(opt.base_note, opt.scale, opt.octaves);\n        println!(\"{}\", music);\n        // Play random melody\n        sink.append(music);\n    };\n    // Sleep thread to allow music to play infinitely\n    sink.sleep_until_end();\n}\n```\n\nMake sure the code generation worked as expected with `cargo run -- -h` - you use `--` to pass command line arguments through `cargo run`, but you'd pass them directly to a binary: `./music -h`:\n\n```txt\n$cargo run -- -h\n    Finished dev [unoptimized + debuginfo] target(s) in 0.05s\n     Running `target/debug/music -h`\nmusic 0.1.0\nmusic is a procedural single-tone melody generator\n\nUSAGE:\n    music [FLAGS] [OPTIONS]\n\nFLAGS:\n    -h, --help          Prints help information\n    -p, --pitch-mode    Single-pitch mode\n    -V, --version       Prints version information\n\nOPTIONS:\n    -b, --base-note <base-note>    The base note to calculate the scale from [default: C4]\n    -o, --octaves <octaves>        Number of octaves over which to range, anything over 8 gets parsed as 8 [default: 1]\n    -s, --scale <scale>            The series of intervals from the base note to use per octave [default: Ionian]\n\n```\n\nStructopt is great for quick prototyping.  We should add an output line to the header to let the user know what's playing:\n\n```rust\nimpl fmt::Display for MusicMaker {\n    fn fmt(&self, f: &mut fmt::Formatter) -> fmt::Result {\n        let key = self.key;\n        write!(\n            f,\n            \"Generating music from the {} {}\\nOctaves: {} - {}\\n{}\",\n            key.base_note.note,\n            key.scale,\n            key.base_note.octave,\n            key.base_note.octave + key.octaves,\n            key\n        )\n    }\n}\n```\n\nNow we should see the current key at the top - both options are optional, and the default value will be used if not found:\n\n```txt\n$ cargo run\n    Finished dev [unoptimized + debuginfo] target(s) in 0.07s\n     Running `target\\debug\\music.exe`\n.: Cool Tunes :.\nGenerating music from the C major scale\nOctaves: 4 - 5\n[ C D E F G A B C ]\n```\n\n```txt\n$ cargo run -- -s chromatic\n    Finished dev [unoptimized + debuginfo] target(s) in 0.07s\n     Running `target\\debug\\music.exe -s chromatic`\n.: Cool Tunes :.\nGenerating music from the C chromatic scale\nOctaves: 4 - 5\n[ C C# D D# E F F# G G# A A# B C ]\n```\n\n```txt\n$ cargo run -- -s locrian -b Eb3 -o 3\n    Finished dev [unoptimized + debuginfo] target(s) in 0.07s\n     Running `target\\debug\\music.exe -s locrian -b Eb2 -o 3`\n.: Cool Tunes :.\nGenerating music from the E♭ Locrian mode\nOctaves: 3 - 6\n[ E♭ E F# G# A B C# E♭ ]\n```\n\n```txt\n$ cargo run -- -p -b C3\n    Finished dev [unoptimized + debuginfo] target(s) in 0.07s\n     Running `target\\debug\\music.exe -p -b C3`\nCool Tunes (tm)\n.: Cool Tunes :.\nPlaying single tone C3\n```\n\nCheck out C0 and A0, and be careful with headphones when getting to the upper octaves!\n\n![human music](https://thepracticaldev.s3.amazonaws.com/i/92xyu0xcenfmpvrf6kbq.gif)\n\n## Challenges\n\n*[top](#table-of-contents)*\n\nI wanted to keep this post to around an hour, but there are a number of ways this code could be extended:\n\n- I can't even hear `C0` - can you?  Restrict the 108-key keyboard to the standard 88-key from the diagram, that only includes the top three notes of Octave 0 and the top note of Octave 8 (12 x 7 + 3 + 1).\n- Support even more types of key signatures like the [harmonic minor](https://en.wikipedia.org/wiki/Minor_scale#Harmonic_minor_scale), which is the Aeolian mode with the seventh note one semitone higher, or [pentatonic scales](https://en.wikipedia.org/wiki/Pentatonic_scale), which were hinted at above as using solely the black keys.  Those have modes too...\n- Generate those extended key signatures from strings like `\"Cmaj\"` or `\"Amin7\"`.\n- Let the user decide how long each note should sound.  Which part of `MusicMaker` do you think is responsible for that?\n- Support [Helmholtz pitch notation](https://en.wikipedia.org/wiki/Helmholtz_pitch_notation).\n- Instead of picking notes at random, support different kinds of seeds.  For instance, every file on your computer is a stream of bytes.  Maybe you could accept an `impl Iterator<Item = u8>`?\n- Support other types of wave forms than sines, such as square waves or sawtooth waves.\n- We can already read piano keys from strings like `\"D#4\"`.  Parse and play back predefined sequences of notes from text files.  This will involve some work: stacked accidentals, naturals, represent durations, etc.\n- A [`WAV`](https://en.wikipedia.org/wiki/WAV) file is an uncompressed audio stream, like the one we've built.  Write audio files containing your music with with [`hound`](https://github.com/ruuda/hound).\n- Implement and play a `Chord`.\n- Port this program to another language.\n\nThis has been a Public Service Announcement on the dangers of online encyclopedias.  Thank you for your time.\n\n*Cover image: [reddit](https://www.reddit.com/r/linuxmasterrace/comments/dyqri7/like_god_would_have_wanted/)*\n",
    "title": "Procedural Melody Generation in Rust"
  },
  {
    "cover_image": "https://res.cloudinary.com/practicaldev/image/fetch/s--W77phB12--/c_imagga_scale,f_auto,fl_progressive,h_420,q_auto,w_1000/https://thepracticaldev.s3.amazonaws.com/i/azx06h9uonlkumw97osz.png",
    "date": "2019-12-11T21:11:33.857Z",
    "description": "",
    "tags": "discuss, webdev, webassembly, qt",
    "markdown": "As of [Qt 5.13](https://doc.qt.io/qt-5/index.html), [WebAssembly](https://webassembly.org/) is a [supported target](https://doc.qt.io/qt-5/wasm.html).\n\n[Qt](https://www.qt.io/) is a cross-platform toolkit for building GUI applications.  It is the toolkit used in the [KDE](https://kde.org/) set of Linux desktop tools, as well as the basis for widely used commercial and FOSS applications such as [Photoshop Elements](https://www.adobe.com/products/photoshop-elements.html), [Mathematica](https://www.wolfram.com/mathematica/), [VLC](https://www.videolan.org/vlc/), and [VirtualBox](https://www.virtualbox.org/) - and [many more](https://en.wikipedia.org/wiki/Qt_%28software%29#Applications_using_Qt).\n\nThis release means you can distribute Qt apps as if they were web applications, and users execute them install-free entirely within in a web browser (or other WASM environment), at near-native performance - almost as if it had been installed locally.\n\nHas anyone tried this out yet?  How did it go?  Will any of you be eschewing [React Native](https://facebook.github.io/react-native/) or [Flutter](https://flutter.dev/) for this, or porting a desktop application?  Why or why not?\n\n*cover image: [kde mascots](https://community.kde.org/Promo/Material/Mascots)*",
    "title": "Qt for WebAssembly"
  },
  {
    "cover_image": "https://thepracticaldev.s3.amazonaws.com/i/lk886f5xd4t64pa2cw9i.jpg",
    "date": "2019-12-16T12:48:53.407Z",
    "description": "A reflection on taking my time with Advent of Code problems",
    "tags": "adventofcode, devjournal, watercooler, beginners",
    "markdown": "---\ntitle: Pressure-Free AoC\npublished: true\ndescription: A reflection on taking my time with Advent of Code problems\ncover_image: https://thepracticaldev.s3.amazonaws.com/i/lk886f5xd4t64pa2cw9i.jpg\ntags: adventofcode, devjournal, watercooler, beginners\n---\n\nI'm really glad I didn't start [Advent of Code 2019](https://adventofcode.com/2019) until halfway through December.\n\nI am *not good* at follow through with this challenge, and in previous years I think I made two mistakes:\n\n1) I used it to learn brand new, funky languages (Clojure, F#, Haskell) instead of leveraging a skill I've cultivated and care about continuing to hone (Rust, C++, JavaScript).\n2) I rushed through the solutions.\n\nI'm not super competitive by nature, but when I realized I was at a comfort level with programming such that I could complete the first few days quickly, I got too in my head about it.  The pressure to \"deliver\" leads me to inevitably burn out sometime in week 2 and never come back.  The days I do get solved are usually not well optimized, as I was just looking for the correct output to get my little star.  Once I solved it I didn't spend enough time revisiting to learn something about the problem - there's another one waiting!\n\nAdditionally, using those types of fancy functional languages gave me a bad habit of looking for \"clever\" concise solutions to problems without thinking about practicality or readability.  While that's a fun exercise, and not *completely* without its educational merit, it doesn't pack quite the same punch as actually practicing how to craft quality software.\n\nI wrote about one such case here, where I missed an algorithm I even already knew in favor of a simple brute-force approach which needlessly abused my laptop's CPU, costing me my speedrun:\n\n{% post deciduously/a-tale-of-two-functions-44h5 %}\n\nIf I had just slowed down, I would have seen the \"proper\" way myself and probably still gotten there that morning, but AoC is a trip.\n\nI still plan to use these old repos I started to learn those cool languages if and when I return, but 2019 is already so much more satisfying than those experiments ever were.\n\nThis year I started Day 1 on December 12, so there was no hope of catching up.  I used Rust, a language I started abandoning projects in [3 years ago](https://github.com/deciduously/dice), so getting organized was not a problem.  It turns out already knowing the idioms and standard library of your AoC language is useful for getting off the ground.  Go figure.  My runner-up was C++ for maximum industry-relevance, but I'm writing enough of that for school and Rust has less hassle and more beginner-friendly tooling.  I feel it's about as educational on an abstracted problem-solving level.\n\nI even took the time to set up some scaffolding, something I'd never gotten around to before:\n\n```rust\n// src/lib.rs\nuse std::{\n    fs::File,\n    io::{self, BufReader, ErrorKind::*, Read},\n};\n\nconst INPUT_DIR: &str = \"inputs\";\n\nfn get_puzzle_string(day: u8) -> Result<String, io::Error> {\n    let filename = format!(\"{}/day{}.txt\", INPUT_DIR, day);\n    let mut ret = String::new();\n\n    if let Ok(file) = File::open(&filename) {\n        // Read it from disk\n        let mut buf = BufReader::new(file);\n        buf.read_to_string(&mut ret)?;\n        Ok(ret)\n    } else {\n        Err(io::Error::new(InvalidData, format!(\"You need to log in to adventofcode.com via a web browser and download the Day {} puzzle input!\", day)))\n    }\n}\n```\n\nAs well as the rudimentaryest of CLIs:\n\n```rust\nuse aoc2019::*;\nuse std::env::args;\n\nconst DAYS_IMPLEMENTED: u32 = 5;\n\nfn main() {\n    if let Some(day) = args().nth(1) {\n        if let Ok(day) = day.parse::<u32>() {\n            if day <= DAYS_IMPLEMENTED && day > 0 {\n                println!(\"Day {}\", day);\n                match day {\n                    1 => day1::run(),\n                    2 => day2::run(),\n                    3 => day3::run(),\n                    4 => day4::run(),\n                    5 => day5::run(),\n                    _ => unreachable!(),\n                }\n            } else {\n                eprintln!(\"Day must be between 1 and {} inclusive\", DAYS_IMPLEMENTED);\n            }\n        } else {\n            eprintln!(\"Day must be a number 1-{}\", DAYS_IMPLEMENTED);\n        }\n    } else {\n        eprintln!(\"You must select a day 1-{} to run\", DAYS_IMPLEMENTED);\n    }\n}\n```\n\nEven tiny little quality-of-life improvements like these make the experience of stepping through these challenges much more fun - no more manually wrangling inputs or calling specific problem entry point functions:\n\n```txt\n$ cargo run -- 4\n   Compiling aoc2019 v0.1.0 (H:\\code\\aoc2019)\n    Finished release [optimized] target(s) in 3.44s\n     Running `target\\release\\aoc.exe 4`\nDay 4\n921\n603\n```\n\nThat didn't take more than a few minutes to put together, but when rushing for stars I'd never even bothered.  This also will let me expand from here - if I want to benchmark each run, or add visualizations, I now have a clear structure for everything instead of just throwing logic wherever it fits.\n\nI knocked off the first day very quickly, but then Day 2 was a step up in complexity.  If I were \"on the clock\", I'd have cut corners, but Rust really shines when you take your time to fully model the problem and craft your solution from all sides.\n\nWhen I sit down to solve anything in Rust, I like to write a whole pile of code modelling the domain in terms of types and the relationships between them before solving problems in the space.  It's not quick and tends towards the overly verbose, but by the end I usually have a pretty good understanding of the problem space and decently abstracted toolkit for working with it.  In some cases I already have a solution ready to go before even reading what the actual test case is.\n\nThis style fits really well for Advent of Code problems because each day is presented in two parts, with the second part building upon the first in some unknown way.  Depending on how you've approached your implementation for Part 1, you may have a lot of work to get to Part 2 - in some cases starting from scratch entirely - or you may already be surprisingly close.\n\nAfter solving each, I've been going back and hardcoding the puzzle solutions as tests in addition to the sample data tests:\n\n```rust\n#[test]\nfn test_solutions() {\n    assert_eq!(IdRange::from_str(PUZZLE).unwrap().total_inputs(false), 921);\n    assert_eq!(IdRange::from_str(PUZZLE).unwrap().total_inputs(true), 603);\n}\n```\n\nThe only problem is that some of these puzzle solutions really put your CPU to work.  If you've written a well-designed, optimized implementation it shouldn't be terrible, but can still slow down the test runner.  The shown Day 4 tests run quickly for me in `release` mode but take several seconds in test mode, which `cargo test` uses.  I don't pull in any crates, so decided to just run optimizations in test mode anyway.  You can override this in `Cargo.toml`:\n\n```toml\n[profile.test]\n\nopt-level = 3\n```\n\nThis way you still get debug symbols built in during testing but it can crunch through all the puzzle solutions in a fraction of a second.\n\nOver the weekend I knocked out the first four days, and now starting Day 5 have found that that extra effort paid off.  I was feeling a little silly about my verbosity - just Days 1-4 have already inflated my repo to nearly 1,000 lines of Rust - but this challenge reuses the \"Intcode Computer\" you build in Day 2 and extends further from there.  This little toy [virtual machine](https://en.wikipedia.org/wiki/Virtual_machine) is going to be used and extended throughout the month.\n\nIf I had gone the quick-and-dirty route to crunch through the specific given inputs had initially thought of, Day 5 would have likely meant starting from scratch and writing *even more* code.  Because I took my time to think about the design and set up a well-abstracted, encapsulated Intcode VM, I'm going to be able to minimally modify what I've already got and have it run both challenges.  I don't anticipate needing to rewrite much, if any, code that I've already created.\n\nTaking the pressure off has turned out to be exactly what I needed to make the most of this super cool event.  This just might be the first set of challenges I complete, but, you know, don't wait up...\n\nThe [GitHub](https://github.com/deciduously/aoc2019) link, for the curious.\n\n*cover image: [reddit](https://www.reddit.com/r/adventofcode/comments/e9sxog/beautiful/)*",
    "title": "Pressure-Free AoC"
  },
  {
    "cover_image": "https://thepracticaldev.s3.amazonaws.com/i/0qfm7joaxu4bvp13w618.jpg",
    "date": "2019-12-19T00:02:13.394Z",
    "description": "An overview of region-based memory management for constructing trees and graphs in Rust",
    "tags": "rust, beginners, tutorial, devjournal",
    "markdown": "---\ntitle: No More Tears, No More Knots: Arena-Allocated Trees in Rust\npublished: true\ndescription: An overview of region-based memory management for constructing trees and graphs in Rust\ncover_image: https://thepracticaldev.s3.amazonaws.com/i/0qfm7joaxu4bvp13w618.jpg\ntags: rust, beginners, tutorial, devjournal\n---\n\n## Enter The Arena\n\nWhen programming in Rust, it's not always straightforward to directly translate idioms you know.  One such category is tree-like data structures.  These are traditionally built out of `Node` structs that refer to other `Node`s in the tree.  To traverse through your structure, you'd use these references, and changing the structure of the tree means changing which nodes are referred to inside each one.\n\nRust *hates* that.  Quickly you'll start running into problems - for instance, when iterating through nodes, you'll generally need to borrow the structure.  After doing so, you'll have a bad time doing anything else with the structure inside.\n\nTrees are a fact of life, though, and very much a useful one at that.  It doesn't have to hurt!  We can use [region-based memory management](https://en.wikipedia.org/wiki/Region-based_memory_management) to pretty much forget about it.\n\n### The Desert\n\nI'll briefly mention a few of the other methods I've bashed my head against before trying this today.\n\nThe simplest is to use `unsafe`, which allows you to use raw pointers like you would in C.   This forfeits a lot of the benefits we get from using safe Rust, as one use of `unsafe` will infect your whole crate.  Now part of the code is only deemed safe because you, the programmer, have deemed it to be, and not the Rust compiler.\n\nTo stick to statically safe Rust, you can wrap your pointers in `Rc<RefCell<T>>` types, which are reference-counted smart pointers with interior mutability.  When you call `Rc::clone(&ptr)`, you get back a brand new pointer to the same data, that can be owned separately from any existing pointer, and when all such `Rc`s have been dropped the data itself will get dropped.  This is a form of static garbage collection.  The `RefCell` that allows you to take mutable borrows of things that aren't mutable, and enforces at runtime instead of statically.  This lets you cheat, and will `panic!()` if screw up, so, hooray I guess.  You need to use methods like `data.borrow_mut()` but then can, for example, change the pointer in a `next` field using an otherwise immutable borrow of the node during your traversal.\n\nAlternatively you can use `Box` smart pointers and clone them around, performing a lot of extra work for no reason - this involves deep-copying whole subtrees to make small edits.  You do you, but that's not really my thing.\n\nYou can even use plain references and introduce explicit lifetimes:\n\n```rust\nstruct Node<'a> {\n    val: i32,\n    next: &'a Node,\n}\n```\n\nYippee, you're probably sprinkling `'a` all over the place now, and there's gonna be a part of you that wants to start getting friendly with `b`, and whoa there.  That's gross, and you're solving a much simpler problem that requires.\n\nAll of these options mean pain, and often compromise.  At least in my experience, while you often can get to a successful compile your code gets unreadable and unmaintainable fast, and should you ever need to make a different choice you're pretty much back to square one trying to fit it all together.  It's also the only way I've ever managed to actually produce a segfault in Rust.  I was pretty impressed with myself for screwing up that hard and I wish I had kept better notes about how I got there, but I know it was some nonsense like the above.\n\nThe problem is that Rust is keeping a close eye on who owns your nodes and what lifetime each has, but as you build a structure it's not always easy for the compiler to understand what it is you're trying to do.  You end up with inferred lifetimes that are too small or not accurate for your structure and no way to efficiently traverse or edit the map.  You end up needing to do manual work to convince the compiler you're right, which sucks.\n\n### The Oasis\n\nWhat if your nodes could all have the SAME lifetime?  I mean, they essentially do, right?  Sure, some may get created after one another, but for all intents and purposes within this program you just care that they're all owned by your top-level tree structure.\n\nThere's a super easy way - pop 'em in a `Vec<T>`:\n\n```rust\n#[derive(Debug, Default)]\nstruct ArenaTree<T> \nwhere\n    T: PartialEq\n{\n    arena: Vec<Node<T>>,\n}\n```\n\nBoom.  Tree.  It's generic for any type that can be compared with `==`, and the lifetime problems are solved.  You want a node?  Use `self.arena[idx]`.  Instead of storing actual references to other nodes, just give 'em each an index:\n\n```rust\n#[derive(Debug)]\nstruct Node<T>\nwhere\n    T: PartialEq\n{\n    idx: usize,\n    val: T,\n    parent: Option<usize>,\n    children: Vec<usize>,\n}\n```\n\nIn this tree, each node has zero or one parents and zero or more children. \n New ones will require an ID specified, as well as a value to store, and will not connect to any other nodes:\n\n```rust\nimpl<T> Node<T>\nwhere\n    T: PartialEq\n{\n    fn new(idx: usize, val: T) -> Self {\n        Self {\n            idx,\n            val,\n            parent: None,\n            children: vec![],\n        }\n    }\n}\n\n```\n\nYou could go on and store as many indices as you want - it's your graph.  This is just the example tree I used for [Day 6 of AoC](https://adventofcode.com/2019/day/6) (and why we're here).\n\nThis is pretty easy to use.  When you want a value, you can just ask for its index:\n\n```rust\nimpl<T> ArenaTree<T>\nwhere\n    T: PartialEq\n{\n    fn node(&mut self, val: T) -> usize {\n        //first see if it exists\n        for node in &self.arena {\n            if node.val == val {\n                return node.idx;\n            }\n        }\n        // Otherwise, add new node\n        let idx = self.arena.len();\n        self.arena.push(Node::new(idx, name));\n        idx\n    }\n}\n```\n\nWhether or not it was there previously, you now have an index for that value in your tree.  If it wasn't already there, a new node was allocated with no connections to any existing nodes.  It will automatically drop when the `ArenaTree` goes out of scope, so all your nodes will always live as long as any other and all will clean up at the same time.\n\nThis snippet shows how easy traversal becomes - you just walk the vector with, e.g., `for node in &self.arena`.  Certain operations become trivial - want the number of nodes?  Ask for it:\n\n```rust\nfn size(&self) -> usize {\n    self.arena.len()\n}\n```\n\nWhat about counting how many edges are there?  Nothing fancy here either, count them:\n\n```rust\nfn edges(&self) -> usize {\n    self.arena.iter().fold(0, |acc, node| acc + node.children.len())\n}\n```\n\nIt's still pretty easy to do your standard recursive data structure stuff, though.  You can see how deep a node is:\n\n```rust\nfn depth(&self, idx: usize) -> usize {\n    match self.arena[idx].parent {\n        Some(id) => 1 + self.depth(id),\n        None => 0,\n    }\n}\n```\n\nSearch for a value from the root, returning its depth:\n\n```rust\nfn depth_to_target(&self, idx: usize, target: &T) -> Option<usize> {\n    // are we here?  If so, Some(0)\n    if target == &self.arena[idx].val {\n        return Some(0);\n    }\n\n    // If not, try all children\n    for p in &self.arena[idx].children {\n        if let Some(x) = self.depth_to_target(*p, &target) {\n            return Some(1 + x);\n        }\n    }\n    // If it cant be found, return None\n    None\n}\n```\n\nYou can of course traverse iteratively as well.  This method finds the distance between the parents of two nodes using both iterative and recursive traversal to perform a series of depth-first searches:\n\n```rust\nfn distance_between(&mut self, from: T, target: T) -> usize {\n    // If it's not in the tree, this will add a new unconnected node\n    // the final function will still return None\n    let start_node = self.node(from);\n    let mut ret = 0;\n    // Start traversal\n    let mut trav = &self.arena[start_node];\n    // Explore all children, then hop up one\n    while let Some(inner) = trav.parent {\n        if let Some(x) =  self.depth_to_target(inner, &target) {\n            ret += x;\n            break;\n        }\n        trav = &self.arena[inner];\n        ret += 1;\n    }\n    // don't go all the way to target, just orbit\n    ret - 1\n}\n```\n\nThis repeats a little work on each backtrack, but at even puzzle scale computes nearly instantly.  It's quite concise and readable, not words I'm used to using for Rust trees!\n\nInserting will depend on the domain, but this application received input as `PARENT)CHILD`, so my `insert` looked like this:\n\n```rust\nfn insert(&mut self, orbit: &str) {\n    // Init nodes\n    let split = orbit.split(')').collect::<Vec<&str>>();\n    let inner = self.node(split[0]);\n    let outer = self.node(split[1]);\n    // set orbit\n    match self.object_arena[outer].parent {\n        Some(_) => panic!(\"Attempt to overwrite existing orbit\"),\n        None => self.object_arena[outer].parent = Some(inner),\n    }\n    // set parents\n    self.object_arena[inner].children.push(outer);\n}\n```\n\nTo recap, whenever you want to manipulate a given node you just need its index to do so.  These are handily `Copy`, so don't worry too much about manipulating them.  To get a node's index, call `tree.node(val)`.  It will always succeed by performing a lookup first and then allocating it to your tree's arena if it wasn't already there.  Then it's up to you to manipulate the node's fields to the indices where it belongs: `self.arena[idx].children.push(outer);`.  You never need to worry about the memory again, your `Vec` will drop itself when it can.  You define the structure of the tree yourself by what indices are stored in each node and what happens when you insert a new one.\n\nBasically, it's a tree like you want it to be, but it's in Rust and you don't even have to fight about it, and it's great.\n\nHere's a [playground link](https://play.rust-lang.org/?version=stable&mode=debug&edition=2018&gist=7cccabd269fd1ee8f61ff23fd79117e7) to poke and prod at.\n\n*cover image by Amanda Flavell on Unsplash*",
    "title": "No More Tears, No More Knots: Arena-Allocated Trees in Rust"
  },
  {
    "cover_image": "https://thepracticaldev.s3.amazonaws.com/i/fv145cd7o6pbzo1jd1s1.png",
    "date": null,
    "description": "Lambda Calculus for the Regular Person",
    "tags": "beginners, functional, tutorial",
    "markdown": "---\ntitle: Lambda Calculus And You\npublished: false\ndescription: Lambda Calculus for the Regular Person\ncover_image: https://thepracticaldev.s3.amazonaws.com/i/fv145cd7o6pbzo1jd1s1.png\ntags: beginners, functional, tutorial\n---\n\n## Intro - TODO BETTER NAME\n\nAlright, kids (I'm in my 20s).  Pull up a chair.  It's time we had a talk.\n\nWe need to talk about functions.\n\n## History\n\n## Basics\n\n## Setup\n\nThis post isn't necessarily about practical application, but if you'd like to follow along this code was written with [Chez Scheme](https://github.com/cisco/chezscheme).\n\n## Building Out",
    "title": "Lambda Calculus And You"
  },
  {
    "cover_image": "https://res.cloudinary.com/practicaldev/image/fetch/s--gjVbKplI--/c_imagga_scale,f_auto,fl_progressive,h_420,q_auto,w_1000/https://thepracticaldev.s3.amazonaws.com/i/jrwv2cv287qzequkx4e0.jpg",
    "date": "2019-12-21T01:12:44.587Z",
    "description": "",
    "tags": "healthydebate, rust, cpp",
    "markdown": "I want to preface this by saying these are my two primary languages.  I have a healthy respect for both and plan to focus on both regardless.  I know this is a provocative question, and I am a beginner in both languages.\n\nI'm not talking about stuff where you're supposed to use [JavaScript](https://en.wikipedia.org/wiki/JavaScript) or [C#](https://en.wikipedia.org/wiki/C_Sharp_%28programming_language%29) or something - even though [Rust](https://www.rust-lang.org/) is [actually kinda okay](https://www.rust-lang.org/what/embedded) at [those too](https://www.rust-lang.org/what/networking) and [improving all the time](https://www.rust-lang.org/what/wasm).  I'm not even talking about [C](https://en.wikipedia.org/wiki/C_%28programming_language%29), even though I think eventually we might be able to have that conversation too.  I'm specifically asserting that Rust could conceivably compete head-to head with [C++](https://isocpp.org/).\n\nThat said, as I learn more about C++, I learn more about how much I don't know about both C++ and programming in general.  From my perspective, the [Hindley-Milner](https://en.wikipedia.org/wiki/Hindley%E2%80%93Milner_type_system)-inspired type system is a perfect match paired with the granular control over memory for the kind of data manipulation Rust is targeting. I am more than willing to be shown why I am wrong.\n\nI recently posted about a Rust tree I implemented with a workaround for how Rust is restrictive, but the very first alternative I mentioned was [`unsafe`](https://doc.rust-lang.org/book/ch19-01-unsafe-rust.html).  Of course, there is always the need to directly manipulate memory.  Many standard library tools are by nature implemented in `unsafe` Rust, with a safe API written that's been vetted by the talented Rust team and the OSS community at large.  There are many `lib*-sys` crates that are essentially the same thing.  Any FFI with C will include `unsafe` raw pointers.\n\nThat's how any tool, OSS or proprietary, is deemed \"safe\", though, right?  Smart people look at it?\n\nI see talk of [templates](https://en.cppreference.com/w/cpp/language/templates) with a reverence, but to me they're a clunkier [Rust trait](https://doc.rust-lang.org/book/ch10-02-traits.html).  What can you do with templates that Rust traits + macros can't?  Speaking of which, [Functors](https://v1.realworldocaml.org/v1/en/html/functors.html) in [OCaml](https://ocaml.org/)?  [Jane Street](https://www.janestreet.com/technology/) is making a solid case for that tool even over Haskell or C++.  OCaml itself is an amazing language for [UNIX/Linux programming](https://ocaml.github.io/ocamlunix/).  C++ is cemented, but new code is written all the time.  Am I off the mark with where C++'s power lies?\n\nWhy not, all memes aside, write all brand new applicable-domain software in Rust, and write Rust interfaces where needed?\n\nI understand that C++ imposes fewer restrictions by default, allowing people to override the machine where people know better.  I don't know that I'm sold on why that precludes a new *foundational* language that's an improvement over what we have, and why Rust isn't it.\n\n*Photo by Edvin Johansson on Unsplash*",
    "title": "What Does C++ Do That Rust Doesn't?"
  },
  {
    "cover_image": "https://res.cloudinary.com/practicaldev/image/fetch/s--35wtqY9v--/c_imagga_scale,f_auto,fl_progressive,h_420,q_auto,w_1000/https://thepracticaldev.s3.amazonaws.com/i/k3f2uwaq1dph7aewsqzm.jpg",
    "date": "2019-12-30T17:25:59.970Z",
    "description": "",
    "tags": "linux, bsd, help, discuss",
    "markdown": "## Is This What Growing Up Feels Like?\n\nI have been an avid, dedicated [Gentoo](https://www.gentoo.org/) user for about seven years (*gulp*).  I love the flexibility of the package manager, and the extremely granular level of control over my system it gives me.  Installing and administrating a Gentoo system for this long is the reason I know as much about Linux as I do, and I don't regret a minute of it.\n\nHowever, all that configuration comes at a cost - my time.  When the system works, it requires little to no maintenance, and should generally continue to work.  If it breaks, it's because I changed something.  However, it does require frequent updates to ensure smooth roll-forwards, and that means rebuilding components from source, a lot.  If nothing else, it's ecologically irresponsible to repeatedly rebuild a whole Linux distribution for negligible gain.\n\nAt the end of the day, my needs are pretty run-of-the-mill, which is kind of a misuse of Gentoo's flexibility.  It's finally time to part ways.\n\nThis is the list of alternatives I'm considering.  I've actually installed and used each of these before as a secondary exploratory distro, but never used any as a daily driver.\n\n* [Debian](https://www.debian.org/)\n\nThis is currently my top choice, but this may just be a reaction to where I'm coming from.  Debian's \"elevator pitch\" is stability.  A Debian system should be expected to be rock-solid once installed.  I don't want to futz with my operating system, I want to turn on my workstation and *do work*.  Debian enjoys a massive package set and widespread compatibility, but I am concerned that the stable branch lags in terms of updates.  I could use Debian Testing, but am I then forfeiting the whole purpose of using Debian in the first place?  How easy is it to selectively use updated (or upstream) package repositories for software I actively use a lot on a largely Debian Stable system?\n\n* [Manjaro](https://manjaro.org/)\n\nManjaro is my second choice.  I came to Gentoo from [Arch Linux](https://www.archlinux.org/), and clearly connect with the \"lego set\" style of DIY linux distros.  Arch was also a highly pleasant, highly stable experience, but this time around I no longer feel the need to build up completely from scratch.  I had a positive experience installing Manjaro back in 2016, and can only assume it's further improved since then.  Arch-diehards - why *shouldn't* I just use Manjaro and instead keep it strictly Arch?\n\n* [Fedora](https://getfedora.org/)\n\nI have much less familiarity with RPM, so it would be nice to learn, and hear this is a solid choice for developers who need their system components to remain relatively tight with upstream but still need a stable, cohesive system that all works together.  This is the furthest from what I know, so it's tempting, but the whole point here is to think *less* about my OS and just get stuff done.\n\n* [OpenSuSE](https://www.opensuse.org/)\n\nOpenSuSE has the somewhat dubious distinction of being my very first Linux distro, about six months before I discovered [Ubuntu](https://ubuntu.com/) Breezy Badger back in 2005.  I also tried and liked using [Tumbleweed](https://www.opensuse.org/#Tumbleweed) in 2018 for a bit as a daily driver, but still ended up running back to Gentoo.  This distro has some serious brand loyalty, though.  Why should I give it another look?\n\n* [KDE Neon](https://neon.kde.org/)\n\nMost of these distributions actually differ somewhat minimally.  It's a choice of a package manager and a default set of applications.  I have already settled on [KDE Plasma](https://kde.org/plasma-desktop) as my desktop environment of choice, so if I don't much care about the base, why not just use their distro and get the most polished KDE experience?  Would this limit me in any significant way?  The Ubuntu LTS base actually ticks all my boxes too.\n\n* [FreeBSD](https://www.freebsd.org/)\n\nNot likely, and not Linux, but Gentoo's [`portage`](https://wiki.gentoo.org/wiki/Portage) is the whole reason I like Gentoo so much and is inspired by the BSD-style [`ports`](https://www.freebsd.org/ports/) system.  Is this actually a viable choice for a daily driver for development work?\n\nI am also using and enjoying [Void Linux](https://voidlinux.org/) on my rapidly aging laptop, but it's not quite as \"just forget about it\" as I want for my more modern desktop, and every so often I have trouble getting something installed (most recently, for example, `dotnet`).\n\nIs there something awesome I've missed?  Other reformed distro-hoppers, what's your Linux forever-home and why?\n\n*Photo by Mantas Hesthaven on Unsplash*",
    "title": "Au Revoir, Gentoo - Sell Me A New Linux Distro"
  },
  {
    "cover_image": "https://res.cloudinary.com/practicaldev/image/fetch/s--ZBRSmA_v--/c_imagga_scale,f_auto,fl_progressive,h_420,q_auto,w_1000/https://thepracticaldev.s3.amazonaws.com/i/g3gxkpx0h3crwhl1ex7t.jpeg",
    "date": "2020-01-01T21:32:51.605Z",
    "description": "",
    "tags": "linux, debian, devjournal, beginners",
    "markdown": "## Yes, Really, Even After All That\n\nThis was an unexpectedly phenomenal discussion:\n\n{% post deciduously/au-revoir-gentoo-sell-me-a-new-linux-distro-4d3e %}\n\nThank you, DEV, seriously, I'm blown away by how many of you were compelled to add your take.  The discussion there turned into a highly useful resource with a wide array of perspectives, experiences, and opinions from people who really know what they're talking about, and I'll be returning to it as a reference time and again.\n\nI carefully read every single comment, and took all of your well-informed perspectives into consideration, but ultimately went with my initial instinct and installed [Debian Buster](https://www.debian.org/releases/buster/).\n\n\nThe [first half](#trusting-instinct) of this post is a somewhat defensive run-down of why I picked [Debian](https://www.debian.org/) instead of, oh, pretty much anything else, and the [second half](#installation-log) is a log of the installation process and post-install configuration I've done so far, more for my own reference than anything else.\n\n## Trusting Instinct\n\nI'm sure many of you are shaking your heads at me, wondering how I could have made such a poor choice after all that discussion.  It's actually happening to me too, don't worry.  I'm looking at this as an experiment.\n\nThe two runners up after reading through the responses were [KDE Neon](https://neon.kde.org/) and [Pop!_OS](https://system76.com/pop).  I hadn't even considered Pop!_OS initially, and am quite glad so many DEV users spoke so highly of it - it's [considerably cooler](https://pop.system76.com/docs/difference-between-pop-ubuntu/) than I thought.  I think there's a good chance y'all are correct about Debian and its shortcomings as a main work distribution, and if so I'm headed straight for Pop!_OS.  I guess I just need to see it for myself first.\n\nAt the end of the day, while I think [Manjaro](https://manjaro.org/) or [Solus](https://getsol.us/home/) sound fun, or sticking with Gentoo or a derivative like [Calculate](https://www.calculate-linux.org/en/), Debian compatibility was the primary driving factor.  Once that decision had been made, it came down to whether I wanted to pin to Debian Stable or [Ubuntu LTS](https://wiki.ubuntu.com/BionicBeaver/ReleaseNotes) as a base.\n\nBetween those two, most (but not all) of you recommended Ubuntu (or an Ubuntu derivative like both Neon and Pop!_OS) because it more squarely fits my \"just forget about it\" criterion.  Debian's philosophy and user experience is great for servers, but perhaps not designed for desktop end-users.  I think that's generally true, but wasn't completely sold that it wasn't right for me specifically anyway.\n\nThe primary shortcoming mentioned for Debian was that all of my software will always be out of date.  I gave this some thought and looked at my current software usage, and concluded that I don't actually care.  I'd much rather have a system that's thoroughly vetted and tested than get all the cool new stuff that comes out.  I often never use it anyway, or at least am happy to wait for some nifty KDE trick until it does trickle its way into Debian in a few years.  I kind of can't believe how long I spent on bleeding edge rolling-release distributions for - if I'm being honest with myself - very little reason.  It makes sense for a lot of people who do care about and use that stuff, but I really just don't.  So what if the version of `cairo` I'm on is years old?  It's doing the thing I need it to do.  More specifically, what I need is for it and all of my system components to play well together, regardless of what specific versions of each I'm running.  That's Debian's entire raison d'être: stable doesn't break.\n\nI also don't need everything to \"just work\" without intervention, which is Ubuntu's sales pitch.  Thinking about it more, I don't think \"just forget about it\" is really my goal.  I want to keep learning from my system, I just don't want to waste time.  I don't think Gentoo itself is necessarily the culprit (it's definitely me, I'm the culprit), but it's not helping in that regard either.  Debian is boring in a way that I need it to be, and Gentoo isn't.\n\nThat said, I am capable of and generally don't mind configuring my system and do like retaining that control.  I had to install non-free drivers for my wireless and graphics cards, so now I *know* what my system needs in the Debian universe.  Now that I've done it once, it's just as much a non-issue ongoing maintenance-wise as Ubuntu would have been.  The problems come for me when that extra control leads to time wasted, or creating extra work for work's sake.  I don't mind a little real work to get everything the way I want it to be, though, especially if it results in a highly stable system.\n\nThere is still a bit of hesitation, because I know inevitably I will want a more updated version of something than what Buster includes, and I did get a bit of a mixed review when it comes to selectively updating specific packages.  Debian packaging itself is mythically horrific, a far cry from what I'm used to with [ebuilds](https://wiki.gentoo.org/wiki/Basic_guide_to_write_Gentoo_Ebuilds).\n\nUltimately, I chose Debian because it's an industry standard, and the base from which all these other operating systems are derived.  I think it's important to become well versed in what's actually widely used in the real world as well as what I find elegant and fun.  This philosophy guides a lot of my tool choices - my two main programming languages right now are [C++](https://en.cppreference.com/w/cpp/language) and [Rust](https://www.rust-lang.org/), I like experimenting with alternate shells like [`zsh`](https://en.wikipedia.org/wiki/Z_shell) and [`fish`](https://fishshell.com/) and scripting tools like [ClojureScript](https://clojurescript.org/)/[`planck`](https://planck-repl.org/) but I still make sure to learn plain [`bash`](https://www.gnu.org/software/bash/), I try to make a point of practicing functional programming concepts in both [Haskell](https://www.haskell.org/) and [JavaScript](https://www.ecma-international.org/ecma-262/10.0/index.html#Title), et cetera.  I get a lot out of comparing and contrasting the tools I learn by learning two sides of a particular coin concurrently, and end up with (I think) a deeper understanding of the pros and cons of both as well as a working familiarity with the one more likely to be useful in the long term.  It makes sense to me to apply this thinking to my OS as well.\n\nFor this reason, I've decided to see Debian through for a while and then potentially re-assess down the road if it turns out I am spending too much time making it work instead of working.  At that point, a more polished Ubuntu LTS-based experience will likely be the remedy.  I know it's far too early to really tell, but for now I'm completely satisfied with Debian Stable.\n\n## Installation Log\n\nThe above was a mild fib.  The very first action I took was trying to install KDE Neon, but the live disc didn't boot on my hardware in either graphical or OEM mode.  It got through GRUB and then crashed, every time.  I wrote it to different media, tried multiple times, nothing.  While I still kinda would have liked to try this distro, and know there absolutely would have been a way to get it running - I'm pretty sure it's just a graphics card issue - that's a poor first impression, and pretty much why I ran straight to Debian next, and in retrospect I am glad I did.\n\n### Getting to First Boot\n\nAs expected, Buster installed without a hitch on the first try.  New in Buster is [UEFI Secure Boot](https://wiki.debian.org/SecureBoot) support, so I didn't have to do a thing first.  I just cleared the way in my partition table and let the installer do it's thang.  It correctly found my other operating systems ([Windows 10](https://www.microsoft.com/en-us/windows/get-windows-10), [NixOS](https://nixos.org/)) and installed GRUB the way I would have done it myself with minimal hand-holding.\n\nThe migration from Gentoo was painless.  I tarballed all my PDFs and popped them on a flash drive, then reformatted my Gentoo partition.  Seven years of configuration, obliterated in a `mkfs`.  Everything else I need is hosted in an offsite git repo, including dotfiles.  No use getting sentimental!\n\nOkay, I lied again - It actually wasn't *quite* without a hitch but it was my fault, not Debian's.  I was a little stupid and didn't bother customizing the install, so initially I had a similar problem to the KDE Neon disc - it would start the boot process and then die trying to load the graphics driver.  Luckily, the Debian live disc has a \"recover\" mode, and I was able to enter a rescue shell on my brand new install.  All I needed to do was edit `/etc/apt/sources.list` to include `contrib` and `non-free`:\n\n```bash\n# https://unix.stackexchange.com/questions/449794/installing-nvidia-driver-for-debian-stretch\nsudo sed -i.bak 's/buster[^ ]* main$/& contrib non-free/g' /etc/apt/sources.list\n```\n\nThen I ran `apt update && apt install nvidia-drivers`.  This actually ended up crashing the live CD once the driver was installed, but then it booted up from the hard drive perfectly.  Solved!\n\nI used a wired connection to run the installation from the `netinst` disc image.  The default installation didn't install the proprietary driver I needed for my Realtek WNIC, but the above step enabled the `non-free` repository I needed.  I installed the firmware with `apt install firmware-realtek` and was immediately able to connect to my home LAN, no other configuration was needed.  The base KDE installation came with NetworkManager and `plasma-nm`.\n\n### Post-Install\n\nI decided instead of trying to replicate any experience I had in the past from a tools-first perspective off the bat based on a preconceived notion of what I'd need, I'd just try to go about my business normally.  This would force me to install and configure stuff as I go organically in hopes of cutting to the core of what I actually care about.  This is what I've done so far.\n\n#### Preloaded Software\n\nMy first order of business was a web browser.  My currently preferred browser is [Firefox](https://www.mozilla.org/en-US/firefox/) and the options I chose at install came preloaded with Firefox ESR v68.3.0.  Eventually this might be one that I look in to getting more recent updates for especially if I end up working more with web development than I currently do but it's fine with me for now.\n\nI did a quick webcam test call, both audio and video worked out of the box on my external USB device with no additional installation or configuration.\n\nI also use [LibreOffice](https://www.libreoffice.org/) for schoolwork and spreadsheets.  This installation came preloaded with version 6.1.5.2 - also fine with me.  I also frequently use both [GIMP](https://www.gimp.org/) and [Imagemagick](https://imagemagick.org/index.php), which were both preloaded as well.  Core components like `gpg` and `ssh` were also preloaded and I was able to configure both as needed with no surprises.  A comprehensive suite of KDE software is included, unlike Gentoo which gives you the basic desktop and lets you pick and choose.  There's a bunch of these I don't use but some I do almost daily like [Spectacle](https://kde.org/applications/utilities/org.kde.spectacle), [Dolphin](https://kde.org/applications/system/org.kde.dolphin), [Kate](https://kde.org/applications/utilities/org.kde.kate), [KNotes](https://kde.org/applications/utilities/org.kde.knotes), [KCalc](https://utils.kde.org/projects/kcalc/), and [Okular](https://okular.kde.org/).  It was honestly great to not have to install anything extra to click right back into my familiar, comfortable workflow.\n\nAll in all, the default set of packages is not excessively bloated at all and largely consists of either things I actively want and use or little extra KDE components that I don't mind having around and may even want to try someday.  The extra stuff I installed was pretty much entirely confined to development environment tools.  That's an A+ experience in my book.\n\n#### Acquiring My Development Environment\n\nBefore getting started with the process of building out the system I need, I needed to add my user to the `sudo` group.  Weirdly `usermod` lives in `/usr/sbin` but that's not in `$PATH` by default, so I added `export PATH=\"$PATH:/usr/sbin/\"` to `.bashrc` for both root and my non-admin account.  Then I was able to run `usermod -a -G sudo ben`, narrowly avoiding starting off my Debian career by having an unauthorized `sudo` incident ominously reported.\n\nNow able to run `apt` safely from my user account, I decided to pull down a few Rust and C++ repositories I've worked on recently and compile them.\n\nFirst, though, I installed my preferred development editors.  [Emacs](https://www.gnu.org/software/emacs/) went in with `apt install emacs`, but lately I use [Visual Studio Code](https://code.visualstudio.com/) for pretty much everything except a few specific cases.  Buster doesn't package this one, so I downloaded the `.deb` directly and invoked `sudo apt install ./code_1.41.1-1576681836_amd64.deb` - easy enough.  I also needed to install [`rustup`](https://rustup.rs) directly using their `curl` one-liner which doesn't come by default.  At that point I grabbed a few other extras I knew I'd need immediately: `apt install curl git htop tmux`.  At this point I've always been in the habit of installing `neovim`, but I skipped it for now - there's nothing wrong with `nano` for tasks I used to use `nvim` for, and it's usually available everywhere.\n\nThe Rust toolchain installed fine, but `cargo install cargo-update` failed when building `openssl_sys`.  I needed to install both `pkg-config` and the `ssl` development headers: `apt install pkg-config libssl-dev`.  To build my [`music`](https://github.com/deciduously/music) project that interfaces with the system audio output device, I needed the ALSA development headers:  `apt install libasound2-dev`.\n\nGetting my [`nannou_dots`](https://github.com/deciduously/nannou_dots) project running was a little more complicated.  I needed the following tools from Buster repos: `apt install cmake python3-distutils libxcb-render0-dev libxcb-xfixes0-dev libxcb-shape0-dev`.  It also depends on the [Vulkan SDK](https://www.lunarg.com/vulkan-sdk/), and I was pleasantly surprised to find I could follow the instructions to [add the Ubuntu 18.04 PPA](https://vulkan.lunarg.com/doc/sdk/latest/linux/getting_started_ubuntu.html) exactly and have it work fine: `apt update && apt install vulkan-sdk`.  Afterwards the `vkvia` test program executed without errors and I could build and run my demo app.\n\nI've heard that's a pretty bad idea.  How bad, exactly, is it?  What Ubuntu<->Debian incompatibilities should I be aware of?\n\nFor C++, I installed a few tools:  `apt install clang cppcheck gdb valgrind`.\n\nI also use [Haskell](https://www.haskell.org/) sometimes: `apt install ghc`.\n\nI set up [Node](https://nodejs.org/en/) and [`pnpm`](https://pnpm.js.org/) with `sudo apt install npm && sudo npm install -g pnpm`.\n\nI also have a soft spot for [`bc`](https://www.geeksforgeeks.org/bc-command-linux-examples/) for doing arithmetic in a terminal: `apt install bc`.\n\nAt this point, I feel I've more or less met all the needs I have after only a few hours, and feel generally confident both that I will be able to meet new ones as they arise and that I shouldn't need to touch it much at all.  Being Debian-compatible does feel like a breath of fresh air even though I did genuinely enjoy Gentoo and found it easy to use, and being Debian *itself* hasn't thus far proven to be a roadblock.\n\n#### Notes\n\nYou can search for a package by keyword with `apt-cache search`.  You can get the current Debian version in `/etc/debian_version`: `10.2`.",
    "title": "Getting Cozy With Debian Buster"
  },
  {
    "cover_image": "https://res.cloudinary.com/practicaldev/image/fetch/s--zCZCtVwg--/c_imagga_scale,f_auto,fl_progressive,h_420,q_auto,w_1000/https://thepracticaldev.s3.amazonaws.com/i/b2hu3dtgb22udkvaru38.jpg",
    "date": "2020-01-04T19:52:29.434Z",
    "description": "",
    "tags": "beginners, help, distributedsystems",
    "markdown": "## Learning in Public\n\nAs I keep learning, DEV knows things.  Ask them stuff.\n\nIn this post, I'm going to *attempt* to ELI5 some buzzword tools and technologies that I don't actually know anything about or use myself, purely based on what I've managed to pick up from Wikipedia and blog posts.\n\nSeveral of these are specifically [distributed computing](https://en.wikipedia.org/wiki/Distributed_computing) tools managed by the open-source [Apache Software Foundation](https://apache.org/), a category of tools I have had zero exposure to or opportunity to work with as a hobbyist/self-learner.\n\nI'd like you to tell me what I'm wrong about or add clarity where I'm inevitably short of the mark about these things:\n\n- [Hadoop](#hadoop)\n- [Spark](#spark)\n- [Cassandra](#cassandra)\n- [Kafka](#kafka)\n- [RabbitMQ](#rabbitmq)\n- [Containers](#containers)\n- [Kubernetes](#kubernetes)\n- [Redis](#redis)\n\n### Hadoop\n\n[Apache Hadoop](https://en.wikipedia.org/wiki/Apache_Hadoop) is a tool for working with huge amounts of data.  It abstracts the physical hardware from the data operations you are running.  Hadoop takes care of dicing up the data and managing where it lives across a bunch of networked computers, each with otherwise separate, self contained memory and processors.  This group is called a \"cluster\".  This allows you to horizontally scale because the software manages how the hardware is utilized for you.  Horizontal scaling means adding more components as opposed to vertical scaling which means making your current components more powerful.  You can simply throw more computers at Hadoop with low overhead to bring online, you don't need to upgrade what you have to get more power.\n\nThe method of interacting with Hadoop is called [MapReduce](https://en.wikipedia.org/wiki/MapReduce).  It's called so because it consists of a \"map\" operation and then a \"reduce\" operation.  A \"map\" means an operation applied to every element of a sequence - in this case each chunk of the data spread across the cluster.  A \"reduce\" will process a number of sources into one source, combining the results of each individual operation.  This is similar to but not exactly like the [`map()`](https://en.wikipedia.org/wiki/Map_(higher-order_function)) and [`reduce()`](https://en.wikipedia.org/wiki/Fold_%28higher-order_function%29) functional programming methods, specifically applied to chunking up a workload in a distributed computing environment.  It's so powerful because during the \"map\" stage you've [parallelized](https://en.wikipedia.org/wiki/Parallel_computing) your operation, as each node in your cluster can run its section simultaneously.\n\nI've kinda-sorta wanted to build a [Raspberry Pi Hadoop cluster](https://dqydj.com/raspberry-pi-hadoop-cluster-apache-spark-yarn/) for a while, but I don't know what the heck I'd do with it.\n\n### Spark\n\n[Apache Spark](https://en.wikipedia.org/wiki/Apache_Spark) is a system for running operations on massive amounts of data, like MapReduce.  Whereas MapReduce is running operations locally on each server, Spark runs operations in-memory.  Spark runs in a Hadoop cluster to speed up the operation over the basic MapReduce model by running everything in its nifty in-memory way, cutting down on disk I/O which can be a bottleneck for some workloads.\n\nHadoop and Spark are both widely used and have different strengths, but I don't know enough to elaborate.  What sorts of workloads are each of these used for, and why do these underlying design differences help?  Why don't *all* Hadoop clusters run Spark if it's so dang fast?\n\nMore importantly, am I even correct about what these things are?\n\n### Cassandra\n\n[Apache Cassandra](https://en.wikipedia.org/wiki/Apache_Cassandra) is a [NoSQL](https://en.wikipedia.org/wiki/NoSQL) database like [MongoDB](https://en.wikipedia.org/wiki/MongoDB) that's designed to be run on distributed systems, and supports MapReduce and Hadoop.  It uses its own query language that looks kinda like SQL called [CQL](https://cassandra.apache.org/doc/latest/cql/).\n\nThat's all I've got, here - it's what you use if you need a NoSQL data store in a distributed system.\n\n### Kafka\n\n[Apache Kafka](https://en.wikipedia.org/wiki/Apache_Kafka) is another distributed computing tool, this time providing a stream of records.  It's kinda like Hadoop in that this stream of records is abstracted from the hardware and Kafka manages any actual physical mapping - or does it run on a Hadoop cluster?  This property allows incoming \"Consumers\" and \"Producers\" of these streams to not care about physical topology, and store logs that are too big for any one server.  Streams can also be connected in some way and processed.  It can be used as a replacement for traditional message brokers like RabbitMQ.\n\n### RabbitMQ\n\n[RabbitMQ](https://en.wikipedia.org/wiki/RabbitMQ) is a traditional message broker.  A [message broker](https://en.wikipedia.org/wiki/Message_broker) provides [queues](https://en.wikipedia.org/wiki/Queue_(abstract_data_type)) for moving messages around in a big system.  This allows you to compose your system from small encapsulated disparate parts, even in different programming languages if you like, and use one of several message queuing protocols to pass around what you need between them.  This model is called [Message-Oriented Middleware](https://en.wikipedia.org/wiki/Message-oriented_middleware) or MOM and is easier to scale than a huge complicated monolithic application design.\n\n### Containers\n\nA [container](https://en.wikipedia.org/wiki/OS-level_virtualization) is a lightweight method of virtualization for an operating system without needing to emulate a whole computer.  It allows you to separately distribute a set of [userspace](https://en.wikipedia.org/wiki/User_space) tools without the [kernel](https://en.wikipedia.org/wiki/Kernel_(operating_system)).  When you enter a container, it uses the host OS's kernel to interact with the CPU and RAM but overlays a separate userspace, providing a sandboxed environment that looks like a completely clean operating system to running software.  This is more space and resource efficient than a traditional virtual machine, which steals a segment of the host's resources and emulates a full computer in software to provide the same result.\n\n[Docker](https://en.wikipedia.org/wiki/Docker_%28software%29) is a commonly used [PaaS](https://en.wikipedia.org/wiki/Platform_as_a_service) for containerization, and allows you to configure these sandboxed environments with a text file called a [Dockerfile](https://docs.docker.com/engine/reference/builder/), and orchestrate multiple containers via a YAML file called [`docker-compose.yml`](https://docs.docker.com/compose/).  This allows you to cheaply and conveniently run different parts of an application, for instance a MySQL database and an API server, in completely separate, sterile, reproducible environments.\n\n### Kubernetes\n\n[Kubernetes](https://en.wikipedia.org/wiki/Kubernetes) is a layer of abstraction on top of containers.  It's a more powerful abstraction than `docker-compose.yml`.  It's an orchestration system that lets you stop thinking in terms of individual containers for these components of a huge system, and instead in terms of services.  It creates and manages clusters of identical containers to run these services.  It can automatically scale by spinning up new containers to manage load or by spinning down unneeded ones, helping to manage server costs.  It can also silently kill and reboot containers that have entered poisoned states.  It sounds like a great idea to me - when should you prefer Docker Compose?\n\n### Redis\n\n[Redis](https://en.wikipedia.org/wiki/Redis) is an in memory key-value store that supports a variety of abstract data types like Lists and Strings, so you can use it with objects directly from your app's programming language.  It's different from a standard relational database in that you don't query an engine which performs your operation, you just run specific operations on these objects directly in memory.  It's both a data store and a cache, and manages both persistent storage and fast client-side data retrieval.  This allows you to cache user requests and stop hitting your server-side database on repeated requests.  It can also be used for messaging like RabbitMQ or Kafka, I guess?  Redis seems pretty cool, it's on my 2020 to-learn list, but I don't feel I have a thorough understanding of it.\n\n*Photo by stem.T4L on Unsplash*",
    "title": "Correct a Beginner About Buzzword Technologies"
  },
  {
    "cover_image": "https://res.cloudinary.com/practicaldev/image/fetch/s--2JthHaiM--/c_imagga_scale,f_auto,fl_progressive,h_420,q_auto,w_1000/https://thepracticaldev.s3.amazonaws.com/i/314jlc0r54roahmfzkxh.jpg",
    "date": "2020-01-08T18:21:21.389Z",
    "description": "",
    "tags": "webdev, typescript, beginners, devjournal",
    "markdown": "## Getting Real\n\nI've just started exploring [`stencil`](https://stenciljs.com/) and am already nursing a crush.\n\nI will be the first to admit that I don't particularly enjoy building frontends.  It's the reason my own [personal website](http://deciduously.com/) is, well, sad.  It's been incomplete and neglected since the day I forced it out in the open, and largely untouched from that pathetic, half-finished state. This means it does not reflect any recent work I have to show off, at all, or accurately demonstrate what I'm capable of in any significant way.  Useful, right?  Why even have one, at this point.\n\nI built that website as a side-effect of a DIY [static site generator](https://github.com/deciduously/deciduously-com-rs) exploratory project in Rust.  The fun part of that project for me was building the static site generator and web server.  To see if it all worked I needed some test stuff to feed it so I figured I *may as well* build a personal website.  Poor thing never stood a chance - talk about falling short of even the bare minimum.\n\nOne of my goals for 2020 is to completely rebuild it into something that isn't embarrassing, and hopefully hone a useful skill and learn more about the domain along the way.\n\n## Runners Up\n\nChoosing a stack in the JavaScript world is daunting, especially when you don't actually know what you're doing.  Before settling on `stencil` I considered the following options:\n\n* [HTML](https://whatwg.org/)/[CSS](https://www.w3.org/Style/CSS/)\n\nMy \"aesthetic\" for tooling choices is barebones and simple.  I prefer to build my own abstractions, at least when I'm learning a domain, before trying to choose someone else's, and also think that for this website even vanilla JS is probably overkill, everything I want to present can be presented statically and simply.  All I really need is HTML and CSS.  I decided not to go this route because I do want to open myself up to more flexible growth paths in the future, and this is the most labor-intensive route if I go beyond the absolute basics.  I also find it extremely boring to do, which means I'd be less likely to finish.\n\n* [Gatsby](https://www.gatsbyjs.org/)\n\nThe framework I've spent the most time with is React, so Gatsby was a natural choice for the next level of organization.  I liked it a lot, and developed a healthy appreciation for [GraphQL](https://graphql.org/), but ultimately found it was like \"React+\" - you're really on your own in terms of ecosystem, and there is a *ton* of complexity going on to achieve what (for me) is a simple end goal, even after I got my head around the basic model (both React itself and then Gatsby over it).  I still think highly of Gatsby in general and would revisit for a larger, more complicated project.\n\n* [Svelte](https://svelte.dev/)/[Sapper](https://sapper.svelte.dev/)\n\nI finally looked at Svelte, because I like the idea of an AOT compiler handling this complexity rather than a bunch of complex runtime logic.  I didn't spend a lot of time with it, though, because it looked like a whole new set of stuff to learn, as well designed as it is, and that's precisely what I want to avoid.  The Sapper [repo](https://github.com/sveltejs/sapper) looks a little dead, too, but that's not always a valid indicator.  I'm keeping my eye on this as well, though.\n\n## Why Stencil Wins\n\nI want to be crystal clear: I am not saying that `stencil` \"wins\".  I am only saying it wins *for me, for this project*.  I know I have a tendency to prod at controversial questions on DEV to see what happens, but this is not one of those posts.\n\nStencil is (mostly) just \"Web\".  It's actually not a \"framework\" at all.  Instead, it's a generator and compiler for [Web Components](https://developer.mozilla.org/en-US/docs/Web/Web_Components), with some extra niceness built-in to streamline the process.\n\nThe Web is an inherently complicated platform, and frontend is not my primary target domain, so I do want some help taming that complexity.  What I don't want is for that help to consist of a whole new set of specifics to learn which may or may not apply to anything else, and which has no guarantee of lasting relevance.  That's been my experience with [JQuery](https://jquery.com/), [Knockout](https://knockoutjs.com/), [Ember](https://emberjs.com/), [Meteor](https://www.meteor.com/), [React](https://reactjs.org/), [Vue](https://vuejs.org/), [Svelte](https://svelte.dev/), whatever else I've touched - even just listing stuff I've test driven makes my head spin and it's all new layers on top of an already complicated topic.\n\nNow, it's a valid point that Web Components may very well represent yet another step along this chain.  There's a phenomenal discussion here:\n\n{% post richharris/why-i-don-t-use-web-components-2cia %}\n\nMy favorite quote from that discussion came from [@josepot](https://dev.to/josepot), who noted that \"web-components are just leaky abstractions built on top of other leaky abstractions\".  That's hard to argue with.  Still, though, what isn't?\n\nI like how Stencil is focused first and foremost on compliance with existing standards.  To write my app, I need to learn TypeScript, not some specific other tool.  I also love how easy it's made it for me to piece together my app.  The `stencil generate` tool can generate just your TSX or include a CSS stylesheet, a [Jest](https://jestjs.io/) `component.spec.ts` file, and a [Puppeteer](https://pptr.dev/) `component.e2e.ts` file.  I'm forcing myself to use all of these for every component as an educational exercise, E2E testing in specific is something I've never experimented with, but it's great that it's all opt-in and you could keep it straightforward as long as you want.\n\nWithin minutes of loading up the template app I had added a new component and hooked it up to a new route with the handy built-in [`stencil-router`](https://github.com/ionic-team/stencil-router) component, purely based on what I already knew about HTML templates going in and the example provided.  Sold!\n\n## Example Component\n\nFor a simple example, here's a component I put together to display a United States postal address:\n\n```tsx\nimport { Component, Prop, h } from '@stencil/core';\nimport { Address } from '../../cvdata';\n\n@Component({\n  tag: 'app-cv-address',\n  styleUrl: 'cv-address.css',\n  shadow: true\n})\nexport class CvAddress {\n  @Prop() address: Address;\n\n  render() {\n    if (this.address) {\n      return (\n        <p itemscope itemtype=\"https://schema.org/PostalAddress\" id=\"address\">\n          <span itemprop=\"streetAddress\">{this.address.street}</span><br />\n          <span itemprop=\"addressLocality\">{this.address.locality.name}</span>, <abbr title={this.address.locality.state.fullName} itemprop=\"addressRegion\">{this.address.locality.state.abbreviation}</abbr> <span itemprop=\"postalCode\">{this.address.locality.postalCode}</span><br />\n          <span itemprop=\"addressCountry\">{this.address.locality.state.country}</span>\n        </p>\n      );\n    }\n  }\n}\n```\n\nIt's just TypeScript, or an ES6 class, with some metadata stored in a decorator.  [JSX](https://reactjs.org/docs/introducing-jsx.html) is a polarizing tool, but I think it's a good fit for the problem it solves.  I've never used [Angular](https://angular.io/) but I think the \"metadata-in-a-decorator\" pattern is not entirely dissimilar.\n\nThis is the over-engineered `Address` TS interface I defined to pass in as a prop:\n\n```ts\ninterface AddressRegion {\n  fullName: string,\n  abbreviation: string,\n  country: string,\n}\n\ninterface Locality {\n  name: string,\n  state: AddressRegion,\n  postalCode: string,\n}\n\nexport interface Address {\n  street: string,\n  locality: Locality\n}\n```\n\nThis is precisely why I like using TypeScript over JavaScript - familiarity.  I'm used to tools that let me define the shape of my data up front, and get frustrated when debugging problems in vanilla JS that would have been caught by a typechecker.  By setting this up before implementing, it's easy for me to dig through the object passed in as a prop.  I know it's not technically any different than doing so without a defined interface, but I like it, dammit.  Having my editor know what I'm doing is a huge help - I like my red squigglies showing me when I'm being stupid.  Typechecked props by default is just awesome.\n\nThis was easy to pop in the larger context:\n\n```tsx\nrender() {\n    return (\n      <div>\n        {/* other stuff... */}\n        <app-cv-address address={this.data.address}></app-cv-address>\n      </div>\n    );\n  }\n```\n\nNo need to import anything, just use your new component!  It couldn't be easier, and I'm off to the races.\n\nBeyond the perceived technical merits of this tool, beginning to build this simple application with `stencil` is pretty much the *only* time I've ever actually enjoyed the process of writing a frontend application.  I thought Gatsby was incredibly cool tech, and Svelte was a solid implementation of an elegant idea, but \"fun\" is a little more elusive for me in this space.\n\nWhy exactly this tool got me there when so many relatively similar others haven't is tricky for me to pinpoint, but I'm not fighting it.  It's simple to get started with, based around core Web technologies that I know will continue to be relevant, and will allow complexity to grow as needed as opposed to including it up-front in a massive convoluted \"starter app\" template.  I'm hoping this tool stays around for a long time and see no reason to hop around, at least for personal use, for the foreseeable future.\n\n*Photo by Karim MANJRA on Unsplash*",
    "title": "Stencil: I Think I Found My Frontend Home"
  },
  {
    "cover_image": "https://res.cloudinary.com/practicaldev/image/fetch/s--BLUAJkDv--/c_imagga_scale,f_auto,fl_progressive,h_420,q_auto,w_1000/https://thepracticaldev.s3.amazonaws.com/i/t5jsf7f5cgihwrfqf883.jpg",
    "date": "2020-01-12T02:35:44.019Z",
    "description": "",
    "tags": "watercooler, irc",
    "markdown": "Just curious who out there still uses this as a primary tool.  [IRC](https://en.wikipedia.org/wiki/Internet_Relay_Chat) was a [huge component](https://en.wikipedia.org/wiki/Nerd) of my middle school-to-high school experience, so ~2003-2010, but I haven't really touched it since except for a few one-off questions.\n\nWhere do you lurk?\n\n*Photo by Museums Victoria on Unsplash*",
    "title": "Who uses IRC?"
  },
  {
    "cover_image": "https://res.cloudinary.com/practicaldev/image/fetch/s--6Lzm3L2e--/c_imagga_scale,f_auto,fl_progressive,h_420,q_auto,w_1000/https://thepracticaldev.s3.amazonaws.com/i/f1ptv4j5ptgx8kbcrp72.jpg",
    "date": "2020-01-12T13:19:25.818Z",
    "description": "",
    "tags": "watercooler, mentalhealth",
    "markdown": "# I Can't Trace Time\n\nThis is what you get when you try [`\"deciduously\"`](https://www.dictionary.com/browse/deciduously) at [Dictionary.com](https://www.dictionary.com/):\n\n> deciduous [ dih-sij-oo-uh s ] / dɪˈsɪdʒ u əs /\n1. shedding the leaves annually, as certain trees and shrubs.\n1. falling off or shed at a particular season, stage of growth, etc., as leaves, horns, or teeth.\n1. not permanent; transitory.\n\nThat's never been an accident.  There's some of my past I want to carry into my future and some I emphatically don't, and I'm glad my story is always in flux.\n\nI mean, right?  Who's with me?\n\nI've been a little extra-prolific this January.  I don't think I'm alone, though, in feeling arbitrarily empowered by not only a new year, but a new *decade*.\n\nIt doesn't make any sense.  It doesn't actually apply to *my life* at all.  It's just a month since `x`, three months until `y`.  But it is how history partitions time, and we're in a new one now, like it or not.\n\nI've got depression and anxiety problems, but who doesn't?  There's so much to LEARN out there.  It's exciting.  Let's define the decade on our terms, based on what's really important.\n\nEverything is always changing and the mere fact that the [Internet](https://en.wikipedia.org/wiki/Internet) and [FOSS software](https://en.wikipedia.org/wiki/Free_and_open-source_software) exist empowers everyone everywhere.  Let's optimize that empowerment, and learn more about our craft.\n\n*Photo by K. Mitch Hodge on Unsplash*",
    "title": "deciduously"
  },
  {
    "cover_image": null,
    "date": null,
    "description": "",
    "tags": "healthydebate",
    "markdown": "I can't stand 'em, but I think I'm in the minority.  What am I missing?  Why do you use them?",
    "title": "Ligatures?"
  },
  {
    "cover_image": "https://res.cloudinary.com/practicaldev/image/fetch/s--7xoWYVac--/c_imagga_scale,f_auto,fl_progressive,h_420,q_auto,w_1000/https://thepracticaldev.s3.amazonaws.com/i/s67yh2hsgfwrg6w08skj.png",
    "date": "2020-01-14T15:36:45.529Z",
    "description": "",
    "tags": "beginners, computerscience, algorithms, cheatsheet",
    "markdown": "A classmate in my Data Structures & Algorithms course this semester posted this link, created by [@ericrowell](https://mobile.twitter.com/ericdrowell).  I'd never seen it and it instantly ended up in my bookmarks, so I wanted to pass it on:\n\n[Big-O Cheat Sheet](https://www.bigocheatsheet.com/)\n\nIt provides a table that gives Big-Θ and Big-O complexities for a set of common operations on range of data structures, as well Big-Ω, Big-Θ, and Big-O for various array sorting algorithms.\n\nI'm thinking about buying [the poster...](https://www.redbubble.com/people/immortalloom/works/22929408-official-big-o-cheat-sheet-poster?p=poster&finish=semi_gloss&size=large&SSAID=389818&utm_source=shareasale&utm_medium=affiliates&utm_campaign=banner&sscid=11k4_ano9b)\n\n![poster image](https://www.bigocheatsheet.com/img/big-o-cheat-sheet-poster.png)",
    "title": "Big-O Cheat Sheet"
  },
  {
    "cover_image": "https://thepracticaldev.s3.amazonaws.com/i/1qd0c8jfqvt82jouug29.jpg",
    "date": "2020-01-21T15:13:54.694Z",
    "description": "A tour of the Phabricator collaboration tool.",
    "tags": "beginners, opensource, productivity, devops",
    "markdown": "---\ntitle: Phabricator is Phabulous\npublished: true\ndescription: A tour of the Phabricator collaboration tool.\ncover_image: https://thepracticaldev.s3.amazonaws.com/i/1qd0c8jfqvt82jouug29.jpg\ntags: beginners, opensource, productivity, devops\n---\n\nPhabricator is SO COOL y'all.  I gotta tell you about it.\n\nUntil this week the only collaborative toolset I'd ever used is what's built in to GitHub.  Which, to be sure, is pretty cool.  Once your projects get to a certain size, Issues and Milestones are a much better way to organize than `//TODO` comments.\n\n[Phabricator](https://www.phacility.com/phabricator/) is a whole other step up, though.  Originally created internally to coordinate software development at Facebook, the project maintainer [Evan Priestly](https://www.linkedin.com/in/evan-priestley-b815102a/) eventually left his post to create the [Phallacity](https://www.phacility.com/) company and work on Phabricator phull-time.\n\n## All-in-one\n\nPhabricator isn't just GitHub Projects.  It's a suite of interconnected tools.  I'm sure it's one of many and most of you probably use a similar integrated solution at work, but this one is my first, and I like it a lot.\n\n### Differential\n\nIt integrates with Git, and if you're familiar with a GitHub Pull Request the analog is a Differential Revision:\n\n![Differential Revision](https://thepracticaldev.s3.amazonaws.com/i/vc3006i1pq6syrfyp3lg.png)\n\nEverything is on one page, making it easy to navigate through this revision's history and see all changes throughout the repository:\n\n![DiffRev Diff](https://thepracticaldev.s3.amazonaws.com/i/hq7ovdlivehxu5i2zm36.png)\n\n#### Harbormaster\n\nHarbormaster is the built-in continuous integration tool:\n\n![Harbormaster](https://thepracticaldev.s3.amazonaws.com/i/037yyqad554nmj9dzxnw.png)\n\nThis project has integrated with [Jenkins](https://jenkins.io/) for a completely automated CI/CD pipeline.\n\n### Maniphest\n\nManiphest is for working on the Task level - more or less analogous to a GitHub Issue.\n\n![Maniphest](https://thepracticaldev.s3.amazonaws.com/i/aeji0rznh095wv0ure4y.png)\n\nYou can associate subtasks and parent tasks, as well as specific Differential Revisions.\n\n### Dashboards\n\nPhabricator is super customizable.  Here's a customized \"Task Finder\" Dashboard that [@codemouse92](https://dev.to/codemouse92) created for this instance:\n\n![task finder](https://thepracticaldev.s3.amazonaws.com/i/aleevxrz0mwhykcymrvp.png)\n\nBy correctly leveraging project and help wanted tags, you can easily guide would-be contributors towards easy entry points in the code.\n\n### Herald\n\nHerald is a rules engine, letting you script logic into many parts of the site.  It can automatically add project tags to new Differential Revisions, or add subscribers, or reject commits from team members without the requisite project affiliations - and much more.  I haven't used it yet, as it's already configured for this instance, but there's clearly a lot of power there.\n\n### Phriction\n\nPhriction is the built-in wiki.\n\n![phriction](https://i.imgur.com/O6YiISF.png)\n\nYup.  It's a wiki.  No surprises there, but useful to have integrated.\n\n### Projects\n\nThis is a way to organize your Maniphest tasks.  There's a Kanban-style Workboard:\n\n![kanban](https://i.imgur.com/eEsKOy7.png)\n\nJust like home!\n\n### Ponder\n\nPonder is a space for open-ended, general discussion that isn't specifically tied to any particular Task or Differential Revision.\n\n![ponder](https://thepracticaldev.s3.amazonaws.com/i/ftew6834qo7xbw1fqzrw.png)\n\nOf course, these are Phabricator objects as well.\n\n### Phurl\n\nThere's even a built-in URL shortener:\n\n![phurl](https://thepracticaldev.s3.amazonaws.com/i/h47ki01xjkg10sxd35yh.png)\n\nSuper handy!\n\n### Conpherence\n\nConpherence is the built-in chat application - think Slack-Lite:\n\n![conpherence](https://thepracticaldev.s3.amazonaws.com/i/6s9szchky0fic8z11jgp.png)\n\n### Phame/Pholio\n\nIn addition to the above sections, there are also dedicated spaces to upload static assets like images and fonts, and a place to publish blog posts - all of course generating hyperlinkable Phabricator objects!\n\n## Hyper-linked to the MAX\n\nThis is the best part.  Every single thing gets a unique identifier.  A Differential Revision might get `D238`, a Task might be `T1235`, the chatrooms are `Z23`, users are `@bdlovy`, et cetera.\n\nWhat's great is that the moment one of these tags is mentioned anywhere it gets hyperlinked in *both* places.  Every Phabricator object ID gets surrounded by a grey box:\n\n![link](https://thepracticaldev.s3.amazonaws.com/i/7zwisid6hmjpxvukoq6w.png)\n\nThat grey box is a link to the object in question - which now has a link right back:\n\n![mention](https://thepracticaldev.s3.amazonaws.com/i/db949zqaaw4txmvkuc26.png)\n\nThe built-in chat widget is a Phabricator object too, so if you ask for help in a chatroom for a specific task, and you'll get a link just like that on the task page to the specific point of the chatroom logs.\n\nOf course, these object IDs are searchable as well:\n\n![search](https://thepracticaldev.s3.amazonaws.com/i/xb6iknwgz4otl6sacqpl.png)\n\n## Arcanist\n\nPhabricator has a command-line tool that exposes nearly all webapp functionality at the command line.  I've so far just used it for creating a new Differential Revision.  Once you've made your changes in your separate branch, you can `git commit` and then run `arc diff`.\n\nYou can use the above tags here, too, though!  When you commit with `arc diff`, your `$EDITOR` will open and let you write up the Differential Revision sections:\n\n```txt\nScrobble BitClass2\n\nSummary: Progress towards T1225: Scrobble ALL the bits.  Bits from BitClass2 have now been fully scrobbled.\n\nTest Plan: Test suite has been updated\n\nReviewers: @smartperson\n\nSubscribers: @peerwhoknowsstuff\n\nRevert Plan: Reset to commit f928ybrv9q48th from landing D291\n```\n\nEdit it, save it, boom.  Automatically, any configured linters and E2E tests get run, your CI/CD is engaged, and you get a link to the created Differential Revision link to your CLI.  At the same time, the Phabricator pages for *each* of T1225, commit f928ybrv9q48th, and Differential Revision D291 have been updated themselves to include a link to the new revision you just created, just because you mentioned it.  Also, any mentioned reviewers and subscribers are notified.\n\nWhen you host a Phabricator mirror in GitHub, you get this whole message.  Phabricator:\n\n![phabricator DR](https://thepracticaldev.s3.amazonaws.com/i/rzu3hq446gatnnppx8yw.png)\n\nGitHub:\n\n![github PR](https://thepracticaldev.s3.amazonaws.com/i/bvr4eyh91sckarf0fdwa.png)\n\nIt's *good stuff*.\n\n## PHP\n\nIf you've been paying attention, you've noticed several of these tools have a phunky `ph` in 'em.  Yep, this tool is implemented in [PHP](https://www.php.net/) - like it or not, it's a staple.  It might not have \"sex appeal\" anymore, whatever the heck that means, but it's hard to deny that it's more than capable of getting the job done however complex that job may be.\n\n## FOSS\n\nPhabricator is phree!  That's right, it's some Pretty Handy Open-Source Software.  It's also completely free of charge.  The source is on GitHub (and Phabricator) and you can run it on your own hardware as-is.  They do offer hosted instances and enterprise support, but there's nothing stopping you from spinning up a personal-use instance right now (except perhaps ISP conditions).\n\nI've had a blast getting familiar with this tool - it blows GitHub out of the water in terms of utility.  Each individual part isn't necessarily novel or groundbreaking, but each does work incredibly seamlessly.  To me, though, the real boon here is the interconnectedness.  The automatic hyperlinking between Phabricator objects is simple, intuitive, and you never need to worry about it.  I feel I'm already spoiled.\n\nAll that said, it's also my first time using a tool like this beyond GitHub - what else ya got for me?\n\n*Photo by Ant Rozetsky on Unsplash*",
    "title": "Phabricator is Phabulous"
  },
  {
    "cover_image": "https://res.cloudinary.com/practicaldev/image/fetch/s--N4JEMcnO--/c_imagga_scale,f_auto,fl_progressive,h_420,q_auto,w_1000/https://thepracticaldev.s3.amazonaws.com/i/ljmiophg9dpous9i2rjc.jpg",
    "date": "2020-01-17T17:37:13.651Z",
    "description": "",
    "tags": "rust, actix, opensource, discuss",
    "markdown": "Sadly, the [actix-web](https://github.com/actix/actix-web) maintainer has quit.  Check out the repo - it's gone.  He moved it back to a personal account and may delete it entirely.  He's not just done with `actix-web`, he's done with open-source.  Way to go, team.\n\n  It's kinda like [last time around](https://dev.to/deciduously/the-trials-and-tribulations-of-actix-web-and-the-oss-community-53ee).  The underlying issue is a legitimate technical concern regarding soundness and unnecessary usage of `unsafe` in the library, which the maintainer does not perceive as problematic.\n\nEnter Reddit, enter vitriol and toxicity.  Real technical concerns, and an utter inability to discuss them like everyone involved is actually people.  It's endlessly frustrating.  I'd quit too, and now everyone loses.\n\nSteve Klabnick [says it better](https://words.steveklabnik.com/a-sad-day-for-rust) than I could.  In his conclusion he observes: \"The Rust community says they’re nice but they will harass you if you use unsafe wrong.\"  Can we do better?\n\nI don't know.  What do we do about this?  What *can* we do about this, what should we do about this?  This is why we can't have nice things, but I really want some nice things.  However you feel about soundness, this is a quality piece of software and a big loss for the Rust community and ecosystem.\n\nI'm not mad, I'm just disappointed.  Like the author says in his post-mortem:\n\n> It was fun trip but now is time to move on. Life should be fun.\n\n*Photo by James Pond on Unsplash*",
    "title": "That About Wraps It Up For Actix-Web"
  },
  {
    "cover_image": "https://res.cloudinary.com/practicaldev/image/fetch/s--zHoeDo9X--/c_imagga_scale,f_auto,fl_progressive,h_420,q_auto,w_1000/https://thepracticaldev.s3.amazonaws.com/i/exg3alw4ixqwsrmp03xn.png",
    "date": "2020-01-23T13:59:01.544Z",
    "description": "",
    "tags": "watercooler, productivity",
    "markdown": "How much would it slow you down if you were required to get work done on a clean install of your OS, assuming you have your compilers/interpreters available, using a plain, unconfigured text editor and an uncustomized shell?  Would your first step *have* to be setting things up to your preferences or could you sit down accomplish a moderately complex task in a reasonable time without it?\n\nNo more squiggly lines...\n\n*[cover image](https://en.wikipedia.org/wiki/File:Windows_Notepad.png) of Windows Notepad [used with permission](https://www.microsoft.com/en-us/legal/intellectualproperty/Permissions/default.aspx) from Microsoft*",
    "title": "How dependent are you on your development environment configuration?"
  },
  {
    "cover_image": "https://res.cloudinary.com/practicaldev/image/fetch/s--UE24ZL6H--/c_imagga_scale,f_auto,fl_progressive,h_420,q_auto,w_1000/https://thepracticaldev.s3.amazonaws.com/i/r405j8k2c1z9pm0lmrl7.jpg",
    "date": "2020-01-24T12:40:52.028Z",
    "description": "",
    "tags": "beginners, cpp, devjournal, todayilearned",
    "markdown": "I sat down yesterday with [@codemouse92](https://dev.to/codemouse92/) via [Visual Studio Live Share](https://marketplace.visualstudio.com/items?itemName=MS-vsliveshare.vsliveshare) for [VS Code](https://code.visualstudio.com/) -- which is an *awesome* tool - to do a mostly straightforward re-arrangement of some C++.  Unexpectedly, we ran into something, well...unexpected.  To DEV!\n\n## The Concept\n\nIn C++, you can write a template:\n\n```cpp\ntemplate <typename T>\nT myIdentityFunction(T val)\n{\n   return val;\n}\n```\n\nThis nearly useless function just returns whatever is passed in, no matter the type.  You use it with a concrete type, like this:\n\n```cpp\n#include <iostream>\n\nint main()\n{\n    int someInt = 5;\n    int aCopyOfTheSameInt = myIdentityFunction(someInt);\n    std::cout << aCopyOfTheSameInt << \"\\n\";\n}\n```\n\nThis will output 5, as expected:\n\n```cpp\n$ clang++ test.cpp -o test\n$ ./test \n5\n```\n\nWhen it gets used, the compiler will generate the specialized version and insert that in your binary:\n\n```cpp\nint myIdentityFunction(int val)\n{\n    return val;\n}\n```\n\nAs I just learned today, you can [specialize](https://en.cppreference.com/w/cpp/language/template_specialization) what types end up in your templates to retain control over what the compiler will guess:\n\n```cpp\ntemplate int myIdentityFunction(int val);\n```\n\nThis is a silly example, but this ability lets you do things like partially specialize a `template<typename T, typename U>` to `template<int, typename U>`, and also makes implicit behaviour explicit, giving you back the keys from the compiler.  You just define one for each type you need.\n\n## The Context\n\nI don't actually know if the fact we're doing this in headers is relevant or not, but I'm including it for completeness in case somebody *does* know and wants to elaborate on this.  I think the issue is just \"in a class\" vs. \"not in a class\".\n\nWe were refactoring a library to be [header-only](https://en.wikipedia.org/wiki/Header-only).  In a standard library, you have your declarations in `someModule.hpp`:\n\n```cpp\nclass idksomefunctions\n{\npublic:\n    idksomefunctions() = delete; // specify there should be no constructor\n    \n    template <typename T>\n    static T myIdentityFunction(T);  // Template declaration\n};\n```\n\nAnd then a corresponding `someModule.cpp` with the actual implementations and specializations:\n\n```cpp\n#include \"someModule.hpp\"\n\ntemplate <typename T>\nT idksomefunctions::myIdentityFunction(T val)\n{\n    return val;\n}\n\n// Any specializations live here\ntemplate int idksomefunctions::myIdentityFunction(int val);\n```\n\nTo refactor this into a header, you just combine them both in `someModule.hpp`:\n\n```cpp\nclass idksomefunctions\n{\npublic:\n    idksomefunctions() = delete; // specify there should be no constructor\n    \n    template <typename T>\n    static T myIdentityFunction(T val)\n    {\n        return val;\n    }\n\n    template static int myIdentityFunction(int val);  // right??\n};\n```\n\nNot quite:\n\n```\n$ clang++ test.cpp -o test\nIn file included from test.cpp:5:\n./test.hpp:15:14: error: expected '<' after 'template'\n    template static int myIdentityFunction(int val);  // right??\n             ^\n1 error generated.\n```\n\nOkay, try the other syntax:\n\n```diff\n-  template static int myIdentityFunction(int val);\n+  template <> static int myIdentityFunction(int val);\n```\n\nGood to go!\n\n## The Switcheroo\n\nNow, `idksomefunctions` doesn't really need to be a class - it's just, I don't know, some functions.  This could just be a [namespace](https://en.cppreference.com/w/cpp/language/namespace).  No more constructor thing, no more [`static`](https://en.cppreference.com/w/cpp/language/static) or `public` (or `storage class` errors), just some good ol' functions:\n\n```diff\n- class idksomefunctions\n+ namespace idksomefunctions\n  {\n-  public:\n-     idksomefunctions() = delete; // specify there should be no constructor\n\n      template <typename T>\n-     static int myIdentityFunction(T val)\n+     T myIdentityFunction(T val)\n      {\n          return val;\n      }\n\n      template <>\n-     static int myIdentityFunction(int val);\n+     int myIdentityFunction(int val);\n  }\n```\n\nGreat!  But wait:\n\n```\n$ clang++ test.cpp -o test\n/bin/x86_64-unknown-linux-gnu-ld: /tmp/test-d48bb0.o: in function `main':\ntest.cpp:(.text+0x13): undefined reference to `int idksomefunctions::myIdentityFunction<int>(int)'\nclang-9: error: linker command failed with exit code 1 (use -v to see invocation)\n```\n\nThat's no good.  There's one more change to make:\n\n```diff\n      template <typename T>\n      int myIdentityFunction(int val)\n      {\n          return val;\n      }\n\n-     template <>\n+     template\n      int myIdentityFunction(int val);\n```\n\nGotta take out the `<>` thingy, back to where we started!  Now it'll compile:\n\n```cpp\n\n#include <iostream>\n\nnamespace idksomefunctions\n{\n    template <typename T>\n    int myIdentityFunction(T val)\n    {\n        return val;\n    }\n\n    template int myIdentityFunction(int val);\n};\n\nint main()\n{\n    int someInt = 5;\n    int aCopyOfTheSameInt = idksomefunctions::myIdentityFunction(someInt);\n    std::cout << aCopyOfTheSameInt << \"\\n\";\n}\n```\n\n## The Recap\n\nInside a class, you specialize via:\n\n```cpp\ntemplate<> static int myIdentityFunction(int val);\n```\n\nOutside of a class, though, you omit the thingy:\n\n```cpp\ntemplate int myIdentityFunction(int val);\n```\n\n## The Question\n\nWhat am I saying when I say `template <>` versus `template` here?\n\n*Photo by Ricardo Gomez Angel on Unsplash*",
    "title": "C++ Template Specialization - Syntax Note"
  }
]
